<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Run - BigDL Project</title>
    <link href="../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/highlight.css">
    <link href="../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../js/jquery-3.2.1.min.js"></script>
    <script src="../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Use an Interactive Shell (W/ pip install)", url: "#use-an-interactive-shell-w-pip-install", children: [
          ]},
          {title: "User an Interactive Shell (W/O pip install)", url: "#user-an-interactive-shell-wo-pip-install", children: [
          ]},
          {title: "Run Python Program in Command Line (W/O pip install)", url: "#run-python-program-in-command-line-wo-pip-install", children: [
          ]},
          {title: "Use Jupyter Notebook (W/ pip install)", url: "#use-jupyter-notebook-w-pip-install", children: [
          ]},
          {title: "Use Jupyter Notebook (W/O pip install)", url: "#use-jupyter-notebook-wo-pip-install", children: [
          ]},
          {title: "Use Python on YARN cluster", url: "#use-python-on-yarn-cluster", children: [
          ]},
        ];

    </script>
    <script src="../../js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    

    <h2 id="use-an-interactive-shell-w-pip-install"><strong>Use an Interactive Shell (W/ pip install)</strong></h2>
<ul>
<li>type <code>python</code> in commandline to start a REPL</li>
<li>initialize bigdl engine as below, and you'll be able to play with BigDL</li>
</ul>
<pre><code class="python"> &gt;&gt;&gt; from bigdl.util.common import *
 &gt;&gt;&gt; init_engine()
 &gt;&gt;&gt; import bigdl.version
 &gt;&gt;&gt; bigdl.version.__version__
 '0.1.1rc0'
 &gt;&gt;&gt; from bigdl.nn.layer import *
 &gt;&gt;&gt; linear = Linear(2, 3)
 creating: createLinear
 &gt;&gt;&gt; ... 
</code></pre>

<hr />
<h2 id="user-an-interactive-shell-wo-pip-install"><strong>User an Interactive Shell (W/O pip install)</strong></h2>
<p>1.Set some environmental variables. Replace SPARK_HOME, BigDL_HOME and BigDL_version, and etc. according to your actual configurations. </p>
<pre><code class="bash">BigDL_HOME=...
export BigDL_version=bigdl-0.2.0-SNAPSHOT
SPARK_HOME=...
spark.master=local[2]

export PYTHONPATH=SPARK_HOME/python/lib/pyspark.zip:SPARK_HOME/python/lib/py4j-0.9-src.zip:BigDL_HOME/spark/dl/src/main/resources/spark-bigdl.conf:${BigDL_HOME}/dist/lib/${BigDL_version}-python-api.zip
SPARK_CLASSPATH=BigDL_HOME/spark/dl/target/${BigDL_version}-jar-with-dependencies.jar
</code></pre>

<p>2.source bigdl.sh and set some environmental variables for BigDL. </p>
<pre><code class="bash">source ${BigDL_HOME}/dist/bin/bigdl.sh  
</code></pre>

<p>3.start python shell</p>
<p>4.Initialize the engine as below and you'll be able to play with BigDL. </p>
<pre><code class="python">  &gt;&gt;&gt; from bigdl.util.common import *
  &gt;&gt;&gt; init_engine()
  &gt;&gt;&gt; import bigdl.version
  &gt;&gt;&gt; from bigdl.nn.layer import *
  &gt;&gt;&gt; linear = Linear(2, 3)
  creating: createLinear
  &gt;&gt;&gt; ...
</code></pre>

<hr />
<h2 id="run-python-program-in-command-line-wo-pip-install"><strong>Run Python Program in Command Line (W/O pip install)</strong></h2>
<p>A BigDL Python program runs as a standard PySPark program, which requires all Python dependency (e.g., NumPy) used by the program be installed on each node in the Spark cluster. You can try run the BigDL <a href="https://github.com/intel-analytics/BigDL/tree/master/pyspark/dl/models/lenet">lenet Python example</a> using <a href="http://spark.apache.org/docs/latest/submitting-applications.html">spark-submit</a> as follows:</p>
<pre><code class="bash">PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-python-api.zip
BigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-jar-with-dependencies.jar
PYTHONPATH=${PYTHON_API_ZIP_PATH}:$PYTHONPATH

${SPARK_HOME}/bin/spark-submit \
    --master ${MASTER} \
    --driver-memory 10g  \
    --driver-cores 4  \
    --executor-memory 20g \
    --total-executor-cores ${TOTAL_CORES}\
    --executor-cores 10 ${EXECUTOR_CORES} \
    --py-files ${PYTHON_API_PATH},${BigDL_HOME}/pyspark/dl/models/lenet/lenet5.py  \
    --properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \
    --jars ${BigDL_JAR_PATH} \
    --conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \
    --conf spark.executor.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \
    ${BigDL_HOME}/pyspark/dl/models/lenet/lenet5.py
</code></pre>

<p>If you are writing your own program, remember to create Spark context and initialize engine before calling any BigDL API's, as below.</p>
<pre><code class="python">from bigdl.util.common import *
# Python code example
conf=create_spark_conf()
sc = SparkContext(conf)
init_engine()
</code></pre>

<hr />
<h2 id="use-jupyter-notebook-w-pip-install">Use Jupyter Notebook (W/ pip install)</h2>
<ul>
<li>Start jupyter notebook as you normally did, e.g.</li>
</ul>
<pre><code class="bash">jupyter notebook --notebook-dir=./ --ip=* --no-browser
</code></pre>

<ul>
<li>Create SparkContext and initialize BigDL engine as below</li>
</ul>
<pre><code class="python">from bigdl.util.common import *
init_engine()

from bigdl.nn.layer import *
linear = Linear(2, 3)
...
</code></pre>

<p>Sometimes you may need to use SparkContext's <code>parallelize</code> method to convert local data into an RDD. You can get SparkContext in below way.</p>
<pre><code>from bigdl.util.common import *
sc = get_spark_context()
# sc.parallelize(...)
</code></pre>

<hr />
<h2 id="use-jupyter-notebook-wo-pip-install">Use Jupyter Notebook (W/O pip install)</h2>
<p>With the full Python API support in BigDL, users can now use BigDL together with powerful notebooks (such as Jupyter notebook) in a distributed fashion across the cluster, combining Python libraries, Spark SQL / dataframes and MLlib, deep learning models in BigDL, as well as interactive visualization tools.</p>
<p>First, install all the necessary libraries on the local node where you will run Jupyter, e.g., </p>
<pre><code class="bash">sudo apt install python
sudo apt install python-pip
sudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud
</code></pre>

<p>Then, you can launch the Jupyter notebook as follows:</p>
<pre><code class="bash">PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-0.1.0-python-api.zip
BigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-0.1.0-jar-with-dependencies.jar

export PYTHONPATH=${PYTHON_API_PATH}:$PYTHONPATH
export PYSPARK_DRIVER_PYTHON=jupyter
export PYSPARK_DRIVER_PYTHON_OPTS=&quot;notebook --notebook-dir=./ --ip=* --no-browser&quot;

${SPARK_HOME}/bin/pyspark \
  --master ${MASTER} \
  --properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \
  --driver-memory 10g  \
  --driver-cores 4  \
  --executor-memory 20g \
  --total-executor-cores {TOTAL_CORES} \
  --executor-cores {EXECUTOR_CORES} \
  --py-files ${PYTHON_API_PATH} \
  --jars ${BigDL_JAR_PATH} \
  --conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \
  --conf spark.executor.extraClassPath=bigdl-0.1.0-jar-with-dependencies.jar
</code></pre>

<p>After successfully launching Jupyter, you will be able to navigate to the notebook dashboard using your browser. You can find the exact URL in the console output when you started Jupyter; by default, the dashboard URL is http://your_node:8888/</p>
<p>Now you can create a blank notebook and start some coding. </p>
<p>Remember to initialize BigDL engine before calling BigDL API's, as shown below.</p>
<pre><code class="python">from bigdl.util.common import *
init_engine()

from bigdl.nn.layer import *
linear = Linear(2, 3)
...
</code></pre>

<p>Sometimes you may need to use SparkContext's <code>parallelize</code> method to convert local    data into an RDD. You can get SparkContext in below way.</p>
<pre><code class="python">from bigdl.util.common import *
sc = get_spark_context()
# sc.parallelize(...)
</code></pre>

<hr />
<h2 id="use-python-on-yarn-cluster"><strong>Use Python on YARN cluster</strong></h2>
<p>You can run BigDL Python programs on YARN clusters without changes to the cluster (e.g., no need to pre-install the      Python dependency). You  can first package all the required Python dependency into a virtual environment on the local    node (where you will run the spark-submit command), and then directly use spark-submit to run the BigDL Python program   on the YARN cluster (using that virtual environment). Please refer to this <a href="https://github.com/intel-analytics/BigDL/pull/706">patch</a> for more details.</p>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>