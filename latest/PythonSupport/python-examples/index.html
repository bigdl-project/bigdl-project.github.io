<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Examples - BigDL Project</title>
    <link href="../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/highlight.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../js/jquery-3.2.1.min.js"></script>
    <script src="../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Text Classification using BigDL Python API", url: "#text-classification-using-bigdl-python-api", children: [
          ]},
        ];

    </script>
    <script src="../../js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    

    <h2 id="text-classification-using-bigdl-python-api"><strong>Text Classification using BigDL Python API</strong></h2>
<p>This tutorial describes the <a href="https://github.com/intel-analytics/BigDL/tree/master/pyspark/dl/models/textclassifier">textclassifier</a> example written using BigDL Python API, which builds a text classifier using a CNN (convolutional neural network) or LSTM or GRU model (as specified by the user). (It was first described by <a href="https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html">this Keras tutorial</a>)</p>
<p>The example first creates the <code>SparkContext</code> using the SparkConf<code>return by the</code>create_spark_conf()` method, and then initialize the engine:</p>
<pre><code class="python">  sc = SparkContext(appName=&quot;text_classifier&quot;,
                    conf=create_spark_conf())
  init_engine()
</code></pre>

<p>It then loads the <a href="http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.html">20 Newsgroup dataset</a> into RDD, and transforms the input data into an RDD of <code>Sample</code>. (Each <code>Sample</code> in essence contains a tuple of two NumPy ndarray representing the feature and label).</p>
<pre><code class="python">  texts = news20.get_news20()
  data_rdd = sc.parallelize(texts, 2)
  ...
  sample_rdd = vector_rdd.map(
      lambda (vectors, label): to_sample(vectors, label, embedding_dim))
  train_rdd, val_rdd = sample_rdd.randomSplit(
      [training_split, 1-training_split])   
</code></pre>

<p>After that, the example creates the neural network model as follows:</p>
<pre><code class="python">def build_model(class_num):
    model = Sequential()

    if model_type.lower() == &quot;cnn&quot;:
        model.add(Reshape([embedding_dim, 1, sequence_len]))
        model.add(SpatialConvolution(embedding_dim, 128, 5, 1))
        model.add(ReLU())
        model.add(SpatialMaxPooling(5, 1, 5, 1))
        model.add(SpatialConvolution(128, 128, 5, 1))
        model.add(ReLU())
        model.add(SpatialMaxPooling(5, 1, 5, 1))
        model.add(Reshape([128]))
    elif model_type.lower() == &quot;lstm&quot;:
        model.add(Recurrent()
                  .add(LSTM(embedding_dim, 128)))
        model.add(Select(2, -1))
    elif model_type.lower() == &quot;gru&quot;:
        model.add(Recurrent()
                  .add(GRU(embedding_dim, 128)))
        model.add(Select(2, -1))
    else:
        raise ValueError('model can only be cnn, lstm, or gru')

    model.add(Linear(128, 100))
    model.add(Linear(100, class_num))
    model.add(LogSoftMax())
    return model
</code></pre>

<p>Finally the example creates the <code>Optimizer</code> (which accepts both the model and the training Sample RDD) and trains the model by calling <code>Optimizer.optimize()</code>:</p>
<pre><code class="python">optimizer = Optimizer(
    model=build_model(news20.CLASS_NUM),
    training_rdd=train_rdd,
    criterion=ClassNLLCriterion(),
    end_trigger=MaxEpoch(max_epoch),
    batch_size=batch_size,
    optim_method=&quot;Adagrad&quot;,
    state=state)
...
train_model = optimizer.optimize()
</code></pre>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>