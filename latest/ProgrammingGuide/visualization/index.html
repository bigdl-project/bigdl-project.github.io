<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Visualization - BigDL Project</title>
    <link href="../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../css/highlight.css">
    <link href="../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../js/jquery-3.2.1.min.js"></script>
    <script src="../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Generating summary info in BigDL", url: "#generating-summary-info-in-bigdl", children: [
          ]},
          {title: "Retrieving summary info as readable format", url: "#retrieving-summary-info-as-readable-format", children: [
          ]},
          {title: "Visualizing training with TensorBoard", url: "#visualizing-training-with-tensorboard", children: [
          ]},
          {title: "Visualizing training with Jupyter notebook", url: "#visualizing-training-with-jupyter-notebook", children: [
          ]},
        ];

    </script>
    <script src="../../js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    

    <h2 id="generating-summary-info-in-bigdl"><strong>Generating summary info in BigDL</strong></h2>
<p>To enable visualization support, you need first properly configure the <code>Optimizer</code> to collect statistics summary in different stages of training (i.e. training (<code>TrainSummary</code>) and validation (<code>ValidationSummary</code>),respectively). It should be done before the training starts (calling <code>Optimizer.optimize()</code>). See examples below: </p>
<p><em><strong>Example: Generating summary info in Scala</strong></em></p>
<pre><code class="scala">val optimizer = Optimizer(...)
...
val logdir = &quot;mylogdir&quot;
val appName = &quot;myapp&quot;
val trainSummary = TrainSummary(logdir, appName)
val validationSummary = ValidationSummary(logdir, appName)
optimizer.setTrainSummary(trainSummary)
optimizer.setValidationSummary(validationSummary)
...
val trained_model = optimizer.optimize()
</code></pre>

<p><em><strong>Example: Configure summary generation in Python</strong></em></p>
<pre><code class="python">optimizer = Optimizer(...)
...
log_dir = 'mylogdir'
app_name = 'myapp'
train_summary = TrainSummary(log_dir=log_dir, app_name=app_name)
val_summary = ValidationSummary(log_dir=log_dir, app_name=app_name)
optimizer.set_train_summary(train_summary)
optimizer.set_val_summary(val_summary)
...
trainedModel = optimizer.optimize()
</code></pre>

<p>After you start to run your spark job, the train and validation summary will be saved to <code>mylogdir/myapp/train</code> and <code>mylogdir/myapp/validation</code> respectively (Note: you may want to use different <code>appName</code> for different job runs to avoid possible conflicts.)</p>
<h2 id="retrieving-summary-info-as-readable-format">Retrieving summary info as readable format</h2>
<p>You can use provided API <code>readScalar</code>(Scala) and <code>read_scalar</code>(Python) to retrieve the summaries into readable format, and export them to other tools for further analysis or visualization.</p>
<p><em><strong>Example: Reading summary info in Scala</strong></em></p>
<pre><code class="scala">val trainLoss = trainSummary.readScalar(&quot;Loss&quot;)
val validationLoss = validationSummary.readScalar(&quot;Loss&quot;)
...
</code></pre>

<p><em><strong>Example: Reading summary info in Python</strong></em></p>
<pre><code class="python">loss = np.array(train_summary.read_scalar('Loss'))
valloss = np.array(val_summary.read_scalar('Loss'))
...
</code></pre>

<h2 id="visualizing-training-with-tensorboard"><strong>Visualizing training with TensorBoard</strong></h2>
<p>With the summary info generated, we can then use <a href="https://pypi.python.org/pypi/tensorboard">TensorBoard</a> to visualize the behaviors of the BigDL program.  </p>
<ul>
<li><strong>Installing TensorBoard</strong></li>
</ul>
<p>Prerequisites:</p>
<ol>
<li>Python verison: 2.7, 3.4, 3.5, or 3.6</li>
<li>Pip version &gt;= 9.0.1</li>
</ol>
<p>To install TensorBoard using Python 2, you may run the command:</p>
<pre><code class="bash">pip install tensorboard==1.0.0a4
</code></pre>

<p>To install TensorBoard using Python 3, you may run the command:</p>
<pre><code class="bash">pip3 install tensorboard==1.0.0a4
</code></pre>

<p>Please refer to <a href="https://github.com/intel-analytics/BigDL/tree/master/spark/dl/src/main/scala/com/intel/analytics/bigdl/visualization#known-issues">this page</a> for possible issues when installing TensorBoard.</p>
<ul>
<li><strong>Launching TensorBoard</strong></li>
</ul>
<p>You can launch TensorBoard using the command below:</p>
<pre><code class="bash">tensorboard --logdir=/tmp/bigdl_summaries
</code></pre>

<p>After that, navigate to the TensorBoard dashboard using a browser. You can find the URL in the console output after TensorBoard is successfully launched; by default the URL is http://your_node:6006</p>
<ul>
<li><strong>Visualizations in TensorBoard</strong></li>
</ul>
<p>Within the TensorBoard dashboard, you will be able to read the visualizations of each run, including the “Loss” and “Throughput” curves under the SCALARS tab (as illustrated below):
<img alt="Scalar" src="../../Image/tensorboard-scalar.png" /></p>
<p>And “weights”, “bias”, “gradientWeights” and “gradientBias” under the DISTRIBUTIONS and HISTOGRAMS tabs (as illustrated below):
<img alt="histogram1" src="../../Image/tensorboard-histo1.png" />
<img alt="histogram2" src="../../Image/tensorboard-histo2.png" /></p>
<h2 id="visualizing-training-with-jupyter-notebook">Visualizing training with Jupyter notebook</h2>
<p>If you're using Jupyter notebook, you can also draw the training curves using popular plotting tools (e.g. matplotlib) and show the plots inline. </p>
<p>First, retrieve the summaries as instructed in <a href="#retrieving-summary-info-as-readable-format">Retrieve Summary</a>. The retrived summary is a list of tuples. Each tuple is a recorded event in format (iteration count, recorded value, timestamp). You can convert it to numpy array or dataframe to plot it. See example below:  </p>
<p><em><strong>Example: Plot the train/validation loss in Jupyter</strong></em></p>
<pre><code class="python">#retrieve train and validation summary object and read the loss data into ndarray's. 
loss = np.array(train_summary.read_scalar(&quot;Loss&quot;))
val_loss  = np.array(val_summary.read_scalar(&quot;Loss&quot;))

#plot the train and validation curves
# each event data is a tuple in form of (iteration_count, value, timestamp)
plt.plot(loss[:,0],loss[:,1],label='train loss')
plt.plot(val_loss[:,0],val_loss[:,1],label='val loss',color='green')
plt.scatter(val_loss[:,0],val_loss[:,1],color='green')
plt.legend();
</code></pre>

<p><img alt="jupyter" src="../../Image/jupyter.png" /></p>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>