
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>bigdl.nn.criterion &#8212; BigDL  documentation</title>
    <link rel="stylesheet" href="../../../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">BigDL  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for bigdl.nn.criterion</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Copyright 2016 The BigDL Authors.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>


<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">from</span> <span class="nn">bigdl.util.common</span> <span class="k">import</span> <span class="n">JavaValue</span>
<span class="kn">from</span> <span class="nn">bigdl.util.common</span> <span class="k">import</span> <span class="n">callBigDlFunc</span>
<span class="kn">from</span> <span class="nn">bigdl.util.common</span> <span class="k">import</span> <span class="n">JTensor</span>
<span class="kn">from</span> <span class="nn">bigdl.nn.layer</span> <span class="k">import</span> <span class="n">Layer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span> <span class="o">&gt;=</span> <span class="s1">&#39;3&#39;</span><span class="p">:</span>
    <span class="n">long</span> <span class="o">=</span> <span class="nb">int</span>
    <span class="n">unicode</span> <span class="o">=</span> <span class="nb">str</span>


<div class="viewcode-block" id="Criterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.Criterion">[docs]</a><span class="k">class</span> <span class="nc">Criterion</span><span class="p">(</span><span class="n">JavaValue</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Criterion is helpful to train a neural network.</span>
<span class="sd">    Given an input and a target, they compute a gradient according to a given loss function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">jvalue</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">jvalue</span> <span class="k">if</span> <span class="n">jvalue</span> <span class="k">else</span> <span class="n">callBigDlFunc</span><span class="p">(</span>
            <span class="n">bigdl_type</span><span class="p">,</span> <span class="n">JavaValue</span><span class="o">.</span><span class="n">jvm_class_constructor</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span> <span class="o">=</span> <span class="n">bigdl_type</span>

    <span class="k">def</span> <span class="nf">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">toString</span><span class="p">()</span>

<div class="viewcode-block" id="Criterion.forward"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.Criterion.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        NB: It&#39;s for debug only, please use optimizer.optimize() in production.</span>
<span class="sd">        Takes an input object, and computes the corresponding loss of the criterion,</span>
<span class="sd">        compared with `target`</span>

<span class="sd">        :param input: ndarray or list of ndarray</span>
<span class="sd">        :param target: ndarray or list of ndarray</span>
<span class="sd">        :return: value of loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">jinput</span><span class="p">,</span> <span class="n">input_is_table</span> <span class="o">=</span> <span class="n">Layer</span><span class="o">.</span><span class="n">check_input</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">jtarget</span><span class="p">,</span> <span class="n">target_is_table</span> <span class="o">=</span> <span class="n">Layer</span><span class="o">.</span><span class="n">check_input</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">callBigDlFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span><span class="p">,</span>
                               <span class="s2">&quot;criterionForward&quot;</span><span class="p">,</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                               <span class="n">jinput</span><span class="p">,</span>
                               <span class="n">input_is_table</span><span class="p">,</span>
                               <span class="n">jtarget</span><span class="p">,</span>
                               <span class="n">target_is_table</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span></div>

<div class="viewcode-block" id="Criterion.backward"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.Criterion.backward">[docs]</a>    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        NB: It&#39;s for debug only, please use optimizer.optimize() in production.</span>
<span class="sd">        Performs a back-propagation step through the criterion, with respect to the given input.</span>

<span class="sd">        :param input: ndarray or list of ndarray</span>
<span class="sd">        :param target: ndarray or list of ndarray</span>
<span class="sd">        :return: ndarray</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">jinput</span><span class="p">,</span> <span class="n">input_is_table</span> <span class="o">=</span> <span class="n">Layer</span><span class="o">.</span><span class="n">check_input</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
        <span class="n">jtarget</span><span class="p">,</span> <span class="n">target_is_table</span> <span class="o">=</span> <span class="n">Layer</span><span class="o">.</span><span class="n">check_input</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">callBigDlFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span><span class="p">,</span>
                               <span class="s2">&quot;criterionBackward&quot;</span><span class="p">,</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span>
                               <span class="n">jinput</span><span class="p">,</span>
                               <span class="n">input_is_table</span><span class="p">,</span>
                               <span class="n">jtarget</span><span class="p">,</span>
                               <span class="n">target_is_table</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Layer</span><span class="o">.</span><span class="n">convert_output</span><span class="p">(</span><span class="n">output</span><span class="p">)</span></div>

<div class="viewcode-block" id="Criterion.of"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.Criterion.of">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">of</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">jcriterion</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a python Criterion by a java criterion object</span>

<span class="sd">        :param jcriterion: A java criterion object which created by Py4j</span>
<span class="sd">        :return: a criterion.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">Criterion</span><span class="p">(</span><span class="n">bigdl_type</span><span class="p">,</span> <span class="n">jcriterion</span><span class="p">)</span>
        <span class="n">criterion</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">jcriterion</span>
        <span class="n">criterion</span><span class="o">.</span><span class="n">bigdl_type</span> <span class="o">=</span> <span class="n">bigdl_type</span>
        <span class="k">return</span> <span class="n">criterion</span></div></div>


<div class="viewcode-block" id="ClassNLLCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.ClassNLLCriterion">[docs]</a><span class="k">class</span> <span class="nc">ClassNLLCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    The negative log likelihood criterion. It is useful to train a classification problem with n</span>
<span class="sd">    classes. If provided, the optional argument weights should be a 1D Tensor assigning weight to</span>
<span class="sd">    each of the classes. This is particularly useful when you have an unbalanced training set.</span>

<span class="sd">    The input given through a forward() is expected to contain log-probabilities/probabilities of</span>
<span class="sd">    each class: input has to be a 1D Tensor of size n. Obtaining log-probabilities/probabilities</span>
<span class="sd">    in a neural network is easily achieved by adding a LogSoftMax/SoftMax layer in the last layer</span>
<span class="sd">    of your neural network. You may use CrossEntropyCriterion instead, if you prefer not to add an</span>
<span class="sd">    extra layer to your network. This criterion expects a class index (1 to the number of class) as</span>
<span class="sd">    target when calling forward(input, target) and backward(input, target).</span>

<span class="sd">    In the log-probabilities case,</span>
<span class="sd">    The loss can be described as:</span>
<span class="sd">        loss(x, class) = -x[class]</span>
<span class="sd">    or in the case of the weights argument it is specified as follows:</span>
<span class="sd">        loss(x, class) = -weights[class] * x[class]</span>
<span class="sd">    Due to the behaviour of the backend code, it is necessary to set sizeAverage to false when</span>
<span class="sd">    calculating losses in non-batch mode.</span>

<span class="sd">    Note that if the target is `-1`, the training process will skip this sample.</span>
<span class="sd">    In other will, the forward process will return zero output and the backward process</span>
<span class="sd">    will also return zero `gradInput`.</span>

<span class="sd">    By default, the losses are averaged over observations for each minibatch. However, if the field</span>
<span class="sd">    sizeAverage is set to false, the losses are instead summed for each minibatch.</span>

<span class="sd">    In particular, when weights=None, size_average=True and logProbAsInput=False, this is same as</span>
<span class="sd">    `sparse_categorical_crossentropy` loss in keras.</span>


<span class="sd">    :param weights: weights of each class</span>
<span class="sd">    :param size_average: whether to average or not</span>
<span class="sd">    :param logProbAsInput: indicating whether to accept log-probabilities or probabilities as input.</span>


<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; weights = np.random.uniform(0, 1, (2,)).astype(&quot;float32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; classNLLCriterion = ClassNLLCriterion(weights, True, True)</span>
<span class="sd">    creating: createClassNLLCriterion</span>
<span class="sd">    &gt;&gt;&gt; classNLLCriterion = ClassNLLCriterion()</span>
<span class="sd">    creating: createClassNLLCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">logProbAsInput</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassNLLCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                <span class="n">JTensor</span><span class="o">.</span><span class="n">from_ndarray</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
                                                <span class="n">size_average</span><span class="p">,</span> <span class="n">logProbAsInput</span><span class="p">)</span></div>


<div class="viewcode-block" id="MSECriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MSECriterion">[docs]</a><span class="k">class</span> <span class="nc">MSECriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a criterion that measures the mean squared error between n elements</span>
<span class="sd">    in the input x and output y:</span>
<span class="sd">```</span>
<span class="sd">    loss(x, y) = 1/n \sum |x_i - y_i|^2</span>
<span class="sd">```</span>


<span class="sd">    If x and y are d-dimensional Tensors with a total of n elements,</span>
<span class="sd">    the sum operation still operates over all the elements, and divides by n.</span>
<span class="sd">    The two Tensors must have the same number of elements (but their sizes might be different).</span>
<span class="sd">    The division by n can be avoided if one sets the internal variable sizeAverage to false.</span>
<span class="sd">    By default, the losses are averaged over observations for each minibatch. However,</span>
<span class="sd">     if the field sizeAverage is set to false, the losses are instead summed.</span>


<span class="sd">    &gt;&gt;&gt; mSECriterion = MSECriterion()</span>
<span class="sd">    creating: createMSECriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MSECriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span></div>


<div class="viewcode-block" id="AbsCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.AbsCriterion">[docs]</a><span class="k">class</span> <span class="nc">AbsCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    measures the mean absolute value of the element-wise difference between input</span>


<span class="sd">    &gt;&gt;&gt; absCriterion = AbsCriterion(True)</span>
<span class="sd">    creating: createAbsCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AbsCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                           <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="ClassSimplexCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.ClassSimplexCriterion">[docs]</a><span class="k">class</span> <span class="nc">ClassSimplexCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    ClassSimplexCriterion implements a criterion for classification.</span>
<span class="sd">    It learns an embedding per class, where each class&#39; embedding is a</span>
<span class="sd">    point on an (N-1)-dimensional simplex, where N is the number of classes.</span>

<span class="sd">    :param nClasses: the number of classes.</span>


<span class="sd">    &gt;&gt;&gt; classSimplexCriterion = ClassSimplexCriterion(2)</span>
<span class="sd">    creating: createClassSimplexCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">n_classes</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ClassSimplexCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                    <span class="n">n_classes</span><span class="p">)</span></div>


<div class="viewcode-block" id="CosineDistanceCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.CosineDistanceCriterion">[docs]</a><span class="k">class</span> <span class="nc">CosineDistanceCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a criterion that measures the loss given an input and target,</span>
<span class="sd">    Loss = 1 - cos(x, y)</span>


<span class="sd">    &gt;&gt;&gt; cosineDistanceCriterion = CosineDistanceCriterion(True)</span>
<span class="sd">    creating: createCosineDistanceCriterion</span>
<span class="sd">    &gt;&gt;&gt; cosineDistanceCriterion.forward(np.array([1.0, 2.0, 3.0, 4.0, 5.0]),</span>
<span class="sd">    ...                                   np.array([5.0, 4.0, 3.0, 2.0, 1.0]))</span>
<span class="sd">    0.07272728</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CosineDistanceCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                      <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="CosineEmbeddingCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.CosineEmbeddingCriterion">[docs]</a><span class="k">class</span> <span class="nc">CosineEmbeddingCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a criterion that measures the loss given an input x = {x1, x2},</span>
<span class="sd">    a table of two Tensors, and a Tensor label y with values 1 or -1.</span>


<span class="sd">    :param margin: a number from -1 to 1, 0 to 0.5 is suggested</span>


<span class="sd">    &gt;&gt;&gt; cosineEmbeddingCriterion = CosineEmbeddingCriterion(1e-5, True)</span>
<span class="sd">    creating: createCosineEmbeddingCriterion</span>
<span class="sd">    &gt;&gt;&gt; cosineEmbeddingCriterion.forward([np.array([1.0, 2.0, 3.0, 4.0, 5.0]),</span>
<span class="sd">    ...                                   np.array([5.0, 4.0, 3.0, 2.0, 1.0])],</span>
<span class="sd">    ...                                 [np.ones(5)])</span>
<span class="sd">    0.0</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">margin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CosineEmbeddingCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                       <span class="n">margin</span><span class="p">,</span>
                                                       <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="DistKLDivCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.DistKLDivCriterion">[docs]</a><span class="k">class</span> <span class="nc">DistKLDivCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    The Kullback-Leibler divergence criterion</span>


<span class="sd">    :param sizeAverage:</span>


<span class="sd">    &gt;&gt;&gt; distKLDivCriterion = DistKLDivCriterion(True)</span>
<span class="sd">    creating: createDistKLDivCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistKLDivCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                 <span class="n">size_average</span><span class="p">)</span></div>

<div class="viewcode-block" id="CategoricalCrossEntropy"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.CategoricalCrossEntropy">[docs]</a><span class="k">class</span> <span class="nc">CategoricalCrossEntropy</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This criterion is same with cross entropy criterion, except it takes a one-hot format target</span>
<span class="sd">    tensor</span>
<span class="sd">    &gt;&gt;&gt; cce = CategoricalCrossEntropy()</span>
<span class="sd">    creating: createCategoricalCrossEntropy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CategoricalCrossEntropy</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span></div>

<div class="viewcode-block" id="HingeEmbeddingCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.HingeEmbeddingCriterion">[docs]</a><span class="k">class</span> <span class="nc">HingeEmbeddingCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a criterion that measures the loss given an</span>
<span class="sd">    input x which is a 1-dimensional vector and a label y (1 or -1).</span>
<span class="sd">    This is usually used for measuring whether two inputs are similar</span>
<span class="sd">    or dissimilar,</span>
<span class="sd">    e.g. using the L1 pairwise distance, and is typically used for</span>
<span class="sd">    learning nonlinear embeddings or semi-supervised learning.</span>


<span class="sd">    If x and y are n-dimensional Tensors, the sum operation still operates</span>
<span class="sd">    over all the elements, and divides by n (this can be avoided if one sets</span>
<span class="sd">    the internal variable sizeAverage to false). The margin has a default</span>
<span class="sd">    value of 1, or can be set in the constructor.</span>


<span class="sd">    &gt;&gt;&gt; hingeEmbeddingCriterion = HingeEmbeddingCriterion(1e-5, True)</span>
<span class="sd">    creating: createHingeEmbeddingCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">HingeEmbeddingCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                      <span class="n">margin</span><span class="p">,</span>
                                                      <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="L1HingeEmbeddingCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.L1HingeEmbeddingCriterion">[docs]</a><span class="k">class</span> <span class="nc">L1HingeEmbeddingCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a criterion that measures the loss given an input x = {x1, x2},</span>
<span class="sd">    a table of two Tensors, and a label y (1 or -1):</span>


<span class="sd">    :param margin:</span>


<span class="sd">    &gt;&gt;&gt; l1HingeEmbeddingCriterion = L1HingeEmbeddingCriterion(1e-5)</span>
<span class="sd">    creating: createL1HingeEmbeddingCriterion</span>
<span class="sd">    &gt;&gt;&gt; l1HingeEmbeddingCriterion = L1HingeEmbeddingCriterion()</span>
<span class="sd">    creating: createL1HingeEmbeddingCriterion</span>
<span class="sd">    &gt;&gt;&gt; input1 = np.array([2.1, -2.2])</span>
<span class="sd">    &gt;&gt;&gt; input2 = np.array([-0.55, 0.298])</span>
<span class="sd">    &gt;&gt;&gt; input = [input1, input2]</span>
<span class="sd">    &gt;&gt;&gt; target = np.array([1.0])</span>
<span class="sd">    &gt;&gt;&gt; result = l1HingeEmbeddingCriterion.forward(input, target)</span>
<span class="sd">    &gt;&gt;&gt; (result == 5.148)</span>
<span class="sd">    True</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">L1HingeEmbeddingCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                        <span class="n">margin</span><span class="p">)</span></div>


<div class="viewcode-block" id="MarginCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MarginCriterion">[docs]</a><span class="k">class</span> <span class="nc">MarginCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a criterion that optimizes a two-class classification hinge loss (margin-based loss)</span>
<span class="sd">    between input x (a Tensor of dimension 1) and output y.</span>

<span class="sd">    When margin = 1, size_average = True and squared = False, this is the same as hinge loss in keras;</span>
<span class="sd">    When margin = 1, size_average = False and squared = True, this is the same as squared_hinge loss in keras.</span>

<span class="sd">    :param margin: if unspecified, is by default 1.</span>
<span class="sd">    :param size_average: size average in a mini-batch</span>
<span class="sd">    :param squared: whether to calculate the squared hinge loss</span>


<span class="sd">    &gt;&gt;&gt; marginCriterion = MarginCriterion(1e-5, True, False)</span>
<span class="sd">    creating: createMarginCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">squared</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MarginCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                              <span class="n">margin</span><span class="p">,</span>
                                              <span class="n">size_average</span><span class="p">,</span>
                                              <span class="n">squared</span><span class="p">)</span></div>


<div class="viewcode-block" id="MarginRankingCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MarginRankingCriterion">[docs]</a><span class="k">class</span> <span class="nc">MarginRankingCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a criterion that measures the loss given an input x = {x1, x2},</span>
<span class="sd">    a table of two Tensors of size 1 (they contain only scalars), and a label y (1 or -1).</span>
<span class="sd">    In batch mode, x is a table of two Tensors of size batchsize, and y is a Tensor of size</span>
<span class="sd">    batchsize containing 1 or -1 for each corresponding pair of elements in the input Tensor.</span>
<span class="sd">    If y == 1 then it assumed the first input should be ranked higher (have a larger value) than</span>
<span class="sd">    the second input, and vice-versa for y == -1.</span>


<span class="sd">    :param margin:</span>


<span class="sd">    &gt;&gt;&gt; marginRankingCriterion = MarginRankingCriterion(1e-5, True)</span>
<span class="sd">    creating: createMarginRankingCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MarginRankingCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                     <span class="n">margin</span><span class="p">,</span>
                                                     <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultiCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MultiCriterion">[docs]</a><span class="k">class</span> <span class="nc">MultiCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    a weighted sum of other criterions each applied to the same input and target</span>


<span class="sd">    &gt;&gt;&gt; multiCriterion = MultiCriterion()</span>
<span class="sd">    creating: createMultiCriterion</span>
<span class="sd">    &gt;&gt;&gt; mSECriterion = MSECriterion()</span>
<span class="sd">    creating: createMSECriterion</span>
<span class="sd">    &gt;&gt;&gt; multiCriterion = multiCriterion.add(mSECriterion)</span>
<span class="sd">    &gt;&gt;&gt; multiCriterion = multiCriterion.add(mSECriterion)</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span>

<div class="viewcode-block" id="MultiCriterion.add"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MultiCriterion.add">[docs]</a>    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">criterion</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>


<div class="viewcode-block" id="MultiLabelMarginCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MultiLabelMarginCriterion">[docs]</a><span class="k">class</span> <span class="nc">MultiLabelMarginCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a criterion that optimizes a multi-class multi-classification hinge loss (</span>
<span class="sd">    margin-based loss) between input x and output y (which is a Tensor of target class indices)</span>


<span class="sd">    :param size_average: size average in a mini-batch</span>


<span class="sd">    &gt;&gt;&gt; multiLabelMarginCriterion = MultiLabelMarginCriterion(True)</span>
<span class="sd">    creating: createMultiLabelMarginCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiLabelMarginCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                        <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="ParallelCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.ParallelCriterion">[docs]</a><span class="k">class</span> <span class="nc">ParallelCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    ParallelCriterion is a weighted sum of other criterions each applied to a different input</span>
<span class="sd">    and target. Set repeatTarget = true to share the target for criterions.</span>


<span class="sd">    Use add(criterion[, weight]) method to add criterion. Where weight is a scalar(default 1).</span>


<span class="sd">    :param repeat_target: Whether to share the target for all criterions.</span>


<span class="sd">    &gt;&gt;&gt; parallelCriterion = ParallelCriterion(True)</span>
<span class="sd">    creating: createParallelCriterion</span>
<span class="sd">    &gt;&gt;&gt; mSECriterion = MSECriterion()</span>
<span class="sd">    creating: createMSECriterion</span>
<span class="sd">    &gt;&gt;&gt; parallelCriterion = parallelCriterion.add(mSECriterion)</span>
<span class="sd">    &gt;&gt;&gt; parallelCriterion = parallelCriterion.add(mSECriterion)</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">repeat_target</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ParallelCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                <span class="n">repeat_target</span><span class="p">)</span>

<div class="viewcode-block" id="ParallelCriterion.add"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.ParallelCriterion.add">[docs]</a>    <span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">criterion</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>

<div class="viewcode-block" id="KLDCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.KLDCriterion">[docs]</a><span class="k">class</span> <span class="nc">KLDCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Computes the KL-divergence of the input normal distribution to a standard normal distribution.</span>
<span class="sd">    The input has to be a table. The first element of input is the mean of the distribution,</span>
<span class="sd">    the second element of input is the log_variance of the distribution. The input distribution is</span>
<span class="sd">    assumed to be diagonal.</span>
<span class="sd">    &gt;&gt;&gt; KLDCriterion = KLDCriterion(True)</span>
<span class="sd">    creating: createKLDCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">KLDCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span> <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="GaussianCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.GaussianCriterion">[docs]</a><span class="k">class</span> <span class="nc">GaussianCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Computes the log-likelihood of a sample x given a Gaussian distribution p.</span>
<span class="sd">    &gt;&gt;&gt; GaussianCriterion = GaussianCriterion()</span>
<span class="sd">    creating: createGaussianCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GaussianCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span></div>

<div class="viewcode-block" id="SmoothL1Criterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.SmoothL1Criterion">[docs]</a><span class="k">class</span> <span class="nc">SmoothL1Criterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a criterion that can be thought of as a smooth version of the AbsCriterion.</span>
<span class="sd">    It uses a squared term if the absolute element-wise error falls below 1.</span>
<span class="sd">    It is less sensitive to outliers than the MSECriterion and in some</span>
<span class="sd">    cases prevents exploding gradients (e.g. see &quot;Fast R-CNN&quot; paper by Ross Girshick).</span>
<span class="sd">```</span>
<span class="sd">                          | 0.5 * (x_i - y_i)^2^, if |x_i - y_i| &lt; 1</span>
<span class="sd">    loss(x, y) = 1/n \sum |</span>
<span class="sd">                          | |x_i - y_i| - 0.5,   otherwise</span>
<span class="sd">```</span>
<span class="sd">    If x and y are d-dimensional Tensors with a total of n elements,</span>
<span class="sd">    the sum operation still operates over all the elements, and divides by n.</span>
<span class="sd">    The division by n can be avoided if one sets the internal variable sizeAverage to false</span>


<span class="sd">    :param size_average: whether to average the loss</span>


<span class="sd">    &gt;&gt;&gt; smoothL1Criterion = SmoothL1Criterion(True)</span>
<span class="sd">    creating: createSmoothL1Criterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SmoothL1Criterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="SmoothL1CriterionWithWeights"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.SmoothL1CriterionWithWeights">[docs]</a><span class="k">class</span> <span class="nc">SmoothL1CriterionWithWeights</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    a smooth version of the AbsCriterion</span>
<span class="sd">    It uses a squared term if the absolute element-wise error falls below 1.</span>
<span class="sd">    It is less sensitive to outliers than the MSECriterion and in some cases</span>
<span class="sd">    prevents exploding gradients (e.g. see &quot;Fast R-CNN&quot; paper by Ross Girshick).</span>

<span class="sd">```</span>
<span class="sd">   d = (x - y) * w_in</span>
<span class="sd">   loss(x, y, w_in, w_out)</span>
<span class="sd">              | 0.5 * (sigma * d_i)^2 * w_out          if |d_i| &lt; 1 / sigma / sigma</span>
<span class="sd">   = 1/n \sum |</span>
<span class="sd">              | (|d_i| - 0.5 / sigma / sigma) * w_out   otherwise</span>
<span class="sd">```</span>

<span class="sd">    &gt;&gt;&gt; smoothL1CriterionWithWeights = SmoothL1CriterionWithWeights(1e-5, 1)</span>
<span class="sd">    creating: createSmoothL1CriterionWithWeights</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">sigma</span><span class="p">,</span>
                 <span class="n">num</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SmoothL1CriterionWithWeights</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                           <span class="n">sigma</span><span class="p">,</span>
                                                           <span class="n">num</span><span class="p">)</span></div>


<div class="viewcode-block" id="SoftmaxWithCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.SoftmaxWithCriterion">[docs]</a><span class="k">class</span> <span class="nc">SoftmaxWithCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Computes the multinomial logistic loss for a one-of-many classification task,</span>
<span class="sd">    passing real-valued predictions through a softmax to get a probability distribution over classes.</span>
<span class="sd">    It should be preferred over separate SoftmaxLayer + MultinomialLogisticLossLayer</span>
<span class="sd">    as its gradient computation is more numerically stable.</span>

<span class="sd">    :param ignoreLabel:   (optional) Specify a label value thatshould be ignored when computing the loss.</span>
<span class="sd">    :param normalizeMode: How to normalize the output loss.</span>


<span class="sd">    &gt;&gt;&gt; softmaxWithCriterion = SoftmaxWithCriterion()</span>
<span class="sd">    creating: createSoftmaxWithCriterion</span>
<span class="sd">    &gt;&gt;&gt; softmaxWithCriterion = SoftmaxWithCriterion(1, &quot;FULL&quot;)</span>
<span class="sd">    creating: createSoftmaxWithCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">ignore_label</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">normalize_mode</span><span class="o">=</span><span class="s2">&quot;VALID&quot;</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SoftmaxWithCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                   <span class="n">ignore_label</span><span class="p">,</span>
                                                   <span class="n">normalize_mode</span><span class="p">)</span></div>

<div class="viewcode-block" id="TimeDistributedMaskCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.TimeDistributedMaskCriterion">[docs]</a><span class="k">class</span> <span class="nc">TimeDistributedMaskCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This class is intended to support inputs with 3 or more dimensions.</span>
<span class="sd">    Apply Any Provided Criterion to every temporal slice of an input.</span>
<span class="sd">    In addition, it supports padding mask.</span>

<span class="sd">    eg. if the target is [ [-1, 1, 2, 3, -1], [5, 4, 3, -1, -1] ],</span>
<span class="sd">      and set the paddingValue property to -1, then the loss of -1 would not</span>
<span class="sd">      be accumulated and the loss is only divided by 6 (ont including the amount of</span>
<span class="sd">      -1, in this case, we are only interested in 1, 2, 3, 5, 4, 3)</span>

<span class="sd">    :param criterion: embedded criterion</span>
<span class="sd">    :param padding_value: padding value</span>


<span class="sd">    &gt;&gt;&gt; td = TimeDistributedMaskCriterion(ClassNLLCriterion())</span>
<span class="sd">    creating: createClassNLLCriterion</span>
<span class="sd">    creating: createTimeDistributedMaskCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TimeDistributedMaskCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">padding_value</span><span class="p">)</span></div>

<div class="viewcode-block" id="TimeDistributedCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.TimeDistributedCriterion">[docs]</a><span class="k">class</span> <span class="nc">TimeDistributedCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This class is intended to support inputs with 3 or more dimensions.</span>
<span class="sd">    Apply Any Provided Criterion to every temporal slice of an input.</span>


<span class="sd">    :param criterion: embedded criterion</span>
<span class="sd">    :param size_average: whether to divide the sequence length</span>


<span class="sd">    &gt;&gt;&gt; td = TimeDistributedCriterion(ClassNLLCriterion())</span>
<span class="sd">    creating: createClassNLLCriterion</span>
<span class="sd">    creating: createTimeDistributedCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TimeDistributedCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="CrossEntropyCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.CrossEntropyCriterion">[docs]</a><span class="k">class</span> <span class="nc">CrossEntropyCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This criterion combines LogSoftMax and ClassNLLCriterion in one single class.</span>


<span class="sd">    :param weights: A tensor assigning weight to each of the classes</span>


<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; weights = np.random.uniform(0, 1, (2,)).astype(&quot;float32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; cec = CrossEntropyCriterion(weights)</span>
<span class="sd">    creating: createCrossEntropyCriterion</span>
<span class="sd">    &gt;&gt;&gt; cec = CrossEntropyCriterion()</span>
<span class="sd">    creating: createCrossEntropyCriterion</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CrossEntropyCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                    <span class="n">JTensor</span><span class="o">.</span><span class="n">from_ndarray</span><span class="p">(</span>
                                                        <span class="n">weights</span><span class="p">),</span>
                                                    <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="BCECriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.BCECriterion">[docs]</a><span class="k">class</span> <span class="nc">BCECriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a criterion that measures the Binary Cross Entropy</span>
<span class="sd">    between the target and the output</span>


<span class="sd">    :param weights: weights for each class</span>
<span class="sd">    :param sizeAverage: whether to average the loss or not</span>


<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; weights = np.random.uniform(0, 1, (2,)).astype(&quot;float32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; bCECriterion = BCECriterion(weights)</span>
<span class="sd">    creating: createBCECriterion</span>
<span class="sd">    &gt;&gt;&gt; bCECriterion = BCECriterion()</span>
<span class="sd">    creating: createBCECriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BCECriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                           <span class="n">JTensor</span><span class="o">.</span><span class="n">from_ndarray</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
                                           <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultiLabelSoftMarginCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MultiLabelSoftMarginCriterion">[docs]</a><span class="k">class</span> <span class="nc">MultiLabelSoftMarginCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    A MultiLabel multiclass criterion based on sigmoid:</span>
<span class="sd">    the loss is:</span>
<span class="sd">```</span>
<span class="sd">     l(x,y) = - sum_i y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i])</span>
<span class="sd">```</span>
<span class="sd">    where p[i] = exp(x[i]) / (1 + exp(x[i]))</span>
<span class="sd">    and with weights:</span>
<span class="sd">```</span>
<span class="sd">     l(x,y) = - sum_i weights[i] (y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i]))</span>
<span class="sd">```</span>

<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; weights = np.random.uniform(0, 1, (2,)).astype(&quot;float32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; multiLabelSoftMarginCriterion = MultiLabelSoftMarginCriterion(weights)</span>
<span class="sd">    creating: createMultiLabelSoftMarginCriterion</span>
<span class="sd">    &gt;&gt;&gt; multiLabelSoftMarginCriterion = MultiLabelSoftMarginCriterion()</span>
<span class="sd">    creating: createMultiLabelSoftMarginCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiLabelSoftMarginCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                            <span class="n">JTensor</span><span class="o">.</span><span class="n">from_ndarray</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
                                                            <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="MultiMarginCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MultiMarginCriterion">[docs]</a><span class="k">class</span> <span class="nc">MultiMarginCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Creates a criterion that optimizes a multi-class classification hinge loss (margin-based loss)</span>
<span class="sd">    between input x and output y (which is a target class index).</span>


<span class="sd">    :param p:</span>
<span class="sd">    :param weights:</span>
<span class="sd">    :param margin:</span>
<span class="sd">    :param size_average:</span>


<span class="sd">    &gt;&gt;&gt; np.random.seed(123)</span>
<span class="sd">    &gt;&gt;&gt; weights = np.random.uniform(0, 1, (2,)).astype(&quot;float32&quot;)</span>
<span class="sd">    &gt;&gt;&gt; multiMarginCriterion = MultiMarginCriterion(1,weights)</span>
<span class="sd">    creating: createMultiMarginCriterion</span>
<span class="sd">    &gt;&gt;&gt; multiMarginCriterion = MultiMarginCriterion()</span>
<span class="sd">    creating: createMultiMarginCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiMarginCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                   <span class="n">p</span><span class="p">,</span>
                                                   <span class="n">JTensor</span><span class="o">.</span><span class="n">from_ndarray</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
                                                   <span class="n">margin</span><span class="p">,</span>
                                                   <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="SoftMarginCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.SoftMarginCriterion">[docs]</a><span class="k">class</span> <span class="nc">SoftMarginCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a criterion that optimizes a two-class classification logistic loss</span>
<span class="sd">    between input x (a Tensor of dimension 1) and output y (which is a tensor</span>
<span class="sd">    containing either 1s or -1s).</span>

<span class="sd">```</span>
<span class="sd">           loss(x, y) = sum_i (log(1 + exp(-y[i]*x[i]))) / x:nElement()</span>
<span class="sd">```</span>

<span class="sd">    :param sizeaverage: The normalization by the number of elements in the inputcan be disabled by setting</span>


<span class="sd">    &gt;&gt;&gt; softMarginCriterion = SoftMarginCriterion(False)</span>
<span class="sd">    creating: createSoftMarginCriterion</span>
<span class="sd">    &gt;&gt;&gt; softMarginCriterion = SoftMarginCriterion()</span>
<span class="sd">    creating: createSoftMarginCriterion</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SoftMarginCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span> <span class="n">size_average</span><span class="p">)</span></div>


<div class="viewcode-block" id="DiceCoefficientCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.DiceCoefficientCriterion">[docs]</a><span class="k">class</span> <span class="nc">DiceCoefficientCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    The Dice-Coefficient criterion</span>
<span class="sd">    input: Tensor,target: Tensor</span>

<span class="sd">```</span>
<span class="sd">    return:      2 * (input intersection target)</span>
<span class="sd">            1 - ----------------------------------</span>
<span class="sd">                    input union target</span>
<span class="sd">```</span>

<span class="sd">    &gt;&gt;&gt; diceCoefficientCriterion = DiceCoefficientCriterion(size_average = True, epsilon = 1.0)</span>
<span class="sd">    creating: createDiceCoefficientCriterion</span>
<span class="sd">    &gt;&gt;&gt; diceCoefficientCriterion = DiceCoefficientCriterion()</span>
<span class="sd">    creating: createDiceCoefficientCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">epsilon</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DiceCoefficientCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                       <span class="n">size_average</span><span class="p">,</span>
                                                       <span class="n">epsilon</span><span class="p">)</span></div>

<div class="viewcode-block" id="L1Cost"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.L1Cost">[docs]</a><span class="k">class</span> <span class="nc">L1Cost</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    compute L1 norm for input, and sign of input</span>

<span class="sd">    &gt;&gt;&gt; l1Cost = L1Cost()</span>
<span class="sd">    creating: createL1Cost</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">L1Cost</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span></div>

<div class="viewcode-block" id="CosineProximityCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.CosineProximityCriterion">[docs]</a><span class="k">class</span> <span class="nc">CosineProximityCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    compute the negative of the mean cosine proximity between predictions and targets.</span>
<span class="sd">```</span>
<span class="sd">   x&#39;(i) = x(i) / sqrt(max(sum(x(i)^2), 1e-12))</span>
<span class="sd">   y&#39;(i) = y(i) / sqrt(max(sum(x(i)^2), 1e-12))</span>
<span class="sd">   cosine_proximity(x, y) = sum_i(-1 * x&#39;(i) * y&#39;(i))</span>
<span class="sd">```</span>

<span class="sd">    &gt;&gt;&gt; cosineProximityCriterion = CosineProximityCriterion()</span>
<span class="sd">    creating: createCosineProximityCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CosineProximityCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span></div>

<div class="viewcode-block" id="MeanAbsolutePercentageCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MeanAbsolutePercentageCriterion">[docs]</a><span class="k">class</span> <span class="nc">MeanAbsolutePercentageCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This method is same as `mean_absolute_percentage_error` loss in keras.</span>
<span class="sd">    It caculates diff = K.abs((y - x) / K.clip(K.abs(y), K.epsilon(), Double.MaxValue))</span>
<span class="sd">    and return 100 * K.mean(diff) as output. Here, the x and y can have or not have a batch.</span>
<span class="sd">    &gt;&gt;&gt; error = MeanAbsolutePercentageCriterion()</span>
<span class="sd">    creating: createMeanAbsolutePercentageCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MeanAbsolutePercentageCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span></div>

<div class="viewcode-block" id="MeanSquaredLogarithmicCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.MeanSquaredLogarithmicCriterion">[docs]</a><span class="k">class</span> <span class="nc">MeanSquaredLogarithmicCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This method is same as `mean_squared_logarithmic_error` loss in keras.</span>
<span class="sd">    It calculates: first_log = K.log(K.clip(y, K.epsilon(),  Double.MaxValue) + 1.)</span>
<span class="sd">    second_log = K.log(K.clip(x, K.epsilon(),  Double.MaxValue) + 1.)</span>
<span class="sd">    and output K.mean(K.square(first_log - second_log)). Here, the x and y can have or not have a batch.</span>
<span class="sd">    &gt;&gt;&gt; error = MeanSquaredLogarithmicCriterion()</span>
<span class="sd">    creating: createMeanSquaredLogarithmicCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MeanSquaredLogarithmicCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span></div>

<div class="viewcode-block" id="KullbackLeiblerDivergenceCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.KullbackLeiblerDivergenceCriterion">[docs]</a><span class="k">class</span> <span class="nc">KullbackLeiblerDivergenceCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    compute Kullback Leibler DivergenceCriterion error for intput and target</span>
<span class="sd">    This method is same as `kullback_leibler_divergence` loss in keras. Loss calculated as:</span>
<span class="sd">    y_true = K.clip(input, K.epsilon(), 1)</span>
<span class="sd">    y_pred = K.clip(target, K.epsilon(), 1)</span>
<span class="sd">    and output K.sum(y_true * K.log(y_true / y_pred), axis=-1)</span>

<span class="sd">    &gt;&gt;&gt; error = KullbackLeiblerDivergenceCriterion()</span>
<span class="sd">    creating: createKullbackLeiblerDivergenceCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">KullbackLeiblerDivergenceCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span></div>

<div class="viewcode-block" id="PoissonCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.PoissonCriterion">[docs]</a><span class="k">class</span> <span class="nc">PoissonCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>

    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    compute Poisson error for input and target, loss calculated as:</span>
<span class="sd">    mean(input - target * K.log(input + K.epsilon()), axis=-1)</span>
<span class="sd">    &gt;&gt;&gt; error = PoissonCriterion()</span>
<span class="sd">    creating: createPoissonCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PoissonCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">)</span></div>

<div class="viewcode-block" id="TransformerCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.TransformerCriterion">[docs]</a><span class="k">class</span> <span class="nc">TransformerCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    The criterion that takes two modules to transform input and target, and take</span>
<span class="sd">    one criterion to compute the loss with the transformed input and target.</span>
<span class="sd">    </span>
<span class="sd">    This criterion can be used to construct complex criterion. For example, the</span>
<span class="sd">    `inputTransformer` and `targetTransformer` can be pre-trained CNN networks,</span>
<span class="sd">    and we can use the networks&#39; output to compute the high-level feature</span>
<span class="sd">    reconstruction loss, which is commonly used in areas like neural style transfer</span>
<span class="sd">    (https://arxiv.org/abs/1508.06576), texture synthesis (https://arxiv.org/abs/1505.07376),</span>
<span class="sd">    .etc.</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; trans = TransformerCriterion(MSECriterion())</span>
<span class="sd">    creating: createMSECriterion</span>
<span class="sd">    creating: createTransformerCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">criterion</span><span class="p">,</span>
                 <span class="n">input_transformer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">target_transformer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span>
                                                   <span class="n">bigdl_type</span><span class="p">,</span>
                                                   <span class="n">criterion</span><span class="p">,</span>
                                                   <span class="n">input_transformer</span><span class="p">,</span>
                                                   <span class="n">target_transformer</span><span class="p">)</span></div>

<div class="viewcode-block" id="DotProductCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.DotProductCriterion">[docs]</a><span class="k">class</span> <span class="nc">DotProductCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Compute the dot product of input and target tensor.</span>
<span class="sd">    Input and target are required to have the same size.</span>
<span class="sd">    :param size_average: whether to average over each observations in the same batch</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; dp =DotProductCriterion(False)</span>
<span class="sd">    creating: createDotProductCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">size_average</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DotProductCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span>
                                                  <span class="n">bigdl_type</span><span class="p">,</span>
                                                  <span class="n">size_average</span><span class="p">)</span></div>

<div class="viewcode-block" id="PGCriterion"><a class="viewcode-back" href="../../../bigdl.nn.html#bigdl.nn.criterion.PGCriterion">[docs]</a><span class="k">class</span> <span class="nc">PGCriterion</span><span class="p">(</span><span class="n">Criterion</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    The Criterion to compute the negative policy gradient given a</span>
<span class="sd">    multinomial distribution and the sampled action and reward.</span>

<span class="sd">    The input to this criterion should be a 2-D tensor representing</span>
<span class="sd">    a batch of multinomial distribution, the target should also be</span>
<span class="sd">    a 2-D tensor with the same size of input, representing the sampled</span>
<span class="sd">    action and reward/advantage with the index of non-zero element in the vector</span>
<span class="sd">    represents the sampled action and the non-zero element itself represents</span>
<span class="sd">    the reward. If the action is space is large, you should consider using</span>
<span class="sd">    SparseTensor for target.</span>
<span class="sd">    </span>
<span class="sd">    The loss computed is simple the standard policy gradient,</span>

<span class="sd">      loss = - 1/n * sum(R_{n} dot_product log(P_{n}))</span>

<span class="sd">    where R_{n} is the reward vector, and P_{n} is the input distribution.</span>

<span class="sd">    :param sizeAverage whether to average over each observations in the same batch</span>
<span class="sd">                           </span>
<span class="sd">    &gt;&gt;&gt; pg = PGCriterion()</span>
<span class="sd">    creating: createPGCriterion</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">sizeAverage</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PGCriterion</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span>
                                          <span class="n">bigdl_type</span><span class="p">,</span>
                                          <span class="n">sizeAverage</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_test</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">doctest</span>
    <span class="kn">from</span> <span class="nn">pyspark</span> <span class="k">import</span> <span class="n">SparkContext</span>
    <span class="kn">from</span> <span class="nn">bigdl.nn</span> <span class="k">import</span> <span class="n">criterion</span>
    <span class="kn">from</span> <span class="nn">bigdl.util.common</span> <span class="k">import</span> <span class="n">init_engine</span>
    <span class="kn">from</span> <span class="nn">bigdl.util.common</span> <span class="k">import</span> <span class="n">create_spark_conf</span>
    <span class="n">globs</span> <span class="o">=</span> <span class="n">criterion</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">sc</span> <span class="o">=</span> <span class="n">SparkContext</span><span class="p">(</span><span class="n">master</span><span class="o">=</span><span class="s2">&quot;local[4]&quot;</span><span class="p">,</span> <span class="n">appName</span><span class="o">=</span><span class="s2">&quot;test criterion&quot;</span><span class="p">,</span>
                      <span class="n">conf</span><span class="o">=</span><span class="n">create_spark_conf</span><span class="p">())</span>
    <span class="n">globs</span><span class="p">[</span><span class="s1">&#39;sc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sc</span>
    <span class="n">init_engine</span><span class="p">()</span>

    <span class="p">(</span><span class="n">failure_count</span><span class="p">,</span> <span class="n">test_count</span><span class="p">)</span> <span class="o">=</span> <span class="n">doctest</span><span class="o">.</span><span class="n">testmod</span><span class="p">(</span><span class="n">globs</span><span class="o">=</span><span class="n">globs</span><span class="p">,</span>
                                                  <span class="n">optionflags</span><span class="o">=</span><span class="n">doctest</span><span class="o">.</span><span class="n">ELLIPSIS</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">failure_count</span><span class="p">:</span>
        <span class="n">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">_test</span><span class="p">()</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">BigDL  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2019, Intel.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.6.
    </div>
  </body>
</html>