{
    "docs": [
        {
            "location": "/", 
            "text": "What is BigDL\n\n\nBigDL is a distributed deep learning library for Apache Spark; with BigDL, users can write their deep learning applications as standard Spark programs, which can directly run on top of existing Spark or Hadoop clusters.\n\n\n\n\n\n\nRich deep learning support.\n Modeled after \nTorch\n, BigDL provides comprehensive support for deep learning, including numeric computing (via \nTensor\n) and high level \nneural networks\n; in addition, users can load pre-trained \nCaffe\n or \nTorch\n models into Spark programs using BigDL.\n\n\n\n\n\n\nExtremely high performance.\n To achieve high performance, BigDL uses \nIntel MKL\n and multi-threaded programming in each Spark task. Consequently, it is orders of magnitude faster than out-of-box open source \nCaffe\n, \nTorch\n or \nTensorFlow\n on a single-node Xeon (i.e., comparable with mainstream GPU).\n\n\n\n\n\n\nEfficiently scale-out.\n BigDL can efficiently scale out to perform data analytics at \"Big Data scale\", by leveraging \nApache Spark\n (a lightning fast distributed data processing framework), as well as efficient implementations of synchronous SGD and all-reduce communications on Spark. \n\n\n\n\n\n\n\n\nWhy BigDL?\n\n\nYou may want to write your deep learning programs using BigDL if:\n\n\n\n\n\n\nYou want to analyze a large amount of data on the same Big Data (Hadoop/Spark) cluster where the data are stored (in, say, HDFS, HBase, Hive, etc.).\n\n\n\n\n\n\nYou want to add deep learning functionalities (either training or prediction) to your Big Data (Spark) programs and/or workflow.\n\n\n\n\n\n\nYou want to leverage existing Hadoop/Spark clusters to run your deep learning applications, which can be then dynamically shared with other workloads (e.g., ETL, data warehouse, feature engineering, classical machine learning, graph analytics, etc.)\n\n\n\n\n\n\n\n\nGetting Help\n\n\n\n\n\n\nYou can join the \nBigDL Google Group\n (or subscribe to the \nMail List\n) for more questions and discussions on BigDL\n\n\n\n\n\n\nYou can post bug reports and feature requests at the \nIssue Page", 
            "title": "Overview"
        }, 
        {
            "location": "/#what-is-bigdl", 
            "text": "BigDL is a distributed deep learning library for Apache Spark; with BigDL, users can write their deep learning applications as standard Spark programs, which can directly run on top of existing Spark or Hadoop clusters.    Rich deep learning support.  Modeled after  Torch , BigDL provides comprehensive support for deep learning, including numeric computing (via  Tensor ) and high level  neural networks ; in addition, users can load pre-trained  Caffe  or  Torch  models into Spark programs using BigDL.    Extremely high performance.  To achieve high performance, BigDL uses  Intel MKL  and multi-threaded programming in each Spark task. Consequently, it is orders of magnitude faster than out-of-box open source  Caffe ,  Torch  or  TensorFlow  on a single-node Xeon (i.e., comparable with mainstream GPU).    Efficiently scale-out.  BigDL can efficiently scale out to perform data analytics at \"Big Data scale\", by leveraging  Apache Spark  (a lightning fast distributed data processing framework), as well as efficient implementations of synchronous SGD and all-reduce communications on Spark.", 
            "title": "What is BigDL"
        }, 
        {
            "location": "/#why-bigdl", 
            "text": "You may want to write your deep learning programs using BigDL if:    You want to analyze a large amount of data on the same Big Data (Hadoop/Spark) cluster where the data are stored (in, say, HDFS, HBase, Hive, etc.).    You want to add deep learning functionalities (either training or prediction) to your Big Data (Spark) programs and/or workflow.    You want to leverage existing Hadoop/Spark clusters to run your deep learning applications, which can be then dynamically shared with other workloads (e.g., ETL, data warehouse, feature engineering, classical machine learning, graph analytics, etc.)", 
            "title": "Why BigDL?"
        }, 
        {
            "location": "/#getting-help", 
            "text": "You can join the  BigDL Google Group  (or subscribe to the  Mail List ) for more questions and discussions on BigDL    You can post bug reports and feature requests at the  Issue Page", 
            "title": "Getting Help"
        }, 
        {
            "location": "/release-download/", 
            "text": "These are built BigDL packages including dependency and python files. You can download these packages instead of building them by yourself. This is useful when you want to do something like run some examples or develop python code.\n\n\n\n\nNightly Build\n\n\nHere are the folders for nightly build packages. The packages are built from latest master code. You can download the .zip files with a timestamp suffix in the name. \n\n\n\n\n\n\n\n\n\n\nLinux x64\n\n\nMac\n\n\n\n\n\n\n\n\n\n\nSpark 1.5.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 1.6.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.0.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.2.0\n\n\n\n\nRelease 0.1.2\n\n\n\n\nRelease 0.1.1\n\n\n\n\n\n\n\n\n\n\nLinux x64\n\n\nMac\n\n\n\n\n\n\n\n\n\n\nSpark 1.5.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 1.6.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.0.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.1.0\n\n\n\n\n\n\n\n\n\n\nLinux x64\n\n\nMac\n\n\n\n\n\n\n\n\n\n\nSpark 1.5.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 1.6.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.0.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.0\n\n\ndownload\n\n\ndownload", 
            "title": "Download"
        }, 
        {
            "location": "/release-download/#nightly-build", 
            "text": "Here are the folders for nightly build packages. The packages are built from latest master code. You can download the .zip files with a timestamp suffix in the name.       Linux x64  Mac      Spark 1.5.1  download  download    Spark 1.6.0  download  download    Spark 2.0.0  download  download    Spark 2.1.0  download  download", 
            "title": "Nightly Build"
        }, 
        {
            "location": "/release-download/#release-020", 
            "text": "", 
            "title": "Release 0.2.0"
        }, 
        {
            "location": "/release-download/#release-012", 
            "text": "", 
            "title": "Release 0.1.2"
        }, 
        {
            "location": "/release-download/#release-011", 
            "text": "Linux x64  Mac      Spark 1.5.1  download  download    Spark 1.6.0  download  download    Spark 2.0.0  download  download    Spark 2.1.0  download  download", 
            "title": "Release 0.1.1"
        }, 
        {
            "location": "/release-download/#release-010", 
            "text": "Linux x64  Mac      Spark 1.5.1  download  download    Spark 1.6.0  download  download    Spark 2.0.0  download  download    Spark 2.1.0  download  download", 
            "title": "Release 0.1.0"
        }, 
        {
            "location": "/release-docs/", 
            "text": "Latest Master\n\n\nlatest Master Docs\n\n\n\n\nRelease 0.2.0\n\n\nBigDL 0.2.0 Docs\n\n\n\n\nRelease 0.1.2\n\n\nBigDL 0.1.2 Docs", 
            "title": "Documentation"
        }, 
        {
            "location": "/release-docs/#latest-master", 
            "text": "latest Master Docs", 
            "title": "Latest Master"
        }, 
        {
            "location": "/release-docs/#release-020", 
            "text": "BigDL 0.2.0 Docs", 
            "title": "Release 0.2.0"
        }, 
        {
            "location": "/release-docs/#release-012", 
            "text": "BigDL 0.1.2 Docs", 
            "title": "Release 0.1.2"
        }, 
        {
            "location": "/getting-started/", 
            "text": "Before using BigDL\n\n\nApache Spark needs to be installed before you start using BigDL. \n\n\nBigDL provide both Scala/Java and Python API.  \n\n\nTo use BigDL \nScala/Java\n API, the first thing is to obtain the BigDL libraries. You can either download the pre-built BigDL libs (\navailable here\n), or build the libs from source code (available at \nBigDL Github\n). When writing programs, you need to ensure the SparkContext is created successfully and initialize BigDL engine before calling BigDL APIs. Refer to \nUse Prebuild Libs\n, \nBuild from Source\n, and \nRun\n for details about how to build BigDL and run a program in Scala.  \n\n\nTo use BigDL \nPython\n API, besides using pre-built BigDL libs or building from source, you can also install BigDL python via pip (only support some spark versions). You may use Python API in an interactive shell, or run a program in commandline, or use Jupyter notebooks. Before calling BigDL API's in your program, you have to ensure the SparkContext is succesfully created and initialize BigDL engine. Refer to \nPython Install\n and \nPython Run\n for details about how to install python and run python programs.\n\n\n\n\nPrepare your Data\n\n\nYou data need to be transformed into specific data structures in order to be fed into BigDL for training, evaluation and prediction.\n\n\nBelow are several data structures that you need to know when using BigDL. \n\n\n\n\nTensor\n is a multi-dimensional array of basic numeric types (e.g., \nInt\n, \nFloat\n,       \nDouble\n, etc.) It is the most essential data structure in BigDL, composing the basic data flow inside the nerual network (i.e. the input, output, weight, bias and gradient of many layers). Refer to \nTensor API doc\n for details about the numeric computation functions provided in BigDL. \n\n\n\n\nTable\n is key-value map. Usually we use Tables to map from digits to Tensors. Some of the layers has \nTable\n as input or output (e.g. \nConcatTable\n). You can also use \nT()\n to create Tables in BigDL - just a syntax sugar. Refer to \nTable API doc\n for detailed usage.\n\n\n\n\n\n\nSample\n is usually a \n(feature, label)\n pair. A \nSample\n can be created from two \nTensors\n (in Scala) or two \nnumpy arrays\n (in Python). Refer to \nSample API doc\n for detailed usage.\n\n\n\n\n\n\nYou need to convert your dataset into \nRDD\n of \nSamples\n (both Scala and Python), and then feed your data into Optimizer for training, validation or prediction. Refer to \nOptimizer docs\n for details.\n\n\n\n\nUse BigDL for Prediction only\n\n\nIf you have an existing model and want to use BigDL only for prediction, you need to first load the model, and then do prediction or evaluation. \n\n\nBigDL supports loading models trained and saved in BigDL, or a trained Tensorflow model. \n\n\n\n\nTo load a BigDL model, you can use \nModule.load\n interface (Scala) or \nModel.load\n (in Python). Refer to \nModel Save\n for details.  \n\n\nTo load a Tensorflow model, refer to \nTensorflow Support\n for details.\n\n\nTo load a Caffe model, refer to \nCaffe Support\n for details.\n\n\n\n\nOnce you have a loaded model, you can call \nmodel.predict()\n to do predictions (refer to \nModel Predict\n for details). Note that you need to convert your input data into proper format which \npredict\n accepts. For how to prepare your data, refer to section \nPrepare your Data\n. \n\n\nIf you are using predicted result as a component inside a Spark ML pipeline, refer to \nDLEsitimator API\n and \nDLClassifier API\n for usage. \n\n\n\n\nTrain a Model from Scratch\n\n\nThe procedure of training a model from scratch usually involves following steps:\n\n\n\n\ndefine your model (by connecting layers/activations into a network)\n\n\ndecide your loss function (which function to optimize)\n\n\noptimization (choose a proper algorithm and hyper parameters, and train)\n\n\nevaluation (evaluate your model) \n\n\n\n\nBefore training models, please make sure BigDL is installed, BigDL engine initialized properly, and your data is in proper format. Refer to \nBefore using BigDL\n and \nPrepare Your Data\n for details.  \n\n\nThe most recommended way to create your first model is to modify from an existing one. BigDL provides plenty of models for you to refer to. See \nScala Models/Examples\n and \nPython Models/Examples and Tutorials\n. \n\n\nTo define a model, you can either use the Sequential API or Functional API. The Functional API is more flexible than Sequential API. Refer to \nSequential API\n and \nFunctional API\n for how to define models in different shapes. Navigate to \nAPI Guide/Layers\n on the side bar to find the documenations of available layers and activation.\n\n\nAfter creating the model, you will have to deside which loss function to use in training. Find the details of losses defined in BigDL in \nLosses\n.  \n\n\nNow you create an \nOptimizer\n and set the loss function, input dataset along with other hyper parameters into the Optimizer. Then call \nOptimizer.optimize\n to train. Refer to \nOptimizer docs\n for details. \n\n\nEvaluation can be performed periodically during a training. Before calling \nOptimizer.optimize\n, use \nOptimizer.setValidation\n (in Scala) or \nOptimizer.set_validation\n (in Python) to set validation configurations, e.g. validation dataset, validation metrics, etc. For a list of defined metrics, refer to \nMetrics\n.\n\n\nWhen \nOptimizer.optimize\n finishes, it will return a trained model. You can then use \nmodel.predict\n for predictions. Refer to \nModel Prediction\n for detailed usage.    \n\n\nSave a Model\n\n\nWhen training is finished, you may need to save the final model for later use. \n\n\nUse \nmodel.save\n to save your BigDL model into a file (in BigDL model format) on local filesystem, HDFS, or Amazon s3 (refer to \nModel Save\n). \n\n\nYou may also save the model to Tensorflow or Caffe format (refer to \nCaffe Support\n, and \nTensorflow Support\n respectively).  \n\n\nStop and Resume a Training\n\n\nTraining a deep learning model sometimes takes a very long time. It may be stopped or interrupted and we need the training to resume from where we have left. \n\n\nTo enable this, you have to configure \nOptimizer\n to periodically take snapshots of the model (trained weights, biases, etc.) and optim-method (configurations and states of the optimization) and dump them into files. Use \nOptimizer.setCheckpoint\n (in Scala) or \noptimizer.set_checkpoint\n (in Python) to configure the frequency and paths of writing snapshots. Then during training, you will find several snapshot files written in the checkpoint path. Refer to \nOptimizer API\n for details. \n\n\nAfter training stops, you can resume from any saved point. Choose one of the model snapshots and the corresponding optim-method snapshot to resume (the iteration number of the the snapshots is in the file name suffix). Use \nModule.load\n (Scala) or \nModel.load\n(Python) to load the model snapshot into an model object, and \nOptimMethod.load\n (Scala only, Python does not support this yet) to load optimization method into an OptimMethod object. Then create a new \nOptimizer\n with the loaded model and optim method. Call \nOptimizer.optimize\n, and you will resume from the point where the snapshot is taken. Refer to \nOptimMethod API\n and \nModule API\n for details.\n\n\nYou can also resume training without loading the optim method, if you intend to change the learning rate schedule or even the optimization algorithm. Just create an \nOptimizer\n with loaded model and a new instance of OptimMethod (both Scala and Python). \n\n\n\n\nUse Pre-trained Models/Layers\n\n\nPre-train is a useful strategy when training deep learning models. You may use the pre-trained features (e.g. embeddings) in your model, or do a fine-tuning for a different dataset or target.\n\n\nTo use a learnt model as a whole, you can use \nModule.load\n to load the entire model, Then create an \nOptimizer\n with the loaded model set into it. Refer to \nOptmizer API\n and \nModule API\n for details. \n\n\nInstead of using an entire model, you can also use pre-trained weights/biases in certain layers. After a layer is created, use \nsetWeightsBias\n (in Scala) or \nset_weights\n (in Python) on the layer to initialize the weights with pre-trained weights. Then continue to train your model as usual. \n\n\n\n\nMonitor your training\n\n\n\n\nVisualization\n\n\n\n\nBigDL provides a convinient way to monitor/visualize your training progress. It writes the statistics collected during training/validation and they can be visualized in real-time using tensorboard. These statistics can also be retrieved into readable data structures later and visualized in other tools (e.g. Jupyter notebook). For details, refer to \nVisualization\n. \n\n\n\n\nLogging\n\n\n\n\nBigDL also has a stright-forward logging output on the console along the training, as shown below. You can see real-time epoch/iteration/loss/throughput in the log.\n\n\n 2017-01-10 10:03:55 INFO  DistriOptimizer$:241 - [Epoch 1 0/5000][Iteration 1][Wall Clock XXX] Train 512 in   XXXseconds. Throughput is XXX records/second. Loss is XXX.\n 2017-01-10 10:03:58 INFO  DistriOptimizer$:241 - [Epoch 1 512/5000][Iteration 2][Wall Clock XXX] Train 512    in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n 2017-01-10 10:04:00 INFO  DistriOptimizer$:241 - [Epoch 1 1024/5000][Iteration 3][Wall Clock XXX] Train 512   in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n\n\n\n\nThe DistriOptimizer log level is INFO by default. We implement a method named with \nredirectSparkInfoLogs\n  in \nspark/utils/LoggerFilter.scala\n. You can import and redirect at first.\n\n\n import com.intel.analytics.bigdl.utils.LoggerFilter\n LoggerFilter.redirectSparkInfoLogs()\n\n\n\n\nThis method will redirect all logs of \norg\n, \nakka\n, \nbreeze\n to \nbigdl.log\n with \nINFO\n level, except \norg.  apache.spark.SparkContext\n. And it will output all \nERROR\n message in console too.\n\n\nYou can disable the redirection with java property \n-Dbigdl.utils.LoggerFilter.disable=true\n. By default,   it will do redirect of all examples and models in our code.\n\n\nYou can set where the \nbigdl.log\n will be generated with \n-Dbigdl.utils.LoggerFilter.logFile=\npath\n. By    default, it will be generated under current workspace.\n\n\n\n\nTuning\n\n\nThere're several strategies that may be useful when tuning an optimization. \n\n\n\n\nChange the learning Rate Schedule in SGD. Refer to \nSGD docs\n for details. \n\n\nIf overfit is seen, try use Regularization. Refer to \nRegularizers\n. \n\n\nTry change the initialization methods. Refer to \nInitailizers\n.\n\n\nTry Adam or Adagrad at the first place. If they can't achive a good score, use SGD and find a proper learning rate schedule - it usually takes time, though. RMSProp is recommended for RNN models. Refer to \nOptimization Algorithms\n for a list of supported optimization methods.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#before-using-bigdl", 
            "text": "Apache Spark needs to be installed before you start using BigDL.   BigDL provide both Scala/Java and Python API.    To use BigDL  Scala/Java  API, the first thing is to obtain the BigDL libraries. You can either download the pre-built BigDL libs ( available here ), or build the libs from source code (available at  BigDL Github ). When writing programs, you need to ensure the SparkContext is created successfully and initialize BigDL engine before calling BigDL APIs. Refer to  Use Prebuild Libs ,  Build from Source , and  Run  for details about how to build BigDL and run a program in Scala.    To use BigDL  Python  API, besides using pre-built BigDL libs or building from source, you can also install BigDL python via pip (only support some spark versions). You may use Python API in an interactive shell, or run a program in commandline, or use Jupyter notebooks. Before calling BigDL API's in your program, you have to ensure the SparkContext is succesfully created and initialize BigDL engine. Refer to  Python Install  and  Python Run  for details about how to install python and run python programs.", 
            "title": "Before using BigDL"
        }, 
        {
            "location": "/getting-started/#prepare-your-data", 
            "text": "You data need to be transformed into specific data structures in order to be fed into BigDL for training, evaluation and prediction.  Below are several data structures that you need to know when using BigDL.    Tensor  is a multi-dimensional array of basic numeric types (e.g.,  Int ,  Float ,        Double , etc.) It is the most essential data structure in BigDL, composing the basic data flow inside the nerual network (i.e. the input, output, weight, bias and gradient of many layers). Refer to  Tensor API doc  for details about the numeric computation functions provided in BigDL.    Table  is key-value map. Usually we use Tables to map from digits to Tensors. Some of the layers has  Table  as input or output (e.g.  ConcatTable ). You can also use  T()  to create Tables in BigDL - just a syntax sugar. Refer to  Table API doc  for detailed usage.    Sample  is usually a  (feature, label)  pair. A  Sample  can be created from two  Tensors  (in Scala) or two  numpy arrays  (in Python). Refer to  Sample API doc  for detailed usage.    You need to convert your dataset into  RDD  of  Samples  (both Scala and Python), and then feed your data into Optimizer for training, validation or prediction. Refer to  Optimizer docs  for details.", 
            "title": "Prepare your Data"
        }, 
        {
            "location": "/getting-started/#use-bigdl-for-prediction-only", 
            "text": "If you have an existing model and want to use BigDL only for prediction, you need to first load the model, and then do prediction or evaluation.   BigDL supports loading models trained and saved in BigDL, or a trained Tensorflow model.    To load a BigDL model, you can use  Module.load  interface (Scala) or  Model.load  (in Python). Refer to  Model Save  for details.    To load a Tensorflow model, refer to  Tensorflow Support  for details.  To load a Caffe model, refer to  Caffe Support  for details.   Once you have a loaded model, you can call  model.predict()  to do predictions (refer to  Model Predict  for details). Note that you need to convert your input data into proper format which  predict  accepts. For how to prepare your data, refer to section  Prepare your Data .   If you are using predicted result as a component inside a Spark ML pipeline, refer to  DLEsitimator API  and  DLClassifier API  for usage.", 
            "title": "Use BigDL for Prediction only"
        }, 
        {
            "location": "/getting-started/#train-a-model-from-scratch", 
            "text": "The procedure of training a model from scratch usually involves following steps:   define your model (by connecting layers/activations into a network)  decide your loss function (which function to optimize)  optimization (choose a proper algorithm and hyper parameters, and train)  evaluation (evaluate your model)    Before training models, please make sure BigDL is installed, BigDL engine initialized properly, and your data is in proper format. Refer to  Before using BigDL  and  Prepare Your Data  for details.    The most recommended way to create your first model is to modify from an existing one. BigDL provides plenty of models for you to refer to. See  Scala Models/Examples  and  Python Models/Examples and Tutorials .   To define a model, you can either use the Sequential API or Functional API. The Functional API is more flexible than Sequential API. Refer to  Sequential API  and  Functional API  for how to define models in different shapes. Navigate to  API Guide/Layers  on the side bar to find the documenations of available layers and activation.  After creating the model, you will have to deside which loss function to use in training. Find the details of losses defined in BigDL in  Losses .    Now you create an  Optimizer  and set the loss function, input dataset along with other hyper parameters into the Optimizer. Then call  Optimizer.optimize  to train. Refer to  Optimizer docs  for details.   Evaluation can be performed periodically during a training. Before calling  Optimizer.optimize , use  Optimizer.setValidation  (in Scala) or  Optimizer.set_validation  (in Python) to set validation configurations, e.g. validation dataset, validation metrics, etc. For a list of defined metrics, refer to  Metrics .  When  Optimizer.optimize  finishes, it will return a trained model. You can then use  model.predict  for predictions. Refer to  Model Prediction  for detailed usage.", 
            "title": "Train a Model from Scratch"
        }, 
        {
            "location": "/getting-started/#save-a-model", 
            "text": "When training is finished, you may need to save the final model for later use.   Use  model.save  to save your BigDL model into a file (in BigDL model format) on local filesystem, HDFS, or Amazon s3 (refer to  Model Save ).   You may also save the model to Tensorflow or Caffe format (refer to  Caffe Support , and  Tensorflow Support  respectively).", 
            "title": "Save a Model"
        }, 
        {
            "location": "/getting-started/#stop-and-resume-a-training", 
            "text": "Training a deep learning model sometimes takes a very long time. It may be stopped or interrupted and we need the training to resume from where we have left.   To enable this, you have to configure  Optimizer  to periodically take snapshots of the model (trained weights, biases, etc.) and optim-method (configurations and states of the optimization) and dump them into files. Use  Optimizer.setCheckpoint  (in Scala) or  optimizer.set_checkpoint  (in Python) to configure the frequency and paths of writing snapshots. Then during training, you will find several snapshot files written in the checkpoint path. Refer to  Optimizer API  for details.   After training stops, you can resume from any saved point. Choose one of the model snapshots and the corresponding optim-method snapshot to resume (the iteration number of the the snapshots is in the file name suffix). Use  Module.load  (Scala) or  Model.load (Python) to load the model snapshot into an model object, and  OptimMethod.load  (Scala only, Python does not support this yet) to load optimization method into an OptimMethod object. Then create a new  Optimizer  with the loaded model and optim method. Call  Optimizer.optimize , and you will resume from the point where the snapshot is taken. Refer to  OptimMethod API  and  Module API  for details.  You can also resume training without loading the optim method, if you intend to change the learning rate schedule or even the optimization algorithm. Just create an  Optimizer  with loaded model and a new instance of OptimMethod (both Scala and Python).", 
            "title": "Stop and Resume a Training"
        }, 
        {
            "location": "/getting-started/#use-pre-trained-modelslayers", 
            "text": "Pre-train is a useful strategy when training deep learning models. You may use the pre-trained features (e.g. embeddings) in your model, or do a fine-tuning for a different dataset or target.  To use a learnt model as a whole, you can use  Module.load  to load the entire model, Then create an  Optimizer  with the loaded model set into it. Refer to  Optmizer API  and  Module API  for details.   Instead of using an entire model, you can also use pre-trained weights/biases in certain layers. After a layer is created, use  setWeightsBias  (in Scala) or  set_weights  (in Python) on the layer to initialize the weights with pre-trained weights. Then continue to train your model as usual.", 
            "title": "Use Pre-trained Models/Layers"
        }, 
        {
            "location": "/getting-started/#monitor-your-training", 
            "text": "Visualization   BigDL provides a convinient way to monitor/visualize your training progress. It writes the statistics collected during training/validation and they can be visualized in real-time using tensorboard. These statistics can also be retrieved into readable data structures later and visualized in other tools (e.g. Jupyter notebook). For details, refer to  Visualization .    Logging   BigDL also has a stright-forward logging output on the console along the training, as shown below. You can see real-time epoch/iteration/loss/throughput in the log.   2017-01-10 10:03:55 INFO  DistriOptimizer$:241 - [Epoch 1 0/5000][Iteration 1][Wall Clock XXX] Train 512 in   XXXseconds. Throughput is XXX records/second. Loss is XXX.\n 2017-01-10 10:03:58 INFO  DistriOptimizer$:241 - [Epoch 1 512/5000][Iteration 2][Wall Clock XXX] Train 512    in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n 2017-01-10 10:04:00 INFO  DistriOptimizer$:241 - [Epoch 1 1024/5000][Iteration 3][Wall Clock XXX] Train 512   in XXXseconds. Throughput is XXX records/second. Loss is XXX.  The DistriOptimizer log level is INFO by default. We implement a method named with  redirectSparkInfoLogs   in  spark/utils/LoggerFilter.scala . You can import and redirect at first.   import com.intel.analytics.bigdl.utils.LoggerFilter\n LoggerFilter.redirectSparkInfoLogs()  This method will redirect all logs of  org ,  akka ,  breeze  to  bigdl.log  with  INFO  level, except  org.  apache.spark.SparkContext . And it will output all  ERROR  message in console too.  You can disable the redirection with java property  -Dbigdl.utils.LoggerFilter.disable=true . By default,   it will do redirect of all examples and models in our code.  You can set where the  bigdl.log  will be generated with  -Dbigdl.utils.LoggerFilter.logFile= path . By    default, it will be generated under current workspace.", 
            "title": "Monitor your training"
        }, 
        {
            "location": "/getting-started/#tuning", 
            "text": "There're several strategies that may be useful when tuning an optimization.    Change the learning Rate Schedule in SGD. Refer to  SGD docs  for details.   If overfit is seen, try use Regularization. Refer to  Regularizers .   Try change the initialization methods. Refer to  Initailizers .  Try Adam or Adagrad at the first place. If they can't achive a good score, use SGD and find a proper learning rate schedule - it usually takes time, though. RMSProp is recommended for RNN models. Refer to  Optimization Algorithms  for a list of supported optimization methods.", 
            "title": "Tuning"
        }, 
        {
            "location": "/UserGuide/install-pre-built/", 
            "text": "Download a pre-built library\n\n\nYou can download the BigDL release (currently v0.1.0) and nightly build from the \nRelease Page\n\n\n\n\nLink with a release version\n\n\nCurrently, BigDL releases are hosted on maven central; here's an example to add the BigDL dependency to your own project:\n\n\ndependency\n\n    \ngroupId\ncom.intel.analytics.bigdl\n/groupId\n\n    \nartifactId\nbigdl\n/artifactId\n\n    \nversion\n${BIGDL_VERSION}\n/version\n\n\n/dependency\n\n\n\n\n\nSBT developers can use\n\n\nlibraryDependencies += \ncom.intel.analytics.bigdl\n % \nbigdl\n % \n${BIGDL_VERSION}\n\n\n\n\n\nSince currently only BigDL 0.1.0 is released, ${BIGDL_VERSION} must be set to 0.1.0 here.\n\n\nNote\n: the BigDL lib default supports Spark 1.5.x and 1.6.x; if your project runs on Spark 2.0 and 2.1, use this\n\n\ndependency\n\n    \ngroupId\ncom.intel.analytics.bigdl\n/groupId\n\n    \nartifactId\nbigdl-SPARK_2.0\n/artifactId\n\n    \nversion\n${BIGDL_VERSION}\n/version\n\n\n/dependency\n\n\n\n\n\nSBT developers can use\n\n\nlibraryDependencies += \ncom.intel.analytics.bigdl\n % \nbigdl-SPARK_2.0\n % \n${BIGDL_VERSION}\n\n\n\n\n\nIf your project runs on MacOS, you should add the dependency below,\n\n\ndependency\n\n    \ngroupId\ncom.intel.analytics.bigdl.native\n/groupId\n\n    \nartifactId\nmkl-java-mac\n/artifactId\n\n    \nversion\n${BIGDL_VERSION}\n/version\n\n    \nexclusions\n\n        \nexclusion\n\n            \ngroupId\ncom.intel.analytics.bigdl.native\n/groupId\n\n            \nartifactId\nbigdl-native\n/artifactId\n\n        \n/exclusion\n\n    \n/exclusions\n\n\n/dependency\n\n\n\n\n\nSBT developers can use\n\n\nlibraryDependencies += \ncom.intel.analytics.bigdl.native\n % \nmkl-java-mac\n % \n${BIGDL_VERSION}\n from \nhttp://repo1.maven.org/maven2/com/intel/analytics/bigdl/native/mkl-java-mac/${BIGDL_VERSION}/mkl-java-mac-${BIGDL_VERSION}.jar\n\n\n\n\n\n\n\nLink with a development version\n\n\nCurrently, BigDL development version is hosted on \nSonaType\n. \n\n\nTo link your application with the latest BigDL development version, you should add some dependencies like \nLinking with BigDL releases\n, but set ${BIGDL_VERSION} to 0.2.0-SNAPSHOT, and add below repository to your pom.xml.\n\n\nrepository\n\n    \nid\nsonatype\n/id\n\n    \nname\nsonatype repository\n/name\n\n    \nurl\nhttps://oss.sonatype.org/content/groups/public/\n/url\n\n    \nreleases\n\n        \nenabled\ntrue\n/enabled\n\n    \n/releases\n\n    \nsnapshots\n\n        \nenabled\ntrue\n/enabled\n\n    \n/snapshots\n\n\n/repository\n\n\n\n\n\nSBT developers can use\n\n\nresolvers += \nSonatype OSS Snapshots\n at \nhttps://oss.sonatype.org/content/repositories/snapshots", 
            "title": "Use Pre-built Libs"
        }, 
        {
            "location": "/UserGuide/install-pre-built/#download-a-pre-built-library", 
            "text": "You can download the BigDL release (currently v0.1.0) and nightly build from the  Release Page", 
            "title": "Download a pre-built library"
        }, 
        {
            "location": "/UserGuide/install-pre-built/#link-with-a-release-version", 
            "text": "Currently, BigDL releases are hosted on maven central; here's an example to add the BigDL dependency to your own project:  dependency \n     groupId com.intel.analytics.bigdl /groupId \n     artifactId bigdl /artifactId \n     version ${BIGDL_VERSION} /version  /dependency   SBT developers can use  libraryDependencies +=  com.intel.analytics.bigdl  %  bigdl  %  ${BIGDL_VERSION}   Since currently only BigDL 0.1.0 is released, ${BIGDL_VERSION} must be set to 0.1.0 here.  Note : the BigDL lib default supports Spark 1.5.x and 1.6.x; if your project runs on Spark 2.0 and 2.1, use this  dependency \n     groupId com.intel.analytics.bigdl /groupId \n     artifactId bigdl-SPARK_2.0 /artifactId \n     version ${BIGDL_VERSION} /version  /dependency   SBT developers can use  libraryDependencies +=  com.intel.analytics.bigdl  %  bigdl-SPARK_2.0  %  ${BIGDL_VERSION}   If your project runs on MacOS, you should add the dependency below,  dependency \n     groupId com.intel.analytics.bigdl.native /groupId \n     artifactId mkl-java-mac /artifactId \n     version ${BIGDL_VERSION} /version \n     exclusions \n         exclusion \n             groupId com.intel.analytics.bigdl.native /groupId \n             artifactId bigdl-native /artifactId \n         /exclusion \n     /exclusions  /dependency   SBT developers can use  libraryDependencies +=  com.intel.analytics.bigdl.native  %  mkl-java-mac  %  ${BIGDL_VERSION}  from  http://repo1.maven.org/maven2/com/intel/analytics/bigdl/native/mkl-java-mac/${BIGDL_VERSION}/mkl-java-mac-${BIGDL_VERSION}.jar", 
            "title": "Link with a release version"
        }, 
        {
            "location": "/UserGuide/install-pre-built/#link-with-a-development-version", 
            "text": "Currently, BigDL development version is hosted on  SonaType .   To link your application with the latest BigDL development version, you should add some dependencies like  Linking with BigDL releases , but set ${BIGDL_VERSION} to 0.2.0-SNAPSHOT, and add below repository to your pom.xml.  repository \n     id sonatype /id \n     name sonatype repository /name \n     url https://oss.sonatype.org/content/groups/public/ /url \n     releases \n         enabled true /enabled \n     /releases \n     snapshots \n         enabled true /enabled \n     /snapshots  /repository   SBT developers can use  resolvers +=  Sonatype OSS Snapshots  at  https://oss.sonatype.org/content/repositories/snapshots", 
            "title": "Link with a development version"
        }, 
        {
            "location": "/UserGuide/install-build-src/", 
            "text": "Download BigDL Source\n\n\nBigDL source code is available at \nGitHub\n\n\n$ git clone https://github.com/intel-analytics/BigDL.git\n\n\n\n\nBy default, \ngit clone\n will download the development version of BigDL, if you want a release version, you can use command \ngit checkout\n to change the version. Available release versions is \nBigDL releases\n.\n\n\nSetup Build Environment\n\n\nThe following instructions are aligned with master code.\n\n\nMaven 3 is needed to build BigDL, you can download it from the \nmaven website\n.\n\n\nAfter installing Maven 3, please set the environment variable MAVEN_OPTS as follows:\n\n\n$ export MAVEN_OPTS=\n-Xmx2g -XX:ReservedCodeCacheSize=512m\n\n\n\n\n\nWhen compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d. \n\n\nBuild with script (Recommended)\n\n\nIt is highly recommended that you build BigDL using the \nmake-dist.sh script\n. And it will handle the MAVEN_OPTS variable.\n\n\nOnce downloaded, you can build BigDL with the following commands:\n\n\n$ bash make-dist.sh\n\n\n\n\nAfter that, you can find a \ndist\n folder, which contains all the needed files to run a BigDL program. The files in \ndist\n include:\n\n\n\n\ndist/bin/bigdl.sh\n: A script used to set up proper environment variables and launch the BigDL program.\n\n\ndist/lib/bigdl-VERSION-jar-with-dependencies.jar\n: This jar package contains all dependencies except Spark classes.\n\n\ndist/lib/bigdl-VERSION-python-api.zip\n: This zip package contains all Python files of BigDL.\n\n\ndist/conf/spark-bigdl.conf\n: This file contains necessary property configurations. \nEngine.createSparkConf\n will populate these properties, so try to use that method in your code. Or you need to pass the file to Spark with the \"--properties-file\" option. \n\n\n\n\nBuild for MacOS\n\n\nThe instructions above will only build for Linux. To build BigDL for macOS, pass \n-P mac\n to the \nmake-dist.sh\n script as follows:\n\n\n$ bash make-dist.sh -P mac\n\n\n\n\nBuild for Windows\n\n\nTo build BigDL for Windows, pass \n-P win64\n to the build command:\n\n\n mvn clean package -DskipTests -P win64\n\n\n\n\nPlease note that we only test it on Windows 10\n\n\n\n\nBuild for Spark 2.0 and above\n\n\n\n\nThe instructions above will build BigDL with Spark 1.5.x or 1.6.x (using Scala 2.10); to build for Spark 2.0 and above (which uses Scala 2.11 by default), pass \n-P spark_2.x\n to the \nmake-dist.sh\n script:\n\n\n$ bash make-dist.sh -P spark_2.x\n\n\n\n\nIt is highly recommended to use \nJava 8\n when running with Spark 2.x; otherwise you may observe very poor performance.\n\n\nBuild for Scala 2.10 or 2.11\n\n\nBy default, \nmake-dist.sh\n uses Scala 2.10 for Spark 1.5.x or 1.6.x, and Scala 2.11 for Spark 2.0.x or 2.1.x. To override the default behaviors, you can pass \n-P scala_2.10\n or \n-P scala_2.11\n to \nmake-dist.sh\n as appropriate.\n\n\n\n\nBuild native libs\n\n\nNote that the instructions above will skip the build of native library code, and pull the corresponding libraries from Maven Central. If you want to build the the native library code by yourself, follow the steps below:\n\n\n\n\n\n\nDownload and install \nIntel Parallel Studio XE\n in your Linux box.\n\n\n\n\n\n\nPrepare build environment as follows:\n\n\n\n\n\n\n    $ source \ninstall-dir\n/bin/compilervars.sh intel64\n    $ source PATH_TO_MKL/bin/mklvars.sh intel64\n\n\n\n\nwhere the `PATH_TO_MKL` is the installation directory of the MKL.\n\n\n\n\n\nFull build\n\n\n\n\nClone BigDL as follows:\n\n\n   git clone git@github.com:intel-analytics/BigDL.git --recursive \n\n\n\n\nFor already cloned repos, just use:\n\n\n   git submodule update --init --recursive \n\n\n\n\nIf the Intel MKL is not installed to the default path \n/opt/intel\n, please pass your libiomp5.so's directory path to the \nmake-dist.sh\n script:\n\n\n   $ bash make-dist.sh -P full-build -DiompLibDir=\nPATH_TO_LIBIOMP5_DIR\n \n\n\n\n\nOtherwise, only pass \n-P full-build\n to the \nmake-dist.sh\n script:\n\n\n   $ bash make-dist.sh -P full-build\n\n\n\n\n\n\nBuild with Maven\n\n\nTo build BigDL directly using Maven, run the command below:\n\n\n$ mvn clean package -DskipTests\n\n\n\n\nAfter that, you can find that the three jar packages in \nPATH_To_BigDL\n/target/, where \nPATH_To_BigDL\n is the path to the directory of the BigDL. \n\n\nNote that the instructions above will build BigDL with Spark 1.5.x or 1.6.x (using Scala 2.10) for Linux, and skip the build of native library code. Similarly, you may customize the default behaviors by passing the following parameters to maven:\n\n\n\n\n-P mac\n: build for maxOS\n\n\n-P win64\n: build for windows\n\n\n-P spark_2.x\n: build for Spark 2.0 and above (using Scala 2.11). (Again, it is highly recommended to use \nJava 8\n when running with Spark 2.0; otherwise you may observe very poor performance.)\n\n\n-P full-build\n: full build\n\n\n-P scala_2.10\n (or \n-P scala_2.11\n): build using Scala 2.10 (or Scala 2.11) \n\n\n\n\n\n\nSetup IDE\n\n\nWe set the scope of spark related library to \nprovided\n in pom.xml. The reason is that we don't want package spark related jars which will make bigdl a huge jar, and generally as bigdl is invoked by spark-submit, these dependencies will be provided by spark at run-time.\n\n\nThis will cause a problem in IDE. When you run applications, it will throw \nNoClassDefFoundError\n because the library scope is \nprovided\n.\n\n\nYou can easily change the scopes by the \nall-in-one\n profile.\n\n\n\n\nIn Intellij, go to View -\n Tools Windows -\n Maven Projects. Then in the Maven Projects panel, Profiles -\n click \"all-in-one\".", 
            "title": "Build from Source Code"
        }, 
        {
            "location": "/UserGuide/install-build-src/#download-bigdl-source", 
            "text": "BigDL source code is available at  GitHub  $ git clone https://github.com/intel-analytics/BigDL.git  By default,  git clone  will download the development version of BigDL, if you want a release version, you can use command  git checkout  to change the version. Available release versions is  BigDL releases .", 
            "title": "Download BigDL Source"
        }, 
        {
            "location": "/UserGuide/install-build-src/#setup-build-environment", 
            "text": "The following instructions are aligned with master code.  Maven 3 is needed to build BigDL, you can download it from the  maven website .  After installing Maven 3, please set the environment variable MAVEN_OPTS as follows:  $ export MAVEN_OPTS= -Xmx2g -XX:ReservedCodeCacheSize=512m   When compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d.", 
            "title": "Setup Build Environment"
        }, 
        {
            "location": "/UserGuide/install-build-src/#build-with-script-recommended", 
            "text": "It is highly recommended that you build BigDL using the  make-dist.sh script . And it will handle the MAVEN_OPTS variable.  Once downloaded, you can build BigDL with the following commands:  $ bash make-dist.sh  After that, you can find a  dist  folder, which contains all the needed files to run a BigDL program. The files in  dist  include:   dist/bin/bigdl.sh : A script used to set up proper environment variables and launch the BigDL program.  dist/lib/bigdl-VERSION-jar-with-dependencies.jar : This jar package contains all dependencies except Spark classes.  dist/lib/bigdl-VERSION-python-api.zip : This zip package contains all Python files of BigDL.  dist/conf/spark-bigdl.conf : This file contains necessary property configurations.  Engine.createSparkConf  will populate these properties, so try to use that method in your code. Or you need to pass the file to Spark with the \"--properties-file\" option.", 
            "title": "Build with script (Recommended)"
        }, 
        {
            "location": "/UserGuide/install-build-src/#build-for-macos", 
            "text": "The instructions above will only build for Linux. To build BigDL for macOS, pass  -P mac  to the  make-dist.sh  script as follows:  $ bash make-dist.sh -P mac", 
            "title": "Build for MacOS"
        }, 
        {
            "location": "/UserGuide/install-build-src/#build-for-windows", 
            "text": "To build BigDL for Windows, pass  -P win64  to the build command:   mvn clean package -DskipTests -P win64  Please note that we only test it on Windows 10   Build for Spark 2.0 and above   The instructions above will build BigDL with Spark 1.5.x or 1.6.x (using Scala 2.10); to build for Spark 2.0 and above (which uses Scala 2.11 by default), pass  -P spark_2.x  to the  make-dist.sh  script:  $ bash make-dist.sh -P spark_2.x  It is highly recommended to use  Java 8  when running with Spark 2.x; otherwise you may observe very poor performance.", 
            "title": "Build for Windows"
        }, 
        {
            "location": "/UserGuide/install-build-src/#build-for-scala-210-or-211", 
            "text": "By default,  make-dist.sh  uses Scala 2.10 for Spark 1.5.x or 1.6.x, and Scala 2.11 for Spark 2.0.x or 2.1.x. To override the default behaviors, you can pass  -P scala_2.10  or  -P scala_2.11  to  make-dist.sh  as appropriate.", 
            "title": "Build for Scala 2.10 or 2.11"
        }, 
        {
            "location": "/UserGuide/install-build-src/#build-native-libs", 
            "text": "Note that the instructions above will skip the build of native library code, and pull the corresponding libraries from Maven Central. If you want to build the the native library code by yourself, follow the steps below:    Download and install  Intel Parallel Studio XE  in your Linux box.    Prepare build environment as follows:        $ source  install-dir /bin/compilervars.sh intel64\n    $ source PATH_TO_MKL/bin/mklvars.sh intel64  where the `PATH_TO_MKL` is the installation directory of the MKL.   Full build   Clone BigDL as follows:     git clone git@github.com:intel-analytics/BigDL.git --recursive   For already cloned repos, just use:     git submodule update --init --recursive   If the Intel MKL is not installed to the default path  /opt/intel , please pass your libiomp5.so's directory path to the  make-dist.sh  script:     $ bash make-dist.sh -P full-build -DiompLibDir= PATH_TO_LIBIOMP5_DIR    Otherwise, only pass  -P full-build  to the  make-dist.sh  script:     $ bash make-dist.sh -P full-build", 
            "title": "Build native libs"
        }, 
        {
            "location": "/UserGuide/install-build-src/#build-with-maven", 
            "text": "To build BigDL directly using Maven, run the command below:  $ mvn clean package -DskipTests  After that, you can find that the three jar packages in  PATH_To_BigDL /target/, where  PATH_To_BigDL  is the path to the directory of the BigDL.   Note that the instructions above will build BigDL with Spark 1.5.x or 1.6.x (using Scala 2.10) for Linux, and skip the build of native library code. Similarly, you may customize the default behaviors by passing the following parameters to maven:   -P mac : build for maxOS  -P win64 : build for windows  -P spark_2.x : build for Spark 2.0 and above (using Scala 2.11). (Again, it is highly recommended to use  Java 8  when running with Spark 2.0; otherwise you may observe very poor performance.)  -P full-build : full build  -P scala_2.10  (or  -P scala_2.11 ): build using Scala 2.10 (or Scala 2.11)", 
            "title": "Build with Maven"
        }, 
        {
            "location": "/UserGuide/install-build-src/#setup-ide", 
            "text": "We set the scope of spark related library to  provided  in pom.xml. The reason is that we don't want package spark related jars which will make bigdl a huge jar, and generally as bigdl is invoked by spark-submit, these dependencies will be provided by spark at run-time.  This will cause a problem in IDE. When you run applications, it will throw  NoClassDefFoundError  because the library scope is  provided .  You can easily change the scopes by the  all-in-one  profile.   In Intellij, go to View -  Tools Windows -  Maven Projects. Then in the Maven Projects panel, Profiles -  click \"all-in-one\".", 
            "title": "Setup IDE"
        }, 
        {
            "location": "/UserGuide/run/", 
            "text": "Use an Interactive Shell\n\n\nYou can try BigDL easily using the Spark interactive shell. Run below command to start spark shell with BigDL support:\n\n\n$ SPARK_HOME/bin/spark-shell --properties-file dist/conf/spark-bigdl.conf    \\\n  --jars bigdl-VERSION-jar-with-dependencies.jar\n\n\n\n\nYou will see a welcome message looking like below:\n\n\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala\n \n\n\n\n\nTo use BigDL, you should first initialize the engine as below. \n\n\nscala\nimport com.intel.analytics.bigdl.utils.Engine\nscala\nEngine.init\n\n\n\n\nOnce the engine is successfully initialted, you'll be able to play with BigDL API's. \nFor instance, to experiment with the \nTensor\n APIs in BigDL, you may try below code:\n\n\nscala\n import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nscala\n Tensor[Double](2,2).fill(1.0)\nres9: com.intel.analytics.bigdl.tensor.Tensor[Double] =\n1.0     1.0\n1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\n\n\nRun a BigDL Program\n\n\nYou can run a BigDL program, e.g., the \nVGG\n training, as a standard Spark program (running in either local mode or cluster mode) as follows:\n\n\n\n\nDownload the CIFAR-10 data from \nhere\n. Remember to choose the binary version.\n\n\n\n\n  # Spark local mode\n  spark-submit --master local[core_number] --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark standalone mode\n  spark-submit --master spark://... --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark yarn mode\n  spark-submit --master yarn --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n\n\n\nThe parameters used in the above command are:\n\n\n\n\n\n\n-f: The folder where your put the CIFAR-10 data set. Note in this example, this is just a local file folder on the Spark driver; as the CIFAR-10 data is somewhat small (about 120MB), we will directly send it from the driver to executors in the example.\n\n\n\n\n\n\n-b: The mini-batch size. The mini-batch size is expected to be a multiple of \ntotal cores\n used in the job. In this example, the mini-batch size is suggested to be set to \ntotal cores * 4\n\n\n\n\n\n\nIf you are to run your own program, do remember to create SparkContext and initialize the engine before call other BigDL API's, as shown below. \n\n\n // Scala code example\n val conf = Engine.createSparkConf()\n val sc = new SparkContext(conf)\n Engine.init", 
            "title": "Run"
        }, 
        {
            "location": "/UserGuide/run/#use-an-interactive-shell", 
            "text": "You can try BigDL easily using the Spark interactive shell. Run below command to start spark shell with BigDL support:  $ SPARK_HOME/bin/spark-shell --properties-file dist/conf/spark-bigdl.conf    \\\n  --jars bigdl-VERSION-jar-with-dependencies.jar  You will see a welcome message looking like below:  Welcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala    To use BigDL, you should first initialize the engine as below.   scala import com.intel.analytics.bigdl.utils.Engine\nscala Engine.init  Once the engine is successfully initialted, you'll be able to play with BigDL API's. \nFor instance, to experiment with the  Tensor  APIs in BigDL, you may try below code:  scala  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nscala  Tensor[Double](2,2).fill(1.0)\nres9: com.intel.analytics.bigdl.tensor.Tensor[Double] =\n1.0     1.0\n1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]", 
            "title": "Use an Interactive Shell"
        }, 
        {
            "location": "/UserGuide/run/#run-a-bigdl-program", 
            "text": "You can run a BigDL program, e.g., the  VGG  training, as a standard Spark program (running in either local mode or cluster mode) as follows:   Download the CIFAR-10 data from  here . Remember to choose the binary version.     # Spark local mode\n  spark-submit --master local[core_number] --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark standalone mode\n  spark-submit --master spark://... --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark yarn mode\n  spark-submit --master yarn --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size  The parameters used in the above command are:    -f: The folder where your put the CIFAR-10 data set. Note in this example, this is just a local file folder on the Spark driver; as the CIFAR-10 data is somewhat small (about 120MB), we will directly send it from the driver to executors in the example.    -b: The mini-batch size. The mini-batch size is expected to be a multiple of  total cores  used in the job. In this example, the mini-batch size is suggested to be set to  total cores * 4    If you are to run your own program, do remember to create SparkContext and initialize the engine before call other BigDL API's, as shown below.    // Scala code example\n val conf = Engine.createSparkConf()\n val sc = new SparkContext(conf)\n Engine.init", 
            "title": "Run a BigDL Program"
        }, 
        {
            "location": "/UserGuide/examples/", 
            "text": "This section is a short introduction of some classic examples/tutorials. They can give you a clear idea of how to build simple deep learning programs using BigDL. Besides these examples, BigDL also provides plenty of models ready for re-use and examples in both Scala and Python - refer to \nResources\n section for details. \n\n\n\n\nTraining LeNet on MNIST - The \"hello world\" for deep learning\n\n\nThis tutorial is an explanation of what is happening in the \nlenet\n example, which trains \nLeNet-5\n on the \nMNIST data\n using BigDL.\n\n\nA BigDL program starts with \nimport com.intel.analytics.bigdl._\n; it then \ncreates the \nSparkContext\n using the \nSparkConf\n returned by the \nEngine\n; after that, it \ninitializes the \nEngine\n.\n\n\n  val conf = Engine.createSparkConf()\n      .setAppName(\nTrain Lenet on MNIST\n)\n      .set(\nspark.task.maxFailures\n, \n1\n)\n  val sc = new SparkContext(conf)\n  Engine.init\n\n\n\n\nEngine.createSparkConf\n will return a \nSparkConf\n populated with some appropriate configuration. And \nEngine.init\n will verify and read some environment information(e.g. executor numbers and executor cores) from the \nSparkContext\n. You can find more information about the initialization in the \nProgramming Guilde\n\n\nAfter the initialization, we need to:\n\n\n\n\nCreate the LeNet model\n by calling the \nLeNet5()\n, which creates the LeNet-5 convolutional network model as follows:\n\n\n\n\n    val model = Sequential()\n    model.add(Reshape(Array(1, 28, 28)))\n      .add(SpatialConvolution(1, 6, 5, 5))\n      .add(Tanh())\n      .add(SpatialMaxPooling(2, 2, 2, 2))\n      .add(Tanh())\n      .add(SpatialConvolution(6, 12, 5, 5))\n      .add(SpatialMaxPooling(2, 2, 2, 2))\n      .add(Reshape(Array(12 * 4 * 4)))\n      .add(Linear(12 * 4 * 4, 100))\n      .add(Tanh())\n      .add(Linear(100, classNum))\n      .add(LogSoftMax())\n\n\n\n\n\n\nLoad the data by \ncreating the \nDataSet\n (either a distributed or local one depending on whether it runs on Spark or not), and then \napplying a series of \nTransformer\n (e.g., \nSampleToGreyImg\n, \nGreyImgNormalizer\n and \nGreyImgToBatch\n):\n\n\n\n\n    val trainSet = (if (sc.isDefined) {\n        DataSet.array(load(trainData, trainLabel), sc.get, param.nodeNumber)\n      } else {\n        DataSet.array(load(trainData, trainLabel))\n      }) -\n SampleToGreyImg(28, 28) -\n GreyImgNormalizer(trainMean, trainStd) -\n GreyImgToBatch(\n        param.batchSize)\n\n\n\n\nAfter that, we \ncreate the \nOptimizer\n (either a distributed or local one depending on whether it runs on Spark or not) by specifying the \nDataSet\n, the model and the \nCriterion\n (which, given input and target, computes gradient per given loss function):\n\n\n  val optimizer = Optimizer(\n    model = model,\n    dataset = trainSet,\n    criterion = ClassNLLCriterion[Float]())\n\n\n\n\nFinally (after optionally specifying the validation data and methods for the \nOptimizer\n), we \ntrain the model by calling \nOptimizer.optimize()\n:\n\n\n  optimizer\n    .setValidation(\n      trigger = Trigger.everyEpoch,\n      dataset = validationSet,\n      vMethods = Array(new Top1Accuracy))\n    .setState(state)\n    .setEndWhen(Trigger.maxEpoch(param.maxEpoch))\n    .optimize()\n\n\n\n\n\n\nText Classification - Working with Spark RDD\n\n\nThis tutorial describes the \ntext_classification\n example, which builds a text classifier using a simple convolutional neural network (CNN) model. (It was first described by \nthis Keras tutorial\n).\n\n\nAfter importing \ncom.intel.analytics.bigdl._\n and some initialization, the \nexample\n broadcasts the pre-trained world embedding and loads the input data using RDD transformations:\n\n\n  // For large dataset, you might want to get such RDD[(String, Float)] from HDFS\n  val dataRdd = sc.parallelize(loadRawData(), param.partitionNum)\n  val (word2Meta, word2Vec) = analyzeTexts(dataRdd)\n  val word2MetaBC = sc.broadcast(word2Meta)\n  val word2VecBC = sc.broadcast(word2Vec)\n  val vectorizedRdd = dataRdd\n      .map {case (text, label) =\n (toTokens(text, word2MetaBC.value), label)}\n      .map {case (tokens, label) =\n (shaping(tokens, sequenceLen), label)}\n      .map {case (tokens, label) =\n (vectorization(\n        tokens, embeddingDim, word2VecBC.value), label)}\n\n\n\n\nThe \nexample\n then converts the processed data (\nvectorizedRdd\n) to an RDD of Sample, and randomly splits the sample RDD (\nsampleRDD\n) into training data (\ntrainingRDD\n) and validation data (\nvalRDD\n):\n\n\n  val sampleRDD = vectorizedRdd.map {case (input: Array[Array[Float]], label: Float) =\n\n        Sample(\n          featureTensor = Tensor(input.flatten, Array(sequenceLen, embeddingDim))\n            .transpose(1, 2).contiguous(),\n          labelTensor = Tensor(Array(label), Array(1)))\n      }\n\n  val Array(trainingRDD, valRDD) = sampleRDD.randomSplit(\n    Array(trainingSplit, 1 - trainingSplit))\n\n\n\n\nAfter that, the \nexample\n builds the CNN model, creates the \nOptimizer\n, pass the RDD of training data (\ntrainingRDD\n) to the \nOptimizer\n (with specific batch size), and finally trains the model (using \nAdagrad\n as the optimization method, and setting relevant hyper parameters in \nstate\n):\n\n\n  val optimizer = Optimizer(\n    model = buildModel(classNum),\n    sampleRDD = trainingRDD,\n    criterion = new ClassNLLCriterion[Float](),\n    batchSize = param.batchSize\n  )\n  val state = T(\nlearningRate\n -\n 0.01, \nlearningRateDecay\n -\n 0.0002)\n  optimizer\n    .setState(state)\n    .setOptimMethod(new Adagrad())\n    .setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy[Float]), param.batchSize)\n    .setEndWhen(Trigger.maxEpoch(2))\n    .optimize()\n\n\n\n\n\n\nImage Classification\n - Working with Spark DataFrame and ML pipeline\n\n\nThis tutorial describes the \nimage_classification\n example, which loads a BigDL (\nInception\n) model or Torch (\nResnet\n) model that is trained on \nImageNet\n data, and then applies the loaded model to predict the contents of a set of images using BigDL and Spark \nML pipeline\n.\n\n\nAfter importing \ncom.intel.analytics.bigdl._\n and some initialization, the \nexample\n first \nloads\n the specified model:\n\n\n  def loadModel[@specialized(Float, Double) T : ClassTag](param : PredictParams)\n    (implicit ev: TensorNumeric[T]): Module[T] = {\n    val model = param.modelType match {\n      case TorchModel =\n\n        Module.loadTorch[T](param.modelPath)\n      case BigDlModel =\n\n        Module.load[T](param.modelPath)\n      case _ =\n throw new IllegalArgumentException(s\n${param.modelType}\n)\n    }\n    model\n  }\n\n\n\n\nIt then creates \nDLClassifer\n (a Spark ML pipelines \nTransformer\n) that predicts the input value based on the specified deep learning model:\n\n\n  val model = loadModel(param)\n  val valTrans = new DLClassifier()\n    .setInputCol(\nfeatures\n)\n    .setOutputCol(\npredict\n)\n\n  val paramsTrans = ParamMap(\n    valTrans.modelTrain -\n model,\n    valTrans.batchShape -\n\n    Array(param.batchSize, 3, imageSize, imageSize))\n\n\n\n\nAfter that, the \nexample\n  loads the input images into a \nDataFrame\n, and then predicts the class of each each image using the \nDLClassifer\n:\n\n\n  val valRDD = sc.parallelize(imageSet).repartition(partitionNum)\n  val transf = RowToByteRecords() -\n\n      SampleToBGRImg() -\n\n      BGRImgCropper(imageSize, imageSize) -\n\n      BGRImgNormalizer(testMean, testStd) -\n\n      BGRImgToImageVector()\n\n  val valDF = transformDF(sqlContext.createDataFrame(valRDD), transf)\n\n  valTrans.transform(valDF, paramsTrans)\n      .select(\nimageName\n, \npredict\n)\n      .show(param.showNum)", 
            "title": "Examples"
        }, 
        {
            "location": "/UserGuide/examples/#training-lenet-on-mnist-the-hello-world-for-deep-learning", 
            "text": "This tutorial is an explanation of what is happening in the  lenet  example, which trains  LeNet-5  on the  MNIST data  using BigDL.  A BigDL program starts with  import com.intel.analytics.bigdl._ ; it then  creates the  SparkContext  using the  SparkConf  returned by the  Engine ; after that, it  initializes the  Engine .    val conf = Engine.createSparkConf()\n      .setAppName( Train Lenet on MNIST )\n      .set( spark.task.maxFailures ,  1 )\n  val sc = new SparkContext(conf)\n  Engine.init  Engine.createSparkConf  will return a  SparkConf  populated with some appropriate configuration. And  Engine.init  will verify and read some environment information(e.g. executor numbers and executor cores) from the  SparkContext . You can find more information about the initialization in the  Programming Guilde  After the initialization, we need to:   Create the LeNet model  by calling the  LeNet5() , which creates the LeNet-5 convolutional network model as follows:       val model = Sequential()\n    model.add(Reshape(Array(1, 28, 28)))\n      .add(SpatialConvolution(1, 6, 5, 5))\n      .add(Tanh())\n      .add(SpatialMaxPooling(2, 2, 2, 2))\n      .add(Tanh())\n      .add(SpatialConvolution(6, 12, 5, 5))\n      .add(SpatialMaxPooling(2, 2, 2, 2))\n      .add(Reshape(Array(12 * 4 * 4)))\n      .add(Linear(12 * 4 * 4, 100))\n      .add(Tanh())\n      .add(Linear(100, classNum))\n      .add(LogSoftMax())   Load the data by  creating the  DataSet  (either a distributed or local one depending on whether it runs on Spark or not), and then  applying a series of  Transformer  (e.g.,  SampleToGreyImg ,  GreyImgNormalizer  and  GreyImgToBatch ):       val trainSet = (if (sc.isDefined) {\n        DataSet.array(load(trainData, trainLabel), sc.get, param.nodeNumber)\n      } else {\n        DataSet.array(load(trainData, trainLabel))\n      }) -  SampleToGreyImg(28, 28) -  GreyImgNormalizer(trainMean, trainStd) -  GreyImgToBatch(\n        param.batchSize)  After that, we  create the  Optimizer  (either a distributed or local one depending on whether it runs on Spark or not) by specifying the  DataSet , the model and the  Criterion  (which, given input and target, computes gradient per given loss function):    val optimizer = Optimizer(\n    model = model,\n    dataset = trainSet,\n    criterion = ClassNLLCriterion[Float]())  Finally (after optionally specifying the validation data and methods for the  Optimizer ), we  train the model by calling  Optimizer.optimize() :    optimizer\n    .setValidation(\n      trigger = Trigger.everyEpoch,\n      dataset = validationSet,\n      vMethods = Array(new Top1Accuracy))\n    .setState(state)\n    .setEndWhen(Trigger.maxEpoch(param.maxEpoch))\n    .optimize()", 
            "title": "Training LeNet on MNIST - The \"hello world\" for deep learning"
        }, 
        {
            "location": "/UserGuide/examples/#text-classification-working-with-spark-rdd", 
            "text": "This tutorial describes the  text_classification  example, which builds a text classifier using a simple convolutional neural network (CNN) model. (It was first described by  this Keras tutorial ).  After importing  com.intel.analytics.bigdl._  and some initialization, the  example  broadcasts the pre-trained world embedding and loads the input data using RDD transformations:    // For large dataset, you might want to get such RDD[(String, Float)] from HDFS\n  val dataRdd = sc.parallelize(loadRawData(), param.partitionNum)\n  val (word2Meta, word2Vec) = analyzeTexts(dataRdd)\n  val word2MetaBC = sc.broadcast(word2Meta)\n  val word2VecBC = sc.broadcast(word2Vec)\n  val vectorizedRdd = dataRdd\n      .map {case (text, label) =  (toTokens(text, word2MetaBC.value), label)}\n      .map {case (tokens, label) =  (shaping(tokens, sequenceLen), label)}\n      .map {case (tokens, label) =  (vectorization(\n        tokens, embeddingDim, word2VecBC.value), label)}  The  example  then converts the processed data ( vectorizedRdd ) to an RDD of Sample, and randomly splits the sample RDD ( sampleRDD ) into training data ( trainingRDD ) and validation data ( valRDD ):    val sampleRDD = vectorizedRdd.map {case (input: Array[Array[Float]], label: Float) = \n        Sample(\n          featureTensor = Tensor(input.flatten, Array(sequenceLen, embeddingDim))\n            .transpose(1, 2).contiguous(),\n          labelTensor = Tensor(Array(label), Array(1)))\n      }\n\n  val Array(trainingRDD, valRDD) = sampleRDD.randomSplit(\n    Array(trainingSplit, 1 - trainingSplit))  After that, the  example  builds the CNN model, creates the  Optimizer , pass the RDD of training data ( trainingRDD ) to the  Optimizer  (with specific batch size), and finally trains the model (using  Adagrad  as the optimization method, and setting relevant hyper parameters in  state ):    val optimizer = Optimizer(\n    model = buildModel(classNum),\n    sampleRDD = trainingRDD,\n    criterion = new ClassNLLCriterion[Float](),\n    batchSize = param.batchSize\n  )\n  val state = T( learningRate  -  0.01,  learningRateDecay  -  0.0002)\n  optimizer\n    .setState(state)\n    .setOptimMethod(new Adagrad())\n    .setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy[Float]), param.batchSize)\n    .setEndWhen(Trigger.maxEpoch(2))\n    .optimize()", 
            "title": "Text Classification - Working with Spark RDD"
        }, 
        {
            "location": "/UserGuide/examples/#image-classification-working-with-spark-dataframe-and-ml-pipeline", 
            "text": "This tutorial describes the  image_classification  example, which loads a BigDL ( Inception ) model or Torch ( Resnet ) model that is trained on  ImageNet  data, and then applies the loaded model to predict the contents of a set of images using BigDL and Spark  ML pipeline .  After importing  com.intel.analytics.bigdl._  and some initialization, the  example  first  loads  the specified model:    def loadModel[@specialized(Float, Double) T : ClassTag](param : PredictParams)\n    (implicit ev: TensorNumeric[T]): Module[T] = {\n    val model = param.modelType match {\n      case TorchModel = \n        Module.loadTorch[T](param.modelPath)\n      case BigDlModel = \n        Module.load[T](param.modelPath)\n      case _ =  throw new IllegalArgumentException(s ${param.modelType} )\n    }\n    model\n  }  It then creates  DLClassifer  (a Spark ML pipelines  Transformer ) that predicts the input value based on the specified deep learning model:    val model = loadModel(param)\n  val valTrans = new DLClassifier()\n    .setInputCol( features )\n    .setOutputCol( predict )\n\n  val paramsTrans = ParamMap(\n    valTrans.modelTrain -  model,\n    valTrans.batchShape - \n    Array(param.batchSize, 3, imageSize, imageSize))  After that, the  example   loads the input images into a  DataFrame , and then predicts the class of each each image using the  DLClassifer :    val valRDD = sc.parallelize(imageSet).repartition(partitionNum)\n  val transf = RowToByteRecords() - \n      SampleToBGRImg() - \n      BGRImgCropper(imageSize, imageSize) - \n      BGRImgNormalizer(testMean, testStd) - \n      BGRImgToImageVector()\n\n  val valDF = transformDF(sqlContext.createDataFrame(valRDD), transf)\n\n  valTrans.transform(valDF, paramsTrans)\n      .select( imageName ,  predict )\n      .show(param.showNum)", 
            "title": "Image Classification - Working with Spark DataFrame and ML pipeline"
        }, 
        {
            "location": "/UserGuide/resources/", 
            "text": "Scala Models\n\n\nBigDL provides loads of popular models ready for use in your application. Some of them are listed blow. See all in \nscala neural network models\n. \n\n\n\n\nLeNet\n: it demonstrates how to use BigDL to train and evaluate the \nLeNet-5\n network on MNIST data.\n\n\nInception\n: it demonstrates how to use BigDL to train and evaluate \nInception v1\n and \nInception v2\n architecture on the ImageNet data.\n\n\nVGG\n: it demonstrates how to use BigDL to train and evaluate a \nVGG-like\n network on CIFAR-10 data.\n\n\nResNet\n: it demonstrates how to use BigDL to train and evaluate the \nResNet\n architecture on CIFAR-10 data.\n\n\nRNN\n: it demonstrates how to use BigDL to build and train a simple recurrent neural network \n(RNN) for language model\n.\n\n\nAuto-encoder\n: it demonstrates how to use BigDL to build and train a basic fully-connected autoencoder using MNIST data.\n\n\n\n\n\n\nScala Examples\n\n\nBigDL ships plenty of Scala examples to show how to use BigDL to solve real problems. Some are listed blow. See all of them in \nscala deep learning examples\n \n\n\n\n\ntext_classification\n: it demonstrates how to use BigDL to build a \ntext classifier\n using a simple convolutional neural network (CNN) model.\n\n\nimage_classification\n: it demonstrates how to load a BigDL or \nTorch\n model trained on ImageNet data (e.g., \nInception\n or \nResNet\n), and then applies the loaded model to classify the contents of a set of images in Spark ML pipeline.\n\n\nload_model\n: it demonstrates how to use BigDL to load a pre-trained \nTorch\n or \nCaffe\n model into Spark program for prediction.", 
            "title": "More Resources"
        }, 
        {
            "location": "/UserGuide/resources/#scala-models", 
            "text": "BigDL provides loads of popular models ready for use in your application. Some of them are listed blow. See all in  scala neural network models .    LeNet : it demonstrates how to use BigDL to train and evaluate the  LeNet-5  network on MNIST data.  Inception : it demonstrates how to use BigDL to train and evaluate  Inception v1  and  Inception v2  architecture on the ImageNet data.  VGG : it demonstrates how to use BigDL to train and evaluate a  VGG-like  network on CIFAR-10 data.  ResNet : it demonstrates how to use BigDL to train and evaluate the  ResNet  architecture on CIFAR-10 data.  RNN : it demonstrates how to use BigDL to build and train a simple recurrent neural network  (RNN) for language model .  Auto-encoder : it demonstrates how to use BigDL to build and train a basic fully-connected autoencoder using MNIST data.", 
            "title": "Scala Models"
        }, 
        {
            "location": "/UserGuide/resources/#scala-examples", 
            "text": "BigDL ships plenty of Scala examples to show how to use BigDL to solve real problems. Some are listed blow. See all of them in  scala deep learning examples     text_classification : it demonstrates how to use BigDL to build a  text classifier  using a simple convolutional neural network (CNN) model.  image_classification : it demonstrates how to load a BigDL or  Torch  model trained on ImageNet data (e.g.,  Inception  or  ResNet ), and then applies the loaded model to classify the contents of a set of images in Spark ML pipeline.  load_model : it demonstrates how to use BigDL to load a pre-trained  Torch  or  Caffe  model into Spark program for prediction.", 
            "title": "Scala Examples"
        }, 
        {
            "location": "/PythonSupport/python-install/", 
            "text": "Use Python without pip Install\n\n\nYou can use Python without pip install. Pip install only supports certain Spark versions and platforms now. You can always use Python this way if pip support is missing.   \n\n\nFirst of all, you need to obtain the BigDL libs. You can either download pre-built libs or build from source code. Refer to \nUse pre-built libs\n and \nBuild from Source\n for details. \n\n\nThen you can either use an interactive shell, run a python program on commandline, or use jupyter notebook. Refer to below sections for details. \n\n\n\n\nUse an interactive shell (without pip install)\n\n\nRun Python program on Commandline (without pip install)\n\n\nUse Jupyter notebook (without pip install)\n\n\n\n\n\n\nInstall BigDL-0.1.2 via pip\n\n\n1.Download Spark1.6.3:  \n\n\nwget https://d3kbcqa49mib13.cloudfront.net/spark-1.6.3-bin-hadoop2.6.tgz \n\n\n\n\n2.Extract the tar ball and set SPARK_HOME\n\n\ntar -zxvf spark-1.6.3-bin-hadoop2.6.tgz\nexport SPARK_HOME=path to spark-1.6.3-bin-hadoop2.6.tgz\n\n\n\n\n3.Install BigDL release via pip (we tested this on pip 9.0.1)\n\n\npip install --upgrade pip\npip install BigDL==0.1.2     # for Python 2.7\npip3 install BigDL==0.1.2  # for Python 3.n\n\n\n\n\nInstall BigDL-0.2.0-snapshot\n\n\n1.Download Spark1.6.3:  \n\n\nget https://d3kbcqa49mib13.cloudfront.net/spark-1.6.3-bin-hadoop2.6.tgz\n\n\n\n\n2.Extract the tar ball and set SPARK_HOME\n\n\ntar -zxvf spark-1.6.3-bin-hadoop2.6.tgz\nexport SPARK_HOME=path to spark-1.6.3-bin-hadoop2.6\n\n\n\n\n3.Install BigDL release via pip (we tested this on pip 9.0.1)\n\n\npip install --upgrade pip\npip install BigDL==0.2.0.dev3     # for Python 2.7\npip3 install BigDL==0.2.0.dev3  # for Python 3.n", 
            "title": "Install"
        }, 
        {
            "location": "/PythonSupport/python-install/#use-python-without-pip-install", 
            "text": "You can use Python without pip install. Pip install only supports certain Spark versions and platforms now. You can always use Python this way if pip support is missing.     First of all, you need to obtain the BigDL libs. You can either download pre-built libs or build from source code. Refer to  Use pre-built libs  and  Build from Source  for details.   Then you can either use an interactive shell, run a python program on commandline, or use jupyter notebook. Refer to below sections for details.    Use an interactive shell (without pip install)  Run Python program on Commandline (without pip install)  Use Jupyter notebook (without pip install)", 
            "title": "Use Python without pip Install"
        }, 
        {
            "location": "/PythonSupport/python-install/#install-bigdl-012-via-pip", 
            "text": "1.Download Spark1.6.3:    wget https://d3kbcqa49mib13.cloudfront.net/spark-1.6.3-bin-hadoop2.6.tgz   2.Extract the tar ball and set SPARK_HOME  tar -zxvf spark-1.6.3-bin-hadoop2.6.tgz\nexport SPARK_HOME=path to spark-1.6.3-bin-hadoop2.6.tgz  3.Install BigDL release via pip (we tested this on pip 9.0.1)  pip install --upgrade pip\npip install BigDL==0.1.2     # for Python 2.7\npip3 install BigDL==0.1.2  # for Python 3.n", 
            "title": "Install BigDL-0.1.2 via pip"
        }, 
        {
            "location": "/PythonSupport/python-install/#install-bigdl-020-snapshot", 
            "text": "1.Download Spark1.6.3:    get https://d3kbcqa49mib13.cloudfront.net/spark-1.6.3-bin-hadoop2.6.tgz  2.Extract the tar ball and set SPARK_HOME  tar -zxvf spark-1.6.3-bin-hadoop2.6.tgz\nexport SPARK_HOME=path to spark-1.6.3-bin-hadoop2.6  3.Install BigDL release via pip (we tested this on pip 9.0.1)  pip install --upgrade pip\npip install BigDL==0.2.0.dev3     # for Python 2.7\npip3 install BigDL==0.2.0.dev3  # for Python 3.n", 
            "title": "Install BigDL-0.2.0-snapshot"
        }, 
        {
            "location": "/PythonSupport/python-run/", 
            "text": "Use an Interactive Shell (W/ pip install)\n\n\n\n\ntype \npython\n in commandline to start a REPL\n\n\ninitialize bigdl engine as below, and you'll be able to play with BigDL\n\n\n\n\n \n from bigdl.util.common import *\n \n init_engine()\n \n import bigdl.version\n \n bigdl.version.__version__\n '0.1.1rc0'\n \n from bigdl.nn.layer import *\n \n linear = Linear(2, 3)\n creating: createLinear\n \n ... \n\n\n\n\n\n\nUser an Interactive Shell (W/O pip install)\n\n\n1.Set some environmental variables. Replace SPARK_HOME, BigDL_HOME and BigDL_version, and etc. according to your actual configurations. \n\n\nBigDL_HOME=...\nexport BigDL_version=bigdl-0.2.0-SNAPSHOT\nSPARK_HOME=...\nspark.master=local[2]\n\nexport PYTHONPATH=SPARK_HOME/python/lib/pyspark.zip:SPARK_HOME/python/lib/py4j-0.9-src.zip:BigDL_HOME/spark/dl/src/main/resources/spark-bigdl.conf:${BigDL_HOME}/dist/lib/${BigDL_version}-python-api.zip\nSPARK_CLASSPATH=BigDL_HOME/spark/dl/target/${BigDL_version}-jar-with-dependencies.jar\n\n\n\n\n2.source bigdl.sh and set some environmental variables for BigDL. \n\n\nsource ${BigDL_HOME}/dist/bin/bigdl.sh  \n\n\n\n\n3.start python shell\n\n\n4.Initialize the engine as below and you'll be able to play with BigDL. \n\n\n  \n from bigdl.util.common import *\n  \n init_engine()\n  \n import bigdl.version\n  \n from bigdl.nn.layer import *\n  \n linear = Linear(2, 3)\n  creating: createLinear\n  \n ...\n\n\n\n\n\n\nRun Python Program in Command Line (W/O pip install)\n\n\nA BigDL Python program runs as a standard PySPark program, which requires all Python dependency (e.g., NumPy) used by the program be installed on each node in the Spark cluster. You can try run the BigDL \nlenet Python example\n using \nspark-submit\n as follows:\n\n\nPYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-python-api.zip\nBigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-jar-with-dependencies.jar\nPYTHONPATH=${PYTHON_API_ZIP_PATH}:$PYTHONPATH\n\n${SPARK_HOME}/bin/spark-submit \\\n    --master ${MASTER} \\\n    --driver-memory 10g  \\\n    --driver-cores 4  \\\n    --executor-memory 20g \\\n    --total-executor-cores ${TOTAL_CORES}\\\n    --executor-cores 10 ${EXECUTOR_CORES} \\\n    --py-files ${PYTHON_API_PATH},${BigDL_HOME}/pyspark/dl/models/lenet/lenet5.py  \\\n    --properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \\\n    --jars ${BigDL_JAR_PATH} \\\n    --conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \\\n    --conf spark.executor.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \\\n    ${BigDL_HOME}/pyspark/dl/models/lenet/lenet5.py\n\n\n\n\nIf you are writing your own program, remember to create Spark context and initialize engine before calling any BigDL API's, as below.\n\n\nfrom bigdl.util.common import *\n# Python code example\nconf=create_spark_conf()\nsc = SparkContext(conf)\ninit_engine()\n\n\n\n\n\n\nUse Jupyter Notebook (W/ pip install)\n\n\n\n\nStart jupyter notebook as you normally did, e.g.\n\n\n\n\njupyter notebook --notebook-dir=./ --ip=* --no-browser\n\n\n\n\n\n\nCreate SparkContext and initialize BigDL engine as below\n\n\n\n\nfrom bigdl.util.common import *\ninit_engine()\n\nfrom bigdl.nn.layer import *\nlinear = Linear(2, 3)\n...\n\n\n\n\nSometimes you may need to use SparkContext's \nparallelize\n method to convert local data into an RDD. You can get SparkContext in below way.\n\n\nfrom bigdl.util.common import *\nsc = get_spark_context()\n# sc.parallelize(...)\n\n\n\n\n\n\nUse Jupyter Notebook (W/O pip install)\n\n\nWith the full Python API support in BigDL, users can now use BigDL together with powerful notebooks (such as Jupyter notebook) in a distributed fashion across the cluster, combining Python libraries, Spark SQL / dataframes and MLlib, deep learning models in BigDL, as well as interactive visualization tools.\n\n\nFirst, install all the necessary libraries on the local node where you will run Jupyter, e.g., \n\n\nsudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud\n\n\n\n\nThen, you can launch the Jupyter notebook as follows:\n\n\nPYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-0.1.0-python-api.zip\nBigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-0.1.0-jar-with-dependencies.jar\n\nexport PYTHONPATH=${PYTHON_API_PATH}:$PYTHONPATH\nexport PYSPARK_DRIVER_PYTHON=jupyter\nexport PYSPARK_DRIVER_PYTHON_OPTS=\nnotebook --notebook-dir=./ --ip=* --no-browser\n\n\n${SPARK_HOME}/bin/pyspark \\\n  --master ${MASTER} \\\n  --properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \\\n  --driver-memory 10g  \\\n  --driver-cores 4  \\\n  --executor-memory 20g \\\n  --total-executor-cores {TOTAL_CORES} \\\n  --executor-cores {EXECUTOR_CORES} \\\n  --py-files ${PYTHON_API_PATH} \\\n  --jars ${BigDL_JAR_PATH} \\\n  --conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \\\n  --conf spark.executor.extraClassPath=bigdl-0.1.0-jar-with-dependencies.jar\n\n\n\n\nAfter successfully launching Jupyter, you will be able to navigate to the notebook dashboard using your browser. You can find the exact URL in the console output when you started Jupyter; by default, the dashboard URL is http://your_node:8888/\n\n\nNow you can create a blank notebook and start some coding. \n\n\nRemember to initialize BigDL engine before calling BigDL API's, as shown below.\n\n\nfrom bigdl.util.common import *\ninit_engine()\n\nfrom bigdl.nn.layer import *\nlinear = Linear(2, 3)\n...\n\n\n\n\nSometimes you may need to use SparkContext's \nparallelize\n method to convert local    data into an RDD. You can get SparkContext in below way.\n\n\nfrom bigdl.util.common import *\nsc = get_spark_context()\n# sc.parallelize(...)\n\n\n\n\n\n\nUse Python on YARN cluster\n\n\nYou can run BigDL Python programs on YARN clusters without changes to the cluster (e.g., no need to pre-install the      Python dependency). You  can first package all the required Python dependency into a virtual environment on the local    node (where you will run the spark-submit command), and then directly use spark-submit to run the BigDL Python program   on the YARN cluster (using that virtual environment). Please refer to this \npatch\n for more details.", 
            "title": "Run"
        }, 
        {
            "location": "/PythonSupport/python-run/#use-an-interactive-shell-w-pip-install", 
            "text": "type  python  in commandline to start a REPL  initialize bigdl engine as below, and you'll be able to play with BigDL      from bigdl.util.common import *\n   init_engine()\n   import bigdl.version\n   bigdl.version.__version__\n '0.1.1rc0'\n   from bigdl.nn.layer import *\n   linear = Linear(2, 3)\n creating: createLinear\n   ...", 
            "title": "Use an Interactive Shell (W/ pip install)"
        }, 
        {
            "location": "/PythonSupport/python-run/#user-an-interactive-shell-wo-pip-install", 
            "text": "1.Set some environmental variables. Replace SPARK_HOME, BigDL_HOME and BigDL_version, and etc. according to your actual configurations.   BigDL_HOME=...\nexport BigDL_version=bigdl-0.2.0-SNAPSHOT\nSPARK_HOME=...\nspark.master=local[2]\n\nexport PYTHONPATH=SPARK_HOME/python/lib/pyspark.zip:SPARK_HOME/python/lib/py4j-0.9-src.zip:BigDL_HOME/spark/dl/src/main/resources/spark-bigdl.conf:${BigDL_HOME}/dist/lib/${BigDL_version}-python-api.zip\nSPARK_CLASSPATH=BigDL_HOME/spark/dl/target/${BigDL_version}-jar-with-dependencies.jar  2.source bigdl.sh and set some environmental variables for BigDL.   source ${BigDL_HOME}/dist/bin/bigdl.sh    3.start python shell  4.Initialize the engine as below and you'll be able to play with BigDL.       from bigdl.util.common import *\n    init_engine()\n    import bigdl.version\n    from bigdl.nn.layer import *\n    linear = Linear(2, 3)\n  creating: createLinear\n    ...", 
            "title": "User an Interactive Shell (W/O pip install)"
        }, 
        {
            "location": "/PythonSupport/python-run/#run-python-program-in-command-line-wo-pip-install", 
            "text": "A BigDL Python program runs as a standard PySPark program, which requires all Python dependency (e.g., NumPy) used by the program be installed on each node in the Spark cluster. You can try run the BigDL  lenet Python example  using  spark-submit  as follows:  PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-python-api.zip\nBigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-jar-with-dependencies.jar\nPYTHONPATH=${PYTHON_API_ZIP_PATH}:$PYTHONPATH\n\n${SPARK_HOME}/bin/spark-submit \\\n    --master ${MASTER} \\\n    --driver-memory 10g  \\\n    --driver-cores 4  \\\n    --executor-memory 20g \\\n    --total-executor-cores ${TOTAL_CORES}\\\n    --executor-cores 10 ${EXECUTOR_CORES} \\\n    --py-files ${PYTHON_API_PATH},${BigDL_HOME}/pyspark/dl/models/lenet/lenet5.py  \\\n    --properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \\\n    --jars ${BigDL_JAR_PATH} \\\n    --conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \\\n    --conf spark.executor.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \\\n    ${BigDL_HOME}/pyspark/dl/models/lenet/lenet5.py  If you are writing your own program, remember to create Spark context and initialize engine before calling any BigDL API's, as below.  from bigdl.util.common import *\n# Python code example\nconf=create_spark_conf()\nsc = SparkContext(conf)\ninit_engine()", 
            "title": "Run Python Program in Command Line (W/O pip install)"
        }, 
        {
            "location": "/PythonSupport/python-run/#use-jupyter-notebook-w-pip-install", 
            "text": "Start jupyter notebook as you normally did, e.g.   jupyter notebook --notebook-dir=./ --ip=* --no-browser   Create SparkContext and initialize BigDL engine as below   from bigdl.util.common import *\ninit_engine()\n\nfrom bigdl.nn.layer import *\nlinear = Linear(2, 3)\n...  Sometimes you may need to use SparkContext's  parallelize  method to convert local data into an RDD. You can get SparkContext in below way.  from bigdl.util.common import *\nsc = get_spark_context()\n# sc.parallelize(...)", 
            "title": "Use Jupyter Notebook (W/ pip install)"
        }, 
        {
            "location": "/PythonSupport/python-run/#use-jupyter-notebook-wo-pip-install", 
            "text": "With the full Python API support in BigDL, users can now use BigDL together with powerful notebooks (such as Jupyter notebook) in a distributed fashion across the cluster, combining Python libraries, Spark SQL / dataframes and MLlib, deep learning models in BigDL, as well as interactive visualization tools.  First, install all the necessary libraries on the local node where you will run Jupyter, e.g.,   sudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud  Then, you can launch the Jupyter notebook as follows:  PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-0.1.0-python-api.zip\nBigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-0.1.0-jar-with-dependencies.jar\n\nexport PYTHONPATH=${PYTHON_API_PATH}:$PYTHONPATH\nexport PYSPARK_DRIVER_PYTHON=jupyter\nexport PYSPARK_DRIVER_PYTHON_OPTS= notebook --notebook-dir=./ --ip=* --no-browser \n\n${SPARK_HOME}/bin/pyspark \\\n  --master ${MASTER} \\\n  --properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \\\n  --driver-memory 10g  \\\n  --driver-cores 4  \\\n  --executor-memory 20g \\\n  --total-executor-cores {TOTAL_CORES} \\\n  --executor-cores {EXECUTOR_CORES} \\\n  --py-files ${PYTHON_API_PATH} \\\n  --jars ${BigDL_JAR_PATH} \\\n  --conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \\\n  --conf spark.executor.extraClassPath=bigdl-0.1.0-jar-with-dependencies.jar  After successfully launching Jupyter, you will be able to navigate to the notebook dashboard using your browser. You can find the exact URL in the console output when you started Jupyter; by default, the dashboard URL is http://your_node:8888/  Now you can create a blank notebook and start some coding.   Remember to initialize BigDL engine before calling BigDL API's, as shown below.  from bigdl.util.common import *\ninit_engine()\n\nfrom bigdl.nn.layer import *\nlinear = Linear(2, 3)\n...  Sometimes you may need to use SparkContext's  parallelize  method to convert local    data into an RDD. You can get SparkContext in below way.  from bigdl.util.common import *\nsc = get_spark_context()\n# sc.parallelize(...)", 
            "title": "Use Jupyter Notebook (W/O pip install)"
        }, 
        {
            "location": "/PythonSupport/python-run/#use-python-on-yarn-cluster", 
            "text": "You can run BigDL Python programs on YARN clusters without changes to the cluster (e.g., no need to pre-install the      Python dependency). You  can first package all the required Python dependency into a virtual environment on the local    node (where you will run the spark-submit command), and then directly use spark-submit to run the BigDL Python program   on the YARN cluster (using that virtual environment). Please refer to this  patch  for more details.", 
            "title": "Use Python on YARN cluster"
        }, 
        {
            "location": "/PythonSupport/python-examples/", 
            "text": "Text Classification using BigDL Python API\n\n\nThis tutorial describes the \ntextclassifier\n example written using BigDL Python API, which builds a text classifier using a CNN (convolutional neural network) or LSTM or GRU model (as specified by the user). (It was first described by \nthis Keras tutorial\n)\n\n\nThe example first creates the \nSparkContext\n using the SparkConf\nreturn by the\ncreate_spark_conf()` method, and then initialize the engine:\n\n\n  sc = SparkContext(appName=\ntext_classifier\n,\n                    conf=create_spark_conf())\n  init_engine()\n\n\n\n\nIt then loads the \n20 Newsgroup dataset\n into RDD, and transforms the input data into an RDD of \nSample\n. (Each \nSample\n in essence contains a tuple of two NumPy ndarray representing the feature and label).\n\n\n  texts = news20.get_news20()\n  data_rdd = sc.parallelize(texts, 2)\n  ...\n  sample_rdd = vector_rdd.map(\n      lambda (vectors, label): to_sample(vectors, label, embedding_dim))\n  train_rdd, val_rdd = sample_rdd.randomSplit(\n      [training_split, 1-training_split])   \n\n\n\n\nAfter that, the example creates the neural network model as follows:\n\n\ndef build_model(class_num):\n    model = Sequential()\n\n    if model_type.lower() == \ncnn\n:\n        model.add(Reshape([embedding_dim, 1, sequence_len]))\n        model.add(SpatialConvolution(embedding_dim, 128, 5, 1))\n        model.add(ReLU())\n        model.add(SpatialMaxPooling(5, 1, 5, 1))\n        model.add(SpatialConvolution(128, 128, 5, 1))\n        model.add(ReLU())\n        model.add(SpatialMaxPooling(5, 1, 5, 1))\n        model.add(Reshape([128]))\n    elif model_type.lower() == \nlstm\n:\n        model.add(Recurrent()\n                  .add(LSTM(embedding_dim, 128)))\n        model.add(Select(2, -1))\n    elif model_type.lower() == \ngru\n:\n        model.add(Recurrent()\n                  .add(GRU(embedding_dim, 128)))\n        model.add(Select(2, -1))\n    else:\n        raise ValueError('model can only be cnn, lstm, or gru')\n\n    model.add(Linear(128, 100))\n    model.add(Linear(100, class_num))\n    model.add(LogSoftMax())\n    return model\n\n\n\n\nFinally the example creates the \nOptimizer\n (which accepts both the model and the training Sample RDD) and trains the model by calling \nOptimizer.optimize()\n:\n\n\noptimizer = Optimizer(\n    model=build_model(news20.CLASS_NUM),\n    training_rdd=train_rdd,\n    criterion=ClassNLLCriterion(),\n    end_trigger=MaxEpoch(max_epoch),\n    batch_size=batch_size,\n    optim_method=\nAdagrad\n,\n    state=state)\n...\ntrain_model = optimizer.optimize()", 
            "title": "Examples"
        }, 
        {
            "location": "/PythonSupport/python-examples/#text-classification-using-bigdl-python-api", 
            "text": "This tutorial describes the  textclassifier  example written using BigDL Python API, which builds a text classifier using a CNN (convolutional neural network) or LSTM or GRU model (as specified by the user). (It was first described by  this Keras tutorial )  The example first creates the  SparkContext  using the SparkConf return by the create_spark_conf()` method, and then initialize the engine:    sc = SparkContext(appName= text_classifier ,\n                    conf=create_spark_conf())\n  init_engine()  It then loads the  20 Newsgroup dataset  into RDD, and transforms the input data into an RDD of  Sample . (Each  Sample  in essence contains a tuple of two NumPy ndarray representing the feature and label).    texts = news20.get_news20()\n  data_rdd = sc.parallelize(texts, 2)\n  ...\n  sample_rdd = vector_rdd.map(\n      lambda (vectors, label): to_sample(vectors, label, embedding_dim))\n  train_rdd, val_rdd = sample_rdd.randomSplit(\n      [training_split, 1-training_split])     After that, the example creates the neural network model as follows:  def build_model(class_num):\n    model = Sequential()\n\n    if model_type.lower() ==  cnn :\n        model.add(Reshape([embedding_dim, 1, sequence_len]))\n        model.add(SpatialConvolution(embedding_dim, 128, 5, 1))\n        model.add(ReLU())\n        model.add(SpatialMaxPooling(5, 1, 5, 1))\n        model.add(SpatialConvolution(128, 128, 5, 1))\n        model.add(ReLU())\n        model.add(SpatialMaxPooling(5, 1, 5, 1))\n        model.add(Reshape([128]))\n    elif model_type.lower() ==  lstm :\n        model.add(Recurrent()\n                  .add(LSTM(embedding_dim, 128)))\n        model.add(Select(2, -1))\n    elif model_type.lower() ==  gru :\n        model.add(Recurrent()\n                  .add(GRU(embedding_dim, 128)))\n        model.add(Select(2, -1))\n    else:\n        raise ValueError('model can only be cnn, lstm, or gru')\n\n    model.add(Linear(128, 100))\n    model.add(Linear(100, class_num))\n    model.add(LogSoftMax())\n    return model  Finally the example creates the  Optimizer  (which accepts both the model and the training Sample RDD) and trains the model by calling  Optimizer.optimize() :  optimizer = Optimizer(\n    model=build_model(news20.CLASS_NUM),\n    training_rdd=train_rdd,\n    criterion=ClassNLLCriterion(),\n    end_trigger=MaxEpoch(max_epoch),\n    batch_size=batch_size,\n    optim_method= Adagrad ,\n    state=state)\n...\ntrain_model = optimizer.optimize()", 
            "title": "Text Classification using BigDL Python API"
        }, 
        {
            "location": "/PythonSupport/python-resources/", 
            "text": "Models/Examples\n\n\nBigDL provides plenty of Python models and examples ready for re-use. Some are listed blow. See all in \npython models\n and \npython examples\n\n\n\n\nLeNet\n: it demonstrates how to use BigDL Python APIs to train and evaluate the \nLeNet-5\n network on MNIST data.\n\n\nText Classifier\n:  it demonstrates how to use BigDL Python APIs to build a text classifier using a simple [convolutional neural network (CNN) model(https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)] or a simple LSTM/GRU model.\n\n\nJupyter Notebook Tutorial\n: it contains a tutorial for using BigDL Python APIs in Jupyter notebooks (together with TensorBoard support) for interactive data explorations and visualizations.\n\n\n\n\n\n\nTutorial Notebooks\n\n\nBigDL Tutorials Notebooks\n - A series of notebooks that step-by- step introduce you how to do data science on Apache Spark and BigDL framework", 
            "title": "More Examples and Tutorials"
        }, 
        {
            "location": "/PythonSupport/python-resources/#modelsexamples", 
            "text": "BigDL provides plenty of Python models and examples ready for re-use. Some are listed blow. See all in  python models  and  python examples   LeNet : it demonstrates how to use BigDL Python APIs to train and evaluate the  LeNet-5  network on MNIST data.  Text Classifier :  it demonstrates how to use BigDL Python APIs to build a text classifier using a simple [convolutional neural network (CNN) model(https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)] or a simple LSTM/GRU model.  Jupyter Notebook Tutorial : it contains a tutorial for using BigDL Python APIs in Jupyter notebooks (together with TensorBoard support) for interactive data explorations and visualizations.", 
            "title": "Models/Examples"
        }, 
        {
            "location": "/PythonSupport/python-resources/#tutorial-notebooks", 
            "text": "BigDL Tutorials Notebooks  - A series of notebooks that step-by- step introduce you how to do data science on Apache Spark and BigDL framework", 
            "title": "Tutorial Notebooks"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/", 
            "text": "BigDL supports two different model definition styles: Sequential API and Functional API.\n\n\nHere we introduce how to define a model in Sequential API.\n\n\n\n\nDefine a simple model\n\n\nSuppose we want to define a model with three layers\n\n\nLinear -\n Sigmoid -\n Softmax\n\n\n\n\nYou can write code like this\n\n\nScala:\n\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(Sigmoid())\nmodel.add(Softmax())\n\n\n\n\nPython:\n\n\nmodel = Sequential()\nmodel.add(Linear(...))\nmodel.add(Sigmoid())\nmodel.add(Softmax())\n\n\n\n\nIn the above code, we first create a container Sequential. Then add the layers\ninto the container one by one. The order of the layers in the model is same with the insertion\norder. This model definition\nlooks very straightforward.\n\n\nBigDL provides multiple types of contianers allow user to define complex model in sequential\nstyle. We will take a look at it.\n\n\n\n\nDefine a model with branches\n\n\nSuppose we want to define a model like this\n\n\nLinear -\n ReLU --\n Linear -\n ReLU\n               |-\n Linear -\n ReLU\n\n\n\n\nThe model has two outputs from two branches. The inputs of the branches are both the\noutput from the first ReLU.\n\n\nYou can define the model like this\n\n\nScala\n\n\nval branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nval branches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\n\n\n\n\nPython\n\n\nbranch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\n\n\n\n\nIn the above code, to handle the branch structure, we use another container ConcatTable.\nWhen you add layers into ConcatTable, the new layer won't be placed after the previous one\nbut will become a new branch.\n\n\nThe input of the model is a tensor and the output of the model is two tensors.\n\n\n\n\nDefine a model with merged branch\n\n\nSuppose we want to define a model like this\n\n\nLinear -\n ReLU --\n Linear -\n ReLU ----\n Add\n               |-\n Linear -\n ReLU --|\n\n\n\n\nIn the model, the outputs of the two branches are merged by an add operation.\n\n\nYou can define the model like this\n\n\nScala\n\n\nval branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nval branches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\nmodel.add(CAddTable())\n\n\n\n\nPython\n\n\nbranch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\nmodel.add(CAddTable())\n\n\n\n\nTo merge the outputs of the branches by an add operation, we use CAddTable. It\ntakes a list of tensors from the previous layer, and merge the tensors by adding them together.\n\n\nBigDL provides many merge layers. Please check Merge layers document page. They all\ntake a list of tensors as input and merge the tensors by some operation.\n\n\n\n\nDefine a model with multiple inputs\n\n\nWe have already seen how to define branches in model and how to merge branches.\nWhat if we have multiple input? Suppose we want to define a model like this\n\n\nLinear -\n ReLU ----\n Add\nLinear -\n ReLU --|\n\n\n\n\nThe above model takes two tensors as input, and merge them together by add operation.\n\n\nYou can define the model like this\n\n\nScala\n\n\nval model = Sequential()\nval branches = ParallelTable()\nval branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches.add(branch1).add(branch2)\nmodel.add(branches).add(CAddTable)\n\n\n\n\nPython\n\n\nmodel = Sequential()\nbranches = ParallelTable()\nbranch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches.add(branch1).add(branch2)\nmodel.add(branches).add(CAddTable)\n\n\n\n\nIn the above code, we use ParallelTable to handle the multiple inputs. ParallelTable also\ndefine a multiple branches structure like ConcatTable. The difference is it takes a list\nof tensors as inputs and assign each tensor to the corresponding branch.", 
            "title": "Using Sequential API"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/#define-a-simple-model", 
            "text": "Suppose we want to define a model with three layers  Linear -  Sigmoid -  Softmax  You can write code like this  Scala:  val model = Sequential()\nmodel.add(Linear(...))\nmodel.add(Sigmoid())\nmodel.add(Softmax())  Python:  model = Sequential()\nmodel.add(Linear(...))\nmodel.add(Sigmoid())\nmodel.add(Softmax())  In the above code, we first create a container Sequential. Then add the layers\ninto the container one by one. The order of the layers in the model is same with the insertion\norder. This model definition\nlooks very straightforward.  BigDL provides multiple types of contianers allow user to define complex model in sequential\nstyle. We will take a look at it.", 
            "title": "Define a simple model"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/#define-a-model-with-branches", 
            "text": "Suppose we want to define a model like this  Linear -  ReLU --  Linear -  ReLU\n               |-  Linear -  ReLU  The model has two outputs from two branches. The inputs of the branches are both the\noutput from the first ReLU.  You can define the model like this  Scala  val branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nval branches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)  Python  branch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)  In the above code, to handle the branch structure, we use another container ConcatTable.\nWhen you add layers into ConcatTable, the new layer won't be placed after the previous one\nbut will become a new branch.  The input of the model is a tensor and the output of the model is two tensors.", 
            "title": "Define a model with branches"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/#define-a-model-with-merged-branch", 
            "text": "Suppose we want to define a model like this  Linear -  ReLU --  Linear -  ReLU ----  Add\n               |-  Linear -  ReLU --|  In the model, the outputs of the two branches are merged by an add operation.  You can define the model like this  Scala  val branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nval branches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\nmodel.add(CAddTable())  Python  branch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\nmodel.add(CAddTable())  To merge the outputs of the branches by an add operation, we use CAddTable. It\ntakes a list of tensors from the previous layer, and merge the tensors by adding them together.  BigDL provides many merge layers. Please check Merge layers document page. They all\ntake a list of tensors as input and merge the tensors by some operation.", 
            "title": "Define a model with merged branch"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/#define-a-model-with-multiple-inputs", 
            "text": "We have already seen how to define branches in model and how to merge branches.\nWhat if we have multiple input? Suppose we want to define a model like this  Linear -  ReLU ----  Add\nLinear -  ReLU --|  The above model takes two tensors as input, and merge them together by add operation.  You can define the model like this  Scala  val model = Sequential()\nval branches = ParallelTable()\nval branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches.add(branch1).add(branch2)\nmodel.add(branches).add(CAddTable)  Python  model = Sequential()\nbranches = ParallelTable()\nbranch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches.add(branch1).add(branch2)\nmodel.add(branches).add(CAddTable)  In the above code, we use ParallelTable to handle the multiple inputs. ParallelTable also\ndefine a multiple branches structure like ConcatTable. The difference is it takes a list\nof tensors as inputs and assign each tensor to the corresponding branch.", 
            "title": "Define a model with multiple inputs"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/", 
            "text": "BigDL supports two different model definition styles: Sequential API and Functional API.\n\n\nIn Functional API, the model is described as a graph. It is more convenient than Sequential API\nwhen define some complex model.\n\n\n\n\nDefine a simple model\n\n\nSuppose we want to define a model with three layers\n\n\nLinear -\n Sigmoid -\n Softmax\n\n\n\n\nYou can write code like this\n\n\nScala:\n\n\nval linear = Linear(...).inputs()\nval sigmoid = Sigmoid().inputs(linear)\nval softmax = Softmax().inputs(sigmoid)\nval model = Graph(Seq[linear], Seq[softmax])\n\n\n\n\nPython:\n\n\nlinear = Linear(...)()\nsigmoid = Sigmoid()(linear)\nsoftmax = Softmax()(sigmoid)\nmodel = Model([linear], [softmax])\n\n\n\n\nAn easy way to understand the Funtional API is to think of each layer in the model as a directed\nedge connecting its input and output\n\n\nIn the above code, first we create an input node named as linear by using\nthe Linear layer, then connect it to the sigmoid node with a Sigmoid\nlayer, then connect the sigmoid node to the softmax node with a Softmax layer.\n\n\nAfter defined the graph, we create the model by passing in the input nodes\nand output nodes.\n\n\n\n\nDefine a model with branches\n\n\nSuppose we want to define a model like this\n\n\nLinear -\n ReLU --\n Linear -\n ReLU\n               |-\n Linear -\n ReLU\n\n\n\n\nThe model has two outputs from two branches. The inputs of the branches are both the\noutput from the first ReLU.\n\n\nYou can define the model like this\n\n\nScala:\n\n\nval linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs(relu1)\nval relu2 = ReLU().inputs(linear2)\nval linear3 = Linear(...).inputs(relu1)\nval relu3 = ReLU().inputs(linear3)\nval model = Graph(Seq[linear1], Seq[relu2, relu3])\n\n\n\n\nPython:\n\n\nlinear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)(relu1)\nrelu2 = ReLU()(linear2)\nlinear3 = Linear(...)(relu1)\nrelu3 = ReLU()(linear3)\nmodel = Model(Seq[linear1], Seq[relu2, relu3])\n\n\n\n\nIn the above node, linear2 and linear3 are both from relu1 with separated\nLinear layers, which construct the branch structure. When we create the model,\nthe outputs parameter contains relu2 and relu3 as the model has two outputs.\n\n\n\n\nDefine a model with merged branch\n\n\nSuppose we want to define a model like this\n\n\nLinear -\n ReLU --\n Linear -\n ReLU ----\n Add\n               |-\n Linear -\n ReLU --|\n\n\n\n\nIn the model, the outputs of the two branches are merged by an add operation.\n\n\nYou can define the model like this\n\n\nScala:\n\n\nval linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs(relu1)\nval relu2 = ReLU().inputs(linear2)\nval linear3 = Linear(...).inputs(relu1)\nval relu3 = ReLU().inputs(linear3)\nval add = CAddTable().inputs(relu2, relu3)\nval model = Graph(Seq[linear1], Seq[add])\n\n\n\n\nPython:\n\n\nlinear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)(relu1)\nrelu2 = ReLU()(linear2)\nlinear3 = Linear(...)(relu1)\nrelu3 = ReLU()(linear3)\nadd = CAddTable()(relu2, relu3)\nmodel = Model(Seq[linear1], Seq[add])\n\n\n\n\nIn the above code, to merge the branch, we use the CAddTable, which takes two\ninput nodes, to generate one output node.\n\n\nBigDL provides many merge layers. Please check Merge layers document page. They all\ntake a list of tensors as input and merge the tensors by some operation.\n\n\n\n\nDefine a model with multiple inputs\n\n\nWe have already seen how to define branches in model and how to merge branches.\nWhat if we have multiple input? Suppose we want to define a model like this\n\n\nLinear -\n ReLU ----\n Add\nLinear -\n ReLU --|\n\n\n\n\nYou can define the model like this\n\n\nScala:\n\n\nval linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs()\nval relu2 = ReLU().inputs(linear2)\nval add = CAddTable().inputs(relu1, relu2)\nval model = Graph(Seq[linear1, linear2], Seq[add])\n\n\n\n\nPython:\n\n\nlinear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)()\nrelu2 = ReLU()(linear2)\nadd = CAddTable()(relu1, relu2)\nmodel = Model(Seq[linear1, linear2], Seq[add])\n\n\n\n\nIn the above code, we define two input nodes linear1 and linear2 and put them\ninto the first parameter when create the graph model.", 
            "title": "Using Functional API"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/#define-a-simple-model", 
            "text": "Suppose we want to define a model with three layers  Linear -  Sigmoid -  Softmax  You can write code like this  Scala:  val linear = Linear(...).inputs()\nval sigmoid = Sigmoid().inputs(linear)\nval softmax = Softmax().inputs(sigmoid)\nval model = Graph(Seq[linear], Seq[softmax])  Python:  linear = Linear(...)()\nsigmoid = Sigmoid()(linear)\nsoftmax = Softmax()(sigmoid)\nmodel = Model([linear], [softmax])  An easy way to understand the Funtional API is to think of each layer in the model as a directed\nedge connecting its input and output  In the above code, first we create an input node named as linear by using\nthe Linear layer, then connect it to the sigmoid node with a Sigmoid\nlayer, then connect the sigmoid node to the softmax node with a Softmax layer.  After defined the graph, we create the model by passing in the input nodes\nand output nodes.", 
            "title": "Define a simple model"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/#define-a-model-with-branches", 
            "text": "Suppose we want to define a model like this  Linear -  ReLU --  Linear -  ReLU\n               |-  Linear -  ReLU  The model has two outputs from two branches. The inputs of the branches are both the\noutput from the first ReLU.  You can define the model like this  Scala:  val linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs(relu1)\nval relu2 = ReLU().inputs(linear2)\nval linear3 = Linear(...).inputs(relu1)\nval relu3 = ReLU().inputs(linear3)\nval model = Graph(Seq[linear1], Seq[relu2, relu3])  Python:  linear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)(relu1)\nrelu2 = ReLU()(linear2)\nlinear3 = Linear(...)(relu1)\nrelu3 = ReLU()(linear3)\nmodel = Model(Seq[linear1], Seq[relu2, relu3])  In the above node, linear2 and linear3 are both from relu1 with separated\nLinear layers, which construct the branch structure. When we create the model,\nthe outputs parameter contains relu2 and relu3 as the model has two outputs.", 
            "title": "Define a model with branches"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/#define-a-model-with-merged-branch", 
            "text": "Suppose we want to define a model like this  Linear -  ReLU --  Linear -  ReLU ----  Add\n               |-  Linear -  ReLU --|  In the model, the outputs of the two branches are merged by an add operation.  You can define the model like this  Scala:  val linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs(relu1)\nval relu2 = ReLU().inputs(linear2)\nval linear3 = Linear(...).inputs(relu1)\nval relu3 = ReLU().inputs(linear3)\nval add = CAddTable().inputs(relu2, relu3)\nval model = Graph(Seq[linear1], Seq[add])  Python:  linear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)(relu1)\nrelu2 = ReLU()(linear2)\nlinear3 = Linear(...)(relu1)\nrelu3 = ReLU()(linear3)\nadd = CAddTable()(relu2, relu3)\nmodel = Model(Seq[linear1], Seq[add])  In the above code, to merge the branch, we use the CAddTable, which takes two\ninput nodes, to generate one output node.  BigDL provides many merge layers. Please check Merge layers document page. They all\ntake a list of tensors as input and merge the tensors by some operation.", 
            "title": "Define a model with merged branch"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/#define-a-model-with-multiple-inputs", 
            "text": "We have already seen how to define branches in model and how to merge branches.\nWhat if we have multiple input? Suppose we want to define a model like this  Linear -  ReLU ----  Add\nLinear -  ReLU --|  You can define the model like this  Scala:  val linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs()\nval relu2 = ReLU().inputs(linear2)\nval add = CAddTable().inputs(relu1, relu2)\nval model = Graph(Seq[linear1, linear2], Seq[add])  Python:  linear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)()\nrelu2 = ReLU()(linear2)\nadd = CAddTable()(relu1, relu2)\nmodel = Model(Seq[linear1, linear2], Seq[add])  In the above code, we define two input nodes linear1 and linear2 and put them\ninto the first parameter when create the graph model.", 
            "title": "Define a model with multiple inputs"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/", 
            "text": "Optimizer\n\n\nYou can use Optimizer to distributed train your model with\na spark cluster.\n\n\nHow to use Optimizer\n\n\nYou need at least provide model, data, loss function and batch size.\n\n\n\n\nmodel\n\n\n\n\nA neural network model. May be a layer, a sequence of layers or a\ngraph of layers.\n\n\n\n\ndata\n\n\n\n\nYour training data. As we train models on Spark, one of\nthe most common distributed data structures is RDD. Of course\nyou can use DataFrame. Please check the BigDL pipeline example.\n\n\nThe element in the RDD is Sample, which is actually a sequence of\nTensors. You need to convert your data record(image, audio, text)\nto Tensors before you feed them into Optimizer. We also provide\nmany utilities to do it.\n\n\n\n\nloss function\n\n\n\n\nIn supervised machine learning, loss function compares the output of\nthe model with the ground truth(the labels of the training data). It\noutputs a loss value to measure how good the model is(the lower the\nbetter). It also provides a gradient to indicate how to tune the model.\n\n\nIn BigDL, all loss functions are subclass of Criterion.\n\n\n\n\nbatch size\n\n\n\n\nTraining is an iterative process. In each iteration, only a batch of data\nis used for training the model. You need to specify the batch size. Please note, \nthe batch size should be divisible by the total cores number.\n\n\nHere's an example of how to train a Linear classification model\n\n\nscala\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n// Define the model\nval model = Linear[Float](2, 1)\nmodel.bias.zero()\n\n// Generate 2D dummy data, y = 0.1 * x[1] + 0.3 * x[2]\nval samples = Seq(\n  Sample[Float](Tensor[Float](T(5f, 5f)), Tensor[Float](T(2.0f))),\n  Sample[Float](Tensor[Float](T(-5f, -5f)), Tensor[Float](T(-2.0f))),\n  Sample[Float](Tensor[Float](T(-2f, 5f)), Tensor[Float](T(1.3f))),\n  Sample[Float](Tensor[Float](T(-5f, 2f)), Tensor[Float](T(0.1f))),\n  Sample[Float](Tensor[Float](T(5f, -2f)), Tensor[Float](T(-0.1f))),\n  Sample[Float](Tensor[Float](T(2f, -5f)), Tensor[Float](T(-1.3f)))\n)\nval trainData = sc.parallelize(samples, 1)\n\n// Define the model\nval optimizer = Optimizer[Float](model, trainData, MSECriterion[Float](), 4)\nEngine.init\noptimizer.optimize()\nprintln(model.weight)\n\n\n\n\nThe weight of linear is init randomly. But the output should be like\n\n\nscala\n println(model.weight)\n0.09316949      0.2887804\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]\n\n\n\n\npython\n\n\nfrom bigdl.nn.layer import Linear\nfrom bigdl.util.common import *\nfrom bigdl.nn.criterion import MSECriterion\nfrom bigdl.optim.optimizer import Optimizer, MaxIteration\nimport numpy as np\n\nmodel = Linear(2, 1)\nsamples = [\n  Sample.from_ndarray(np.array([5, 5]), np.array([2.0])),\n  Sample.from_ndarray(np.array([-5, -5]), np.array([-2.0])),\n  Sample.from_ndarray(np.array([-2, 5]), np.array([1.3])),\n  Sample.from_ndarray(np.array([-5, 2]), np.array([0.1])),\n  Sample.from_ndarray(np.array([5, -2]), np.array([-0.1])),\n  Sample.from_ndarray(np.array([2, -5]), np.array([-1.3]))\n]\ntrain_data = sc.parallelize(samples, 1)\ninit_engine()\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4)\noptimizer.optimize()\nmodel.get_weights()[0]\n\n\n\n\nThe output should be like\n\n\narray([[ 0.11578175,  0.28315681]], dtype=float32)\n\n\n\n\nYou can see the model is trained.\n\n\nDefine when to end the training\n\n\nYou need define when to end the training. It can be several iterations, or how many round\ndata you want to process, a.k.a epoch.\n\n\nscala\n\n\n// The default endWhen in scala is 100 iterations\noptimizer.setEndWhen(Trigger.maxEpoch(10))  // Change to 10 epoch\n\n\n\n\npython\n\n\n# Python need to define in the constructor\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4)\n\n\n\n\nChange the optimization algorithm\n\n\nGradient based optimization algorithms are the most popular algorithms to train the neural\nnetwork model. The most famous one is SGD. SGD has many variants, adagrad, adam, etc.\n\n\nscala\n\n\n// The default is SGD\noptimizer.setOptimMethod(new Adam())  // Change to adam\n\n\n\n\npython\n\n\n# Python need to define the optimization algorithm in the constructor\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4, optim_method = Adam())\n\n\n\n\nValidate your model in training\n\n\nSometimes, people want to evaluate the model with a seperated dataset. When model\nperforms well on train dataset, but bad on validation dataset, we call the model is overfit or\nweak generalization. People may want to evaluate the model every serveral iterations or \nepochs. BigDL can easily do this by\n\n\nscala\n\n\noptimizer.setValidation(trigger, testData, validationMethod, batchSize)\n\n\n\n\noptimizer.set_validation(batch_size, val_rdd, trigger, validationMethod)\n\n\n\n\nFor validation, you need to provide\n\n\n\n\ntrigger: how often to do validation, maybe each several iterations or epochs\n\n\ntest data: the seperate dataset for test\n\n\nvalidation method: how to evaluate the model, maybe top1 accuracy, etc.\n\n\nbatch size: how many data evaluate in one time\n\n\n\n\nVisualize training process\n\n\nSee \nVisualization with TensorBoard", 
            "title": "Optimization"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#optimizer", 
            "text": "You can use Optimizer to distributed train your model with\na spark cluster.", 
            "title": "Optimizer"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#how-to-use-optimizer", 
            "text": "You need at least provide model, data, loss function and batch size.   model   A neural network model. May be a layer, a sequence of layers or a\ngraph of layers.   data   Your training data. As we train models on Spark, one of\nthe most common distributed data structures is RDD. Of course\nyou can use DataFrame. Please check the BigDL pipeline example.  The element in the RDD is Sample, which is actually a sequence of\nTensors. You need to convert your data record(image, audio, text)\nto Tensors before you feed them into Optimizer. We also provide\nmany utilities to do it.   loss function   In supervised machine learning, loss function compares the output of\nthe model with the ground truth(the labels of the training data). It\noutputs a loss value to measure how good the model is(the lower the\nbetter). It also provides a gradient to indicate how to tune the model.  In BigDL, all loss functions are subclass of Criterion.   batch size   Training is an iterative process. In each iteration, only a batch of data\nis used for training the model. You need to specify the batch size. Please note, \nthe batch size should be divisible by the total cores number.  Here's an example of how to train a Linear classification model  scala  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n// Define the model\nval model = Linear[Float](2, 1)\nmodel.bias.zero()\n\n// Generate 2D dummy data, y = 0.1 * x[1] + 0.3 * x[2]\nval samples = Seq(\n  Sample[Float](Tensor[Float](T(5f, 5f)), Tensor[Float](T(2.0f))),\n  Sample[Float](Tensor[Float](T(-5f, -5f)), Tensor[Float](T(-2.0f))),\n  Sample[Float](Tensor[Float](T(-2f, 5f)), Tensor[Float](T(1.3f))),\n  Sample[Float](Tensor[Float](T(-5f, 2f)), Tensor[Float](T(0.1f))),\n  Sample[Float](Tensor[Float](T(5f, -2f)), Tensor[Float](T(-0.1f))),\n  Sample[Float](Tensor[Float](T(2f, -5f)), Tensor[Float](T(-1.3f)))\n)\nval trainData = sc.parallelize(samples, 1)\n\n// Define the model\nval optimizer = Optimizer[Float](model, trainData, MSECriterion[Float](), 4)\nEngine.init\noptimizer.optimize()\nprintln(model.weight)  The weight of linear is init randomly. But the output should be like  scala  println(model.weight)\n0.09316949      0.2887804\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]  python  from bigdl.nn.layer import Linear\nfrom bigdl.util.common import *\nfrom bigdl.nn.criterion import MSECriterion\nfrom bigdl.optim.optimizer import Optimizer, MaxIteration\nimport numpy as np\n\nmodel = Linear(2, 1)\nsamples = [\n  Sample.from_ndarray(np.array([5, 5]), np.array([2.0])),\n  Sample.from_ndarray(np.array([-5, -5]), np.array([-2.0])),\n  Sample.from_ndarray(np.array([-2, 5]), np.array([1.3])),\n  Sample.from_ndarray(np.array([-5, 2]), np.array([0.1])),\n  Sample.from_ndarray(np.array([5, -2]), np.array([-0.1])),\n  Sample.from_ndarray(np.array([2, -5]), np.array([-1.3]))\n]\ntrain_data = sc.parallelize(samples, 1)\ninit_engine()\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4)\noptimizer.optimize()\nmodel.get_weights()[0]  The output should be like  array([[ 0.11578175,  0.28315681]], dtype=float32)  You can see the model is trained.", 
            "title": "How to use Optimizer"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#define-when-to-end-the-training", 
            "text": "You need define when to end the training. It can be several iterations, or how many round\ndata you want to process, a.k.a epoch.  scala  // The default endWhen in scala is 100 iterations\noptimizer.setEndWhen(Trigger.maxEpoch(10))  // Change to 10 epoch  python  # Python need to define in the constructor\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4)", 
            "title": "Define when to end the training"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#change-the-optimization-algorithm", 
            "text": "Gradient based optimization algorithms are the most popular algorithms to train the neural\nnetwork model. The most famous one is SGD. SGD has many variants, adagrad, adam, etc.  scala  // The default is SGD\noptimizer.setOptimMethod(new Adam())  // Change to adam  python  # Python need to define the optimization algorithm in the constructor\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4, optim_method = Adam())", 
            "title": "Change the optimization algorithm"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#validate-your-model-in-training", 
            "text": "Sometimes, people want to evaluate the model with a seperated dataset. When model\nperforms well on train dataset, but bad on validation dataset, we call the model is overfit or\nweak generalization. People may want to evaluate the model every serveral iterations or \nepochs. BigDL can easily do this by  scala  optimizer.setValidation(trigger, testData, validationMethod, batchSize)  optimizer.set_validation(batch_size, val_rdd, trigger, validationMethod)  For validation, you need to provide   trigger: how often to do validation, maybe each several iterations or epochs  test data: the seperate dataset for test  validation method: how to evaluate the model, maybe top1 accuracy, etc.  batch size: how many data evaluate in one time", 
            "title": "Validate your model in training"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#visualize-training-process", 
            "text": "See  Visualization with TensorBoard", 
            "title": "Visualize training process"
        }, 
        {
            "location": "/ProgrammingGuide/MLPipeline/DLEstimator/", 
            "text": "Scala:\n\n\nval estimator = new DLEstimator(\n    model,\n    criterion,\n    featureSize,\n    labelSize\n  )\n\n\n\n\nDLEstimator\n helps to train a BigDL Model with the Spark ML \nEstimator\n/\nTransfomer\n pattern,\nthus Spark users can conveniently fit BigDL into Spark ML pipeline.\n\n\nDLEstimator\n supports feature and label data in the format of \nArray[Double], Array[Float],\norg.apache.spark.mllib.linalg.{Vector, VectorUDT}\n for Spark 1.5, 1.6 and\n\norg.apache.spark.ml.linalg.{Vector, VectorUDT}\n for Spark 2.0+. Also label data can be of\nDouble type.\nUser should specify the feature data dimensions and label data dimensions via the constructor\nparameters \nfeatureSize\n and \nlabelSize\n respectively. E.g., a sample from\n\nMNist\n may have the \nfeatureSize\n as Array(28, 28) and\n\nlabelSize\n as Array(1). And the feature column contains an array\nor a vector of 576 numbers. Internally the feature and label data are converted to BigDL\ntensors, to further train a BigDL model efficiently.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport org.apache.spark.ml.DLEstimator\n\nval model = Sequential().add(Linear(2, 2))\nval criterion = MSECriterion()\nval estimator = new DLEstimator(model, criterion, Array(2), Array(2))\n  .setBatchSize(4)\n  .setMaxEpoch(10)\nval data = sc.parallelize(Seq(\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0)),\n  (Array(2.0, 1.0), Array(1.0, 2.0)),\n  (Array(1.0, 2.0), Array(2.0, 1.0))))\nval df: DataFrame = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\n\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)\n\n\n\n\n\nOutput is\n\n\n\n\n\n\n\n\nfeatures\n\n\nlabel\n\n\nprediction\n\n\n\n\n\n\n\n\n\n\n[2.0, 1.0]\n\n\n[1.0, 2.0]\n\n\n[1.0034767389297485, 2.006068706512451]\n\n\n\n\n\n\n[1.0, 2.0]\n\n\n[2.0, 1.0]\n\n\n[2.006953001022339, 1.0039551258087158]\n\n\n\n\n\n\n[2.0, 1.0]\n\n\n[1.0, 2.0]\n\n\n[1.0034767389297485, 2.006068706512451]\n\n\n\n\n\n\n[1.0, 2.0]\n\n\n[2.0, 1.0]\n\n\n[2.006953001022339, 1.0039551258087158]", 
            "title": "DLEstimator"
        }, 
        {
            "location": "/ProgrammingGuide/MLPipeline/DLClassifier/", 
            "text": "Scala:\n\n\nval classifier = new DLClassifier(\n    model,\n    criterion,\n    featureSize\n  )\n\n\n\n\nDLClassifier\n is a specialized \nDLEstimator\n that simplifies the data format for\nclassification tasks. It only supports label column of DoubleType, and the fitted\n\nDLClassifierModel\n will have the prediction column of DoubleType.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport org.apache.spark.ml.DLClassifier\n\nval model = Sequential().add(Linear(2, 2)).add(LogSoftMax())\nval criterion = ClassNLLCriterion()\nval estimator = new DLClassifier(model, criterion, Array(2))\n  .setBatchSize(4)\n  .setMaxEpoch(10)\nval data = sc.parallelize(Seq(\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0),\n  (Array(0.0, 1.0), 1.0),\n  (Array(1.0, 0.0), 2.0)))\nval df: DataFrame = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\n\nval dlModel = estimator.fit(df)\ndlModel.transform(df).show(false)\n\n\n\n\nOutput is\n\n\n\n\n\n\n\n\nfeatures\n\n\nlabel\n\n\nprediction\n\n\n\n\n\n\n\n\n\n\n[0.0, 1.0]\n\n\n1.0\n\n\n1.0\n\n\n\n\n\n\n[1.0, 0.0]\n\n\n2.0\n\n\n2.0\n\n\n\n\n\n\n[0.0, 1.0]\n\n\n1.0\n\n\n1.0\n\n\n\n\n\n\n[1.0, 0.0]\n\n\n2.0\n\n\n2.0", 
            "title": "DLClassifier"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/", 
            "text": "Generating summary info in BigDL\n\n\nTo enable visualization support, you need first properly configure the \nOptimizer\n to collect statistics summary in different stages of training (i.e. training (\nTrainSummary\n) and validation (\nValidationSummary\n),respectively). It should be done before the training starts (calling \nOptimizer.optimize()\n). See examples below: \n\n\nExample: Generating summary info in Scala\n\n\nval optimizer = Optimizer(...)\n...\nval logdir = \nmylogdir\n\nval appName = \nmyapp\n\nval trainSummary = TrainSummary(logdir, appName)\nval validationSummary = ValidationSummary(logdir, appName)\noptimizer.setTrainSummary(trainSummary)\noptimizer.setValidationSummary(validationSummary)\n...\nval trained_model = optimizer.optimize()\n\n\n\n\nExample: Configure summary generation in Python\n\n\noptimizer = Optimizer(...)\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\ntrain_summary = TrainSummary(log_dir=log_dir, app_name=app_name)\nval_summary = ValidationSummary(log_dir=log_dir, app_name=app_name)\noptimizer.set_train_summary(train_summary)\noptimizer.set_val_summary(val_summary)\n...\ntrainedModel = optimizer.optimize()\n\n\n\n\nAfter you start to run your spark job, the train and validation summary will be saved to \nmylogdir/myapp/train\n and \nmylogdir/myapp/validation\n respectively (Note: you may want to use different \nappName\n for different job runs to avoid possible conflicts.)\n\n\n\n\nRetrieving summary info as readable format\n\n\nYou can use provided API \nreadScalar\n(Scala) and \nread_scalar\n(Python) to retrieve the summaries into readable format, and export them to other tools for further analysis or visualization.\n\n\nExample: Reading summary info in Scala\n\n\nval trainLoss = trainSummary.readScalar(\nLoss\n)\nval validationLoss = validationSummary.readScalar(\nLoss\n)\n...\n\n\n\n\nExample: Reading summary info in Python\n\n\nloss = np.array(train_summary.read_scalar('Loss'))\nvalloss = np.array(val_summary.read_scalar('Loss'))\n...\n\n\n\n\n\n\nVisualizing training with TensorBoard\n\n\nWith the summary info generated, we can then use \nTensorBoard\n to visualize the behaviors of the BigDL program.  \n\n\n\n\nInstalling TensorBoard\n\n\n\n\nPrerequisites:\n\n\n\n\nPython verison: 2.7, 3.4, 3.5, or 3.6\n\n\nPip version \n= 9.0.1\n\n\n\n\nTo install TensorBoard using Python 2, you may run the command:\n\n\npip install tensorboard==1.0.0a4\n\n\n\n\nTo install TensorBoard using Python 3, you may run the command:\n\n\npip3 install tensorboard==1.0.0a4\n\n\n\n\nPlease refer to \nthis page\n for possible issues when installing TensorBoard.\n\n\n\n\nLaunching TensorBoard\n\n\n\n\nYou can launch TensorBoard using the command below:\n\n\ntensorboard --logdir=/tmp/bigdl_summaries\n\n\n\n\nAfter that, navigate to the TensorBoard dashboard using a browser. You can find the URL in the console output after TensorBoard is successfully launched; by default the URL is http://your_node:6006\n\n\n\n\nVisualizations in TensorBoard\n\n\n\n\nWithin the TensorBoard dashboard, you will be able to read the visualizations of each run, including the \u201cLoss\u201d and \u201cThroughput\u201d curves under the SCALARS tab (as illustrated below):\n\n\n\nAnd \u201cweights\u201d, \u201cbias\u201d, \u201cgradientWeights\u201d and \u201cgradientBias\u201d under the DISTRIBUTIONS and HISTOGRAMS tabs (as illustrated below):\n\n\n\n\n\n\n\nVisualizing training with Jupyter notebook\n\n\nIf you're using Jupyter notebook, you can also draw the training curves using popular plotting tools (e.g. matplotlib) and show the plots inline. \n\n\nFirst, retrieve the summaries as instructed in \nRetrieve Summary\n. The retrived summary is a list of tuples. Each tuple is a recorded event in format (iteration count, recorded value, timestamp). You can convert it to numpy array or dataframe to plot it. See example below:  \n\n\nExample: Plot the train/validation loss in Jupyter\n\n\n#retrieve train and validation summary object and read the loss data into ndarray's. \nloss = np.array(train_summary.read_scalar(\nLoss\n))\nval_loss  = np.array(val_summary.read_scalar(\nLoss\n))\n\n#plot the train and validation curves\n# each event data is a tuple in form of (iteration_count, value, timestamp)\nplt.plot(loss[:,0],loss[:,1],label='train loss')\nplt.plot(val_loss[:,0],val_loss[:,1],label='val loss',color='green')\nplt.scatter(val_loss[:,0],val_loss[:,1],color='green')\nplt.legend();", 
            "title": "Visualization"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#generating-summary-info-in-bigdl", 
            "text": "To enable visualization support, you need first properly configure the  Optimizer  to collect statistics summary in different stages of training (i.e. training ( TrainSummary ) and validation ( ValidationSummary ),respectively). It should be done before the training starts (calling  Optimizer.optimize() ). See examples below:   Example: Generating summary info in Scala  val optimizer = Optimizer(...)\n...\nval logdir =  mylogdir \nval appName =  myapp \nval trainSummary = TrainSummary(logdir, appName)\nval validationSummary = ValidationSummary(logdir, appName)\noptimizer.setTrainSummary(trainSummary)\noptimizer.setValidationSummary(validationSummary)\n...\nval trained_model = optimizer.optimize()  Example: Configure summary generation in Python  optimizer = Optimizer(...)\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\ntrain_summary = TrainSummary(log_dir=log_dir, app_name=app_name)\nval_summary = ValidationSummary(log_dir=log_dir, app_name=app_name)\noptimizer.set_train_summary(train_summary)\noptimizer.set_val_summary(val_summary)\n...\ntrainedModel = optimizer.optimize()  After you start to run your spark job, the train and validation summary will be saved to  mylogdir/myapp/train  and  mylogdir/myapp/validation  respectively (Note: you may want to use different  appName  for different job runs to avoid possible conflicts.)", 
            "title": "Generating summary info in BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#retrieving-summary-info-as-readable-format", 
            "text": "You can use provided API  readScalar (Scala) and  read_scalar (Python) to retrieve the summaries into readable format, and export them to other tools for further analysis or visualization.  Example: Reading summary info in Scala  val trainLoss = trainSummary.readScalar( Loss )\nval validationLoss = validationSummary.readScalar( Loss )\n...  Example: Reading summary info in Python  loss = np.array(train_summary.read_scalar('Loss'))\nvalloss = np.array(val_summary.read_scalar('Loss'))\n...", 
            "title": "Retrieving summary info as readable format"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#visualizing-training-with-tensorboard", 
            "text": "With the summary info generated, we can then use  TensorBoard  to visualize the behaviors of the BigDL program.     Installing TensorBoard   Prerequisites:   Python verison: 2.7, 3.4, 3.5, or 3.6  Pip version  = 9.0.1   To install TensorBoard using Python 2, you may run the command:  pip install tensorboard==1.0.0a4  To install TensorBoard using Python 3, you may run the command:  pip3 install tensorboard==1.0.0a4  Please refer to  this page  for possible issues when installing TensorBoard.   Launching TensorBoard   You can launch TensorBoard using the command below:  tensorboard --logdir=/tmp/bigdl_summaries  After that, navigate to the TensorBoard dashboard using a browser. You can find the URL in the console output after TensorBoard is successfully launched; by default the URL is http://your_node:6006   Visualizations in TensorBoard   Within the TensorBoard dashboard, you will be able to read the visualizations of each run, including the \u201cLoss\u201d and \u201cThroughput\u201d curves under the SCALARS tab (as illustrated below):  And \u201cweights\u201d, \u201cbias\u201d, \u201cgradientWeights\u201d and \u201cgradientBias\u201d under the DISTRIBUTIONS and HISTOGRAMS tabs (as illustrated below):", 
            "title": "Visualizing training with TensorBoard"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#visualizing-training-with-jupyter-notebook", 
            "text": "If you're using Jupyter notebook, you can also draw the training curves using popular plotting tools (e.g. matplotlib) and show the plots inline.   First, retrieve the summaries as instructed in  Retrieve Summary . The retrived summary is a list of tuples. Each tuple is a recorded event in format (iteration count, recorded value, timestamp). You can convert it to numpy array or dataframe to plot it. See example below:    Example: Plot the train/validation loss in Jupyter  #retrieve train and validation summary object and read the loss data into ndarray's. \nloss = np.array(train_summary.read_scalar( Loss ))\nval_loss  = np.array(val_summary.read_scalar( Loss ))\n\n#plot the train and validation curves\n# each event data is a tuple in form of (iteration_count, value, timestamp)\nplt.plot(loss[:,0],loss[:,1],label='train loss')\nplt.plot(val_loss[:,0],val_loss[:,1],label='val loss',color='green')\nplt.scatter(val_loss[:,0],val_loss[:,1],color='green')\nplt.legend();", 
            "title": "Visualizing training with Jupyter notebook"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/", 
            "text": "The Public AMI\n\n\nTo make it easier to try out BigDL examples on Spark using EC2, a public AMI is provided. It will automatically retrieve the latest BigDL package, download the necessary input data, and then run the specified BigDL example (using Java 8 on a Spark cluster). The details of the public AMI are shown in the table below.\n\n\n\n\n\n\n\n\nBigDL version\n\n\nAMI version\n\n\nDate\n\n\nAMI ID\n\n\nAMI Name\n\n\nRegion\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n0.2S\n\n\nMar 13, 2017\n\n\nami-37b73957\n\n\nBigDL Client 0.2S\n\n\nUS West (Oregon)\n\n\nActive\n\n\n\n\n\n\nmaster\n\n\n0.2S\n\n\nApr 10, 2017\n\n\nami-8c87099a\n\n\nBigDL Client 0.2S\n\n\nUS East (N. Virginia)\n\n\nActive\n\n\n\n\n\n\n0.1.0\n\n\n0.1.0\n\n\nApr 10, 2017\n\n\nami-9a8818fa\n\n\nBigDL Client 0.1.0\n\n\nUS West (Oregon)\n\n\nActive\n\n\n\n\n\n\n0.1.0\n\n\n0.1.0\n\n\nApr 10, 2017\n\n\nami-6476f872\n\n\nBigDL Client 0.1.0\n\n\nUS East (N. Virginia)\n\n\nActive\n\n\n\n\n\n\n\n\nPlease note that it is highly recommended to run BigDL using EC2 instances with Xeon E5 v3 or v4 processors.\n\n\nAfter launching the AMI on EC2, please log on to the instance and run a \"bootstrap.sh\" script to download example scripts.\n\n\n./bootstrap.sh\n\n\n\n\n\n\nBefore you start\n\n\nBefore running the BigDL examples, you need to launch a Spark cluster on EC2 (you may refer to \nhttps://github.com/amplab/spark-ec2\n for more instructions). In addition, to run the Inception-v1 example, you also need to start a HDFS cluster on EC2 to store the input image data.\n\n\n\n\nRun BigDL Examples\n\n\nYou can run BigDL examples using the \nrun.example.sh\n script in home directory of your BigDL Client instance (e.g. \n/home/ubuntu/\n) with the following parameters:\n* Mandatory parameters:\n  * \n-m|--model\n which model to train, including\n    * lenet: train the \nLeNet\n example\n    * vgg: train the \nVGG\n example\n    * inception-v1: train the \nInception v1\n example\n    * perf: test the training speed using the \nInception v1\n model with dummy data\n\n\n\n\n\n\n-s|--spark-url\n the master URL for the Spark cluster\n\n\n\n\n\n\n-n|--nodes\n number of Spark slave nodes\n\n\n\n\n\n\n-o|--cores\n number of cores used on each node\n\n\n\n\n\n\n-r|--memory\n memory used on each node, e.g. 200g\n\n\n\n\n\n\n-b|--batch-size\n batch size when training the model; it is expected to be a multiple of \"nodes * cores\"\n\n\n\n\n\n\n-f|--hdfs-data-dir\n HDFS directory for the input images (for the \"inception-v1\" model training only)\n\n\n\n\n\n\nOptional parameters:\n\n\n\n\n\n\n-e|--max-epoch\n the maximum number of epochs (i.e., going through all the input data once) used in the training; default to 90 if not specified\n\n\n\n\n\n\n-p|--spark\n by default the example will run with Spark 1.5 or 1.6; to use Spark 2.0, please specify \"spark_2.0\" here (it is highly recommended to use \nJava 8\n when running BigDL for Spark 2.0, otherwise you may observe very poor performance)\n\n\n\n\n\n\n-l|--learning-rate\n by default the the example will use an initial learning rate of \"0.01\"; you can specify a different value here\n\n\n\n\n\n\nAfter the training, you can check the log files and generated models in the home directory (e.g., \n/home/ubuntu/\n).  \n\n\n\n\nRun the \"inception-v1\" example\n\n\nYou can refer to the \nInception v1\n example to prepare the input \nImageNet\n data here. Alternatively, you may also download just a small set of images (with dummy labels) to run the example as follows, which can be useful if you only want to try it out to see the training speed on a Spark cluster.\n\n\n\n\nDownload and prepare the input image data (a subset of the \nFlickr Style\n data)\n\n\n\n\n  ./download.sh $HDFS-NAMENODE\n\n\n\n\nAfter the download completes, the downloaded images are stored in \nhdfs://HDFS-NAMENODE:9000/seq\n. (If the download fails with error \"Unable to establish SSL connection.\" please check your network connection and retry this later.)\n\n\n\n\nTo run the \"inception-v1\" example on a 4-worker Spark cluster (using, say, the \"m4.10xlarge\" instance), run the example command below: \n\n\n\n\n  nohup bash ./run.example.sh --model inception-v1  \\\n         --spark-url spark://SPARK-MASTER:7077    \\\n         --nodes 4 --cores 20 --memory 150g       \\\n         --batch-size 400 --learning-rate 0.0898  \\\n         --hdfs-data-dir hdfs://HDFS-NAMENODE:9000/seq \\\n         --spark spark_2.0 --max-epoch 4 \\\n         \n incep.log 2\n1 \n     \n\n\n\n\n\n\nView output of the training in the log file generated by the previous step:\n\n\n\n\n  $ tail -f incep.log\n  2017-01-10 10:03:55 INFO  DistriOptimizer$:241 - [Epoch 1 0/5000][Iteration 1][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:03:58 INFO  DistriOptimizer$:241 - [Epoch 1 512/5000][Iteration 2][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:00 INFO  DistriOptimizer$:241 - [Epoch 1 1024/5000][Iteration 3][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:03 INFO  DistriOptimizer$:241 - [Epoch 1 1536/5000][Iteration 4][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:05 INFO  DistriOptimizer$:241 - [Epoch 1 2048/5000][Iteration 5][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n\n\n\n\n\n\nRun the \"perf\" example\n\n\nTo run the \"perf\" example on a 4-worker Spark cluster (using, say, the \"m4.10xlarge\" instance), you may try the example command below: \n\n\n  nohup bash ./run.example.sh --model perf  \\\n       --spark-url spark://SPARK-MASTER:7077    \\\n       --nodes 4 --cores 20 --memory 150g       \\\n       --spark spark_2.0 --max-epoch 4 \\\n       \n perf.log 2\n1", 
            "title": "Run on Amazon EC2"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#the-public-ami", 
            "text": "To make it easier to try out BigDL examples on Spark using EC2, a public AMI is provided. It will automatically retrieve the latest BigDL package, download the necessary input data, and then run the specified BigDL example (using Java 8 on a Spark cluster). The details of the public AMI are shown in the table below.     BigDL version  AMI version  Date  AMI ID  AMI Name  Region  Status      master  0.2S  Mar 13, 2017  ami-37b73957  BigDL Client 0.2S  US West (Oregon)  Active    master  0.2S  Apr 10, 2017  ami-8c87099a  BigDL Client 0.2S  US East (N. Virginia)  Active    0.1.0  0.1.0  Apr 10, 2017  ami-9a8818fa  BigDL Client 0.1.0  US West (Oregon)  Active    0.1.0  0.1.0  Apr 10, 2017  ami-6476f872  BigDL Client 0.1.0  US East (N. Virginia)  Active     Please note that it is highly recommended to run BigDL using EC2 instances with Xeon E5 v3 or v4 processors.  After launching the AMI on EC2, please log on to the instance and run a \"bootstrap.sh\" script to download example scripts.  ./bootstrap.sh", 
            "title": "The Public AMI"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#before-you-start", 
            "text": "Before running the BigDL examples, you need to launch a Spark cluster on EC2 (you may refer to  https://github.com/amplab/spark-ec2  for more instructions). In addition, to run the Inception-v1 example, you also need to start a HDFS cluster on EC2 to store the input image data.", 
            "title": "Before you start"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#run-bigdl-examples", 
            "text": "You can run BigDL examples using the  run.example.sh  script in home directory of your BigDL Client instance (e.g.  /home/ubuntu/ ) with the following parameters:\n* Mandatory parameters:\n  *  -m|--model  which model to train, including\n    * lenet: train the  LeNet  example\n    * vgg: train the  VGG  example\n    * inception-v1: train the  Inception v1  example\n    * perf: test the training speed using the  Inception v1  model with dummy data    -s|--spark-url  the master URL for the Spark cluster    -n|--nodes  number of Spark slave nodes    -o|--cores  number of cores used on each node    -r|--memory  memory used on each node, e.g. 200g    -b|--batch-size  batch size when training the model; it is expected to be a multiple of \"nodes * cores\"    -f|--hdfs-data-dir  HDFS directory for the input images (for the \"inception-v1\" model training only)    Optional parameters:    -e|--max-epoch  the maximum number of epochs (i.e., going through all the input data once) used in the training; default to 90 if not specified    -p|--spark  by default the example will run with Spark 1.5 or 1.6; to use Spark 2.0, please specify \"spark_2.0\" here (it is highly recommended to use  Java 8  when running BigDL for Spark 2.0, otherwise you may observe very poor performance)    -l|--learning-rate  by default the the example will use an initial learning rate of \"0.01\"; you can specify a different value here    After the training, you can check the log files and generated models in the home directory (e.g.,  /home/ubuntu/ ).", 
            "title": "Run BigDL Examples"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#run-the-inception-v1-example", 
            "text": "You can refer to the  Inception v1  example to prepare the input  ImageNet  data here. Alternatively, you may also download just a small set of images (with dummy labels) to run the example as follows, which can be useful if you only want to try it out to see the training speed on a Spark cluster.   Download and prepare the input image data (a subset of the  Flickr Style  data)     ./download.sh $HDFS-NAMENODE  After the download completes, the downloaded images are stored in  hdfs://HDFS-NAMENODE:9000/seq . (If the download fails with error \"Unable to establish SSL connection.\" please check your network connection and retry this later.)   To run the \"inception-v1\" example on a 4-worker Spark cluster (using, say, the \"m4.10xlarge\" instance), run the example command below:      nohup bash ./run.example.sh --model inception-v1  \\\n         --spark-url spark://SPARK-MASTER:7077    \\\n         --nodes 4 --cores 20 --memory 150g       \\\n         --batch-size 400 --learning-rate 0.0898  \\\n         --hdfs-data-dir hdfs://HDFS-NAMENODE:9000/seq \\\n         --spark spark_2.0 --max-epoch 4 \\\n           incep.log 2 1          View output of the training in the log file generated by the previous step:     $ tail -f incep.log\n  2017-01-10 10:03:55 INFO  DistriOptimizer$:241 - [Epoch 1 0/5000][Iteration 1][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:03:58 INFO  DistriOptimizer$:241 - [Epoch 1 512/5000][Iteration 2][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:00 INFO  DistriOptimizer$:241 - [Epoch 1 1024/5000][Iteration 3][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:03 INFO  DistriOptimizer$:241 - [Epoch 1 1536/5000][Iteration 4][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:05 INFO  DistriOptimizer$:241 - [Epoch 1 2048/5000][Iteration 5][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.", 
            "title": "Run the \"inception-v1\" example"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#run-the-perf-example", 
            "text": "To run the \"perf\" example on a 4-worker Spark cluster (using, say, the \"m4.10xlarge\" instance), you may try the example command below:     nohup bash ./run.example.sh --model perf  \\\n       --spark-url spark://SPARK-MASTER:7077    \\\n       --nodes 4 --cores 20 --memory 150g       \\\n       --spark spark_2.0 --max-epoch 4 \\\n         perf.log 2 1", 
            "title": "Run the \"perf\" example"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/", 
            "text": "Loading a Tensorflow model into BigDL\n\n\nIf you have a pre-trained Tensorflow model saved in a \".pb\" file, you can load it\ninto BigDL.\n\n\nFor more information on how to generate\nthe \".pb\" file, you can refer to \nA Tool Developer's Guide to TensorFlow Model Files\n.\nSpecifically, you should generate a model definition file and a set of checkpoints, then use the \nfreeze_graph\n\nscript to freeze the graph definition and weights in checkpoints into a single file.\n\n\nGenerate model definition file and checkpoints in Tensorflow\n\n\nPython\n\n\nimport tensorflow as tf\nxs = tf.placeholder(tf.float32, [None, 1])\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name=\noutput\n)\n\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    init = tf.global_variables_initializer()\n    sess.run(init)\n    checkpointpath = saver.save(sess, '/tmp/model/test.chkp')\n    tf.train.write_graph(sess.graph, '/tmp/model', 'test.pbtxt')\n\n\n\n\nFreeze graph definition and checkpoints into a single \".pb\" file\n\n\nShell\n\n\nwget https://raw.githubusercontent.com/tensorflow/tensorflow/v1.0.0/tensorflow/python/tools/freeze_graph.py\npython freeze_graph.py --input_graph /tmp/model/test.pbtxt --input_checkpoint /tmp/model/test.chkp --output_node_names=output --output_graph \n/tmp/model/test.pb\n\n\n\n\n\nLoad Tensorflow model in BigDL\n\n\nScala\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.nn.Module\nimport java.nio.ByteOrder\n\nval path = \n/tmp/model/test.pb\n\nval inputs = Seq(\nPlaceholder\n)\nval outputs = Seq(\noutput\n)\nval model = Module.loadTF(path, Seq(\nPlaceholder\n), Seq(\noutput\n), ByteOrder.LITTLE_ENDIAN)\n\n\n\n\nPython\n\n\nfrom bigdl.nn.layer import *\npath = \n/tmp/model/test.pb\n\ninputs = [\nPlaceholder\n]\noutputs = [\noutput\n]\nmodel = Model.load_tensorflow(path, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n)\n\n\n\n\n\n\nSaving a BigDL functional model to Tensorflow model file\n\n\nYou can also save a \nfunctional model\n to protobuf files so that it can be used in Tensorflow inference.\n\n\nWhen saving the model, placeholders will be added to the tf model as input nodes. So\nyou need to pass in the names and shapes of the placeholders. BigDL model does not have\nsuch information. The order of the placeholder information should be same as the inputs\nof the graph model.\n\n\nScala\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.tf.TensorflowSaver\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n// create a graph model\nval linear = Linear(10, 2).inputs()\nval sigmoid = Sigmoid().inputs(linear)\nval softmax = SoftMax().inputs(sigmoid)\nval model = Graph(Array(linear), Array(softmax))\n\n// save it to Tensorflow model file\nmodel.saveTF(Seq((\ninput\n, Seq(4, 10))), \n/tmp/model.pb\n)\n\n\n\n\nPython\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\n# create a graph model\nlinear = Linear(10, 2)()\nsigmoid = Sigmoid()(linear)\nsoftmax = SoftMax()(sigmoid)\nmodel = Model([linear], [softmax])\n\n# save it to Tensorflow model file\nmodel.save_tensorflow([(\ninput\n, [4, 10])], \n/tmp/model.pb\n)\n\n\n\n\n\n\nBuild Tensorflow model and run on BigDL\n\n\nYou can construct your BigDL model directly from the input and output nodes of\nTensorflow model. That is to say, you can use Tensorflow to define\na model and use BigDL to run it.\n\n\nPython:\n\n\nimport tensorflow as tf\nimport numpy as np\nfrom bigdl.nn.layer import *\n\ntf.set_random_seed(1234)\ninput = tf.placeholder(tf.float32, [None, 5])\nweight = tf.Variable(tf.random_uniform([5, 10]))\nbias = tf.Variable(tf.random_uniform([10]))\nmiddle = tf.nn.bias_add(tf.matmul(input, weight), bias)\noutput = tf.nn.tanh(middle)\n\n# construct BigDL model and get the result form \nbigdl_model = Model(input, output, model_type=\ntensorflow\n)", 
            "title": "Tensorflow Support"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#loading-a-tensorflow-model-into-bigdl", 
            "text": "If you have a pre-trained Tensorflow model saved in a \".pb\" file, you can load it\ninto BigDL.  For more information on how to generate\nthe \".pb\" file, you can refer to  A Tool Developer's Guide to TensorFlow Model Files .\nSpecifically, you should generate a model definition file and a set of checkpoints, then use the  freeze_graph \nscript to freeze the graph definition and weights in checkpoints into a single file.", 
            "title": "Loading a Tensorflow model into BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#generate-model-definition-file-and-checkpoints-in-tensorflow", 
            "text": "Python  import tensorflow as tf\nxs = tf.placeholder(tf.float32, [None, 1])\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name= output )\n\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    init = tf.global_variables_initializer()\n    sess.run(init)\n    checkpointpath = saver.save(sess, '/tmp/model/test.chkp')\n    tf.train.write_graph(sess.graph, '/tmp/model', 'test.pbtxt')", 
            "title": "Generate model definition file and checkpoints in Tensorflow"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#freeze-graph-definition-and-checkpoints-into-a-single-pb-file", 
            "text": "Shell  wget https://raw.githubusercontent.com/tensorflow/tensorflow/v1.0.0/tensorflow/python/tools/freeze_graph.py\npython freeze_graph.py --input_graph /tmp/model/test.pbtxt --input_checkpoint /tmp/model/test.chkp --output_node_names=output --output_graph  /tmp/model/test.pb", 
            "title": "Freeze graph definition and checkpoints into a single \".pb\" file"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#load-tensorflow-model-in-bigdl", 
            "text": "Scala  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.nn.Module\nimport java.nio.ByteOrder\n\nval path =  /tmp/model/test.pb \nval inputs = Seq( Placeholder )\nval outputs = Seq( output )\nval model = Module.loadTF(path, Seq( Placeholder ), Seq( output ), ByteOrder.LITTLE_ENDIAN)  Python  from bigdl.nn.layer import *\npath =  /tmp/model/test.pb \ninputs = [ Placeholder ]\noutputs = [ output ]\nmodel = Model.load_tensorflow(path, inputs, outputs, byte_order =  little_endian , bigdl_type= float )", 
            "title": "Load Tensorflow model in BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#saving-a-bigdl-functional-model-to-tensorflow-model-file", 
            "text": "You can also save a  functional model  to protobuf files so that it can be used in Tensorflow inference.  When saving the model, placeholders will be added to the tf model as input nodes. So\nyou need to pass in the names and shapes of the placeholders. BigDL model does not have\nsuch information. The order of the placeholder information should be same as the inputs\nof the graph model.  Scala  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.tf.TensorflowSaver\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n// create a graph model\nval linear = Linear(10, 2).inputs()\nval sigmoid = Sigmoid().inputs(linear)\nval softmax = SoftMax().inputs(sigmoid)\nval model = Graph(Array(linear), Array(softmax))\n\n// save it to Tensorflow model file\nmodel.saveTF(Seq(( input , Seq(4, 10))),  /tmp/model.pb )  Python  from bigdl.nn.layer import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\n# create a graph model\nlinear = Linear(10, 2)()\nsigmoid = Sigmoid()(linear)\nsoftmax = SoftMax()(sigmoid)\nmodel = Model([linear], [softmax])\n\n# save it to Tensorflow model file\nmodel.save_tensorflow([( input , [4, 10])],  /tmp/model.pb )", 
            "title": "Saving a BigDL functional model to Tensorflow model file"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#build-tensorflow-model-and-run-on-bigdl", 
            "text": "You can construct your BigDL model directly from the input and output nodes of\nTensorflow model. That is to say, you can use Tensorflow to define\na model and use BigDL to run it.  Python:  import tensorflow as tf\nimport numpy as np\nfrom bigdl.nn.layer import *\n\ntf.set_random_seed(1234)\ninput = tf.placeholder(tf.float32, [None, 5])\nweight = tf.Variable(tf.random_uniform([5, 10]))\nbias = tf.Variable(tf.random_uniform([10]))\nmiddle = tf.nn.bias_add(tf.matmul(input, weight), bias)\noutput = tf.nn.tanh(middle)\n\n# construct BigDL model and get the result form \nbigdl_model = Model(input, output, model_type= tensorflow )", 
            "title": "Build Tensorflow model and run on BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/", 
            "text": "If you have a pretrained caffe model(model definition prototxt and model binary file), you can load it as BigDL model.\nYou can also convert a BigDL model to caffe model.\n\n\nLoad Caffe Model\n\n\nAssume you have a \ncaffe.prototxt\n and \ncaffe.model\n,\nyou can load it into BigDL by calling \nModule.loadCaffeModel\n (scala) or \nModel.load_caffe_model\n (python).\n\n\n\n\nScala Example\n\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval model = Module.loadCaffeModel(caffe.prototxt, caffe.model)\n\n\n\n\n\n\nPython Example\n\n\n\n\nmodel = Model.load_caffe_model(caffe.prototxt, caffe.model)\n\n\n\n\nLoad Caffe Model Weights to Predefined BigDL Model\n\n\nIf you have a predefined BigDL model, and want to load caffe model weights into BigDl model\n\n\n\n\nScala Example\n\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval model = Module.loadCaffe(bigdlModel, caffe.prototxt, caffe.model, matchAll = true)\n\n\n\n\n\n\nPython Example\n\n\n\n\nmodel = Model.load_caffe_model(bigdlModel, caffe.prototxt, caffe.model, match_all=True)\n\n\n\n\nNote that if \nmatchAll/match_all = false\n, then only layers with same name will be loaded, the rest will use initialized parameters.\n\n\nSave BigDL Model to Caffe Model\n\n\n\n\nScala Example\n\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nbigdlModel.saveCaffe(prototxtPath, modelPath, useV2 = true, overwrite = false)\n\n\n\n\n\n\nPython Example\n\n\n\n\nbigdl_model.save_caffe(prototxt_path, model_path, use_v2 = True, overwrite = False)\n\n\n\n\nIn the above examples, if \nuseV2/use_v2 = true\n, it will convert to caffe V2 layer,\n otherwise, it will convert to caffe V1 layer.\nIf \noverwrite = true\n, it will overwrite the existing files.\n\n\nNote: only graph model can be saved to caffe model.", 
            "title": "Caffe Support"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/#load-caffe-model", 
            "text": "Assume you have a  caffe.prototxt  and  caffe.model ,\nyou can load it into BigDL by calling  Module.loadCaffeModel  (scala) or  Model.load_caffe_model  (python).   Scala Example   import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval model = Module.loadCaffeModel(caffe.prototxt, caffe.model)   Python Example   model = Model.load_caffe_model(caffe.prototxt, caffe.model)", 
            "title": "Load Caffe Model"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/#load-caffe-model-weights-to-predefined-bigdl-model", 
            "text": "If you have a predefined BigDL model, and want to load caffe model weights into BigDl model   Scala Example   import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval model = Module.loadCaffe(bigdlModel, caffe.prototxt, caffe.model, matchAll = true)   Python Example   model = Model.load_caffe_model(bigdlModel, caffe.prototxt, caffe.model, match_all=True)  Note that if  matchAll/match_all = false , then only layers with same name will be loaded, the rest will use initialized parameters.", 
            "title": "Load Caffe Model Weights to Predefined BigDL Model"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/#save-bigdl-model-to-caffe-model", 
            "text": "Scala Example   import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nbigdlModel.saveCaffe(prototxtPath, modelPath, useV2 = true, overwrite = false)   Python Example   bigdl_model.save_caffe(prototxt_path, model_path, use_v2 = True, overwrite = False)  In the above examples, if  useV2/use_v2 = true , it will convert to caffe V2 layer,\n otherwise, it will convert to caffe V1 layer.\nIf  overwrite = true , it will overwrite the existing files.  Note: only graph model can be saved to caffe model.", 
            "title": "Save BigDL Model to Caffe Model"
        }, 
        {
            "location": "/APIdocs/Data/", 
            "text": "Tensor\n\n\nModeled after the \nTensor\n class in \nTorch\n, the \nTensor\n \npackage\n (written in Scala and leveraging \nIntel MKL\n) in BigDL provides numeric computing support for the deep learning applications (e.g., the input, output, weight, bias and   gradient of the neural networks).\n\n\nA \nTensor\n is essentially a multi-dimensional array of numeric types (\nFloat\n or \nDouble\n), you can import the numeric implicit objects(\ncom.intel.analytics.bigdl.numeric.NumericFloat\n or \ncom.intel.analytics.bigdl.numeric.NumericDouble\n), to specify the numeric type you want.\n\n\nScala example:\n\n\nYou may check it out in the interactive Scala shell (by typing \nscala -cp bigdl_SPARKVERSION-BIGDLVERSION-SNAPSHOT-jar-with-dependencies.jar\n), for instance:\n\n\n scala\n import com.intel.analytics.bigdl.tensor.Tensor\n import com.intel.analytics.bigdl.tensor.Tensor\n\n scala\n import com.intel.analytics.bigdl.numeric.NumericFloat\n import com.intel.analytics.bigdl.numeric.NumericFloat\n\n scala\n import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.utils.T\n\n scala\n val tensor = Tensor(2, 3)\n tensor: com.intel.analytics.bigdl.tensor.Tensor =\n 0.0     0.0     0.0\n 0.0     0.0     0.0\n [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nTensor can be created with existing data.\n\n\nscala\n val a = Tensor(T(\n     | T(1f, 2f, 3f),\n     | T(4f, 5f, 6f)))\na: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 2.0 3.0\n4.0 5.0 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n val b = Tensor(T(\n     | T(6f, 5f, 4f),\n     | T(3f, 2f, 1f)))\nb: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n6.0 5.0 4.0\n3.0 2.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\n\n\n\n+\n \n-\n \n*\n \n/\n can be applied to tensor. When the second parameter is a constant value, \n+\n \n-\n \n*\n \n*\n is element-wise operation. But when the second parameter is a tensor, \n+\n \n-\n \n/\n is element-wise operation to the tensor too, but \n*\n is a matrix multipy on two 2D tensors. \n\n\nscala\n a + 1\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.0 3.0 4.0\n5.0 6.0 7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n a + b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n7.0 7.0 7.0\n7.0 7.0 7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\nscala\n a - b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-5.0    -3.0    -1.0\n1.0 3.0 5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\nscala\n a * b.t\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n28.0    10.0\n73.0    28.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala\n a / b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.16666667  0.4 0.75\n1.3333334   2.5 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nFor more API, please visit \nbigdl scala doc\n\n\n\n\nTable\n\n\nModeled after the \nTable\n class in \nTorch\n, the \nTable\n class (defined in package \ncom.intel.analytics.bigdl.utils\n) is widely used in BigDL (e.g., a \nTable\n of \nTensor\n can be used as the input or output of neural networks). In essence, a \nTable\n can be considered as a key-value map, and there is also a syntax sugar to create a \nTable\n using \nT()\n in BigDL.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nprintln(T(Tensor(2,2).fill(1), Tensor(2,2).fill(2)))\n\n\n\n\nOutput is\n\n\n {\n    2: 2.0  2.0 \n       2.0  2.0 \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1: 1.0  1.0 \n       1.0  1.0 \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }\n\n\n\n\n\n\nSample\n\n\nA \nSample\n represent one record of your data set. One record contains feature and label, feature is one tensor or a few tensors; while label is one tensor or a few tensors, and it may be empty in testing or unsupervised learning. For example, one image and its category in image classification, one word in word2vec and one sentence and its label in RNN language model are all \nSample\n.\n\n\nEvery Sample is actually a set of tensors, and them will be transformed to the input/output of the model. For example, in the case of image classification, a Sample have two tensors. One is 3D tensor representing a image, another is a 1-element tensor representing its category. For the 1-element label, you also can use a \nT\n instead of tensor.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval image = Tensor(3, 32, 32).rand\nval label = 1f\nval sample = Sample(image, label)\n\n\n\n\nPython example:\n\n\nfrom bigdl.util.common import Sample\nimport numpy as np\n\nimage = np.random.rand(3, 32, 32)\nlabel = np.array(1)\nSample.from_ndarray(image, label)\n\n\n\n\n\n\nMiniBatch\n\n\nMiniBatch\n is a data structure to feed input/target to model in \nOptimizer\n. It provide \ngetInput()\n and \ngetTarget()\n function to get the input and target in this \nMiniBatch\n.\n\n\nIn almost all the cases, BigDL's default \nMiniBatch\n class can fit user's requirement. Just create your \nRDD[Sample]\n and pass it to \nOptimizer\n. If \nMiniBatch\n can't meet your requirement, you can implement your own \nMiniBatch\n class by extends \nMiniBatch\n.\n\n\nMiniBatch\n can be created by \nMiniBatch(nInputs: Int, nOutputs: Int)\n, \nnInputs\n means number of inputs, \nnOutputs\n means number of outputs. And you can use \nset(samples: Seq[Sample[T])\n to fill the content in this MiniBatch. If you \nSample\ns are not the same size, you can use \nPaddingParam\n to pad the \nSample\ns to the same size.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.dataset.MiniBatch\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval samples  = Array.tabulate(5)(i =\n Sample(Tensor(1, 3, 3).fill(i), i + 1f))\nval miniBatch = MiniBatch(1, 1).set(samples)\nprintln(miniBatch.getInput())\nprintln(miniBatch.getTarget())\n\n\n\n\nOutput is\n\n\n(1,1,.,.) =\n0.0 0.0 0.0 \n0.0 0.0 0.0 \n0.0 0.0 0.0 \n\n(2,1,.,.) =\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n1.0 1.0 1.0 \n\n(3,1,.,.) =\n2.0 2.0 2.0 \n2.0 2.0 2.0 \n2.0 2.0 2.0 \n\n(4,1,.,.) =\n3.0 3.0 3.0 \n3.0 3.0 3.0 \n3.0 3.0 3.0 \n\n(5,1,.,.) =\n4.0 4.0 4.0 \n4.0 4.0 4.0 \n4.0 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x1x3x3]\n1.0 \n2.0 \n3.0 \n4.0 \n5.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x1]\n\n\n\n\nIf you \nSample\ns are not the same size, you can use \nPaddingParam\n to pad the \nSample\ns to the same size.\n\n\nimport com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval sample1 = Sample(Tensor.range(1, 6, 1).resize(2, 3), 1f)\nval sample2 = Sample(Tensor.range(7, 9, 1).resize(1, 3), 2f)\nval sample3 = Sample(Tensor.range(10, 18, 1).resize(3, 3), 3f)\nval samples = Array(sample1, sample2, sample3)\nval featurePadding = PaddingParam(Some(Array(Tensor(T(-1f, -2f, -3f)))), FixedLength(Array(4)))\nval labelPadding = PaddingParam[Float](None, FixedLength(Array(4)))\n\nval miniBatch = MiniBatch(1, 1, Some(featurePadding), Some(labelPadding)).set(samples)\nprintln(miniBatch.getInput())\nprintln(miniBatch.getTarget())\n\n\n\n\nOutput is \n\n\n(1,.,.) =\n1.0 2.0 3.0 \n4.0 5.0 6.0 \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n\n(2,.,.) =\n7.0 8.0 9.0 \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n\n(3,.,.) =\n10.0    11.0    12.0    \n13.0    14.0    15.0    \n16.0    17.0    18.0    \n-1.0    -2.0    -3.0    \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x3]\n\n\n1.0 0.0 0.0 0.0 \n2.0 0.0 0.0 0.0 \n3.0 0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\n\n\n\n\nDataSet\n\n\nDataSet\n is a set of data which is used in the model optimization process. You can use \nDataSet.array()\n and \nDataSet.rdd()\n function to create a \nDataset\n. The \nDataSet\n can be accessed in a random data sample sequence. In the training process, the data sequence is a looped endless sequence. While in the validation process, the data sequence is a limited length sequence. User can use the \ndata()\n method to get the data sequence. \n\n\nNotice: In most case, we recommand using a RDD[Sample] for \nOptimizer\n. Only when you want to write an application with some advanced optimization, using \nDataSet\n directly is recommanded.  \n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.dataset.DataSet\n\nval tensors  = Array.tabulate(5)(i =\n Tensor(1, 3, 3).fill(i))\nval dataset = DataSet.array(tensors) // Local model, just for testing and example.\ndataset.shuffle()\nval iter = dataset.data(false)\nwhile (iter.hasNext) {\n  val d = iter.next()\n  println(d)\n}\n\n\n\n\nOutput may be\n\n\n(1,.,.) =\n4.0 4.0 4.0 \n4.0 4.0 4.0 \n4.0 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n0.0 0.0 0.0 \n0.0 0.0 0.0 \n0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n2.0 2.0 2.0 \n2.0 2.0 2.0 \n2.0 2.0 2.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n1.0 1.0 1.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n3.0 3.0 3.0 \n3.0 3.0 3.0 \n3.0 3.0 3.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]", 
            "title": "Data"
        }, 
        {
            "location": "/APIdocs/Data/#tensor", 
            "text": "Modeled after the  Tensor  class in  Torch , the  Tensor   package  (written in Scala and leveraging  Intel MKL ) in BigDL provides numeric computing support for the deep learning applications (e.g., the input, output, weight, bias and   gradient of the neural networks).  A  Tensor  is essentially a multi-dimensional array of numeric types ( Float  or  Double ), you can import the numeric implicit objects( com.intel.analytics.bigdl.numeric.NumericFloat  or  com.intel.analytics.bigdl.numeric.NumericDouble ), to specify the numeric type you want.  Scala example:  You may check it out in the interactive Scala shell (by typing  scala -cp bigdl_SPARKVERSION-BIGDLVERSION-SNAPSHOT-jar-with-dependencies.jar ), for instance:   scala  import com.intel.analytics.bigdl.tensor.Tensor\n import com.intel.analytics.bigdl.tensor.Tensor\n\n scala  import com.intel.analytics.bigdl.numeric.NumericFloat\n import com.intel.analytics.bigdl.numeric.NumericFloat\n\n scala  import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.utils.T\n\n scala  val tensor = Tensor(2, 3)\n tensor: com.intel.analytics.bigdl.tensor.Tensor =\n 0.0     0.0     0.0\n 0.0     0.0     0.0\n [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Tensor can be created with existing data.  scala  val a = Tensor(T(\n     | T(1f, 2f, 3f),\n     | T(4f, 5f, 6f)))\na: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 2.0 3.0\n4.0 5.0 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  val b = Tensor(T(\n     | T(6f, 5f, 4f),\n     | T(3f, 2f, 1f)))\nb: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n6.0 5.0 4.0\n3.0 2.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]  +   -   *   /  can be applied to tensor. When the second parameter is a constant value,  +   -   *   *  is element-wise operation. But when the second parameter is a tensor,  +   -   /  is element-wise operation to the tensor too, but  *  is a matrix multipy on two 2D tensors.   scala  a + 1\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.0 3.0 4.0\n5.0 6.0 7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  a + b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n7.0 7.0 7.0\n7.0 7.0 7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\nscala  a - b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-5.0    -3.0    -1.0\n1.0 3.0 5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\nscala  a * b.t\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n28.0    10.0\n73.0    28.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala  a / b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.16666667  0.4 0.75\n1.3333334   2.5 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  For more API, please visit  bigdl scala doc", 
            "title": "Tensor"
        }, 
        {
            "location": "/APIdocs/Data/#table", 
            "text": "Modeled after the  Table  class in  Torch , the  Table  class (defined in package  com.intel.analytics.bigdl.utils ) is widely used in BigDL (e.g., a  Table  of  Tensor  can be used as the input or output of neural networks). In essence, a  Table  can be considered as a key-value map, and there is also a syntax sugar to create a  Table  using  T()  in BigDL.  Scala example:  import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nprintln(T(Tensor(2,2).fill(1), Tensor(2,2).fill(2)))  Output is   {\n    2: 2.0  2.0 \n       2.0  2.0 \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1: 1.0  1.0 \n       1.0  1.0 \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }", 
            "title": "Table"
        }, 
        {
            "location": "/APIdocs/Data/#sample", 
            "text": "A  Sample  represent one record of your data set. One record contains feature and label, feature is one tensor or a few tensors; while label is one tensor or a few tensors, and it may be empty in testing or unsupervised learning. For example, one image and its category in image classification, one word in word2vec and one sentence and its label in RNN language model are all  Sample .  Every Sample is actually a set of tensors, and them will be transformed to the input/output of the model. For example, in the case of image classification, a Sample have two tensors. One is 3D tensor representing a image, another is a 1-element tensor representing its category. For the 1-element label, you also can use a  T  instead of tensor.  Scala example:  import com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval image = Tensor(3, 32, 32).rand\nval label = 1f\nval sample = Sample(image, label)  Python example:  from bigdl.util.common import Sample\nimport numpy as np\n\nimage = np.random.rand(3, 32, 32)\nlabel = np.array(1)\nSample.from_ndarray(image, label)", 
            "title": "Sample"
        }, 
        {
            "location": "/APIdocs/Data/#minibatch", 
            "text": "MiniBatch  is a data structure to feed input/target to model in  Optimizer . It provide  getInput()  and  getTarget()  function to get the input and target in this  MiniBatch .  In almost all the cases, BigDL's default  MiniBatch  class can fit user's requirement. Just create your  RDD[Sample]  and pass it to  Optimizer . If  MiniBatch  can't meet your requirement, you can implement your own  MiniBatch  class by extends  MiniBatch .  MiniBatch  can be created by  MiniBatch(nInputs: Int, nOutputs: Int) ,  nInputs  means number of inputs,  nOutputs  means number of outputs. And you can use  set(samples: Seq[Sample[T])  to fill the content in this MiniBatch. If you  Sample s are not the same size, you can use  PaddingParam  to pad the  Sample s to the same size.  Scala example:  import com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.dataset.MiniBatch\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval samples  = Array.tabulate(5)(i =  Sample(Tensor(1, 3, 3).fill(i), i + 1f))\nval miniBatch = MiniBatch(1, 1).set(samples)\nprintln(miniBatch.getInput())\nprintln(miniBatch.getTarget())  Output is  (1,1,.,.) =\n0.0 0.0 0.0 \n0.0 0.0 0.0 \n0.0 0.0 0.0 \n\n(2,1,.,.) =\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n1.0 1.0 1.0 \n\n(3,1,.,.) =\n2.0 2.0 2.0 \n2.0 2.0 2.0 \n2.0 2.0 2.0 \n\n(4,1,.,.) =\n3.0 3.0 3.0 \n3.0 3.0 3.0 \n3.0 3.0 3.0 \n\n(5,1,.,.) =\n4.0 4.0 4.0 \n4.0 4.0 4.0 \n4.0 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x1x3x3]\n1.0 \n2.0 \n3.0 \n4.0 \n5.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x1]  If you  Sample s are not the same size, you can use  PaddingParam  to pad the  Sample s to the same size.  import com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval sample1 = Sample(Tensor.range(1, 6, 1).resize(2, 3), 1f)\nval sample2 = Sample(Tensor.range(7, 9, 1).resize(1, 3), 2f)\nval sample3 = Sample(Tensor.range(10, 18, 1).resize(3, 3), 3f)\nval samples = Array(sample1, sample2, sample3)\nval featurePadding = PaddingParam(Some(Array(Tensor(T(-1f, -2f, -3f)))), FixedLength(Array(4)))\nval labelPadding = PaddingParam[Float](None, FixedLength(Array(4)))\n\nval miniBatch = MiniBatch(1, 1, Some(featurePadding), Some(labelPadding)).set(samples)\nprintln(miniBatch.getInput())\nprintln(miniBatch.getTarget())  Output is   (1,.,.) =\n1.0 2.0 3.0 \n4.0 5.0 6.0 \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n\n(2,.,.) =\n7.0 8.0 9.0 \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n\n(3,.,.) =\n10.0    11.0    12.0    \n13.0    14.0    15.0    \n16.0    17.0    18.0    \n-1.0    -2.0    -3.0    \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x3]\n\n\n1.0 0.0 0.0 0.0 \n2.0 0.0 0.0 0.0 \n3.0 0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]", 
            "title": "MiniBatch"
        }, 
        {
            "location": "/APIdocs/Data/#dataset", 
            "text": "DataSet  is a set of data which is used in the model optimization process. You can use  DataSet.array()  and  DataSet.rdd()  function to create a  Dataset . The  DataSet  can be accessed in a random data sample sequence. In the training process, the data sequence is a looped endless sequence. While in the validation process, the data sequence is a limited length sequence. User can use the  data()  method to get the data sequence.   Notice: In most case, we recommand using a RDD[Sample] for  Optimizer . Only when you want to write an application with some advanced optimization, using  DataSet  directly is recommanded.    Scala example:  import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.dataset.DataSet\n\nval tensors  = Array.tabulate(5)(i =  Tensor(1, 3, 3).fill(i))\nval dataset = DataSet.array(tensors) // Local model, just for testing and example.\ndataset.shuffle()\nval iter = dataset.data(false)\nwhile (iter.hasNext) {\n  val d = iter.next()\n  println(d)\n}  Output may be  (1,.,.) =\n4.0 4.0 4.0 \n4.0 4.0 4.0 \n4.0 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n0.0 0.0 0.0 \n0.0 0.0 0.0 \n0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n2.0 2.0 2.0 \n2.0 2.0 2.0 \n2.0 2.0 2.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n1.0 1.0 1.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n3.0 3.0 3.0 \n3.0 3.0 3.0 \n3.0 3.0 3.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]", 
            "title": "DataSet"
        }, 
        {
            "location": "/APIdocs/Module/", 
            "text": "Module Class Overview\n\n\nModule (Scala) or Model (Python) provides API to faciliate user's requirement to save model to specific path, load model from given path, evaluate model and predict with model, etc.\n\n\nModel Save\n\n\nBigDL supports different file systems like Linux file system, HDFS and AWS S3. Use \nmodel.save\n to save models. Below is an example of how to save a model to local file system. \n\n\nScala example\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval model = Sequential().add(Linear(10, 5)).add(Sigmoid()).add(SoftMax())\n//...train\nmodel.save(\n/tmp/model.bigdl\n, true)\n\n\n\n\nPython example\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.util.common import *\nfrom bigdl.optim.optimizer import *\n\nmodel = Sequential().add(Linear(10, 5)).add(Sigmoid()).add(SoftMax())\n//...train\nmodel.save(\n/tmp/model.bigdl\n, True)\n\n\n\n\nIn \nmodel.save\n, the first parameter is the path where we want to save our model, the second paramter is to specify if we need to overwrite the file if it already exists, it's set to false by default\n\n\nModel Load\n\n\nUse \nModule.load\n(in Scala) or \nModel.load\n (in Python) to load an existing model. We just need to specify the model path where we previously saved the model to load it to memory for resume training or prediction purpose\n\n\nScala example\n\n\nval loadedModel = Module.load(\n/tmp/model.bigdl\n)\n\n\n\n\nModule\n above is a utilily  to manipulate module APIs\n\n\nPython example\n\n\nmodel = Model.load(\n/tmp/model.bigdl\n)\n\n\n\n\nModel\n is a utility for python mirroring \nModule\n in scala\n\n\nModel Evaluation\n\n\nUse \nmodel.evaluate\n to evaluate the model with validation data.\n\n\nScala example\n\n\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.optim.Top1Accuracy\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n//create some dummy dataset for evaluation\nval feature = Tensor(10).rand()\nval label = Tensor(1).randn()\n\nval testSample = Sample(feature, label)\n//sc is is the SparkContxt instance\nval testSet = sc.parallelize(Seq(testSample))\n\n//train a new model or load an existing model\n//val model=...\nval evaluateResult = model.evaluate(testSet, Array(new Top1Accuracy))\n\n\n\n\nPython example\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.util.common import *\nfrom bigdl.optim.optimizer import *\nimport numpy as np\n\nsamples=[Sample.from_ndarray(np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]), np.array([2.0]))]\ntestSet = sc.parallelize(samples)\n\n//train a model or load an existing model...\n//model = ...\nevaluateResult = model.evaluate(testSet, 1, [Top1Accuracy])\n\n\n\n\nModel Prediction\n\n\nUse \nmodel.predict\n for Prediction.\n\n\nScala example\n\n\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.optim.Top1Accuracy\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n//create some dummy dataset for prediction as example\nval feature = Tensor(10).rand()\nval label = Tensor(1).randn()\nval predictSample = Sample(feature, label)\nval predictSet = sc.parallelize(Seq(predictSample))\n\n//train a new model or load an existing model\n//val model=... \nval preductResult = model.predict(predictSet)\n\n\n\n\nPython example\n\n\n from bigdl.nn.layer import *\n from bigdl.util.common import *\n from bigdl.optim.optimizer import *\n import numpy as np\n\n samples=[Sample.from_ndarray(np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]), np.  array([2.0]))]\n\n predictSet = sc.parallelize(samples)\n\n //train a model or load an existing model...\n //model = ...\n preductResult = model.predict(predictSet)", 
            "title": "Module"
        }, 
        {
            "location": "/APIdocs/Module/#module-class-overview", 
            "text": "Module (Scala) or Model (Python) provides API to faciliate user's requirement to save model to specific path, load model from given path, evaluate model and predict with model, etc.", 
            "title": "Module Class Overview"
        }, 
        {
            "location": "/APIdocs/Module/#model-save", 
            "text": "BigDL supports different file systems like Linux file system, HDFS and AWS S3. Use  model.save  to save models. Below is an example of how to save a model to local file system.   Scala example  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval model = Sequential().add(Linear(10, 5)).add(Sigmoid()).add(SoftMax())\n//...train\nmodel.save( /tmp/model.bigdl , true)  Python example  from bigdl.nn.layer import *\nfrom bigdl.util.common import *\nfrom bigdl.optim.optimizer import *\n\nmodel = Sequential().add(Linear(10, 5)).add(Sigmoid()).add(SoftMax())\n//...train\nmodel.save( /tmp/model.bigdl , True)  In  model.save , the first parameter is the path where we want to save our model, the second paramter is to specify if we need to overwrite the file if it already exists, it's set to false by default", 
            "title": "Model Save"
        }, 
        {
            "location": "/APIdocs/Module/#model-load", 
            "text": "Use  Module.load (in Scala) or  Model.load  (in Python) to load an existing model. We just need to specify the model path where we previously saved the model to load it to memory for resume training or prediction purpose  Scala example  val loadedModel = Module.load( /tmp/model.bigdl )  Module  above is a utilily  to manipulate module APIs  Python example  model = Model.load( /tmp/model.bigdl )  Model  is a utility for python mirroring  Module  in scala", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIdocs/Module/#model-evaluation", 
            "text": "Use  model.evaluate  to evaluate the model with validation data.  Scala example  import com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.optim.Top1Accuracy\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n//create some dummy dataset for evaluation\nval feature = Tensor(10).rand()\nval label = Tensor(1).randn()\n\nval testSample = Sample(feature, label)\n//sc is is the SparkContxt instance\nval testSet = sc.parallelize(Seq(testSample))\n\n//train a new model or load an existing model\n//val model=...\nval evaluateResult = model.evaluate(testSet, Array(new Top1Accuracy))  Python example  from bigdl.nn.layer import *\nfrom bigdl.util.common import *\nfrom bigdl.optim.optimizer import *\nimport numpy as np\n\nsamples=[Sample.from_ndarray(np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]), np.array([2.0]))]\ntestSet = sc.parallelize(samples)\n\n//train a model or load an existing model...\n//model = ...\nevaluateResult = model.evaluate(testSet, 1, [Top1Accuracy])", 
            "title": "Model Evaluation"
        }, 
        {
            "location": "/APIdocs/Module/#model-prediction", 
            "text": "Use  model.predict  for Prediction.  Scala example  import com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.optim.Top1Accuracy\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n//create some dummy dataset for prediction as example\nval feature = Tensor(10).rand()\nval label = Tensor(1).randn()\nval predictSample = Sample(feature, label)\nval predictSet = sc.parallelize(Seq(predictSample))\n\n//train a new model or load an existing model\n//val model=... \nval preductResult = model.predict(predictSet)  Python example   from bigdl.nn.layer import *\n from bigdl.util.common import *\n from bigdl.optim.optimizer import *\n import numpy as np\n\n samples=[Sample.from_ndarray(np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]), np.  array([2.0]))]\n\n predictSet = sc.parallelize(samples)\n\n //train a model or load an existing model...\n //model = ...\n preductResult = model.predict(predictSet)", 
            "title": "Model Prediction"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/", 
            "text": "Graph\n\n\nScala:\n\n\nval graph = Graph(Array(Node), Array(Node))\n\n\n\n\nPython:\n\n\nmodel = Model([Node], [Node])\n\n\n\n\nA graph container. Each node can have multiple inputs. The output of the node should be a tensor.\n The output tensor can be connected to multiple nodes. So the module in each node can have a\n tensor or table input, and should have a tensor output.\n\n\nThe graph container can have multiple inputs and multiple outputs. If there's one input, the\n input data fed to the graph module should be a tensor. If there're multiple inputs, the input\n data fed to the graph module should be a table, which is actually an sequence of tensor. The\n order of the input tensors should be same with the order of the input nodes. This is also\n applied to the gradient from the module in the back propagation.\n\n\nAll of the input modules must accept a tensor input. If your input module accept multiple\n tensors as input, you should add some \nInput layer\n before\n it as input nodes and connect the output of the Input modules to that module.\n\n\nIf there's one output, the module output is a tensor. If there're multiple outputs, the module\n output is a table, which is actually an sequence of tensor. The order of the output tensors is\n same with the order of the output modules. This is also applied to the gradient passed to the\n module in the back propagation.\n\n\nAll inputs should be able to connect to outputs through some paths in the graph. It is\n allowed that some successors of the inputs node are not connect to outputs. If so, these nodes\n will be excluded in the computation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\n\nval input1 = Input()\nval input2 = Input()\nval cadd = CAddTable().inputs(input1, input2)\nval graph = Graph(Array(input1, input2), cadd)\n\nval output = graph.forward(T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n    Tensor(T(0.5f, 0.4f, -0.2f, -0.1f))))\nval gradInput = graph.backward(T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n    Tensor(T(0.5f, 0.4f, -0.2f, -0.1f))),\n    Tensor(T(0.1f, 0.2f, 0.3f, 0.4f)))\n\n\n println(output)\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.6\n0.6\n-0.5\n-0.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n println(gradInput)\ngradInput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n {\n        2: 0.1\n           0.2\n           0.3\n           0.4\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n        1: 0.1\n           0.2\n           0.3\n           0.4\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n }\n\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\n\ninput1 = Input()\ninput2 = Input()\ncadd = CAddTable()([input1, input2])\nmodel = Model([input1, input2], [cadd])\noutput = model.forward([\n    np.array([0.1, 0.2, -0.3, -0.4]),\n    np.array([0.5, 0.4, -0.2, -0.1])])\n\n\n output\narray([ 0.60000002,  0.60000002, -0.5       , -0.5       ], dtype=float32)\n\ngradInput = model.backward([\n        np.array([0.1, 0.2, -0.3, -0.4]),\n        np.array([0.5, 0.4, -0.2, -0.1])\n    ],\n    np.array([0.1, 0.2, 0.3, 0.4])\n)\n\n\n gradInput\n[array([ 0.1       ,  0.2       ,  0.30000001,  0.40000001], dtype=float32),\n    array([ 0.1       ,  0.2       ,  0.30000001,  0.40000001], dtype=float32)]\n\n\n\n\n\n\nBottle\n\n\nScala:\n\n\nval model = Bottle(module, nInputDim, nOutputDim)\n\n\n\n\nPython:\n\n\nmodel = Bottle(module, nInputDim, nOutputDim)\n\n\n\n\nBottle allows varying dimensionality input to be forwarded through any module that accepts input of nInputDim dimensions, and generates output of nOutputDim dimensions.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Bottle(Linear(3, 2), 2, 2)\nval input = Tensor(2, 3, 3).rand()\n\nscala\n print(input)\n(1,.,.) =\n0.7843752   0.17286697  0.20767091  \n0.8594811   0.9100018   0.8448141   \n0.7683892   0.36661968  0.76637685  \n\n(2,.,.) =\n0.7163263   0.083962396 0.81222403  \n0.7947034   0.09976136  0.114404656 \n0.14890474  0.43289232  0.1489096   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3x3] \n\nval output = model.forward(input)\n\nscala\n print(output)\n(1,.,.) =\n-0.31146684 0.40719786  \n-0.51778656 0.58715886  \n-0.51676923 0.4027511   \n\n(2,.,.) =\n-0.5498678  0.29658738  \n-0.280177   0.39901164  \n-0.2387946  0.24809375  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2]\n\n\n\n\nPython example:\n\n\nmodel = Bottle(Linear(3, 2), 2, 2)\n\ninput = np.random.randn(2, 3, 3)\noutput = model.forward(input)\n\n\n print(input)\n[[[ 0.42370589 -1.7938942   0.56666373]\n  [-1.78501381  0.55676471 -0.50150367]\n  [-1.59262182  0.82079469  1.1873599 ]]\n\n [[ 0.95799792 -0.71447244  1.05344083]\n  [-0.07838376 -0.88780484 -1.80491177]\n  [ 0.99996222  1.39876002 -0.16326094]]]\n\n print(output)\n[[[ 0.26298434  0.74947536]\n  [-1.24375117 -0.33148435]\n  [-1.35218966  0.17042145]]\n\n [[ 0.08041853  0.91245329]\n  [-0.08317742 -0.13909879]\n  [-0.52287608  0.3667658 ]]]\n\n\n\n\nContainer\n\n\nContainer is a subclass of abstract class AbstractModule, which\ndeclares methods defined in all containers. A container usually\ncontains some other modules in the \nmodules\n variable. It overrides\nmany module methods such that calls are propogated to the contained\nmodules.\n\n\nTimeDistributed\n\n\nScala:\n\n\nval layer = TimeDistributed(layer)\n\n\n\n\nPython:\n\n\nlayer = TimeDistributed(layer)\n\n\n\n\nThis layer is intended to apply contained layer to each temporal time slice\nof input tensor.\n\n\nThe input data format is [Batch, Time, Other dims]. For the contained layer, it must not change\nthe Other dims length.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = TimeDistributed(Sum(1, squeeze = false, nInputDims = 2))\nval input = Tensor(T(T(\n  T(\n    T(1.0f, 2.0f),\n    T(3.0f, 4.0f)\n  ),\n  T(\n    T(2.0f, 3.0f),\n    T(4.0f, 5.0f)\n  )\n)))\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(\n  T(\n    T(0.1f, 0.2f)\n  ),\n  T(\n    T(0.3f, 0.4f)\n  )\n))))\n\n\n\n\nIts output should be\n\n\n(1,1,.,.) =\n4.0     6.0\n\n(1,2,.,.) =\n6.0     8.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1x2]\n\n(1,1,.,.) =\n0.1     0.2\n0.1     0.2\n\n(1,2,.,.) =\n0.3     0.4\n0.3     0.4\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import TimeDistributed,Sum\nimport numpy as np\n\nlayer = TimeDistributed(Sum(1, squeeze = False, n_input_dims = 2))\n\ninput = np.array([[\n  [\n    [1.0, 2.0],\n    [3.0, 4.0]\n  ],\n  [\n    [2.0, 3.0],\n    [4.0, 5.0]\n  ]\n]])\nlayer.forward(input)\nlayer.backward(input, np.array([[\n  [\n    [0.1, 0.2]\n  ],\n  [\n    [0.3, 0.4]\n  ]\n]]))\n\n\n\n\nIts output should be\n\n\narray([[[[ 4.,  6.]],\n\n        [[ 6.,  8.]]]], dtype=float32)\n\narray([[[[ 0.1       ,  0.2       ],\n         [ 0.1       ,  0.2       ]],\n\n        [[ 0.30000001,  0.40000001],\n         [ 0.30000001,  0.40000001]]]], dtype=float32)\n\n\n\n\nMapTable\n\n\nScala:\n\n\nval mod = MapTable(module=null)\n\n\n\n\nPython:\n\n\nmod = MapTable(module=None)\n\n\n\n\nThis class is a container for a single module which will be applied\nto all input elements. The member module is cloned as necessary to\nprocess all input elements.\n\n\nmodule\n a member module.  \n\n\n+----------+         +-----------+\n| {input1, +---------\n {member,  |\n|          |         |           |\n|  input2, +---------\n  clone,   |\n|          |         |           |\n|  input3} +---------\n  clone}   |\n+----------+         +-----------+\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T \n\nval map = MapTable()\nmap.add(Linear(10, 3))\nval input = T(\n      Tensor(10).randn(),\n      Tensor(10).randn())\n\n print(map.forward(input))\n{\n    2: 0.2444828\n       -1.1700082\n       0.15887381\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    1: 0.06696482\n       0.18692614\n       -1.432079\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nmap = MapTable()\nmap.add(Linear(10, 3))\ninput = [np.random.rand(10), np.random.rand(10)]\n\nmap.forward(input)\n[array([ 0.69586945, -0.70547599, -0.05802459], dtype=float32),\n array([ 0.47995114, -0.67459631, -0.52500772], dtype=float32)]\n\n\n\n\nConcatTable\n\n\nScala:\n\n\nval module = ConcatTable()\n\n\n\n\nPython:\n\n\nmodule = ConcatTable()\n\n\n\n\nConcateTable is a container module like Concate. Applies an input\nto each member module, input can be a tensor or a table.\n\n\nConcateTable usually works with CAddTable and CMulTable to\n implement element wise add/multiply on outputs of two modules.\n\n\n                   +-----------+\n             +----\n {member1, |\n+-------+    |    |           |\n| input +----+----\n  member2, |\n+-------+    |    |           |\n   or        +----\n  member3} |\n {input}          +-----------+\n\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mlp = ConcatTable()\nmlp.add(Linear(3, 2))\nmlp.add(Linear(3, 4))\n\n\n print(mlp.forward(Tensor(2, 3).rand()))\n\n{\n    2: -0.37111914  0.8542446   -0.362602   -0.75522065 \n       -0.28713673  0.6021913   -0.16525984 -0.44689763 \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n    1: -0.79941726  0.8303885   \n       -0.8342782   0.89961016  \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nmlp = ConcatTable()\nmlp.add(Linear(3, 2))   \nmlp.add(Linear(3, 4))\n\n mlp.forward(np.array([[1, 2, 3], [1, 2, 3]]))\nout: [array([[ 1.16408789, -0.1508013 ],\n             [ 1.16408789, -0.1508013 ]], dtype=float32),\n      array([[-0.24672163, -0.56958938, -0.51390374,  0.64546645],\n             [-0.24672163, -0.56958938, -0.51390374,  0.64546645]], dtype=float32)]\n\n\n\n\n\nParallelTable\n\n\nScala:\n\n\nval module = ParallelTable()\n\n\n\n\nPython:\n\n\nmodule = ParallelTable()\n\n\n\n\nIt is a container module that applies the i-th member module to the i-th\n input, and outputs an output in the form of Table\n\n\n+----------+         +-----------+\n| {input1, +---------\n {member1, |\n|          |         |           |\n|  input2, +---------\n  member2, |\n|          |         |           |\n|  input3} +---------\n  member3} |\n+----------+         +-----------+\n\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = ParallelTable()\nval log = Log()\nval exp = Exp()\nmodule.add(log)\nmodule.add(exp)\nval input1 = Tensor(3, 3).rand(0, 1)\nval input2 = Tensor(3).rand(0, 1)\nval input = T(1 -\n input1, 2 -\n input2)\n\n print(module.forward(input))\n {\n        2: 2.6996834\n           2.0741253\n           1.0625387\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: -1.073425    -0.6672964      -1.8160943\n           -0.54094607  -1.3029919      -1.7064717\n           -0.66175103  -0.08288143     -1.1840979\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nmodule = ParallelTable()\nlog = Log()\nexp = Exp()\nmodule.add(log)\nmodule.add(exp)\ninput1 = np.random.rand(3,3)\ninput2 = np.random.rand(3)\n\nmodule.forward([input1, input2])\n[array([[-1.27472472, -2.18216252, -0.60752904],\n        [-2.76213861, -1.77966928, -0.13652121],\n        [-1.47725129, -0.03578046, -1.37736678]], dtype=float32),\n array([ 1.10634041,  1.46384597,  1.96525407], dtype=float32)]\n\n\n\n\nConcat\n\n\nScala:\n\n\nval module = Concat(dimension)\n\n\n\n\nPython:\n\n\nmodule = Concat(dimension)\n\n\n\n\nConcat is a container who concatenates the output of it's submodules along the\nprovided \ndimension\n: all submodules take the same inputs, and their output is\nconcatenated.\n\n\n                 +----Concat----+\n            +----\n  submodule1  -----+\n            |    |              |    |\n input -----+----\n  submodule2  -----+----\n output\n            |    |              |    |\n            +----\n  submodule3  -----+\n                 +--------------+\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mlp = Concat(2)\nmlp.add(Linear(3,2))\nmlp.add(Linear(3,4))\n\nprintln(mlp.forward(Tensor(2, 3).rand()))\n\n\n\n\nOutput is\n\n\n-0.17087375 0.12954286  0.15685591  -0.027277306    0.38549712  -0.20375136\n-0.9473443  0.030516684 0.23380546  0.625985    -0.031360716    0.40449825\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmlp = Concat(2)\nmlp.add(Linear(3,2))\nmlp.add(Linear(3,4))\nprint(mlp.forward(np.array([[1, 2, 3], [1, 2, 3]])))\n\n\n\n\nOutput is\n\n\n[array([\n[-0.71994132,  2.17439198, -1.46522939,  0.64588934,  2.61534023, -2.39528942],\n[-0.89125222,  5.49583197, -2.8865242 ,  1.44914722,  5.26639175, -6.26586771]]\n      dtype=float32)]\n\n\n\n\n\nSequential\n\n\nScala:\n\n\nval module = Sequential()\n\n\n\n\nPython:\n\n\nseq = Sequential()\n\n\n\n\nSequential provides a means to plug layers together\nin a feed-forward fully connected manner.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nimport com.intel.analytics.bigdl.nn.{Sequential, Linear}\n\nval module = Sequential()\nmodule.add(Linear(10, 25))\nmodule.add(Linear(25, 10))\n\nval input = Tensor(10).range(1, 10, 1)\nval gradOutput = Tensor(10).range(1, 10, 1)\n\nval output = module.forward(input).toTensor\nval gradInput = module.backward(input, gradOutput).toTensor\n\nprintln(output)\nprintln(gradInput)\n\n\n\n\nThe output is,\n\n\n-2.3750305\n2.4512818\n1.6998017\n-0.47432393\n4.3048754\n-0.044168986\n-1.1643536\n0.60341483\n2.0216258\n2.1190155\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10]\n\n\n\n\nThe gradInput is,\n\n\n2.593382\n-1.4137214\n-1.8271983\n1.229643\n0.51384985\n1.509845\n2.9537349\n1.088281\n0.2618509\n1.4840821\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nseq = Sequential()\nseq.add(Linear(10, 25))\nseq.add(Linear(25, 10))\n\ninput = np.arange(1, 11, 1).astype(\nfloat32\n)\ninput = input.reshape(1, 10)\n\noutput = seq.forward(input)\nprint output\n\ngradOutput = np.arange(1, 11, 1).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(1, 10)\n\ngradInput = seq.backward(input, gradOutput)\nprint gradInput\n\n\n\n\nThe output is,\n\n\n[array([[ 1.08462083, -2.03257799, -0.5400058 ,  0.27452484,  1.85562158,\n         1.64338267,  2.45694995,  1.70170391, -2.12998056, -1.28924525]], dtype=float32)]\n\n\n\n\nThe gradInput is,\n\n\n\n[array([[ 1.72007763,  1.64403224,  2.52977395, -1.00021958,  0.1134415 ,\n         2.06711197,  2.29631734, -3.39587498,  1.01093054, -0.54482007]], dtype=float32)]", 
            "title": "Containers"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/#graph", 
            "text": "Scala:  val graph = Graph(Array(Node), Array(Node))  Python:  model = Model([Node], [Node])  A graph container. Each node can have multiple inputs. The output of the node should be a tensor.\n The output tensor can be connected to multiple nodes. So the module in each node can have a\n tensor or table input, and should have a tensor output.  The graph container can have multiple inputs and multiple outputs. If there's one input, the\n input data fed to the graph module should be a tensor. If there're multiple inputs, the input\n data fed to the graph module should be a table, which is actually an sequence of tensor. The\n order of the input tensors should be same with the order of the input nodes. This is also\n applied to the gradient from the module in the back propagation.  All of the input modules must accept a tensor input. If your input module accept multiple\n tensors as input, you should add some  Input layer  before\n it as input nodes and connect the output of the Input modules to that module.  If there's one output, the module output is a tensor. If there're multiple outputs, the module\n output is a table, which is actually an sequence of tensor. The order of the output tensors is\n same with the order of the output modules. This is also applied to the gradient passed to the\n module in the back propagation.  All inputs should be able to connect to outputs through some paths in the graph. It is\n allowed that some successors of the inputs node are not connect to outputs. If so, these nodes\n will be excluded in the computation.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\n\nval input1 = Input()\nval input2 = Input()\nval cadd = CAddTable().inputs(input1, input2)\nval graph = Graph(Array(input1, input2), cadd)\n\nval output = graph.forward(T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n    Tensor(T(0.5f, 0.4f, -0.2f, -0.1f))))\nval gradInput = graph.backward(T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n    Tensor(T(0.5f, 0.4f, -0.2f, -0.1f))),\n    Tensor(T(0.1f, 0.2f, 0.3f, 0.4f)))  println(output)\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.6\n0.6\n-0.5\n-0.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  println(gradInput)\ngradInput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n {\n        2: 0.1\n           0.2\n           0.3\n           0.4\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n        1: 0.1\n           0.2\n           0.3\n           0.4\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n }  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\n\ninput1 = Input()\ninput2 = Input()\ncadd = CAddTable()([input1, input2])\nmodel = Model([input1, input2], [cadd])\noutput = model.forward([\n    np.array([0.1, 0.2, -0.3, -0.4]),\n    np.array([0.5, 0.4, -0.2, -0.1])])  output\narray([ 0.60000002,  0.60000002, -0.5       , -0.5       ], dtype=float32)\n\ngradInput = model.backward([\n        np.array([0.1, 0.2, -0.3, -0.4]),\n        np.array([0.5, 0.4, -0.2, -0.1])\n    ],\n    np.array([0.1, 0.2, 0.3, 0.4])\n)  gradInput\n[array([ 0.1       ,  0.2       ,  0.30000001,  0.40000001], dtype=float32),\n    array([ 0.1       ,  0.2       ,  0.30000001,  0.40000001], dtype=float32)]", 
            "title": "Graph"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/#bottle", 
            "text": "Scala:  val model = Bottle(module, nInputDim, nOutputDim)  Python:  model = Bottle(module, nInputDim, nOutputDim)  Bottle allows varying dimensionality input to be forwarded through any module that accepts input of nInputDim dimensions, and generates output of nOutputDim dimensions.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Bottle(Linear(3, 2), 2, 2)\nval input = Tensor(2, 3, 3).rand()\n\nscala  print(input)\n(1,.,.) =\n0.7843752   0.17286697  0.20767091  \n0.8594811   0.9100018   0.8448141   \n0.7683892   0.36661968  0.76637685  \n\n(2,.,.) =\n0.7163263   0.083962396 0.81222403  \n0.7947034   0.09976136  0.114404656 \n0.14890474  0.43289232  0.1489096   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3x3] \n\nval output = model.forward(input)\n\nscala  print(output)\n(1,.,.) =\n-0.31146684 0.40719786  \n-0.51778656 0.58715886  \n-0.51676923 0.4027511   \n\n(2,.,.) =\n-0.5498678  0.29658738  \n-0.280177   0.39901164  \n-0.2387946  0.24809375  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2]  Python example:  model = Bottle(Linear(3, 2), 2, 2)\n\ninput = np.random.randn(2, 3, 3)\noutput = model.forward(input)  print(input)\n[[[ 0.42370589 -1.7938942   0.56666373]\n  [-1.78501381  0.55676471 -0.50150367]\n  [-1.59262182  0.82079469  1.1873599 ]]\n\n [[ 0.95799792 -0.71447244  1.05344083]\n  [-0.07838376 -0.88780484 -1.80491177]\n  [ 0.99996222  1.39876002 -0.16326094]]]  print(output)\n[[[ 0.26298434  0.74947536]\n  [-1.24375117 -0.33148435]\n  [-1.35218966  0.17042145]]\n\n [[ 0.08041853  0.91245329]\n  [-0.08317742 -0.13909879]\n  [-0.52287608  0.3667658 ]]]", 
            "title": "Bottle"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/#container", 
            "text": "Container is a subclass of abstract class AbstractModule, which\ndeclares methods defined in all containers. A container usually\ncontains some other modules in the  modules  variable. It overrides\nmany module methods such that calls are propogated to the contained\nmodules.", 
            "title": "Container"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/#timedistributed", 
            "text": "Scala:  val layer = TimeDistributed(layer)  Python:  layer = TimeDistributed(layer)  This layer is intended to apply contained layer to each temporal time slice\nof input tensor.  The input data format is [Batch, Time, Other dims]. For the contained layer, it must not change\nthe Other dims length.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = TimeDistributed(Sum(1, squeeze = false, nInputDims = 2))\nval input = Tensor(T(T(\n  T(\n    T(1.0f, 2.0f),\n    T(3.0f, 4.0f)\n  ),\n  T(\n    T(2.0f, 3.0f),\n    T(4.0f, 5.0f)\n  )\n)))\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(\n  T(\n    T(0.1f, 0.2f)\n  ),\n  T(\n    T(0.3f, 0.4f)\n  )\n))))  Its output should be  (1,1,.,.) =\n4.0     6.0\n\n(1,2,.,.) =\n6.0     8.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1x2]\n\n(1,1,.,.) =\n0.1     0.2\n0.1     0.2\n\n(1,2,.,.) =\n0.3     0.4\n0.3     0.4\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]  Python example:  from bigdl.nn.layer import TimeDistributed,Sum\nimport numpy as np\n\nlayer = TimeDistributed(Sum(1, squeeze = False, n_input_dims = 2))\n\ninput = np.array([[\n  [\n    [1.0, 2.0],\n    [3.0, 4.0]\n  ],\n  [\n    [2.0, 3.0],\n    [4.0, 5.0]\n  ]\n]])\nlayer.forward(input)\nlayer.backward(input, np.array([[\n  [\n    [0.1, 0.2]\n  ],\n  [\n    [0.3, 0.4]\n  ]\n]]))  Its output should be  array([[[[ 4.,  6.]],\n\n        [[ 6.,  8.]]]], dtype=float32)\n\narray([[[[ 0.1       ,  0.2       ],\n         [ 0.1       ,  0.2       ]],\n\n        [[ 0.30000001,  0.40000001],\n         [ 0.30000001,  0.40000001]]]], dtype=float32)", 
            "title": "TimeDistributed"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/#maptable", 
            "text": "Scala:  val mod = MapTable(module=null)  Python:  mod = MapTable(module=None)  This class is a container for a single module which will be applied\nto all input elements. The member module is cloned as necessary to\nprocess all input elements.  module  a member module.    +----------+         +-----------+\n| {input1, +---------  {member,  |\n|          |         |           |\n|  input2, +---------   clone,   |\n|          |         |           |\n|  input3} +---------   clone}   |\n+----------+         +-----------+  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T \n\nval map = MapTable()\nmap.add(Linear(10, 3))\nval input = T(\n      Tensor(10).randn(),\n      Tensor(10).randn())  print(map.forward(input))\n{\n    2: 0.2444828\n       -1.1700082\n       0.15887381\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    1: 0.06696482\n       0.18692614\n       -1.432079\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }  Python example:  from bigdl.nn.layer import *\n\nmap = MapTable()\nmap.add(Linear(10, 3))\ninput = [np.random.rand(10), np.random.rand(10)] map.forward(input)\n[array([ 0.69586945, -0.70547599, -0.05802459], dtype=float32),\n array([ 0.47995114, -0.67459631, -0.52500772], dtype=float32)]", 
            "title": "MapTable"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/#concattable", 
            "text": "Scala:  val module = ConcatTable()  Python:  module = ConcatTable()  ConcateTable is a container module like Concate. Applies an input\nto each member module, input can be a tensor or a table.  ConcateTable usually works with CAddTable and CMulTable to\n implement element wise add/multiply on outputs of two modules.                     +-----------+\n             +----  {member1, |\n+-------+    |    |           |\n| input +----+----   member2, |\n+-------+    |    |           |\n   or        +----   member3} |\n {input}          +-----------+  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mlp = ConcatTable()\nmlp.add(Linear(3, 2))\nmlp.add(Linear(3, 4))  print(mlp.forward(Tensor(2, 3).rand()))\n\n{\n    2: -0.37111914  0.8542446   -0.362602   -0.75522065 \n       -0.28713673  0.6021913   -0.16525984 -0.44689763 \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n    1: -0.79941726  0.8303885   \n       -0.8342782   0.89961016  \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n }  Python example:  from bigdl.nn.layer import *\n\nmlp = ConcatTable()\nmlp.add(Linear(3, 2))   \nmlp.add(Linear(3, 4))  mlp.forward(np.array([[1, 2, 3], [1, 2, 3]]))\nout: [array([[ 1.16408789, -0.1508013 ],\n             [ 1.16408789, -0.1508013 ]], dtype=float32),\n      array([[-0.24672163, -0.56958938, -0.51390374,  0.64546645],\n             [-0.24672163, -0.56958938, -0.51390374,  0.64546645]], dtype=float32)]", 
            "title": "ConcatTable"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/#paralleltable", 
            "text": "Scala:  val module = ParallelTable()  Python:  module = ParallelTable()  It is a container module that applies the i-th member module to the i-th\n input, and outputs an output in the form of Table  +----------+         +-----------+\n| {input1, +---------  {member1, |\n|          |         |           |\n|  input2, +---------   member2, |\n|          |         |           |\n|  input3} +---------   member3} |\n+----------+         +-----------+  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = ParallelTable()\nval log = Log()\nval exp = Exp()\nmodule.add(log)\nmodule.add(exp)\nval input1 = Tensor(3, 3).rand(0, 1)\nval input2 = Tensor(3).rand(0, 1)\nval input = T(1 -  input1, 2 -  input2)  print(module.forward(input))\n {\n        2: 2.6996834\n           2.0741253\n           1.0625387\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: -1.073425    -0.6672964      -1.8160943\n           -0.54094607  -1.3029919      -1.7064717\n           -0.66175103  -0.08288143     -1.1840979\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }  Python example:  from bigdl.nn.layer import *\n\nmodule = ParallelTable()\nlog = Log()\nexp = Exp()\nmodule.add(log)\nmodule.add(exp)\ninput1 = np.random.rand(3,3)\ninput2 = np.random.rand(3) module.forward([input1, input2])\n[array([[-1.27472472, -2.18216252, -0.60752904],\n        [-2.76213861, -1.77966928, -0.13652121],\n        [-1.47725129, -0.03578046, -1.37736678]], dtype=float32),\n array([ 1.10634041,  1.46384597,  1.96525407], dtype=float32)]", 
            "title": "ParallelTable"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/#concat", 
            "text": "Scala:  val module = Concat(dimension)  Python:  module = Concat(dimension)  Concat is a container who concatenates the output of it's submodules along the\nprovided  dimension : all submodules take the same inputs, and their output is\nconcatenated.                   +----Concat----+\n            +----   submodule1  -----+\n            |    |              |    |\n input -----+----   submodule2  -----+----  output\n            |    |              |    |\n            +----   submodule3  -----+\n                 +--------------+  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mlp = Concat(2)\nmlp.add(Linear(3,2))\nmlp.add(Linear(3,4))\n\nprintln(mlp.forward(Tensor(2, 3).rand()))  Output is  -0.17087375 0.12954286  0.15685591  -0.027277306    0.38549712  -0.20375136\n-0.9473443  0.030516684 0.23380546  0.625985    -0.031360716    0.40449825\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmlp = Concat(2)\nmlp.add(Linear(3,2))\nmlp.add(Linear(3,4))\nprint(mlp.forward(np.array([[1, 2, 3], [1, 2, 3]])))  Output is  [array([\n[-0.71994132,  2.17439198, -1.46522939,  0.64588934,  2.61534023, -2.39528942],\n[-0.89125222,  5.49583197, -2.8865242 ,  1.44914722,  5.26639175, -6.26586771]]\n      dtype=float32)]", 
            "title": "Concat"
        }, 
        {
            "location": "/APIdocs/Layers/Containers/#sequential", 
            "text": "Scala:  val module = Sequential()  Python:  seq = Sequential()  Sequential provides a means to plug layers together\nin a feed-forward fully connected manner.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nimport com.intel.analytics.bigdl.nn.{Sequential, Linear}\n\nval module = Sequential()\nmodule.add(Linear(10, 25))\nmodule.add(Linear(25, 10))\n\nval input = Tensor(10).range(1, 10, 1)\nval gradOutput = Tensor(10).range(1, 10, 1)\n\nval output = module.forward(input).toTensor\nval gradInput = module.backward(input, gradOutput).toTensor\n\nprintln(output)\nprintln(gradInput)  The output is,  -2.3750305\n2.4512818\n1.6998017\n-0.47432393\n4.3048754\n-0.044168986\n-1.1643536\n0.60341483\n2.0216258\n2.1190155\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10]  The gradInput is,  2.593382\n-1.4137214\n-1.8271983\n1.229643\n0.51384985\n1.509845\n2.9537349\n1.088281\n0.2618509\n1.4840821\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nseq = Sequential()\nseq.add(Linear(10, 25))\nseq.add(Linear(25, 10))\n\ninput = np.arange(1, 11, 1).astype( float32 )\ninput = input.reshape(1, 10)\n\noutput = seq.forward(input)\nprint output\n\ngradOutput = np.arange(1, 11, 1).astype( float32 )\ngradOutput = gradOutput.reshape(1, 10)\n\ngradInput = seq.backward(input, gradOutput)\nprint gradInput  The output is,  [array([[ 1.08462083, -2.03257799, -0.5400058 ,  0.27452484,  1.85562158,\n         1.64338267,  2.45694995,  1.70170391, -2.12998056, -1.28924525]], dtype=float32)]  The gradInput is,  \n[array([[ 1.72007763,  1.64403224,  2.52977395, -1.00021958,  0.1134415 ,\n         2.06711197,  2.29631734, -3.39587498,  1.01093054, -0.54482007]], dtype=float32)]", 
            "title": "Sequential"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/", 
            "text": "Reverse\n\n\nScala:\n\n\nval m = Reverse(dim = 1, isInplace = false)\n\n\n\n\nPython:\n\n\nm = Reverse(dimension=1)\n\n\n\n\nReverse the input w.r.t given dimension.\n The input can be a Tensor or Table. \nDimension is one-based index\n \n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\ndef randomn(): Float = RandomGenerator.RNG.uniform(0, 1)\nval input = Tensor(2, 3)\ninput.apply1(x =\n randomn().toFloat)\nprintln(\ninput:\n)\nprintln(input)\nval layer = new Reverse(1)\nprintln(\noutput:\n)\nprintln(layer.forward(input))\n\n\n\n\ninput:\n0.17271264898590744 0.019822501810267568    0.18107921979390085 \n0.4003877849318087  0.5567442716564983  0.14120339532382786 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\noutput:\n0.4003877849318087  0.5567442716564983  0.14120339532382786 \n0.17271264898590744 0.019822501810267568    0.18107921979390085 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\n\nPython example:\n\n\ninput = np.random.random((2,3))\nlayer = Reverse(1)\nprint(\ninput:\n)\nprint(input)\nprint(\noutput:\n)\nprint(layer.forward(input))\n\n\n\n\ncreating: createReverse\ninput:\n[[ 0.89089717  0.07629756  0.30863782]\n [ 0.16066851  0.06421963  0.96719367]]\noutput:\n[[ 0.16066851  0.06421963  0.96719366]\n [ 0.89089715  0.07629756  0.30863783]]\n\n\n\n\n\n\nReshape\n\n\nScala:\n\n\nval reshape = Reshape(size, batchMode)\n\n\n\n\nPython:\n\n\nreshape = Reshape(size, batch_mode)\n\n\n\n\nThe \nforward(input)\n reshape the input tensor into \nsize(0) * size(1) * ...\n tensor,\ntaking the elements row-wise.\n\n\nparameters\n\n\n \nsize\n - the size after reshape\n\n \nbatchMode\n - It is a optional argument. If it is set to \nSome(true)\n,\n                  the first dimension of input is considered as batch dimension,\n                  and thus keep this dimension size fixed. This is necessary\n                  when dealing with batch sizes of one. When set to \nSome(false)\n,\n                  it forces the entire input (including the first dimension) to be reshaped\n                  to the input size. Default is \nNone\n, which means the module considers\n                  inputs with more elements than the product of provided sizes (size(0) *\n                  size(1) * ..) to be batches, otherwise in no batch mode.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval reshape = Reshape(Array(3, 2))\nval input = Tensor(2, 2, 3).rand()\nval output = reshape.forward(input)\n-\n print(output.size().toList)      \nList(2, 3, 2)\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nreshape =  Reshape([3, 2])\ninput = np.random.rand(2, 2, 3)\noutput = reshape.forward(input)\n-\n print output[0].shape\n(2, 3, 2)\n\n\n\n\nIndex\n\n\nScala:\n\n\nval model = Index(dimension)\n\n\n\n\nPython:\n\n\nmodel = Index(dimension)\n\n\n\n\nApplies the Tensor index operation along the given dimension.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor(3).rand()\nval input2 = Tensor(4)\ninput2(Array(1)) = 1.0f\ninput2(Array(2)) = 2.0f\ninput2(Array(3)) = 2.0f\ninput2(Array(4)) = 3.0f\n\nval input = T(input1, input2)\nval model = Index(1)\nval output = model.forward(input)\n\nscala\n print(input)\n {\n    2: 1.0\n       2.0\n       2.0\n       3.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 4]\n    1: 0.124325536\n       0.8768922\n       0.6378146\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\nscala\n print(output)\n0.124325536\n0.8768922\n0.8768922\n0.6378146\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput1 = np.random.randn(3)\ninput2 = np.array([1, 2, 2, 3])\ninput = [input1, input2]\n\nmodel = Index(1)\noutput = model.forward(input)\n\n\n print(input)\n[array([-0.45804847, -0.20176707,  0.50963248]), array([1, 2, 2, 3])]\n\n\n print(output)\n[-0.45804846 -0.20176707 -0.20176707  0.50963247]\n\n\n\n\nIdentity\n\n\nScala:\n\n\nval identity = Identity()\n\n\n\n\nPython:\n\n\nidentity = Identity()\n\n\n\n\nIdentity just return input as the output which is useful in same parallel container to get an origin input\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval identity = Identity()\n\nval input = Tensor(3, 3).rand()\n\n print(input)\n0.043098174 0.1035049   0.7522675   \n0.9999951   0.794151    0.18344955  \n0.9419861   0.02398399  0.6228095   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n print(identity.forward(input))\n0.043098174 0.1035049   0.7522675   \n0.9999951   0.794151    0.18344955  \n0.9419861   0.02398399  0.6228095   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nidentity = Identity()\n\n  identity.forward(np.array([[1, 2, 3], [4, 5, 6]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.]], dtype=float32)]\n\n\n\n\n\nNarrow\n\n\nScala:\n\n\nval layer = Narrow(dimension, offset, length = 1)\n\n\n\n\nPython:\n\n\nlayer = Narrow(dimension, offset, length=1)\n\n\n\n\nNarrow is an application of narrow operation in a module.\nThe module further supports a negative length in order to handle inputs with an unknown size.\n\n\nParameters:\n\n\ndimension\n -narrow along this dimension\n\n\noffset\n -the start index on the given dimension\n\n\nlength\n -length to narrow, default value is 1\n\n\nScala Example\n\n\nimport com.intel.analytics.bigdl.nn.Narrow\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Narrow(2, 2)\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(3f, 4f, 5f))\n\nval output = layer.forward(input)\n2.0\n3.0\n4.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1]\n\nval grad = layer.backward(input, gradOutput)\n0.0 3.0 0.0\n0.0 4.0 0.0\n0.0 5.0 0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython Example\n\n\nlayer = Narrow(2, 2)\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([3.0, 4.0, 5.0])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[ 2.]\n [ 3.]\n [ 4.]]\n\nprint grad\n[[ 0.  3.  0.]\n [ 0.  4.  0.]\n [ 0.  5.  0.]]\n\n\n\n\nUnsqueeze\n\n\nScala:\n\n\nval layer = Unsqueeze(dim)\n\n\n\n\nPython:\n\n\nlayer = Unsqueeze(dim)\n\n\n\n\nInsert singleton dim (i.e., dimension 1) at position pos. For an input with dim = input.dim(),\nthere are dim + 1 possible positions to insert the singleton dimension. The dim starts from 1.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = Unsqueeze(2)\nval input = Tensor(2, 2, 2).rand\nval gradOutput = Tensor(2, 1, 2, 2).rand\nval output = layer.forward(input)\nval gradInput = layer.backward(input, gradOutput)\n\n\n println(input.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n println(gradOutput.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x2x2]\n\n\n println(output.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x2x2]\n\n\n println(gradInput.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nlayer = Unsqueeze(2)\ninput = np.random.uniform(0, 1, (2, 2, 2)).astype(\nfloat32\n)\ngradOutput = np.random.uniform(0, 1, (2, 1, 2, 2)).astype(\nfloat32\n)\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, gradOutput)\n\n\n output\n[array([[[[ 0.97488612,  0.43463323],\n          [ 0.39069486,  0.0949123 ]]],\n\n\n        [[[ 0.19310953,  0.73574477],\n          [ 0.95347691,  0.37380624]]]], dtype=float32)]\n\n gradInput\n[array([[[ 0.9995622 ,  0.69787127],\n         [ 0.65975296,  0.87002522]],\n\n        [[ 0.76349133,  0.96734989],\n         [ 0.88068211,  0.07284366]]], dtype=float32)]\n\n\n\n\nSqueeze\n\n\nScala:\n\n\nval module = Squeeze(dims=null, numInputDims=Int.MinValue)\n\n\n\n\nPython:\n\n\nmodule = Squeeze(dims, numInputDims=-2147483648)\n\n\n\n\nDelete all singleton dimensions or a specific singleton dimension.\n\n\ndims\n Optional. If this dimension is singleton dimension, it will be deleted.\n           The first index starts from 1. Default: delete all dimensions.\n\n\nnum_input_dims\n Optional. If in a batch model, set to the inputDims.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = Squeeze(2)\n\n print(layer.forward(Tensor(2, 1, 3).rand()))\n0.43709445  0.42752415  0.43069172  \n0.67029667  0.95641375  0.28823504  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = Squeeze(2)\n\nlayer.forward(np.array([[[1, 2, 3]], [[1, 2, 3]]]))\nout: array([[ 1.,  2.,  3.],\n            [ 1.,  2.,  3.]], dtype=float32)\n\n\n\n\n\nSelect\n\n\nScala:\n\n\nval layer = Select(dim, index)\n\n\n\n\nPython:\n\n\nlayer = Select(dim, index)\n\n\n\n\nA Simple layer selecting an index of the input tensor in the given dimension.\nPlease note that the index and dimension start from 1. In collaborative filtering, it can used together with LookupTable to create embeddings for users or items.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = Select(1, 2)\nlayer.forward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)))\n\nlayer.backward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)), Tensor(T(0.1f, 0.2f, 0.3f)))\n\n\n\n\nIts output should be\n\n\n4.0\n5.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n0.0     0.0     0.0\n0.1     0.2     0.3\n0.0     0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import Select\nimport numpy as np\n\nlayer = Select(1, 2)\nlayer.forward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]))\nlayer.backward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]), np.array([0.1, 0.2, 0.3]))\n\n\n\n\nIts output should be\n\n\narray([ 4.,  5.,  6.], dtype=float32)\n\narray([[ 0.        ,  0.        ,  0.        ],\n       [ 0.1       ,  0.2       ,  0.30000001],\n       [ 0.        ,  0.        ,  0.        ]], dtype=float32)\n\n\n\n\nMaskedSelect\n\n\nScala:\n\n\nval module = MaskedSelect()\n\n\n\n\nPython:\n\n\nmodule = MaskedSelect()\n\n\n\n\nPerforms a torch.MaskedSelect on a Tensor. The mask is supplied as a tabular argument\n with the input on the forward and backward passes.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport scala.util.Random\n\n\nval layer = MaskedSelect()\nval input1 = Tensor(2, 2).apply1(e =\n Random.nextFloat())\nval mask = Tensor(2, 2)\nmask(Array(1, 1)) = 1\nmask(Array(1, 2)) = 0\nmask(Array(2, 1)) = 0\nmask(Array(2, 2)) = 1\nval input = T()\ninput(1.0) = input1\ninput(2.0) = mask\n\n print(layer.forward(input))\n0.2577119\n0.5061479\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = MaskedSelect()\ninput1 = np.random.rand(2,2)\nmask = np.array([[1,0], [0, 1]])\n\nlayer.forward([input1, mask])\narray([ 0.1525335 ,  0.05474588], dtype=float32)\n\n\n\n\nTranspose\n\n\nScala:\n\n\nval module = Transpose(permutations)\n\n\n\n\nPython:\n\n\nmodule = Transpose(permutations)\n\n\n\n\nConcat is a layer who transpose input along specified dimensions.\npermutations are dimension pairs that need to swap.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(2, 3).rand()\nval layer = Transpose(Array((1, 2)))\nval output = layer.forward(input)\n\n\n input\n0.6653826   0.25350887  0.33434764  \n0.9618287   0.5484164   0.64844745  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\n\n output\n0.6653826   0.9618287   \n0.25350887  0.5484164   \n0.33434764  0.64844745  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nlayer = Transpose([(1,2)])\ninput = np.array([[0.6653826, 0.25350887, 0.33434764], [0.9618287, 0.5484164, 0.64844745]])\noutput = layer.forward(input)\n\n\n output\n[array([[ 0.66538262,  0.96182871],\n       [ 0.25350887,  0.54841638],\n       [ 0.33434764,  0.64844745]], dtype=float32)]\n\n\n\n\n\nInferReshape\n\n\nScala:\n\n\nval layer = InferReshape(size, batchMode = false)\n\n\n\n\nPython:\n\n\nlayer = InferReshape(size, batch_mode=False)\n\n\n\n\nReshape the input tensor with automatic size inference support.\nPositive numbers in the \nsize\n argument are used to reshape the input to the\ncorresponding dimension size.\n\n\nThere are also two special values allowed in \nsize\n:\n\n\n\n\n0\n means keep the corresponding dimension size of the input unchanged.\n      i.e., if the 1st dimension size of the input is 2,\n      the 1st dimension size of output will be set as 2 as well.\n\n\n-1\n means infer this dimension size from other dimensions.\n      This dimension size is calculated by keeping the amount of output elements\n      consistent with the input.\n      Only one \n-1\n is allowable in \nsize\n.\n\n\n\n\nFor example,\n\n\n   Input tensor with size: (4, 5, 6, 7)\n   -\n InferReshape(Array(4, 0, 3, -1))\n   Output tensor with size: (4, 5, 3, 14)\n\n\n\n\nThe 1st and 3rd dim are set to given sizes, keep the 2nd dim unchanged,\nand inferred the last dim as 14.\n\n\nParameters:\n\n\nsize\n      -the target tensor size\n\n\nbatchMode\n -whether in batch mode\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.InferReshape\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval layer = InferReshape(Array(0, 3, -1))\nval input = Tensor(1, 2, 3).rand()\nval gradOutput = Tensor(1, 3, 2).rand()\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n(1,.,.) =\n0.8170822   0.40073588\n0.49389255  0.3782435\n0.42660004  0.5917206\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x2]\n\nprintln(grad)\n(1,.,.) =\n0.8294597   0.57101834  0.90910035\n0.32783163  0.30494633  0.7339092\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3]\n\n\n\n\nPython example:\n\n\nlayer = InferReshape([0, 3, -1])\ninput = np.random.rand(1, 2, 3)\n\ngradOutput = np.random.rand(1, 3, 2)\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[[ 0.68635464  0.21277553]\n  [ 0.13390459  0.65662414]\n  [ 0.1021723   0.92319047]]]\n\nprint grad\n[[[ 0.84927064  0.55205333  0.25077972]\n  [ 0.76105869  0.30828172  0.1237276 ]]]\n\n\n\n\nReplicate\n\n\nScala:\n\n\nval module = Replicate(\n  nFeatures,\n  dim = 1,\n  nDim = Int.MaxValue)\n\n\n\n\nPython:\n\n\nmodule = Replicate(\n  n_features,\n  dim=1,\n  n_dim=INTMAX)\n\n\n\n\nReplicate repeats input \nnFeatures\n times along its \ndim\n dimension\n\n\nNotice: No memory copy, it set the stride along the \ndim\n-th dimension to zero.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Replicate(4, 1, 2)\n\nprintln(module.forward(Tensor.range(1, 6, 1).resize(1, 2, 3)))\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,2,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,3,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,4,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x4x2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Replicate(4, 1, 2)\n\nprint(module.forward(np.arange(1, 7, 1).reshape(1, 2, 3)))\n\n\n\n\nOutput is \n\n\n[array([[[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]]]], dtype=float32)]\n\n\n\n\nView\n\n\nScala:\n\n\nval view = View(2, 8)\n\n\n\n\nor\n\n\nval view = View(Array(2, 8))\n\n\n\n\nPython:\n\n\nview = View([2, 8])\n\n\n\n\nThis module creates a new view of the input tensor using the sizes passed to the constructor.\nThe method setNumInputDims() allows to specify the expected number of dimensions of the inputs\nof the modules. This makes it possible to use minibatch inputs\nwhen using a size -1 for one of the dimensions.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.View\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval view = View(2, 8)\n\nval input = Tensor(4, 4).randn()\nval gradOutput = Tensor(2, 8).randn()\n\nval output = view.forward(input)\nval gradInput = view.backward(input, gradOutput)\n\n\n\n\nThe output is,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.43037438     1.2982363       -1.4723133      -0.2602826      0.7178128       -1.8763185      0.88629466      0.8346704\n0.20963766      -0.9349786      1.0376515       1.3153045       1.5450214       1.084113        -0.29929757     -0.18356979\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nThe gradInput is,\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.7360089       0.9133299       0.40443268      -0.94965595\n0.80520976      -0.09671917     -0.5498001      -0.098691925\n-2.3119886      -0.8455147      0.75891125      1.2985301\n0.5023749       1.4983269       0.42038065      -1.7002305\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nview = View([2, 8])\n\ninput = np.random.uniform(0, 1, [4, 4]).astype(\nfloat32\n)\ngradOutput = np.random.uniform(0, 1, [2, 8]).astype(\nfloat32\n)\n\noutput = view.forward(input)\ngradInput = view.backward(input, gradOutput)\n\nprint output\nprint gradInput\n\n\n\n\nContiguous\n\n\nBe used to make input, gradOutput both contiguous\n\n\nScala:\n\n\nval contiguous = Contiguous()\n\n\n\n\nPython:\n\n\ncontiguous = Contiguous()\n\n\n\n\nUsed to make input, gradOutput both contiguous\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Contiguous\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(5).range(1, 5, 1)\nval contiguous = new Contiguous()\nval output = contiguous.forward(input)\nprintln(output)\n\nval gradOutput = Tensor(5).range(2, 6, 1)\nval gradInput = contiguous.backward(input, gradOutput)\nprintln(gradOutput)\n\n\n\n\nThe output will be,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n2.0\n3.0\n4.0\n5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\n\n\n\nThe gradInput will be,\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.0\n3.0\n4.0\n5.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncontiguous = Contiguous()\n\ninput = np.arange(1, 6, 1).astype(\nfloat32\n)\ninput = input.reshape(1, 5)\n\noutput = contiguous.forward(input)\nprint output\n\ngradOutput = np.arange(2, 7, 1).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(1, 5)\n\ngradInput = contiguous.backward(input, gradOutput)\nprint gradInput\n\n\n\n\n\nThe output will be,\n\n\n[array([[ 1.,  2.,  3.,  4.,  5.]], dtype=float32)]\n\n\n\n\nThe gradInput will be,\n\n\n[array([[ 2.,  3.,  4.,  5.,  6.]], dtype=float32)]\n\n\n\n\nLinear\n\n\nScala:\n\n\nval module = Linear(\n  inputSize,\n  outputSize,\n  withBias = true,\n  wRegularizer = null,\n  bRegularizer = null,\n  initWeight = null,\n  initBias = null,\n  initGradWeight = null,\n  initGradBias = null)\n\n\n\n\nPython:\n\n\nmodule = Linear(\n  input_size,\n  output_size,\n  init_method=\ndefault\n,\n  with_bias=True,\n  wRegularizer=None,\n  bRegularizer=None,\n  init_weight=None,\n  init_bias=None,\n  init_grad_weight=None,\n  init_grad_bias=None)\n\n\n\n\nThe \nLinear\n module applies a linear transformation to the input data,\ni.e. \ny = Wx + b\n. The \ninput\n given in \nforward(input)\n must be either\na vector (1D tensor) or matrix (2D tensor). If the input is a vector, it must\nhave the size of \ninputSize\n. If it is a matrix, then each row is assumed to be\nan input sample of given batch (the number of rows means the batch size and\nthe number of columns should be equal to the \ninputSize\n).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Linear(3, 5)\n\nprintln(module.forward(Tensor.range(1, 3, 1)))\n\n\n\n\nOutput is\n```com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.79338956\n-2.3417668\n-2.7557678\n-0.07507719\n-1.009765\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n\n**Python example:**\n```python\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Linear(3, 5)\n\nprint(module.forward(np.arange(1, 4, 1)))\n\n\n\n\nOutput is\n\n\n[array([ 0.31657887, -1.11062765, -1.16235781, -0.67723978,  0.74650359], dtype=float32)]", 
            "title": "Simple Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#reverse", 
            "text": "Scala:  val m = Reverse(dim = 1, isInplace = false)  Python:  m = Reverse(dimension=1)  Reverse the input w.r.t given dimension.\n The input can be a Tensor or Table.  Dimension is one-based index    Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\ndef randomn(): Float = RandomGenerator.RNG.uniform(0, 1)\nval input = Tensor(2, 3)\ninput.apply1(x =  randomn().toFloat)\nprintln( input: )\nprintln(input)\nval layer = new Reverse(1)\nprintln( output: )\nprintln(layer.forward(input))  input:\n0.17271264898590744 0.019822501810267568    0.18107921979390085 \n0.4003877849318087  0.5567442716564983  0.14120339532382786 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\noutput:\n0.4003877849318087  0.5567442716564983  0.14120339532382786 \n0.17271264898590744 0.019822501810267568    0.18107921979390085 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  input = np.random.random((2,3))\nlayer = Reverse(1)\nprint( input: )\nprint(input)\nprint( output: )\nprint(layer.forward(input))  creating: createReverse\ninput:\n[[ 0.89089717  0.07629756  0.30863782]\n [ 0.16066851  0.06421963  0.96719367]]\noutput:\n[[ 0.16066851  0.06421963  0.96719366]\n [ 0.89089715  0.07629756  0.30863783]]", 
            "title": "Reverse"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#reshape", 
            "text": "Scala:  val reshape = Reshape(size, batchMode)  Python:  reshape = Reshape(size, batch_mode)  The  forward(input)  reshape the input tensor into  size(0) * size(1) * ...  tensor,\ntaking the elements row-wise.  parameters    size  - the size after reshape   batchMode  - It is a optional argument. If it is set to  Some(true) ,\n                  the first dimension of input is considered as batch dimension,\n                  and thus keep this dimension size fixed. This is necessary\n                  when dealing with batch sizes of one. When set to  Some(false) ,\n                  it forces the entire input (including the first dimension) to be reshaped\n                  to the input size. Default is  None , which means the module considers\n                  inputs with more elements than the product of provided sizes (size(0) *\n                  size(1) * ..) to be batches, otherwise in no batch mode.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval reshape = Reshape(Array(3, 2))\nval input = Tensor(2, 2, 3).rand()\nval output = reshape.forward(input)\n-  print(output.size().toList)      \nList(2, 3, 2)  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nreshape =  Reshape([3, 2])\ninput = np.random.rand(2, 2, 3)\noutput = reshape.forward(input)\n-  print output[0].shape\n(2, 3, 2)", 
            "title": "Reshape"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#index", 
            "text": "Scala:  val model = Index(dimension)  Python:  model = Index(dimension)  Applies the Tensor index operation along the given dimension.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor(3).rand()\nval input2 = Tensor(4)\ninput2(Array(1)) = 1.0f\ninput2(Array(2)) = 2.0f\ninput2(Array(3)) = 2.0f\ninput2(Array(4)) = 3.0f\n\nval input = T(input1, input2)\nval model = Index(1)\nval output = model.forward(input)\n\nscala  print(input)\n {\n    2: 1.0\n       2.0\n       2.0\n       3.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 4]\n    1: 0.124325536\n       0.8768922\n       0.6378146\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\nscala  print(output)\n0.124325536\n0.8768922\n0.8768922\n0.6378146\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput1 = np.random.randn(3)\ninput2 = np.array([1, 2, 2, 3])\ninput = [input1, input2]\n\nmodel = Index(1)\noutput = model.forward(input)  print(input)\n[array([-0.45804847, -0.20176707,  0.50963248]), array([1, 2, 2, 3])]  print(output)\n[-0.45804846 -0.20176707 -0.20176707  0.50963247]", 
            "title": "Index"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#identity", 
            "text": "Scala:  val identity = Identity()  Python:  identity = Identity()  Identity just return input as the output which is useful in same parallel container to get an origin input  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval identity = Identity()\n\nval input = Tensor(3, 3).rand()  print(input)\n0.043098174 0.1035049   0.7522675   \n0.9999951   0.794151    0.18344955  \n0.9419861   0.02398399  0.6228095   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(identity.forward(input))\n0.043098174 0.1035049   0.7522675   \n0.9999951   0.794151    0.18344955  \n0.9419861   0.02398399  0.6228095   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  Python example:  from bigdl.nn.layer import *\nidentity = Identity()   identity.forward(np.array([[1, 2, 3], [4, 5, 6]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.]], dtype=float32)]", 
            "title": "Identity"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#narrow", 
            "text": "Scala:  val layer = Narrow(dimension, offset, length = 1)  Python:  layer = Narrow(dimension, offset, length=1)  Narrow is an application of narrow operation in a module.\nThe module further supports a negative length in order to handle inputs with an unknown size.  Parameters:  dimension  -narrow along this dimension  offset  -the start index on the given dimension  length  -length to narrow, default value is 1  Scala Example  import com.intel.analytics.bigdl.nn.Narrow\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Narrow(2, 2)\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(3f, 4f, 5f))\n\nval output = layer.forward(input)\n2.0\n3.0\n4.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1]\n\nval grad = layer.backward(input, gradOutput)\n0.0 3.0 0.0\n0.0 4.0 0.0\n0.0 5.0 0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python Example  layer = Narrow(2, 2)\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([3.0, 4.0, 5.0])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[ 2.]\n [ 3.]\n [ 4.]]\n\nprint grad\n[[ 0.  3.  0.]\n [ 0.  4.  0.]\n [ 0.  5.  0.]]", 
            "title": "Narrow"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#unsqueeze", 
            "text": "Scala:  val layer = Unsqueeze(dim)  Python:  layer = Unsqueeze(dim)  Insert singleton dim (i.e., dimension 1) at position pos. For an input with dim = input.dim(),\nthere are dim + 1 possible positions to insert the singleton dimension. The dim starts from 1.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = Unsqueeze(2)\nval input = Tensor(2, 2, 2).rand\nval gradOutput = Tensor(2, 1, 2, 2).rand\nval output = layer.forward(input)\nval gradInput = layer.backward(input, gradOutput)  println(input.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  println(gradOutput.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x2x2]  println(output.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x2x2]  println(gradInput.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nlayer = Unsqueeze(2)\ninput = np.random.uniform(0, 1, (2, 2, 2)).astype( float32 )\ngradOutput = np.random.uniform(0, 1, (2, 1, 2, 2)).astype( float32 )\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, gradOutput)  output\n[array([[[[ 0.97488612,  0.43463323],\n          [ 0.39069486,  0.0949123 ]]],\n\n\n        [[[ 0.19310953,  0.73574477],\n          [ 0.95347691,  0.37380624]]]], dtype=float32)]  gradInput\n[array([[[ 0.9995622 ,  0.69787127],\n         [ 0.65975296,  0.87002522]],\n\n        [[ 0.76349133,  0.96734989],\n         [ 0.88068211,  0.07284366]]], dtype=float32)]", 
            "title": "Unsqueeze"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#squeeze", 
            "text": "Scala:  val module = Squeeze(dims=null, numInputDims=Int.MinValue)  Python:  module = Squeeze(dims, numInputDims=-2147483648)  Delete all singleton dimensions or a specific singleton dimension.  dims  Optional. If this dimension is singleton dimension, it will be deleted.\n           The first index starts from 1. Default: delete all dimensions.  num_input_dims  Optional. If in a batch model, set to the inputDims.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = Squeeze(2)  print(layer.forward(Tensor(2, 1, 3).rand()))\n0.43709445  0.42752415  0.43069172  \n0.67029667  0.95641375  0.28823504  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  from bigdl.nn.layer import *\n\nlayer = Squeeze(2) layer.forward(np.array([[[1, 2, 3]], [[1, 2, 3]]]))\nout: array([[ 1.,  2.,  3.],\n            [ 1.,  2.,  3.]], dtype=float32)", 
            "title": "Squeeze"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#select", 
            "text": "Scala:  val layer = Select(dim, index)  Python:  layer = Select(dim, index)  A Simple layer selecting an index of the input tensor in the given dimension.\nPlease note that the index and dimension start from 1. In collaborative filtering, it can used together with LookupTable to create embeddings for users or items.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = Select(1, 2)\nlayer.forward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)))\n\nlayer.backward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)), Tensor(T(0.1f, 0.2f, 0.3f)))  Its output should be  4.0\n5.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n0.0     0.0     0.0\n0.1     0.2     0.3\n0.0     0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import Select\nimport numpy as np\n\nlayer = Select(1, 2)\nlayer.forward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]))\nlayer.backward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]), np.array([0.1, 0.2, 0.3]))  Its output should be  array([ 4.,  5.,  6.], dtype=float32)\n\narray([[ 0.        ,  0.        ,  0.        ],\n       [ 0.1       ,  0.2       ,  0.30000001],\n       [ 0.        ,  0.        ,  0.        ]], dtype=float32)", 
            "title": "Select"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#maskedselect", 
            "text": "Scala:  val module = MaskedSelect()  Python:  module = MaskedSelect()  Performs a torch.MaskedSelect on a Tensor. The mask is supplied as a tabular argument\n with the input on the forward and backward passes.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport scala.util.Random\n\n\nval layer = MaskedSelect()\nval input1 = Tensor(2, 2).apply1(e =  Random.nextFloat())\nval mask = Tensor(2, 2)\nmask(Array(1, 1)) = 1\nmask(Array(1, 2)) = 0\nmask(Array(2, 1)) = 0\nmask(Array(2, 2)) = 1\nval input = T()\ninput(1.0) = input1\ninput(2.0) = mask  print(layer.forward(input))\n0.2577119\n0.5061479\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]  Python example:  from bigdl.nn.layer import *\n\nlayer = MaskedSelect()\ninput1 = np.random.rand(2,2)\nmask = np.array([[1,0], [0, 1]]) layer.forward([input1, mask])\narray([ 0.1525335 ,  0.05474588], dtype=float32)", 
            "title": "MaskedSelect"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#transpose", 
            "text": "Scala:  val module = Transpose(permutations)  Python:  module = Transpose(permutations)  Concat is a layer who transpose input along specified dimensions.\npermutations are dimension pairs that need to swap.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(2, 3).rand()\nval layer = Transpose(Array((1, 2)))\nval output = layer.forward(input)  input\n0.6653826   0.25350887  0.33434764  \n0.9618287   0.5484164   0.64844745  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]  output\n0.6653826   0.9618287   \n0.25350887  0.5484164   \n0.33434764  0.64844745  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nlayer = Transpose([(1,2)])\ninput = np.array([[0.6653826, 0.25350887, 0.33434764], [0.9618287, 0.5484164, 0.64844745]])\noutput = layer.forward(input)  output\n[array([[ 0.66538262,  0.96182871],\n       [ 0.25350887,  0.54841638],\n       [ 0.33434764,  0.64844745]], dtype=float32)]", 
            "title": "Transpose"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#inferreshape", 
            "text": "Scala:  val layer = InferReshape(size, batchMode = false)  Python:  layer = InferReshape(size, batch_mode=False)  Reshape the input tensor with automatic size inference support.\nPositive numbers in the  size  argument are used to reshape the input to the\ncorresponding dimension size.  There are also two special values allowed in  size :   0  means keep the corresponding dimension size of the input unchanged.\n      i.e., if the 1st dimension size of the input is 2,\n      the 1st dimension size of output will be set as 2 as well.  -1  means infer this dimension size from other dimensions.\n      This dimension size is calculated by keeping the amount of output elements\n      consistent with the input.\n      Only one  -1  is allowable in  size .   For example,     Input tensor with size: (4, 5, 6, 7)\n   -  InferReshape(Array(4, 0, 3, -1))\n   Output tensor with size: (4, 5, 3, 14)  The 1st and 3rd dim are set to given sizes, keep the 2nd dim unchanged,\nand inferred the last dim as 14.  Parameters:  size       -the target tensor size  batchMode  -whether in batch mode  Scala example:  import com.intel.analytics.bigdl.nn.InferReshape\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval layer = InferReshape(Array(0, 3, -1))\nval input = Tensor(1, 2, 3).rand()\nval gradOutput = Tensor(1, 3, 2).rand()\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n(1,.,.) =\n0.8170822   0.40073588\n0.49389255  0.3782435\n0.42660004  0.5917206\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x2]\n\nprintln(grad)\n(1,.,.) =\n0.8294597   0.57101834  0.90910035\n0.32783163  0.30494633  0.7339092\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3]  Python example:  layer = InferReshape([0, 3, -1])\ninput = np.random.rand(1, 2, 3)\n\ngradOutput = np.random.rand(1, 3, 2)\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[[ 0.68635464  0.21277553]\n  [ 0.13390459  0.65662414]\n  [ 0.1021723   0.92319047]]]\n\nprint grad\n[[[ 0.84927064  0.55205333  0.25077972]\n  [ 0.76105869  0.30828172  0.1237276 ]]]", 
            "title": "InferReshape"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#replicate", 
            "text": "Scala:  val module = Replicate(\n  nFeatures,\n  dim = 1,\n  nDim = Int.MaxValue)  Python:  module = Replicate(\n  n_features,\n  dim=1,\n  n_dim=INTMAX)  Replicate repeats input  nFeatures  times along its  dim  dimension  Notice: No memory copy, it set the stride along the  dim -th dimension to zero.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Replicate(4, 1, 2)\n\nprintln(module.forward(Tensor.range(1, 6, 1).resize(1, 2, 3)))  Output is  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,2,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,3,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,4,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x4x2x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Replicate(4, 1, 2)\n\nprint(module.forward(np.arange(1, 7, 1).reshape(1, 2, 3)))  Output is   [array([[[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]]]], dtype=float32)]", 
            "title": "Replicate"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#view", 
            "text": "Scala:  val view = View(2, 8)  or  val view = View(Array(2, 8))  Python:  view = View([2, 8])  This module creates a new view of the input tensor using the sizes passed to the constructor.\nThe method setNumInputDims() allows to specify the expected number of dimensions of the inputs\nof the modules. This makes it possible to use minibatch inputs\nwhen using a size -1 for one of the dimensions.  Scala example:  import com.intel.analytics.bigdl.nn.View\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval view = View(2, 8)\n\nval input = Tensor(4, 4).randn()\nval gradOutput = Tensor(2, 8).randn()\n\nval output = view.forward(input)\nval gradInput = view.backward(input, gradOutput)  The output is,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.43037438     1.2982363       -1.4723133      -0.2602826      0.7178128       -1.8763185      0.88629466      0.8346704\n0.20963766      -0.9349786      1.0376515       1.3153045       1.5450214       1.084113        -0.29929757     -0.18356979\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  The gradInput is,  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.7360089       0.9133299       0.40443268      -0.94965595\n0.80520976      -0.09671917     -0.5498001      -0.098691925\n-2.3119886      -0.8455147      0.75891125      1.2985301\n0.5023749       1.4983269       0.42038065      -1.7002305  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nview = View([2, 8])\n\ninput = np.random.uniform(0, 1, [4, 4]).astype( float32 )\ngradOutput = np.random.uniform(0, 1, [2, 8]).astype( float32 )\n\noutput = view.forward(input)\ngradInput = view.backward(input, gradOutput)\n\nprint output\nprint gradInput", 
            "title": "View"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#contiguous", 
            "text": "Be used to make input, gradOutput both contiguous  Scala:  val contiguous = Contiguous()  Python:  contiguous = Contiguous()  Used to make input, gradOutput both contiguous  Scala example:  import com.intel.analytics.bigdl.nn.Contiguous\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(5).range(1, 5, 1)\nval contiguous = new Contiguous()\nval output = contiguous.forward(input)\nprintln(output)\n\nval gradOutput = Tensor(5).range(2, 6, 1)\nval gradInput = contiguous.backward(input, gradOutput)\nprintln(gradOutput)  The output will be,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n2.0\n3.0\n4.0\n5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]  The gradInput will be,  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.0\n3.0\n4.0\n5.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncontiguous = Contiguous()\n\ninput = np.arange(1, 6, 1).astype( float32 )\ninput = input.reshape(1, 5)\n\noutput = contiguous.forward(input)\nprint output\n\ngradOutput = np.arange(2, 7, 1).astype( float32 )\ngradOutput = gradOutput.reshape(1, 5)\n\ngradInput = contiguous.backward(input, gradOutput)\nprint gradInput  The output will be,  [array([[ 1.,  2.,  3.,  4.,  5.]], dtype=float32)]  The gradInput will be,  [array([[ 2.,  3.,  4.,  5.,  6.]], dtype=float32)]", 
            "title": "Contiguous"
        }, 
        {
            "location": "/APIdocs/Layers/Simple-Layers/#linear", 
            "text": "Scala:  val module = Linear(\n  inputSize,\n  outputSize,\n  withBias = true,\n  wRegularizer = null,\n  bRegularizer = null,\n  initWeight = null,\n  initBias = null,\n  initGradWeight = null,\n  initGradBias = null)  Python:  module = Linear(\n  input_size,\n  output_size,\n  init_method= default ,\n  with_bias=True,\n  wRegularizer=None,\n  bRegularizer=None,\n  init_weight=None,\n  init_bias=None,\n  init_grad_weight=None,\n  init_grad_bias=None)  The  Linear  module applies a linear transformation to the input data,\ni.e.  y = Wx + b . The  input  given in  forward(input)  must be either\na vector (1D tensor) or matrix (2D tensor). If the input is a vector, it must\nhave the size of  inputSize . If it is a matrix, then each row is assumed to be\nan input sample of given batch (the number of rows means the batch size and\nthe number of columns should be equal to the  inputSize ).  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Linear(3, 5)\n\nprintln(module.forward(Tensor.range(1, 3, 1)))  Output is\n```com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.79338956\n-2.3417668\n-2.7557678\n-0.07507719\n-1.009765\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  \n**Python example:**\n```python\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Linear(3, 5)\n\nprint(module.forward(np.arange(1, 4, 1)))  Output is  [array([ 0.31657887, -1.11062765, -1.16235781, -0.67723978,  0.74650359], dtype=float32)]", 
            "title": "Linear"
        }, 
        {
            "location": "/APIdocs/Layers/Convolution-Layers/", 
            "text": "SpatialShareConvolution\n\n\nScala:\n\n\nval layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH,\n      padW, padH)\n\n\n\n\nPython:\n\n\nlayer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH, padW, padH)\n\n\n\n\nApplies a 2D convolution over an input image composed of several input planes.\n The input tensor in forward(input) is expected to be\n a 3D tensor (nInputPlane x height x width).\n\n\nThis layer has been optimized to save memory. If using this layer to construct multiple convolution\n layers, please add sharing script for the fInput and fGradInput. Please refer to the ResNet example.\n\n\nScala example:\n\n\n\n    import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n    import com.intel.analytics.bigdl.nn._\n    import com.intel.analytics.bigdl.tensor._\n\n    val nInputPlane = 1\n    val nOutputPlane = 1\n    val kW = 2\n    val kH = 2\n    val dW = 1\n    val dH = 1\n    val padW = 0\n    val padH = 0\n    val layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH,\n      padW, padH)\n\n    val inputData = Array(\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1\n    )\n\n    val kernelData = Array(\n      2.0, 3,\n      4, 5\n    )\n\n    val biasData = Array(0.0)\n\n    layer.weight.copy(Tensor(Storage(kernelData), 1,\n      Array(nOutputPlane, nInputPlane, kH, kW)))\n    layer.bias.copy(Tensor(Storage(biasData), 1, Array(nOutputPlane)))\n\n    val input = Tensor(Storage(inputData), 1, Array(3, 1, 3, 4))\n    val output = layer.updateOutput(input)\n\n    \n output\nres2: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n(2,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n(3,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n\n\n\nPython example:\n\n\nnInputPlane = 1\nnOutputPlane = 1\nkW = 2\nkH = 2\ndW = 1\ndH = 1\npadW = 0\npadH = 0\nlayer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH, padW, padH)\n\ninput = np.array([\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1]\n    ).astype(\nfloat32\n).reshape(3, 1, 3, 4)\nlayer.forward(input)\n\n\n print (output)\narray([[[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]],\n\n\n       [[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]],\n\n\n       [[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]]], dtype=float32)\n\n\n\n\nSpatialConvolution\n\n\nScala:\n\n\nval m = SpatialConvolution(nInputPlane,nOutputPlane,kernelW,kernelH,strideW=1,strideH=1,padW=0,padH=0,nGroup=1,propagateBack=true,wRegularizer=null,bRegularizer=null,initWeight=null, initBias=null, initGradWeight=null, initGradBias=null)\n\n\n\n\nPython:\n\n\nm = SpatialConvolution(n_input_plane,n_output_plane,kernel_w,kernel_h,stride_w=1,stride_h=1,pad_w=0,pad_h=0,n_group=1,propagate_back=True,wRegularizer=None,bRegularizer=None,init_weight=None,init_bias=None,init_grad_weight=None,init_grad_bias=None)\n\n\n\n\nSpatialConvolution is a module that applies a 2D convolution over an input image.\n\n\nThe input tensor in \nforward(input)\n is expected to be\neither a 4D tensor (\nbatch x nInputPlane x height x width\n) or a 3D tensor (\nnInputPlane x height x width\n). The convolution is performed on the last two dimensions.\n\n\nDetailed paramter explaination for the constructor.\n\n\n\n\nparam nInputPlane: The number of expected input planes in the image given into forward()\n\n\nparam nOutputPlane: The number of output planes the convolution layer will produce.\n\n\nparam kernelW: The kernel width of the convolution\n\n\nparam kernelH: The kernel height of the convolution\n\n\nparam strideW: The step of the convolution in the width dimension.\n\n\nparam strideH: The step of the convolution in the height dimension\n\n\nparam padW:  padding to be added to width to the input.\n\n\nparam padH: padding to be added to height to the input.\n\n\nparam nGroup: Kernel group number\n\n\nparam propagateBack: whether to propagate gradient back\n\n\nparam wRegularizer: regularizer on weight. an instance of [[Regularizer]] (e.g. L1 or L2)\n\n\nparam bRegularizer: regularizer on bias. an instance of [[Regularizer]] (e.g. L1 or L2).\n\n\nparam initWeight: weight initializer\n\n\nparam initBias:  bias initializer\n\n\nparam initGradWeight: weight gradient initializer\n\n\nparam initGradBias: bias gradient initializer\n\n\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval m = SpatialConvolution(2,1,2,2,1,1,0,0)\nm.setInitMethod(weightInitMethod = BilinearFiller, biasInitMethod = Zeros)\nval params = m.getParameters()\n\nscala\n print(params)\n(1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9],0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9])\n\nscala\n\nval input = Tensor(1,2,3,3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1,1,2,2).fill(0.2f)\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n(1,1,.,.) =\n-0.37011376     0.13565119      -0.73574775\n-0.19486316     -0.4430604      -0.62543416\n0.7017611       -0.6441595      -1.2953792\n\n(1,2,.,.) =\n-0.9903588      0.5669722       0.2630131\n0.03392942      -0.6984676      -0.12389368\n0.78704715      0.5411976       -1.3877676\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3]\n\nscala\n print(output)\n(1,1,.,.) =\n-1.3604726      0.70262337\n-0.16093373     -1.141528\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\nscala\n print(gradOut)\n(1,1,.,.) =\n0.2     0.2\n0.2     0.2\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x2x2]\n\nscala\n print(gradIn)\n(1,1,.,.) =\n0.2     0.2     0.0\n0.2     0.2     0.0\n0.0     0.0     0.0\n\n(1,2,.,.) =\n0.2     0.2     0.0\n0.2     0.2     0.0\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(1,3,3,3)\nprint \ninput is :\n,input\n\nm = SpatialConvolution(3,1,2,2,1,1,0,0)\nout = m.forward(input)\nprint \noutput m is :\n,out\n\ngrad_out = np.random.rand(1,1,2,2)\nprint \ngrad out of m is :\n,grad_out\ngrad_in = m.backward(input,grad_out)\nprint \ngrad input of m is :\n,grad_in\n\n\n\n\nproduces output:\n\n\ninput is : [[[[ 0.75276617  0.44212513  0.90275949]\n   [ 0.78205279  0.77864714  0.83647254]\n   [ 0.76220944  0.22106036  0.68762202]]\n\n  [[ 0.37346971  0.31532213  0.33276243]\n   [ 0.69872884  0.07262236  0.66372462]\n   [ 0.47803013  0.80194459  0.53313873]]\n\n  [[ 0.56196833  0.20599878  0.47575818]\n   [ 0.35454298  0.96910557  0.36234704]\n   [ 0.64017738  0.95762579  0.50073035]]]]\ncreating: createSpatialConvolution\noutput m is : [[[[-1.08398974 -0.67615652]\n   [-0.77027249 -0.82885492]]]]\ngrad out of m is : [[[[ 0.38295452  0.77048361]\n   [ 0.11671955  0.76357513]]]]\ngrad input of m is : [[[[-0.02344826 -0.06515953 -0.03618064]\n   [-0.06770924 -0.22586647 -0.14004168]\n   [-0.01845866 -0.13653883 -0.10325129]]\n\n  [[-0.09294108 -0.14361492  0.08727306]\n   [-0.09885897 -0.21209857  0.29151234]\n   [-0.02149716 -0.10957514  0.20318349]]\n\n  [[-0.05926216 -0.04542646  0.14849319]\n   [-0.09506465 -0.34244278 -0.03763583]\n   [-0.02346931 -0.1815301  -0.18314059]]]]\n\n\n\n\nSpatialFullConvolution\n\n\nScala:\n\n\nval m  = SpatialFullConvolution(nInputPlane, nOutputPlane, kW, kH, dW=1, dH=1, padW=0, padH=0, adjW=0, adjH=0,nGroup=1, noBias=false,wRegularizer=null,bRegularizer=null)\n\n\n\n\nor\n\n\nval m = SpatialFullConvolution(InputPlane, nOutputPlane, kW, kH, dW=1, dH=1, padW=0, padH=0, adjW=0, adjH=0,nGroup=1, noBias=false,wRegularizer=null,bRegularizer=null)\n\n\n\n\nPython:\n\n\nm = SpatialFullConvolution(n_input_plane,n_output_plane,kw,kh,dw=1,dh=1,pad_w=0,pad_h=0,adj_w=0,adj_h=0,n_group=1,no_bias=False,init_method='default',wRegularizer=None,bRegularizer=None)\n\n\n\n\nSpatialFullConvolution is a module that applies a 2D full convolution over an input image. \n\n\nThe input tensor in \nforward(input)\n is expected to be\neither a 4D tensor (\nbatch x nInputPlane x height x width\n) or a 3D tensor (\nnInputPlane x height x width\n). The convolution is performed on the last two dimensions. \nadjW\n and \nadjH\n are used to adjust the size of the output image. The size of output tensor of \nforward\n will be :\n\n\n  output width  = (width  - 1) * dW - 2*padW + kW + adjW\n  output height = (height - 1) * dH - 2*padH + kH + adjH\n\n\n\n\nNote, scala API also accepts a table input with two tensors: \nT(convInput, sizeTensor)\n where \nconvInput\n is the standard input tensor, and the size of \nsizeTensor\n is used to set the size of the output (will ignore the \nadjW\n and \nadjH\n values used to construct the module). Use \nSpatialFullConvolution[Table, T](...)\n instead of \nSpatialFullConvolution[Tensor,T](...)\n) for table input.\n\n\nThis module can also be used without a bias by setting parameter \nnoBias = true\n while constructing the module.\n\n\nOther frameworks may call this operation \"In-network Upsampling\", \"Fractionally-strided convolution\", \"Backwards Convolution,\" \"Deconvolution\", or \"Upconvolution.\"\n\n\nReference: Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3431-3440.\n\n\nDetailed explaination of arguments in constructor. \n\n\n\n\nparam nInputPlane The number of expected input planes in the image given into forward()\n\n\nparam nOutputPlane The number of output planes the convolution layer will produce.\n\n\nparam kW The kernel width of the convolution.\n\n\nparam kH The kernel height of the convolution.\n\n\nparam dW The step of the convolution in the width dimension. Default is 1.\n\n\nparam dH The step of the convolution in the height dimension. Default is 1.\n\n\nparam padW The additional zeros added per width to the input planes. Default is 0.\n\n\nparam padH The additional zeros added per height to the input planes. Default is 0.\n\n\nparam adjW Extra width to add to the output image. Default is 0.\n\n\nparam adjH Extra height to add to the output image. Default is 0.\n\n\nparam nGroup Kernel group number.\n\n\nparam noBias If bias is needed.\n\n\nparam wRegularizer: instance of [[Regularizer]]\n\n\n(eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nparam bRegularizer: instance of [[Regularizer]]\n\n\napplied to the bias.\n\n\n\n\nScala example:\n\n\nTensor Input example: \n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval m = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, false)\n\nval input = Tensor(1,1,3,3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1,2,4,4).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n(1,1,.,.) =\n0.18219171      1.3252861       -1.3991559\n0.82611334      1.0313315       0.6075537\n-0.7336061      0.3156875       -0.70616096\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x3x3]\n\nscala\n print(output)\n(1,1,.,.) =\n-0.49278542     -0.5823938      -0.8304068      -0.077556044\n-0.5028842      -0.7281958      -1.1927067      -0.34262076\n-0.41680115     -0.41400516     -0.7599415      -0.42024887\n-0.5286566      -0.30015367     -0.5997892      -0.32439864\n\n(1,2,.,.) =\n-0.13131973     -0.5770084      1.1069719       -0.6003375\n-0.40302444     -0.07293816     -0.2654545      0.39749345\n0.37311426      -0.49090374     0.3088816       -0.41700447\n-0.12861171     0.09394867      -0.17229918     0.05556257\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\nscala\n print(gradOut)\n(1,1,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n(1,2,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x4x4]\n\nscala\n print(gradIn)\n(1,1,.,.) =\n-0.05955213     -0.05955213     -0.05955213\n-0.05955213     -0.05955213     -0.05955213\n-0.05955213     -0.05955213     -0.05955213\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3x3]\n\n\n\n\n\n\nTable input Example\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nval m = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, false)\n\nval input1 = Tensor(1, 3, 3).randn()\nval input2 = Tensor(3, 3).fill(2.0f)\nval input = T(input1, input2)\nval output = m.forward(input)\nval gradOut = Tensor(2,4,4).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n {\n        2: 2.0  2.0     2.0\n           2.0  2.0     2.0\n           2.0  2.0     2.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n        1: (1,.,.) =\n           1.276177     0.62761325      0.2715257\n           -0.030832397 0.5046206       0.6835176\n           -0.5832693   0.17266633      0.7461992\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n }\n\nscala\n print(output)\n(1,.,.) =\n-0.18339296     0.04208675      -0.17708774     -0.30901802\n-0.1484881      0.23592418      0.115615785     -0.11288056\n-0.47266048     -0.41772115     0.07501307      0.041751802\n-0.4851033      -0.5427048      -0.18293871     -0.12682784\n\n(2,.,.) =\n0.6391188       0.845774        0.41208875      0.13754106\n-0.45785713     0.31221163      0.6006259       0.36563575\n-0.24076991     -0.31931365     0.31651747      0.4836449\n0.24247466      -0.16731171     -0.20887817     0.19513035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x4]\n\nscala\n print(gradOut)\n(1,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n(2,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x4x4]\n\nscala\n print(gradIn)\n {\n        2: 0.0  0.0     0.0\n           0.0  0.0     0.0\n           0.0  0.0     0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n        1: (1,.,.) =\n           0.16678208   0.16678208      0.16678208\n           0.16678208   0.16678208      0.16678208\n           0.16678208   0.16678208      0.16678208\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nm = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, False)\n\nprint \n--------- tensor input---------\n\ntensor_input = np.random.rand(1,3,3)\nprint \ninput is :\n,tensor_input\nout = m.forward(tensor_input)\nprint \noutput m is :\n,out\n\nprint \n----------- table input --------\n\nadj_input=np.empty([3,3])\nadj_input.fill(2.0)\ntable_input = [tensor_input,adj_input]\nprint \ninput is :\n,table_input\nout = m.forward(table_input)\nprint \noutput m is :\n,out\n\n\n\n\nproduces output:\n\n\ncreating: createSpatialFullConvolution\n--------- tensor input---------\ninput is : [[[  9.03998497e-01   4.43054896e-01   6.19571211e-01]\n  [  4.24573060e-01   3.29886286e-04   5.48427154e-02]\n  [  8.99004782e-01   3.25514441e-01   6.85294650e-01]]]\noutput m is : [[[-0.04712385  0.21949144  0.0843184   0.14336972]\n  [-0.28748769  0.39192575  0.00372696  0.27235305]\n  [-0.16292028  0.41943201  0.03476509  0.18813471]\n  [-0.28051955  0.29929382 -0.0689255   0.28749463]]\n\n [[-0.21336153 -0.35994443 -0.29239666 -0.38612381]\n  [-0.33000433 -0.41727966 -0.36827195 -0.34524575]\n  [-0.2410759  -0.38439807 -0.27613443 -0.39401439]\n  [-0.38188276 -0.36746511 -0.37627563 -0.34141305]]]\n----------- table input --------\ninput is : [array([[[  9.03998497e-01,   4.43054896e-01,   6.19571211e-01],\n        [  4.24573060e-01,   3.29886286e-04,   5.48427154e-02],\n        [  8.99004782e-01,   3.25514441e-01,   6.85294650e-01]]]), array([[ 2.,  2.,  2.],\n       [ 2.,  2.,  2.],\n       [ 2.,  2.,  2.]])]\noutput m is : [[[-0.04712385  0.21949144  0.0843184   0.14336972]\n  [-0.28748769  0.39192575  0.00372696  0.27235305]\n  [-0.16292028  0.41943201  0.03476509  0.18813471]\n  [-0.28051955  0.29929382 -0.0689255   0.28749463]]\n\n [[-0.21336153 -0.35994443 -0.29239666 -0.38612381]\n  [-0.33000433 -0.41727966 -0.36827195 -0.34524575]\n  [-0.2410759  -0.38439807 -0.27613443 -0.39401439]\n  [-0.38188276 -0.36746511 -0.37627563 -0.34141305]]]\n\n\n\n\nSpatialDilatedConvolution\n\n\nScala:\n\n\nval layer = SpatialDilatedConvolution(\n  inputPlanes,\n  outputPlanes,\n  kernelW,\n  kernelH,\n  strideW,\n  strideH,\n  paddingW,\n  paddingH,\n  dilationW,\n  dilationH\n)\n\n\n\n\nPython:\n\n\nlayer = SpatialDilatedConvolution(\n  inputPlanes,\n  outputPlanes,\n  kernelW,\n  kernelH,\n  strideW,\n  strideH,\n  paddingW,\n  paddingH,\n  dilationW,\n  dilationH\n)\n\n\n\n\nApply a 2D dilated convolution over an input image.\n\n\nThe input tensor is expected to be a 3D or 4D(with batch) tensor.\n\n\nFor a normal SpatialConvolution, the kernel will multiply with input\nimage element-by-element contiguous. In dilated convolution, it\u2019s possible\nto have filters that have spaces between each cell. For example, filter w and\nimage x, when dilatiionW and dilationH both = 1, this is normal 2D convolution\n\n\nw(0, 0) * x(0, 0), w(0, 1) * x(0, 1)\nw(1, 0) * x(1, 0), w(1, 1) * x(1, 1)\n\n\n\n\nwhen dilationW and dilationH both = 2\n\n\nw(0, 0) * x(0, 0), w(0, 1) * x(0, 2)\nw(1, 0) * x(2, 0), w(1, 1) * x(2, 2)\n\n\n\n\nwhen dilationW and dilationH both = 3\n\n\nw(0, 0) * x(0, 0), w(0, 1) * x(0, 3)\nw(1, 0) * x(3, 0), w(1, 1) * x(3, 3)\n\n\n\n\nIf input is a 3D tensor nInputPlane x height x width,\n * owidth  = floor(width + 2 * padW - dilationW * (kW-1) - 1) / dW + 1\n * oheight = floor(height + 2 * padH - dilationH * (kH-1) - 1) / dH + 1\n\n\nReference Paper:\n\n\n\n\nYu F, Koltun V. Multi-scale context aggregation by dilated convolutions[J].\narXiv preprint arXiv:1511.07122, 2015.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SpatialDilatedConvolution(1, 1, 2, 2, 1, 1, 0, 0, 2, 2)\nval input = Tensor(T(T(\n  T(1.0f, 2.0f, 3.0f, 4.0f),\n  T(5.0f, 6.0f, 7.0f, 8.0f),\n  T(9.0f, 1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f, 7.0f)\n)))\nval filter = Tensor(T(T(T(\n  T(1.0f, 1.0f),\n  T(1.0f, 1.0f)\n))))\nlayer.weight.copy(filter)\nlayer.bias.zero()\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n))))\n\n\n\n\nIts output should be\n\n\n(1,.,.) =\n15.0    10.0\n22.0    26.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n(1,.,.) =\n0.1     0.2     0.1     0.2\n0.3     0.4     0.3     0.4\n0.1     0.2     0.1     0.2\n0.3     0.4     0.3     0.4\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x4x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import SpatialDilatedConvolution\nimport numpy as np\n\nlayer = SpatialDilatedConvolution(1, 1, 2, 2, 1, 1, 0, 0, 2, 2)\ninput = np.array([[\n  [1.0, 2.0, 3.0, 4.0],\n  [5.0, 6.0, 7.0, 8.0],\n  [9.0, 1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0, 7.0]\n]])\nfilter = np.array([[[\n  [1.0, 1.0],\n  [1.0, 1.0]\n]]])\nbias = np.array([0.0])\nlayer.set_weights([filter, bias])\nlayer.forward(input)\nlayer.backward(input, np.array([[[0.1, 0.2], [0.3, 0.4]]]))\n\n\n\n\nIts output should be\n\n\narray([[[ 15.,  10.],\n        [ 22.,  26.]]], dtype=float32)\n\narray([[[ 0.1       ,  0.2       ,  0.1       ,  0.2       ],\n        [ 0.30000001,  0.40000001,  0.30000001,  0.40000001],\n        [ 0.1       ,  0.2       ,  0.1       ,  0.2       ],\n        [ 0.30000001,  0.40000001,  0.30000001,  0.40000001]]], dtype=float32)\n\n\n\n\n\nVolumetricConvolution\n\n\nScala:\n\n\nval module = VolumetricConvolution(nInputPlane, nOutputPlane, kT, kW, kH,\n  dT=1, dW=1, dH=1, padT=0, padW=0, padH=0, withBias=true)\n\n\n\n\nPython:\n\n\nmodule = VolumetricConvolution(n_input_plane, n_output_plane, k_t, k_w, k_h,\n  d_t=1, d_w=1, d_h=1, pad_t=0, pad_w=0, pad_h=0, with_bias=true)\n\n\n\n\nApplies a 3D convolution over an input image composed of several input planes. The input tensor\nin forward(input) is expected to be a 4D tensor (nInputPlane x time x height x width).\n * @param nInputPlane The number of expected input planes in the image given into forward()\n * @param nOutputPlane The number of output planes the convolution layer will produce.\n * @param kT The kernel size of the convolution in time\n * @param kW The kernel width of the convolution\n * @param kH The kernel height of the convolution\n * @param dT The step of the convolution in the time dimension. Default is 1\n * @param dW The step of the convolution in the width dimension. Default is 1\n * @param dH The step of the convolution in the height dimension. Default is 1\n * @param padT Additional zeros added to the input plane data on both sides of time axis.\n * Default is 0. (kT-1)/2 is often used here.\n * @param padW The additional zeros added per width to the input planes.\n * @param padH The additional zeros added per height to the input planes.\n * @param withBias whether with bias.\n\n\nScala example:\n\n\nval layer = VolumetricConvolution(2, 3, 2, 2, 2, dT=1, dW=1, dH=1,\n  padT=0, padW=0, padH=0, withBias=true)\nval input = Tensor(2, 2, 2, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.54846555      0.5549177\n0.43748873      0.6596535\n\n(1,2,.,.) =\n0.87915933      0.5955469\n0.67464 0.40921077\n\n(2,1,.,.) =\n0.24127467      0.49356017\n0.6707502       0.5421975\n\n(2,2,.,.) =\n0.007834963     0.08188637\n0.51387626      0.7376101\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]\n\nlayer.forward(input)\nres16: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6680023\n\n(2,1,.,.) =\n0.41926455\n\n(3,1,.,.) =\n-0.029196609\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x1x1]\n\n\n\n\nPython example:\n\n\nlayer = VolumetricConvolution(2, 3, 2, 2, 2, d_t=1, d_w=1, d_h=1,\n          pad_t=0, pad_w=0, pad_h=0, with_bias=True, init_method=\ndefault\n,\n          bigdl_type=\nfloat\n)\ninput = np.random.rand(2,2,2,2)\n array([[[[ 0.47639062,  0.76800312],\n         [ 0.28834351,  0.21883535]],\n\n        [[ 0.86097919,  0.89812597],\n         [ 0.43632181,  0.58004824]]],\n\n\n       [[[ 0.65784027,  0.34700039],\n         [ 0.64511955,  0.1660241 ]],\n\n        [[ 0.36060054,  0.71265665],\n         [ 0.51755249,  0.6508298 ]]]])\n\nlayer.forward(input)\narray([[[[ 0.54268712]]],\n\n\n       [[[ 0.17670505]]],\n\n\n       [[[ 0.40953237]]]], dtype=float32)\n\n\n\n\n\nSpatialConvolutionMap\n\n\nScala:\n\n\nval layer = SpatialConvolutionMap(\n  connTable,\n  kW,\n  kH,\n  dW = 1,\n  dH = 1,\n  padW = 0,\n  padH = 0,\n  wRegularizer = null,\n  bRegularizer = null)\n\n\n\n\nPython:\n\n\nlayer = SpatialConvolutionMap(\n  conn_table,\n  kw,\n  kh,\n  dw=1,\n  dh=1,\n  pad_w=0,\n  pad_h=0,\n  wRegularizer=None,\n  bRegularizer=None)\n\n\n\n\nThis class is a generalization of SpatialConvolution.\nIt uses a generic connection table between input and output features.\nThe SpatialConvolution is equivalent to using a full connection table.\n\nA Connection Table is the mapping of input/output feature map, stored in a 2D Tensor. The first column is the input feature maps. The second column is output feature maps.\n\n\nFull Connection table:\n\n\nval conn = SpatialConvolutionMap.full(nin: Int, nout: In)\n\n\n\n\nOne to One connection table:\n\n\nval conn = SpatialConvolutionMap.oneToOne(nfeat: Int)\n\n\n\n\nRandom Connection table:\n\n\nval conn = SpatialConvolutionMap.random(nin: Int, nout: Int, nto: Int)\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval conn = SpatialConvolutionMap.oneToOne(3)\n\n\n\n\nconn\n is\n\n\nconn: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 1.0\n2.0 2.0\n3.0 3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\n\n\n\nval module = SpatialConvolutionMap(SpatialConvolutionMap.oneToOne(3), 2, 2)\n\npritnln(module.forward(Tensor.range(1, 48, 1).resize(3, 4, 4)))\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n4.5230045   5.8323975   7.1417904\n9.760576    11.069969   12.379362\n14.998148   16.30754    17.616934\n\n(2,.,.) =\n-5.6122046  -5.9227824  -6.233361\n-6.8545156  -7.165093   -7.4756703\n-8.096827   -8.407404   -8.71798\n\n(3,.,.) =\n13.534529   13.908197   14.281864\n15.029203   15.402873   15.77654\n16.523876   16.897545   17.271214\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SpatialConvolutionMap(np.array([(1, 1), (2, 2), (3, 3)]), 2, 2)\n\nprint(module.forward(np.arange(1, 49, 1).reshape(3, 4, 4)))\n\n\n\n\nOutput is\n\n\n[array([[[-1.24280548, -1.70889318, -2.17498088],\n        [-3.10715604, -3.57324386, -4.03933144],\n        [-4.97150755, -5.43759441, -5.90368223]],\n\n       [[-5.22062826, -5.54696751, -5.87330723],\n        [-6.52598572, -6.85232496, -7.17866373],\n        [-7.8313427 , -8.15768337, -8.48402214]],\n\n       [[ 0.5065825 ,  0.55170798,  0.59683061],\n        [ 0.68707776,  0.73219943,  0.77732348],\n        [ 0.86757064,  0.91269422,  0.95781779]]], dtype=float32)]", 
            "title": "Convolution Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Convolution-Layers/#spatialshareconvolution", 
            "text": "Scala:  val layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH,\n      padW, padH)  Python:  layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH, padW, padH)  Applies a 2D convolution over an input image composed of several input planes.\n The input tensor in forward(input) is expected to be\n a 3D tensor (nInputPlane x height x width).  This layer has been optimized to save memory. If using this layer to construct multiple convolution\n layers, please add sharing script for the fInput and fGradInput. Please refer to the ResNet example.  Scala example:  \n    import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n    import com.intel.analytics.bigdl.nn._\n    import com.intel.analytics.bigdl.tensor._\n\n    val nInputPlane = 1\n    val nOutputPlane = 1\n    val kW = 2\n    val kH = 2\n    val dW = 1\n    val dH = 1\n    val padW = 0\n    val padH = 0\n    val layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH,\n      padW, padH)\n\n    val inputData = Array(\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1\n    )\n\n    val kernelData = Array(\n      2.0, 3,\n      4, 5\n    )\n\n    val biasData = Array(0.0)\n\n    layer.weight.copy(Tensor(Storage(kernelData), 1,\n      Array(nOutputPlane, nInputPlane, kH, kW)))\n    layer.bias.copy(Tensor(Storage(biasData), 1, Array(nOutputPlane)))\n\n    val input = Tensor(Storage(inputData), 1, Array(3, 1, 3, 4))\n    val output = layer.updateOutput(input)\n\n      output\nres2: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n(2,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n(3,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0  Python example:  nInputPlane = 1\nnOutputPlane = 1\nkW = 2\nkH = 2\ndW = 1\ndH = 1\npadW = 0\npadH = 0\nlayer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH, padW, padH)\n\ninput = np.array([\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1]\n    ).astype( float32 ).reshape(3, 1, 3, 4)\nlayer.forward(input)  print (output)\narray([[[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]],\n\n\n       [[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]],\n\n\n       [[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]]], dtype=float32)", 
            "title": "SpatialShareConvolution"
        }, 
        {
            "location": "/APIdocs/Layers/Convolution-Layers/#spatialconvolution", 
            "text": "Scala:  val m = SpatialConvolution(nInputPlane,nOutputPlane,kernelW,kernelH,strideW=1,strideH=1,padW=0,padH=0,nGroup=1,propagateBack=true,wRegularizer=null,bRegularizer=null,initWeight=null, initBias=null, initGradWeight=null, initGradBias=null)  Python:  m = SpatialConvolution(n_input_plane,n_output_plane,kernel_w,kernel_h,stride_w=1,stride_h=1,pad_w=0,pad_h=0,n_group=1,propagate_back=True,wRegularizer=None,bRegularizer=None,init_weight=None,init_bias=None,init_grad_weight=None,init_grad_bias=None)  SpatialConvolution is a module that applies a 2D convolution over an input image.  The input tensor in  forward(input)  is expected to be\neither a 4D tensor ( batch x nInputPlane x height x width ) or a 3D tensor ( nInputPlane x height x width ). The convolution is performed on the last two dimensions.  Detailed paramter explaination for the constructor.   param nInputPlane: The number of expected input planes in the image given into forward()  param nOutputPlane: The number of output planes the convolution layer will produce.  param kernelW: The kernel width of the convolution  param kernelH: The kernel height of the convolution  param strideW: The step of the convolution in the width dimension.  param strideH: The step of the convolution in the height dimension  param padW:  padding to be added to width to the input.  param padH: padding to be added to height to the input.  param nGroup: Kernel group number  param propagateBack: whether to propagate gradient back  param wRegularizer: regularizer on weight. an instance of [[Regularizer]] (e.g. L1 or L2)  param bRegularizer: regularizer on bias. an instance of [[Regularizer]] (e.g. L1 or L2).  param initWeight: weight initializer  param initBias:  bias initializer  param initGradWeight: weight gradient initializer  param initGradBias: bias gradient initializer   Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval m = SpatialConvolution(2,1,2,2,1,1,0,0)\nm.setInitMethod(weightInitMethod = BilinearFiller, biasInitMethod = Zeros)\nval params = m.getParameters()\n\nscala  print(params)\n(1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9],0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9])\n\nscala \nval input = Tensor(1,2,3,3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1,1,2,2).fill(0.2f)\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n(1,1,.,.) =\n-0.37011376     0.13565119      -0.73574775\n-0.19486316     -0.4430604      -0.62543416\n0.7017611       -0.6441595      -1.2953792\n\n(1,2,.,.) =\n-0.9903588      0.5669722       0.2630131\n0.03392942      -0.6984676      -0.12389368\n0.78704715      0.5411976       -1.3877676\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3]\n\nscala  print(output)\n(1,1,.,.) =\n-1.3604726      0.70262337\n-0.16093373     -1.141528\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\nscala  print(gradOut)\n(1,1,.,.) =\n0.2     0.2\n0.2     0.2\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x2x2]\n\nscala  print(gradIn)\n(1,1,.,.) =\n0.2     0.2     0.0\n0.2     0.2     0.0\n0.0     0.0     0.0\n\n(1,2,.,.) =\n0.2     0.2     0.0\n0.2     0.2     0.0\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(1,3,3,3)\nprint  input is : ,input\n\nm = SpatialConvolution(3,1,2,2,1,1,0,0)\nout = m.forward(input)\nprint  output m is : ,out\n\ngrad_out = np.random.rand(1,1,2,2)\nprint  grad out of m is : ,grad_out\ngrad_in = m.backward(input,grad_out)\nprint  grad input of m is : ,grad_in  produces output:  input is : [[[[ 0.75276617  0.44212513  0.90275949]\n   [ 0.78205279  0.77864714  0.83647254]\n   [ 0.76220944  0.22106036  0.68762202]]\n\n  [[ 0.37346971  0.31532213  0.33276243]\n   [ 0.69872884  0.07262236  0.66372462]\n   [ 0.47803013  0.80194459  0.53313873]]\n\n  [[ 0.56196833  0.20599878  0.47575818]\n   [ 0.35454298  0.96910557  0.36234704]\n   [ 0.64017738  0.95762579  0.50073035]]]]\ncreating: createSpatialConvolution\noutput m is : [[[[-1.08398974 -0.67615652]\n   [-0.77027249 -0.82885492]]]]\ngrad out of m is : [[[[ 0.38295452  0.77048361]\n   [ 0.11671955  0.76357513]]]]\ngrad input of m is : [[[[-0.02344826 -0.06515953 -0.03618064]\n   [-0.06770924 -0.22586647 -0.14004168]\n   [-0.01845866 -0.13653883 -0.10325129]]\n\n  [[-0.09294108 -0.14361492  0.08727306]\n   [-0.09885897 -0.21209857  0.29151234]\n   [-0.02149716 -0.10957514  0.20318349]]\n\n  [[-0.05926216 -0.04542646  0.14849319]\n   [-0.09506465 -0.34244278 -0.03763583]\n   [-0.02346931 -0.1815301  -0.18314059]]]]", 
            "title": "SpatialConvolution"
        }, 
        {
            "location": "/APIdocs/Layers/Convolution-Layers/#spatialfullconvolution", 
            "text": "Scala:  val m  = SpatialFullConvolution(nInputPlane, nOutputPlane, kW, kH, dW=1, dH=1, padW=0, padH=0, adjW=0, adjH=0,nGroup=1, noBias=false,wRegularizer=null,bRegularizer=null)  or  val m = SpatialFullConvolution(InputPlane, nOutputPlane, kW, kH, dW=1, dH=1, padW=0, padH=0, adjW=0, adjH=0,nGroup=1, noBias=false,wRegularizer=null,bRegularizer=null)  Python:  m = SpatialFullConvolution(n_input_plane,n_output_plane,kw,kh,dw=1,dh=1,pad_w=0,pad_h=0,adj_w=0,adj_h=0,n_group=1,no_bias=False,init_method='default',wRegularizer=None,bRegularizer=None)  SpatialFullConvolution is a module that applies a 2D full convolution over an input image.   The input tensor in  forward(input)  is expected to be\neither a 4D tensor ( batch x nInputPlane x height x width ) or a 3D tensor ( nInputPlane x height x width ). The convolution is performed on the last two dimensions.  adjW  and  adjH  are used to adjust the size of the output image. The size of output tensor of  forward  will be :    output width  = (width  - 1) * dW - 2*padW + kW + adjW\n  output height = (height - 1) * dH - 2*padH + kH + adjH  Note, scala API also accepts a table input with two tensors:  T(convInput, sizeTensor)  where  convInput  is the standard input tensor, and the size of  sizeTensor  is used to set the size of the output (will ignore the  adjW  and  adjH  values used to construct the module). Use  SpatialFullConvolution[Table, T](...)  instead of  SpatialFullConvolution[Tensor,T](...) ) for table input.  This module can also be used without a bias by setting parameter  noBias = true  while constructing the module.  Other frameworks may call this operation \"In-network Upsampling\", \"Fractionally-strided convolution\", \"Backwards Convolution,\" \"Deconvolution\", or \"Upconvolution.\"  Reference: Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3431-3440.  Detailed explaination of arguments in constructor.    param nInputPlane The number of expected input planes in the image given into forward()  param nOutputPlane The number of output planes the convolution layer will produce.  param kW The kernel width of the convolution.  param kH The kernel height of the convolution.  param dW The step of the convolution in the width dimension. Default is 1.  param dH The step of the convolution in the height dimension. Default is 1.  param padW The additional zeros added per width to the input planes. Default is 0.  param padH The additional zeros added per height to the input planes. Default is 0.  param adjW Extra width to add to the output image. Default is 0.  param adjH Extra height to add to the output image. Default is 0.  param nGroup Kernel group number.  param noBias If bias is needed.  param wRegularizer: instance of [[Regularizer]]  (eg. L1 or L2 regularization), applied to the input weights matrices.  param bRegularizer: instance of [[Regularizer]]  applied to the bias.   Scala example:  Tensor Input example:   \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval m = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, false)\n\nval input = Tensor(1,1,3,3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1,2,4,4).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n(1,1,.,.) =\n0.18219171      1.3252861       -1.3991559\n0.82611334      1.0313315       0.6075537\n-0.7336061      0.3156875       -0.70616096\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x3x3]\n\nscala  print(output)\n(1,1,.,.) =\n-0.49278542     -0.5823938      -0.8304068      -0.077556044\n-0.5028842      -0.7281958      -1.1927067      -0.34262076\n-0.41680115     -0.41400516     -0.7599415      -0.42024887\n-0.5286566      -0.30015367     -0.5997892      -0.32439864\n\n(1,2,.,.) =\n-0.13131973     -0.5770084      1.1069719       -0.6003375\n-0.40302444     -0.07293816     -0.2654545      0.39749345\n0.37311426      -0.49090374     0.3088816       -0.41700447\n-0.12861171     0.09394867      -0.17229918     0.05556257\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\nscala  print(gradOut)\n(1,1,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n(1,2,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x4x4]\n\nscala  print(gradIn)\n(1,1,.,.) =\n-0.05955213     -0.05955213     -0.05955213\n-0.05955213     -0.05955213     -0.05955213\n-0.05955213     -0.05955213     -0.05955213\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3x3]  Table input Example  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nval m = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, false)\n\nval input1 = Tensor(1, 3, 3).randn()\nval input2 = Tensor(3, 3).fill(2.0f)\nval input = T(input1, input2)\nval output = m.forward(input)\nval gradOut = Tensor(2,4,4).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n {\n        2: 2.0  2.0     2.0\n           2.0  2.0     2.0\n           2.0  2.0     2.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n        1: (1,.,.) =\n           1.276177     0.62761325      0.2715257\n           -0.030832397 0.5046206       0.6835176\n           -0.5832693   0.17266633      0.7461992\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n }\n\nscala  print(output)\n(1,.,.) =\n-0.18339296     0.04208675      -0.17708774     -0.30901802\n-0.1484881      0.23592418      0.115615785     -0.11288056\n-0.47266048     -0.41772115     0.07501307      0.041751802\n-0.4851033      -0.5427048      -0.18293871     -0.12682784\n\n(2,.,.) =\n0.6391188       0.845774        0.41208875      0.13754106\n-0.45785713     0.31221163      0.6006259       0.36563575\n-0.24076991     -0.31931365     0.31651747      0.4836449\n0.24247466      -0.16731171     -0.20887817     0.19513035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x4]\n\nscala  print(gradOut)\n(1,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n(2,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x4x4]\n\nscala  print(gradIn)\n {\n        2: 0.0  0.0     0.0\n           0.0  0.0     0.0\n           0.0  0.0     0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n        1: (1,.,.) =\n           0.16678208   0.16678208      0.16678208\n           0.16678208   0.16678208      0.16678208\n           0.16678208   0.16678208      0.16678208\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n }  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nm = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, False)\n\nprint  --------- tensor input--------- \ntensor_input = np.random.rand(1,3,3)\nprint  input is : ,tensor_input\nout = m.forward(tensor_input)\nprint  output m is : ,out\n\nprint  ----------- table input -------- \nadj_input=np.empty([3,3])\nadj_input.fill(2.0)\ntable_input = [tensor_input,adj_input]\nprint  input is : ,table_input\nout = m.forward(table_input)\nprint  output m is : ,out  produces output:  creating: createSpatialFullConvolution\n--------- tensor input---------\ninput is : [[[  9.03998497e-01   4.43054896e-01   6.19571211e-01]\n  [  4.24573060e-01   3.29886286e-04   5.48427154e-02]\n  [  8.99004782e-01   3.25514441e-01   6.85294650e-01]]]\noutput m is : [[[-0.04712385  0.21949144  0.0843184   0.14336972]\n  [-0.28748769  0.39192575  0.00372696  0.27235305]\n  [-0.16292028  0.41943201  0.03476509  0.18813471]\n  [-0.28051955  0.29929382 -0.0689255   0.28749463]]\n\n [[-0.21336153 -0.35994443 -0.29239666 -0.38612381]\n  [-0.33000433 -0.41727966 -0.36827195 -0.34524575]\n  [-0.2410759  -0.38439807 -0.27613443 -0.39401439]\n  [-0.38188276 -0.36746511 -0.37627563 -0.34141305]]]\n----------- table input --------\ninput is : [array([[[  9.03998497e-01,   4.43054896e-01,   6.19571211e-01],\n        [  4.24573060e-01,   3.29886286e-04,   5.48427154e-02],\n        [  8.99004782e-01,   3.25514441e-01,   6.85294650e-01]]]), array([[ 2.,  2.,  2.],\n       [ 2.,  2.,  2.],\n       [ 2.,  2.,  2.]])]\noutput m is : [[[-0.04712385  0.21949144  0.0843184   0.14336972]\n  [-0.28748769  0.39192575  0.00372696  0.27235305]\n  [-0.16292028  0.41943201  0.03476509  0.18813471]\n  [-0.28051955  0.29929382 -0.0689255   0.28749463]]\n\n [[-0.21336153 -0.35994443 -0.29239666 -0.38612381]\n  [-0.33000433 -0.41727966 -0.36827195 -0.34524575]\n  [-0.2410759  -0.38439807 -0.27613443 -0.39401439]\n  [-0.38188276 -0.36746511 -0.37627563 -0.34141305]]]", 
            "title": "SpatialFullConvolution"
        }, 
        {
            "location": "/APIdocs/Layers/Convolution-Layers/#spatialdilatedconvolution", 
            "text": "Scala:  val layer = SpatialDilatedConvolution(\n  inputPlanes,\n  outputPlanes,\n  kernelW,\n  kernelH,\n  strideW,\n  strideH,\n  paddingW,\n  paddingH,\n  dilationW,\n  dilationH\n)  Python:  layer = SpatialDilatedConvolution(\n  inputPlanes,\n  outputPlanes,\n  kernelW,\n  kernelH,\n  strideW,\n  strideH,\n  paddingW,\n  paddingH,\n  dilationW,\n  dilationH\n)  Apply a 2D dilated convolution over an input image.  The input tensor is expected to be a 3D or 4D(with batch) tensor.  For a normal SpatialConvolution, the kernel will multiply with input\nimage element-by-element contiguous. In dilated convolution, it\u2019s possible\nto have filters that have spaces between each cell. For example, filter w and\nimage x, when dilatiionW and dilationH both = 1, this is normal 2D convolution  w(0, 0) * x(0, 0), w(0, 1) * x(0, 1)\nw(1, 0) * x(1, 0), w(1, 1) * x(1, 1)  when dilationW and dilationH both = 2  w(0, 0) * x(0, 0), w(0, 1) * x(0, 2)\nw(1, 0) * x(2, 0), w(1, 1) * x(2, 2)  when dilationW and dilationH both = 3  w(0, 0) * x(0, 0), w(0, 1) * x(0, 3)\nw(1, 0) * x(3, 0), w(1, 1) * x(3, 3)  If input is a 3D tensor nInputPlane x height x width,\n * owidth  = floor(width + 2 * padW - dilationW * (kW-1) - 1) / dW + 1\n * oheight = floor(height + 2 * padH - dilationH * (kH-1) - 1) / dH + 1  Reference Paper:   Yu F, Koltun V. Multi-scale context aggregation by dilated convolutions[J].\narXiv preprint arXiv:1511.07122, 2015.   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SpatialDilatedConvolution(1, 1, 2, 2, 1, 1, 0, 0, 2, 2)\nval input = Tensor(T(T(\n  T(1.0f, 2.0f, 3.0f, 4.0f),\n  T(5.0f, 6.0f, 7.0f, 8.0f),\n  T(9.0f, 1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f, 7.0f)\n)))\nval filter = Tensor(T(T(T(\n  T(1.0f, 1.0f),\n  T(1.0f, 1.0f)\n))))\nlayer.weight.copy(filter)\nlayer.bias.zero()\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n))))  Its output should be  (1,.,.) =\n15.0    10.0\n22.0    26.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n(1,.,.) =\n0.1     0.2     0.1     0.2\n0.3     0.4     0.3     0.4\n0.1     0.2     0.1     0.2\n0.3     0.4     0.3     0.4\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x4x4]  Python example:  from bigdl.nn.layer import SpatialDilatedConvolution\nimport numpy as np\n\nlayer = SpatialDilatedConvolution(1, 1, 2, 2, 1, 1, 0, 0, 2, 2)\ninput = np.array([[\n  [1.0, 2.0, 3.0, 4.0],\n  [5.0, 6.0, 7.0, 8.0],\n  [9.0, 1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0, 7.0]\n]])\nfilter = np.array([[[\n  [1.0, 1.0],\n  [1.0, 1.0]\n]]])\nbias = np.array([0.0])\nlayer.set_weights([filter, bias])\nlayer.forward(input)\nlayer.backward(input, np.array([[[0.1, 0.2], [0.3, 0.4]]]))  Its output should be  array([[[ 15.,  10.],\n        [ 22.,  26.]]], dtype=float32)\n\narray([[[ 0.1       ,  0.2       ,  0.1       ,  0.2       ],\n        [ 0.30000001,  0.40000001,  0.30000001,  0.40000001],\n        [ 0.1       ,  0.2       ,  0.1       ,  0.2       ],\n        [ 0.30000001,  0.40000001,  0.30000001,  0.40000001]]], dtype=float32)", 
            "title": "SpatialDilatedConvolution"
        }, 
        {
            "location": "/APIdocs/Layers/Convolution-Layers/#volumetricconvolution", 
            "text": "Scala:  val module = VolumetricConvolution(nInputPlane, nOutputPlane, kT, kW, kH,\n  dT=1, dW=1, dH=1, padT=0, padW=0, padH=0, withBias=true)  Python:  module = VolumetricConvolution(n_input_plane, n_output_plane, k_t, k_w, k_h,\n  d_t=1, d_w=1, d_h=1, pad_t=0, pad_w=0, pad_h=0, with_bias=true)  Applies a 3D convolution over an input image composed of several input planes. The input tensor\nin forward(input) is expected to be a 4D tensor (nInputPlane x time x height x width).\n * @param nInputPlane The number of expected input planes in the image given into forward()\n * @param nOutputPlane The number of output planes the convolution layer will produce.\n * @param kT The kernel size of the convolution in time\n * @param kW The kernel width of the convolution\n * @param kH The kernel height of the convolution\n * @param dT The step of the convolution in the time dimension. Default is 1\n * @param dW The step of the convolution in the width dimension. Default is 1\n * @param dH The step of the convolution in the height dimension. Default is 1\n * @param padT Additional zeros added to the input plane data on both sides of time axis.\n * Default is 0. (kT-1)/2 is often used here.\n * @param padW The additional zeros added per width to the input planes.\n * @param padH The additional zeros added per height to the input planes.\n * @param withBias whether with bias.  Scala example:  val layer = VolumetricConvolution(2, 3, 2, 2, 2, dT=1, dW=1, dH=1,\n  padT=0, padW=0, padH=0, withBias=true)\nval input = Tensor(2, 2, 2, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.54846555      0.5549177\n0.43748873      0.6596535\n\n(1,2,.,.) =\n0.87915933      0.5955469\n0.67464 0.40921077\n\n(2,1,.,.) =\n0.24127467      0.49356017\n0.6707502       0.5421975\n\n(2,2,.,.) =\n0.007834963     0.08188637\n0.51387626      0.7376101\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]\n\nlayer.forward(input)\nres16: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6680023\n\n(2,1,.,.) =\n0.41926455\n\n(3,1,.,.) =\n-0.029196609\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x1x1]  Python example:  layer = VolumetricConvolution(2, 3, 2, 2, 2, d_t=1, d_w=1, d_h=1,\n          pad_t=0, pad_w=0, pad_h=0, with_bias=True, init_method= default ,\n          bigdl_type= float )\ninput = np.random.rand(2,2,2,2)\n array([[[[ 0.47639062,  0.76800312],\n         [ 0.28834351,  0.21883535]],\n\n        [[ 0.86097919,  0.89812597],\n         [ 0.43632181,  0.58004824]]],\n\n\n       [[[ 0.65784027,  0.34700039],\n         [ 0.64511955,  0.1660241 ]],\n\n        [[ 0.36060054,  0.71265665],\n         [ 0.51755249,  0.6508298 ]]]])\n\nlayer.forward(input)\narray([[[[ 0.54268712]]],\n\n\n       [[[ 0.17670505]]],\n\n\n       [[[ 0.40953237]]]], dtype=float32)", 
            "title": "VolumetricConvolution"
        }, 
        {
            "location": "/APIdocs/Layers/Convolution-Layers/#spatialconvolutionmap", 
            "text": "Scala:  val layer = SpatialConvolutionMap(\n  connTable,\n  kW,\n  kH,\n  dW = 1,\n  dH = 1,\n  padW = 0,\n  padH = 0,\n  wRegularizer = null,\n  bRegularizer = null)  Python:  layer = SpatialConvolutionMap(\n  conn_table,\n  kw,\n  kh,\n  dw=1,\n  dh=1,\n  pad_w=0,\n  pad_h=0,\n  wRegularizer=None,\n  bRegularizer=None)  This class is a generalization of SpatialConvolution.\nIt uses a generic connection table between input and output features.\nThe SpatialConvolution is equivalent to using a full connection table. \nA Connection Table is the mapping of input/output feature map, stored in a 2D Tensor. The first column is the input feature maps. The second column is output feature maps.  Full Connection table:  val conn = SpatialConvolutionMap.full(nin: Int, nout: In)  One to One connection table:  val conn = SpatialConvolutionMap.oneToOne(nfeat: Int)  Random Connection table:  val conn = SpatialConvolutionMap.random(nin: Int, nout: Int, nto: Int)  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval conn = SpatialConvolutionMap.oneToOne(3)  conn  is  conn: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 1.0\n2.0 2.0\n3.0 3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]  val module = SpatialConvolutionMap(SpatialConvolutionMap.oneToOne(3), 2, 2)\n\npritnln(module.forward(Tensor.range(1, 48, 1).resize(3, 4, 4)))  Output is  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n4.5230045   5.8323975   7.1417904\n9.760576    11.069969   12.379362\n14.998148   16.30754    17.616934\n\n(2,.,.) =\n-5.6122046  -5.9227824  -6.233361\n-6.8545156  -7.165093   -7.4756703\n-8.096827   -8.407404   -8.71798\n\n(3,.,.) =\n13.534529   13.908197   14.281864\n15.029203   15.402873   15.77654\n16.523876   16.897545   17.271214\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SpatialConvolutionMap(np.array([(1, 1), (2, 2), (3, 3)]), 2, 2)\n\nprint(module.forward(np.arange(1, 49, 1).reshape(3, 4, 4)))  Output is  [array([[[-1.24280548, -1.70889318, -2.17498088],\n        [-3.10715604, -3.57324386, -4.03933144],\n        [-4.97150755, -5.43759441, -5.90368223]],\n\n       [[-5.22062826, -5.54696751, -5.87330723],\n        [-6.52598572, -6.85232496, -7.17866373],\n        [-7.8313427 , -8.15768337, -8.48402214]],\n\n       [[ 0.5065825 ,  0.55170798,  0.59683061],\n        [ 0.68707776,  0.73219943,  0.77732348],\n        [ 0.86757064,  0.91269422,  0.95781779]]], dtype=float32)]", 
            "title": "SpatialConvolutionMap"
        }, 
        {
            "location": "/APIdocs/Layers/Pooling-Layers/", 
            "text": "SpatialAveragePooling\n\n\nScala:\n\n\nval m = SpatialAveragePooling(kW, kH, dW=1, dH=1, padW=0, padH=0, ceilMode=false, countIncludePad=true, divide=true)\n\n\n\n\nPython:\n\n\nm = SpatialAveragePooling(kw, kh, dw=1, dh=1, pad_w=0, pad_h=0,ceil_mode=False, count_include_pad=True, divide=True)\n\n\n\n\nSpatialAveragePooling is a module that applies 2D average-pooling operation in \nkW\nx\nkH\n regions by step size \ndW\nx\ndH\n.\n\n\nThe number of output features is equal to the number of input planes.\n\n\nScala example:\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(1, 3, 3).randn()\nval m = SpatialAveragePooling(3, 2, 2, 1)\nval output = m.forward(input)\nval gradOut = Tensor(1, 2, 1).randn()\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n(1,.,.) =\n0.9916249       1.0299556       0.5608558\n-0.1664829      1.5031902       0.48598626\n0.37362042      -0.0966136      -1.4257964\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n\nscala\n print(output)\n(1,.,.) =\n0.7341883\n0.1123173\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1]\n\nscala\n print(gradOut)\n(1,.,.) =\n-0.42837557\n-1.5104272\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x1]\n\nscala\n print(gradIn)\n(1,.,.) =\n-0.071395926    -0.071395926    -0.071395926\n-0.3231338      -0.3231338      -0.3231338\n-0.25173786     -0.25173786     -0.25173786\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.randn(1,3,3)\nprint \ninput is :\n,input\n\nm = SpatialAveragePooling(3,2,2,1)\nout = m.forward(input)\nprint \noutput of m is :\n,out\n\ngrad_out = np.random.rand(1,3,1)\ngrad_in = m.backward(input,grad_out)\nprint \ngrad input of m is :\n,grad_in\n\n\n\n\nproduces output:\n\n\ninput is : [[[ 1.50602425 -0.92869054 -1.9393117 ]\n  [ 0.31447547  0.63450578 -0.92485516]\n  [-2.07858315 -0.05688643  0.73648798]]]\ncreating: createSpatialAveragePooling\noutput of m is : [array([[[-0.22297533],\n        [-0.22914261]]], dtype=float32)]\ngrad input of m is : [array([[[ 0.06282618,  0.06282618,  0.06282618],\n        [ 0.09333335,  0.09333335,  0.09333335],\n        [ 0.03050717,  0.03050717,  0.03050717]]], dtype=float32)]\n\n\n\n\n\nVolumetricMaxPooling\n\n\nScala:\n\n\nval layer = VolumetricMaxPooling(\n  kernelT, kernelW, kernelH,\n  strideT, strideW, strideH,\n  paddingT, paddingW, paddingH\n)\n\n\n\n\nPython:\n\n\nlayer = VolumetricMaxPooling(\n  kernelT, kernelW, kernelH,\n  strideT, strideW, strideH,\n  paddingT, paddingW, paddingH\n)\n\n\n\n\nApplies 3D max-pooling operation in kT x kW x kH regions by step size dT x dW x dH.\nThe number of output features is equal to the number of input planes / dT.\nThe input can optionally be padded with zeros. Padding should be smaller than\nhalf of kernel size. That is, padT \n kT/2, padW \n kW/2 and padH \n kH/2\n\n\nThe input layout should be [batch, plane, time, height, width] or [plane, time, height, width]\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = VolumetricMaxPooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\nval input = Tensor(T(T(\n  T(\n    T(1.0f, 2.0f, 3.0f),\n    T(4.0f, 5.0f, 6.0f),\n    T(7.0f, 8.0f, 9.0f)\n  ),\n  T(\n    T(4.0f, 5.0f, 6.0f),\n    T(1.0f, 3.0f, 9.0f),\n    T(2.0f, 3.0f, 7.0f)\n  )\n)))\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n)))))\n\n\n\n\nIts output should be\n\n\n(1,1,.,.) =\n5.0     9.0\n8.0     9.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\n(1,1,.,.) =\n0.0     0.0     0.0\n0.0     0.1     0.0\n0.0     0.3     0.4\n\n(1,2,.,.) =\n0.0     0.0     0.0\n0.0     0.0     0.2\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import VolumetricMaxPooling\nimport numpy as np\n\nlayer = VolumetricMaxPooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\ninput = np.array([[\n  [\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0]\n  ],\n  [\n    [4.0, 5.0, 6.0],\n    [1.0, 3.0, 9.0],\n    [2.0, 3.0, 7.0]\n  ]\n]])\nlayer.forward(input)\nlayer.backward(input, np.array([[[\n  [0.1, 0.2],\n  [0.3, 0.4]\n]]]))\n\n\n\n\nIts output should be\n\n\narray([[[[ 5.,  9.],\n         [ 8.,  9.]]]], dtype=float32)\n\narray([[[[ 0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.1       ,  0.        ],\n         [ 0.        ,  0.30000001,  0.40000001]],\n\n        [[ 0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.2       ],\n         [ 0.        ,  0.        ,  0.        ]]]], dtype=float32)\n\n\n\n\nRoiPooling\n\n\nScala:\n\n\nval m =  RoiPooling(pooled_w, pooled_h, spatial_scale)\n\n\n\n\nPython:\n\n\nm = RoiPooling(pooled_w, pooled_h, spatial_scale)\n\n\n\n\nRoiPooling is a module that performs Region of Interest pooling. \n\n\nIt uses max pooling to convert the features inside any valid region of interest into a small feature map with a fixed spatial extent of pooledH \u00d7 pooledW (e.g., 7 \u00d7 7).\n\n\nAn RoI is a rectangular window into a conv feature map. Each RoI is defined by a four-tuple (x1, y1, x2, y2) that specifies its top-left corner (x1, y1) and its bottom-right corner (x2, y2).\n\n\nRoI max pooling works by dividing the h \u00d7 w RoI window into an pooledH \u00d7 pooledW grid of sub-windows of approximate size h/H \u00d7 w/W and then max-pooling the values in each sub-window into the corresponding output grid cell. Pooling is applied independently to each feature map channel\n\n\nforward\n accepts a table containing 2 tensors as input, the first tensor is the input image, the second tensor is the ROI regions. The dimension of the second tensor should be (*,5) (5 are  \nbatch_num, x1, y1, x2, y2\n).  \n\n\nScala example:\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input_data = Tensor(2,2,6,8).randn()\nval rois = Array(0, 0, 0, 7, 5, 1, 6, 2, 7, 5, 1, 3, 1, 6, 4, 0, 3, 3, 3, 3)\nval input_rois = Tensor(Storage(rois.map(x =\n x.toFloat))).resize(4, 5)\nval input = T(input_data,input_rois)\nval m = RoiPooling(3, 2, 1)\nval output = m.forward(input)\n\nscala\n print(input)\n {\n        2: 0.0  0.0     0.0     7.0     5.0\n           1.0  6.0     2.0     7.0     5.0\n           1.0  3.0     1.0     6.0     4.0\n           0.0  3.0     3.0     3.0     3.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 4x5]\n        1: (1,1,.,.) =\n           0.48066297   1.0994664       0.32474303      2.3391871       -0.79605865     0.836963950.36107457      1.2622415\n           0.657079     0.12720469      0.39894578      -0.41185552     -0.53111094     -0.36016005       -0.9726423      -2.5785272\n           0.3091435    -0.03613516     0.2375721       -1.1920663      -0.6757661      1.10612681.5409279        -0.17411499\n           0.23274016   -0.7149633      0.5473105       -0.40570387     -1.7966263      0.2071798-1.1530842       -0.010083453\n           -1.5769979   0.17043112      -0.28578365     -0.90779626     0.61457515      -0.1553582-0.3912479      -0.15326484\n           -0.24283029  1.3215472       1.3795123       -0.36933053     0.7077386       -0.56398267       0.6159163       0.5802894\n\n           (1,2,.,.) =\n           -1.1817129   -0.20470592     -1.3201113      0.36523122      -0.18260211     1.30210171.214403 1.1019816\n           0.7186407    0.78731173      1.5452348       0.0396181       0.5927014       1.17697431.0501136        -0.58295316\n           -0.96753055  0.6427254       -1.1396345      0.8701054       -0.22860864     -1.18719451.3372624       0.8616691\n           0.796831     -0.16609778     0.2950535       0.4595303       0.192339        0.6086106-0.76351887      -0.65964174\n           -0.12746814  -0.036058053    0.8858275       0.9677718       -1.1074747      -1.36859390.8783633       -0.11723315\n           -0.6947403   -0.23226547     -1.8510057      -1.3695518      -0.22317407     -0.36249024       -0.24097045     1.5691053\n\n           (2,1,.,.) =\n           0.84056973   1.144949        -1.0660682      0.4416162       -0.94440234     -0.24461010.91145027      -0.88650835\n           -0.81542057  0.14578317      -0.6531974      0.60776395      -0.32058007     -1.80771481.7660322       1.0680646\n           1.1328241    0.43677545      -0.9402618      -1.3002211      0.26012567      1.69481340.37849447       0.39286092\n           1.9443163    0.5415504       1.0793099       1.3312546       0.48346 1.2019655       0.3718734 0.21091922\n           0.5499047    1.6418253       0.8064177       0.37626198      0.8736181       -0.40816033       -0.5806787      1.286581\n           -0.5904657   -0.21188398     -0.040509004    1.2989452       1.6827602       1.3229258-0.68433124      0.87974\n\n           (2,2,.,.) =\n           -0.09759476  -0.32767114     0.16223079      2.3114302       -0.48496276     1.19290720.8572289        0.43429425\n           -1.0245247   0.19002944      1.5659521       -1.3689835      -1.4437296      -0.38216656       0.6333655       -0.57124794\n           -0.31111157  1.5184602       -1.3835855      -0.9295573      2.244521        -1.11849820.5451996       -0.4441631\n           -1.534093    -0.5599659      1.1980947       -1.0140935      1.3288999       0.19487387-0.1261734      -1.2222558\n           -0.070535585 0.9047848       -0.6719811      -1.6532638      -0.5290511      -0.18300447       0.69385433      0.018756092\n           0.24767837   0.620484        -0.5346291      1.0685066       -0.36903372     -0.26955062       1.1042496       0.5944603\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x6x8]\n }\n\nscala\n print(output)\n(1,1,.,.) =\n1.0994664       2.3391871       1.5409279\n1.3795123       1.3795123       0.6159163\n\n(1,2,.,.) =\n1.5452348       1.5452348       1.3372624\n0.8858275       0.9677718       1.5691053\n\n(2,1,.,.) =\n0.37849447      0.39286092      0.39286092\n-0.5806787      1.286581        1.286581\n\n(2,2,.,.) =\n0.5451996       0.5451996       -0.4441631\n1.1042496       1.1042496       0.5944603\n\n(3,1,.,.) =\n0.60776395      1.6948134       1.7660322\n1.3312546       1.2019655       1.2019655\n\n(3,2,.,.) =\n2.244521        2.244521        0.6333655\n1.3288999       1.3288999       0.69385433\n\n(4,1,.,.) =\n-0.40570387     -0.40570387     -0.40570387\n-0.40570387     -0.40570387     -0.40570387\n\n(4,2,.,.) =\n0.4595303       0.4595303       0.4595303\n0.4595303       0.4595303       0.4595303\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4x2x2x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput_data = np.random.randn(2,2,6,8)\ninput_rois = np.array([0, 0, 0, 7, 5, 1, 6, 2, 7, 5, 1, 3, 1, 6, 4, 0, 3, 3, 3, 3],dtype='float64').reshape(4,5)\nprint \ninput is :\n,[input_data, input_rois]\n\nm = RoiPooling(3,2,1.0)\nout = m.forward([input_data,input_rois])\nprint \noutput of m is :\n,out\n\n\n\n\nproduces output:\n\n\ninput is : [array([[[[ 0.08500103,  0.33421796,  0.29084699,  1.60344635, -0.24289341,\n          -0.4793888 ,  0.09452426,  0.16842477],\n         [-1.18575497, -0.53337542,  0.11661001,  0.9647904 , -0.25187936,\n           0.36516823, -0.16647209, -0.08095158],\n         [ 1.1982232 , -0.33549174,  0.11721347, -0.29319686, -0.01290122,\n           0.12344296,  0.30074829, -2.34951463],\n         [-0.60470899, -0.84657051,  0.1269276 , -0.06152321, -1.68838416,\n          -0.69808296, -2.06112892, -1.44790449],\n         [ 1.03944288,  0.13871728,  0.91478479,  0.47517105,  1.24638374,\n           0.98666841,  0.49403488,  1.26101127],\n         [-1.03949343, -0.39291108,  1.39107512,  1.73779253,  0.91656129,\n           0.103381  ,  0.956243  ,  0.44743548]],\n\n        [[ 0.79028054,  0.64244228, -0.37997334, -0.09130215, -2.3903429 ,\n           0.71919208, -0.14079786,  0.98304272],\n         [ 1.14678457,  1.58825227,  0.17137367, -0.62121819, -0.36103113,\n          -0.04452576, -0.0886136 , -1.32884721],\n         [ 0.06728957, -0.29701304, -0.52754207, -1.5785875 ,  1.47354834,\n          -0.28545156,  0.49874194,  0.10277613],\n         [-0.10117571, -1.34902427, -1.40789327,  0.09853599,  0.60420022,\n           0.54869115, -0.49067696,  0.26696793],\n         [ 1.11780279, -0.77929016,  1.13772094,  0.14374057,  0.33199688,\n          -0.54057374, -0.45718861,  1.1577623 ],\n         [-1.4005645 ,  1.15870496,  0.39292003,  0.88379515,  0.06440974,\n           0.65013063,  0.03759244,  0.18730126]]],\n\n\n       [[[-2.28272906,  0.06056305,  0.73632597,  0.10063274, -1.27497525,\n          -0.95597581, -0.22745785,  0.40146498],\n         [-1.37783475,  1.66000653, -1.80071745, -0.11805539, -0.27160583,\n           0.30691418,  2.62243232, -1.95274516],\n         [ 1.61364148,  1.91470546, -1.51984424,  2.13598224, -0.23156685,\n          -0.74203698,  0.65316888,  0.08018846],\n         [-1.8912854 , -0.50106158,  0.94937966, -0.10930541,  0.82136627,\n          -1.33209063,  1.43371302, -1.36370916],\n         [-0.52737928, -0.0681305 , -0.63472587,  0.41979229, -0.57093624,\n          -0.15968764, -1.005951  , -2.06873572],\n         [-2.34089346,  1.02593977,  0.90183415,  0.09504819,  0.53185448,\n           1.11305345,  1.290016  , -1.76216646]],\n\n        [[-0.10885459, -0.57089742, -0.55340708, -1.94445884,  1.30130049,\n           0.6333372 , -1.03100083,  0.0111167 ],\n         [ 0.59678149, -0.67601521, -1.25288718, -0.10922251,  3.06808996,\n          -1.46701513, -0.42140765,  1.12485412],\n         [ 1.21301567, -1.43304957, -0.56047239,  0.20716087,  1.40737646,\n          -0.08386437, -0.21916043,  0.85692906],\n         [ 1.59992399, -1.37044315, -0.71884386,  2.61830979, -0.74305496,\n          -0.32021174,  1.43275058, -0.3891857 ],\n         [-0.41355145,  0.22589689,  0.33154415,  0.86146815, -1.66326091,\n           0.37581697, -3.2250516 , -0.48807863],\n         [-2.52968957,  0.95801598, -1.20118154,  0.01141421, -0.11871498,\n           0.04555184,  1.3950473 ,  0.37887998]]]]), array([[ 0.,  0.,  0.,  7.,  5.],\n       [ 1.,  6.,  2.,  7.,  5.],\n       [ 1.,  3.,  1.,  6.,  4.],\n       [ 0.,  3.,  3.,  3.,  3.]])]\ncreating: createRoiPooling\noutput of m is : [[[[ 1.19822323  1.60344636  0.36516821]\n   [ 1.39107513  1.73779249  1.26101124]]\n\n  [[ 1.58825231  1.47354829  0.98304272]\n   [ 1.158705    1.13772094  1.15776229]]]\n\n\n [[[ 1.43371308  1.43371308  0.08018846]\n   [ 1.29001606  1.29001606 -1.7621665 ]]\n\n  [[ 1.43275058  1.43275058  0.85692906]\n   [ 1.39504731  1.39504731  0.37887999]]]\n\n\n [[[ 2.13598228  0.30691418  2.62243223]\n   [ 0.82136625  0.82136625  1.43371308]]\n\n  [[ 3.06808996  3.06808996 -0.08386437]\n   [ 2.61830974  0.37581697  1.43275058]]]\n\n\n [[[-0.06152321 -0.06152321 -0.06152321]\n   [-0.06152321 -0.06152321 -0.06152321]]\n\n  [[ 0.09853599  0.09853599  0.09853599]\n   [ 0.09853599  0.09853599  0.09853599]]]]\n\n\n\n\n\nSpatialMaxPooling\n\n\nScala:\n\n\nval mp = SpatialMaxPooling(2, 2, dW=2, dH=2, padW=0, padH=0)\n\n\n\n\nPython:\n\n\nmp = SpatialMaxPooling(2, 2, dw=2, dh=2, pad_w=0, pad_h=0, to_ceil=false)\n\n\n\n\nApplies 2D max-pooling operation in kWxkH regions by step size dWxdH steps.\nThe number of output features is equal to the number of input planes.\nIf the input image is a 3D tensor nInputPlane x height x width,\nthe output image size will be nOutputPlane x oheight x owidth where\nowidth  = op((width  + 2\npadW - kW) / dW + 1)\noheight = op((height + 2\npadH - kH) / dH + 1)\nop is a rounding operator. By default, it is floor.\nIt can be changed by calling :ceil() or :floor() methods.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.SpatialMaxPooling\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mp = SpatialMaxPooling(2, 2, 2, 2)\nval input = Tensor(1, 3, 3)\n\ninput(Array(1, 1, 1)) = 0.5336726f\ninput(Array(1, 1, 2)) = 0.7963769f\ninput(Array(1, 1, 3)) = 0.5674766f\ninput(Array(1, 2, 1)) = 0.1803996f\ninput(Array(1, 2, 2)) = 0.2460861f\ninput(Array(1, 2, 3)) = 0.2295625f\ninput(Array(1, 3, 1)) = 0.3073633f\ninput(Array(1, 3, 2)) = 0.5973460f\ninput(Array(1, 3, 3)) = 0.4298954f\n\nval gradOutput = Tensor(1, 1, 1)\ngradOutput(Array(1, 1, 1)) = 0.023921491578221f\n\nval output = mp.forward(input)\nval gradInput = mp.backward(input, gradOutput)\n\nprintln(output)\nprintln(gradInput)\n\n\n\n\nThe output is,\n\n\n(1,.,.) =\n0.7963769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1]\n\n\n\n\nThe gradInput is,\n\n\n(1,.,.) =\n0.0     0.023921492     0.0\n0.0     0.0     0.0\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nmp = SpatialMaxPooling(2, 2, 2, 2)\n\n\ninput = np.array([0.5336726, 0.7963769, 0.5674766, 0.1803996, 0.2460861, 0.2295625, 0.3073633, 0.5973460, 0.4298954]).astype(\nfloat32\n)\ninput = input.reshape(1, 3, 3)\n\noutput = mp.forward(input)\nprint output\n\ngradOutput = np.array([0.023921491578221]).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(1, 1, 1)\n\ngradInput = mp.backward(input, gradOutput)\nprint gradInput\n\n\n\n\nThe output is,\n\n\n[array([[[ 0.79637688]]], dtype=float32)]\n\n\n\n\nThe gradInput is,\n\n\n[array([[[ 0.        ,  0.02392149,  0.        ],\n        [ 0.        ,  0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        ]]], dtype=float32)]", 
            "title": "Pooling Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Pooling-Layers/#spatialaveragepooling", 
            "text": "Scala:  val m = SpatialAveragePooling(kW, kH, dW=1, dH=1, padW=0, padH=0, ceilMode=false, countIncludePad=true, divide=true)  Python:  m = SpatialAveragePooling(kw, kh, dw=1, dh=1, pad_w=0, pad_h=0,ceil_mode=False, count_include_pad=True, divide=True)  SpatialAveragePooling is a module that applies 2D average-pooling operation in  kW x kH  regions by step size  dW x dH .  The number of output features is equal to the number of input planes.  Scala example:  scala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(1, 3, 3).randn()\nval m = SpatialAveragePooling(3, 2, 2, 1)\nval output = m.forward(input)\nval gradOut = Tensor(1, 2, 1).randn()\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n(1,.,.) =\n0.9916249       1.0299556       0.5608558\n-0.1664829      1.5031902       0.48598626\n0.37362042      -0.0966136      -1.4257964\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n\nscala  print(output)\n(1,.,.) =\n0.7341883\n0.1123173\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1]\n\nscala  print(gradOut)\n(1,.,.) =\n-0.42837557\n-1.5104272\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x1]\n\nscala  print(gradIn)\n(1,.,.) =\n-0.071395926    -0.071395926    -0.071395926\n-0.3231338      -0.3231338      -0.3231338\n-0.25173786     -0.25173786     -0.25173786\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.randn(1,3,3)\nprint  input is : ,input\n\nm = SpatialAveragePooling(3,2,2,1)\nout = m.forward(input)\nprint  output of m is : ,out\n\ngrad_out = np.random.rand(1,3,1)\ngrad_in = m.backward(input,grad_out)\nprint  grad input of m is : ,grad_in  produces output:  input is : [[[ 1.50602425 -0.92869054 -1.9393117 ]\n  [ 0.31447547  0.63450578 -0.92485516]\n  [-2.07858315 -0.05688643  0.73648798]]]\ncreating: createSpatialAveragePooling\noutput of m is : [array([[[-0.22297533],\n        [-0.22914261]]], dtype=float32)]\ngrad input of m is : [array([[[ 0.06282618,  0.06282618,  0.06282618],\n        [ 0.09333335,  0.09333335,  0.09333335],\n        [ 0.03050717,  0.03050717,  0.03050717]]], dtype=float32)]", 
            "title": "SpatialAveragePooling"
        }, 
        {
            "location": "/APIdocs/Layers/Pooling-Layers/#volumetricmaxpooling", 
            "text": "Scala:  val layer = VolumetricMaxPooling(\n  kernelT, kernelW, kernelH,\n  strideT, strideW, strideH,\n  paddingT, paddingW, paddingH\n)  Python:  layer = VolumetricMaxPooling(\n  kernelT, kernelW, kernelH,\n  strideT, strideW, strideH,\n  paddingT, paddingW, paddingH\n)  Applies 3D max-pooling operation in kT x kW x kH regions by step size dT x dW x dH.\nThe number of output features is equal to the number of input planes / dT.\nThe input can optionally be padded with zeros. Padding should be smaller than\nhalf of kernel size. That is, padT   kT/2, padW   kW/2 and padH   kH/2  The input layout should be [batch, plane, time, height, width] or [plane, time, height, width]  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = VolumetricMaxPooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\nval input = Tensor(T(T(\n  T(\n    T(1.0f, 2.0f, 3.0f),\n    T(4.0f, 5.0f, 6.0f),\n    T(7.0f, 8.0f, 9.0f)\n  ),\n  T(\n    T(4.0f, 5.0f, 6.0f),\n    T(1.0f, 3.0f, 9.0f),\n    T(2.0f, 3.0f, 7.0f)\n  )\n)))\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n)))))  Its output should be  (1,1,.,.) =\n5.0     9.0\n8.0     9.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\n(1,1,.,.) =\n0.0     0.0     0.0\n0.0     0.1     0.0\n0.0     0.3     0.4\n\n(1,2,.,.) =\n0.0     0.0     0.0\n0.0     0.0     0.2\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]  Python example:  from bigdl.nn.layer import VolumetricMaxPooling\nimport numpy as np\n\nlayer = VolumetricMaxPooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\ninput = np.array([[\n  [\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0]\n  ],\n  [\n    [4.0, 5.0, 6.0],\n    [1.0, 3.0, 9.0],\n    [2.0, 3.0, 7.0]\n  ]\n]])\nlayer.forward(input)\nlayer.backward(input, np.array([[[\n  [0.1, 0.2],\n  [0.3, 0.4]\n]]]))  Its output should be  array([[[[ 5.,  9.],\n         [ 8.,  9.]]]], dtype=float32)\n\narray([[[[ 0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.1       ,  0.        ],\n         [ 0.        ,  0.30000001,  0.40000001]],\n\n        [[ 0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.2       ],\n         [ 0.        ,  0.        ,  0.        ]]]], dtype=float32)", 
            "title": "VolumetricMaxPooling"
        }, 
        {
            "location": "/APIdocs/Layers/Pooling-Layers/#roipooling", 
            "text": "Scala:  val m =  RoiPooling(pooled_w, pooled_h, spatial_scale)  Python:  m = RoiPooling(pooled_w, pooled_h, spatial_scale)  RoiPooling is a module that performs Region of Interest pooling.   It uses max pooling to convert the features inside any valid region of interest into a small feature map with a fixed spatial extent of pooledH \u00d7 pooledW (e.g., 7 \u00d7 7).  An RoI is a rectangular window into a conv feature map. Each RoI is defined by a four-tuple (x1, y1, x2, y2) that specifies its top-left corner (x1, y1) and its bottom-right corner (x2, y2).  RoI max pooling works by dividing the h \u00d7 w RoI window into an pooledH \u00d7 pooledW grid of sub-windows of approximate size h/H \u00d7 w/W and then max-pooling the values in each sub-window into the corresponding output grid cell. Pooling is applied independently to each feature map channel  forward  accepts a table containing 2 tensors as input, the first tensor is the input image, the second tensor is the ROI regions. The dimension of the second tensor should be (*,5) (5 are   batch_num, x1, y1, x2, y2 ).    Scala example:  scala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input_data = Tensor(2,2,6,8).randn()\nval rois = Array(0, 0, 0, 7, 5, 1, 6, 2, 7, 5, 1, 3, 1, 6, 4, 0, 3, 3, 3, 3)\nval input_rois = Tensor(Storage(rois.map(x =  x.toFloat))).resize(4, 5)\nval input = T(input_data,input_rois)\nval m = RoiPooling(3, 2, 1)\nval output = m.forward(input)\n\nscala  print(input)\n {\n        2: 0.0  0.0     0.0     7.0     5.0\n           1.0  6.0     2.0     7.0     5.0\n           1.0  3.0     1.0     6.0     4.0\n           0.0  3.0     3.0     3.0     3.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 4x5]\n        1: (1,1,.,.) =\n           0.48066297   1.0994664       0.32474303      2.3391871       -0.79605865     0.836963950.36107457      1.2622415\n           0.657079     0.12720469      0.39894578      -0.41185552     -0.53111094     -0.36016005       -0.9726423      -2.5785272\n           0.3091435    -0.03613516     0.2375721       -1.1920663      -0.6757661      1.10612681.5409279        -0.17411499\n           0.23274016   -0.7149633      0.5473105       -0.40570387     -1.7966263      0.2071798-1.1530842       -0.010083453\n           -1.5769979   0.17043112      -0.28578365     -0.90779626     0.61457515      -0.1553582-0.3912479      -0.15326484\n           -0.24283029  1.3215472       1.3795123       -0.36933053     0.7077386       -0.56398267       0.6159163       0.5802894\n\n           (1,2,.,.) =\n           -1.1817129   -0.20470592     -1.3201113      0.36523122      -0.18260211     1.30210171.214403 1.1019816\n           0.7186407    0.78731173      1.5452348       0.0396181       0.5927014       1.17697431.0501136        -0.58295316\n           -0.96753055  0.6427254       -1.1396345      0.8701054       -0.22860864     -1.18719451.3372624       0.8616691\n           0.796831     -0.16609778     0.2950535       0.4595303       0.192339        0.6086106-0.76351887      -0.65964174\n           -0.12746814  -0.036058053    0.8858275       0.9677718       -1.1074747      -1.36859390.8783633       -0.11723315\n           -0.6947403   -0.23226547     -1.8510057      -1.3695518      -0.22317407     -0.36249024       -0.24097045     1.5691053\n\n           (2,1,.,.) =\n           0.84056973   1.144949        -1.0660682      0.4416162       -0.94440234     -0.24461010.91145027      -0.88650835\n           -0.81542057  0.14578317      -0.6531974      0.60776395      -0.32058007     -1.80771481.7660322       1.0680646\n           1.1328241    0.43677545      -0.9402618      -1.3002211      0.26012567      1.69481340.37849447       0.39286092\n           1.9443163    0.5415504       1.0793099       1.3312546       0.48346 1.2019655       0.3718734 0.21091922\n           0.5499047    1.6418253       0.8064177       0.37626198      0.8736181       -0.40816033       -0.5806787      1.286581\n           -0.5904657   -0.21188398     -0.040509004    1.2989452       1.6827602       1.3229258-0.68433124      0.87974\n\n           (2,2,.,.) =\n           -0.09759476  -0.32767114     0.16223079      2.3114302       -0.48496276     1.19290720.8572289        0.43429425\n           -1.0245247   0.19002944      1.5659521       -1.3689835      -1.4437296      -0.38216656       0.6333655       -0.57124794\n           -0.31111157  1.5184602       -1.3835855      -0.9295573      2.244521        -1.11849820.5451996       -0.4441631\n           -1.534093    -0.5599659      1.1980947       -1.0140935      1.3288999       0.19487387-0.1261734      -1.2222558\n           -0.070535585 0.9047848       -0.6719811      -1.6532638      -0.5290511      -0.18300447       0.69385433      0.018756092\n           0.24767837   0.620484        -0.5346291      1.0685066       -0.36903372     -0.26955062       1.1042496       0.5944603\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x6x8]\n }\n\nscala  print(output)\n(1,1,.,.) =\n1.0994664       2.3391871       1.5409279\n1.3795123       1.3795123       0.6159163\n\n(1,2,.,.) =\n1.5452348       1.5452348       1.3372624\n0.8858275       0.9677718       1.5691053\n\n(2,1,.,.) =\n0.37849447      0.39286092      0.39286092\n-0.5806787      1.286581        1.286581\n\n(2,2,.,.) =\n0.5451996       0.5451996       -0.4441631\n1.1042496       1.1042496       0.5944603\n\n(3,1,.,.) =\n0.60776395      1.6948134       1.7660322\n1.3312546       1.2019655       1.2019655\n\n(3,2,.,.) =\n2.244521        2.244521        0.6333655\n1.3288999       1.3288999       0.69385433\n\n(4,1,.,.) =\n-0.40570387     -0.40570387     -0.40570387\n-0.40570387     -0.40570387     -0.40570387\n\n(4,2,.,.) =\n0.4595303       0.4595303       0.4595303\n0.4595303       0.4595303       0.4595303\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4x2x2x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput_data = np.random.randn(2,2,6,8)\ninput_rois = np.array([0, 0, 0, 7, 5, 1, 6, 2, 7, 5, 1, 3, 1, 6, 4, 0, 3, 3, 3, 3],dtype='float64').reshape(4,5)\nprint  input is : ,[input_data, input_rois]\n\nm = RoiPooling(3,2,1.0)\nout = m.forward([input_data,input_rois])\nprint  output of m is : ,out  produces output:  input is : [array([[[[ 0.08500103,  0.33421796,  0.29084699,  1.60344635, -0.24289341,\n          -0.4793888 ,  0.09452426,  0.16842477],\n         [-1.18575497, -0.53337542,  0.11661001,  0.9647904 , -0.25187936,\n           0.36516823, -0.16647209, -0.08095158],\n         [ 1.1982232 , -0.33549174,  0.11721347, -0.29319686, -0.01290122,\n           0.12344296,  0.30074829, -2.34951463],\n         [-0.60470899, -0.84657051,  0.1269276 , -0.06152321, -1.68838416,\n          -0.69808296, -2.06112892, -1.44790449],\n         [ 1.03944288,  0.13871728,  0.91478479,  0.47517105,  1.24638374,\n           0.98666841,  0.49403488,  1.26101127],\n         [-1.03949343, -0.39291108,  1.39107512,  1.73779253,  0.91656129,\n           0.103381  ,  0.956243  ,  0.44743548]],\n\n        [[ 0.79028054,  0.64244228, -0.37997334, -0.09130215, -2.3903429 ,\n           0.71919208, -0.14079786,  0.98304272],\n         [ 1.14678457,  1.58825227,  0.17137367, -0.62121819, -0.36103113,\n          -0.04452576, -0.0886136 , -1.32884721],\n         [ 0.06728957, -0.29701304, -0.52754207, -1.5785875 ,  1.47354834,\n          -0.28545156,  0.49874194,  0.10277613],\n         [-0.10117571, -1.34902427, -1.40789327,  0.09853599,  0.60420022,\n           0.54869115, -0.49067696,  0.26696793],\n         [ 1.11780279, -0.77929016,  1.13772094,  0.14374057,  0.33199688,\n          -0.54057374, -0.45718861,  1.1577623 ],\n         [-1.4005645 ,  1.15870496,  0.39292003,  0.88379515,  0.06440974,\n           0.65013063,  0.03759244,  0.18730126]]],\n\n\n       [[[-2.28272906,  0.06056305,  0.73632597,  0.10063274, -1.27497525,\n          -0.95597581, -0.22745785,  0.40146498],\n         [-1.37783475,  1.66000653, -1.80071745, -0.11805539, -0.27160583,\n           0.30691418,  2.62243232, -1.95274516],\n         [ 1.61364148,  1.91470546, -1.51984424,  2.13598224, -0.23156685,\n          -0.74203698,  0.65316888,  0.08018846],\n         [-1.8912854 , -0.50106158,  0.94937966, -0.10930541,  0.82136627,\n          -1.33209063,  1.43371302, -1.36370916],\n         [-0.52737928, -0.0681305 , -0.63472587,  0.41979229, -0.57093624,\n          -0.15968764, -1.005951  , -2.06873572],\n         [-2.34089346,  1.02593977,  0.90183415,  0.09504819,  0.53185448,\n           1.11305345,  1.290016  , -1.76216646]],\n\n        [[-0.10885459, -0.57089742, -0.55340708, -1.94445884,  1.30130049,\n           0.6333372 , -1.03100083,  0.0111167 ],\n         [ 0.59678149, -0.67601521, -1.25288718, -0.10922251,  3.06808996,\n          -1.46701513, -0.42140765,  1.12485412],\n         [ 1.21301567, -1.43304957, -0.56047239,  0.20716087,  1.40737646,\n          -0.08386437, -0.21916043,  0.85692906],\n         [ 1.59992399, -1.37044315, -0.71884386,  2.61830979, -0.74305496,\n          -0.32021174,  1.43275058, -0.3891857 ],\n         [-0.41355145,  0.22589689,  0.33154415,  0.86146815, -1.66326091,\n           0.37581697, -3.2250516 , -0.48807863],\n         [-2.52968957,  0.95801598, -1.20118154,  0.01141421, -0.11871498,\n           0.04555184,  1.3950473 ,  0.37887998]]]]), array([[ 0.,  0.,  0.,  7.,  5.],\n       [ 1.,  6.,  2.,  7.,  5.],\n       [ 1.,  3.,  1.,  6.,  4.],\n       [ 0.,  3.,  3.,  3.,  3.]])]\ncreating: createRoiPooling\noutput of m is : [[[[ 1.19822323  1.60344636  0.36516821]\n   [ 1.39107513  1.73779249  1.26101124]]\n\n  [[ 1.58825231  1.47354829  0.98304272]\n   [ 1.158705    1.13772094  1.15776229]]]\n\n\n [[[ 1.43371308  1.43371308  0.08018846]\n   [ 1.29001606  1.29001606 -1.7621665 ]]\n\n  [[ 1.43275058  1.43275058  0.85692906]\n   [ 1.39504731  1.39504731  0.37887999]]]\n\n\n [[[ 2.13598228  0.30691418  2.62243223]\n   [ 0.82136625  0.82136625  1.43371308]]\n\n  [[ 3.06808996  3.06808996 -0.08386437]\n   [ 2.61830974  0.37581697  1.43275058]]]\n\n\n [[[-0.06152321 -0.06152321 -0.06152321]\n   [-0.06152321 -0.06152321 -0.06152321]]\n\n  [[ 0.09853599  0.09853599  0.09853599]\n   [ 0.09853599  0.09853599  0.09853599]]]]", 
            "title": "RoiPooling"
        }, 
        {
            "location": "/APIdocs/Layers/Pooling-Layers/#spatialmaxpooling", 
            "text": "Scala:  val mp = SpatialMaxPooling(2, 2, dW=2, dH=2, padW=0, padH=0)  Python:  mp = SpatialMaxPooling(2, 2, dw=2, dh=2, pad_w=0, pad_h=0, to_ceil=false)  Applies 2D max-pooling operation in kWxkH regions by step size dWxdH steps.\nThe number of output features is equal to the number of input planes.\nIf the input image is a 3D tensor nInputPlane x height x width,\nthe output image size will be nOutputPlane x oheight x owidth where\nowidth  = op((width  + 2 padW - kW) / dW + 1)\noheight = op((height + 2 padH - kH) / dH + 1)\nop is a rounding operator. By default, it is floor.\nIt can be changed by calling :ceil() or :floor() methods.  Scala example:  import com.intel.analytics.bigdl.nn.SpatialMaxPooling\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mp = SpatialMaxPooling(2, 2, 2, 2)\nval input = Tensor(1, 3, 3)\n\ninput(Array(1, 1, 1)) = 0.5336726f\ninput(Array(1, 1, 2)) = 0.7963769f\ninput(Array(1, 1, 3)) = 0.5674766f\ninput(Array(1, 2, 1)) = 0.1803996f\ninput(Array(1, 2, 2)) = 0.2460861f\ninput(Array(1, 2, 3)) = 0.2295625f\ninput(Array(1, 3, 1)) = 0.3073633f\ninput(Array(1, 3, 2)) = 0.5973460f\ninput(Array(1, 3, 3)) = 0.4298954f\n\nval gradOutput = Tensor(1, 1, 1)\ngradOutput(Array(1, 1, 1)) = 0.023921491578221f\n\nval output = mp.forward(input)\nval gradInput = mp.backward(input, gradOutput)\n\nprintln(output)\nprintln(gradInput)  The output is,  (1,.,.) =\n0.7963769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1]  The gradInput is,  (1,.,.) =\n0.0     0.023921492     0.0\n0.0     0.0     0.0\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nmp = SpatialMaxPooling(2, 2, 2, 2)\n\n\ninput = np.array([0.5336726, 0.7963769, 0.5674766, 0.1803996, 0.2460861, 0.2295625, 0.3073633, 0.5973460, 0.4298954]).astype( float32 )\ninput = input.reshape(1, 3, 3)\n\noutput = mp.forward(input)\nprint output\n\ngradOutput = np.array([0.023921491578221]).astype( float32 )\ngradOutput = gradOutput.reshape(1, 1, 1)\n\ngradInput = mp.backward(input, gradOutput)\nprint gradInput  The output is,  [array([[[ 0.79637688]]], dtype=float32)]  The gradInput is,  [array([[[ 0.        ,  0.02392149,  0.        ],\n        [ 0.        ,  0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        ]]], dtype=float32)]", 
            "title": "SpatialMaxPooling"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/", 
            "text": "SoftSign\n\n\nScala:\n\n\nval softSign = SoftSign()\n\n\n\n\nPython:\n\n\nsoftSign = SoftSign()\n\n\n\n\nSoftSign applies SoftSign function to the input tensor\n\n\nSoftSign function: \nf_i(x) = x_i / (1+|x_i|)\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval softSign = SoftSign()\nval input = Tensor(3, 3).rand()\n\n\n print(input)\n0.6733504   0.7566517   0.43793806  \n0.09683273  0.05829774  0.4567967   \n0.20021072  0.11158377  0.31668025\n\n\n print(softSign.forward(input))\n0.40239656  0.4307352   0.30455974  \n0.08828395  0.05508633  0.31356242  \n0.16681297  0.10038269  0.24051417  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nsoftSign=SoftSign()\n\n softSign.forward(np.array([[1, 2, 4],[-1, -2, -4]]))\n[array([[ 0.5       ,  0.66666669,  0.80000001],\n       [-0.5       , -0.66666669, -0.80000001]], dtype=float32)]\n\n\n\n\n\nReLU6\n\n\nScala:\n\n\nval module = ReLU6(inplace = false)\n\n\n\n\nPython:\n\n\nmodule = ReLU6(inplace=False)\n\n\n\n\nSame as ReLU except that the rectifying function f(x) saturates at x = 6 \nReLU6 is defined as:\n\nf(x) = min(max(0, x), 6)\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = ReLU6()\n\nprintln(module.forward(Tensor.range(-2, 8, 1)))\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0\n0.0\n0.0\n1.0\n2.0\n3.0\n4.0\n5.0\n6.0\n6.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 11]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = ReLU6()\n\nprint(module.forward(np.arange(-2, 9, 1)))\n\n\n\n\nOutput is\n\n\n[array([ 0.,  0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  6.,  6.], dtype=float32)]\n\n\n\n\nTanhShrink\n\n\nScala:\n\n\nval tanhShrink = TanhShrink()\n\n\n\n\nPython:\n\n\ntanhShrink = TanhShrink()\n\n\n\n\nTanhShrink applies element-wise Tanh and Shrink function to the input\n\n\nTanhShrink function : \nf(x) = scala.math.tanh(x) - 1\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval tanhShrink = TanhShrink()\nval input = Tensor(3, 3).rand()\n\n\n print(input)\n0.7056571   0.25239098  0.75746965  \n0.89736927  0.31193605  0.23842576  \n0.69492024  0.7512544   0.8386124   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n print(tanhShrink.forward(input))\n0.09771085  0.0052260756    0.11788553  \n0.18235475  0.009738684 0.004417494 \n0.09378672  0.1153577   0.153539    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\ntanhShrink = TanhShrink()\n\n\n  tanhShrink.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 0.23840582,  1.03597236,  2.00494528],\n       [ 3.00067067,  4.0000906 ,  5.0000124 ],\n       [ 6.00000191,  7.        ,  8.        ]], dtype=float32)]\n\n\n\n\n\nSoftMax\n\n\nScala:\n\n\nval layer = SoftMax()\n\n\n\n\nPython:\n\n\nlayer = SoftMax()\n\n\n\n\nApplies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the\nelements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1.\nSoftmax is defined as: f_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift)\nwhere shift = max_i(x_i).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SoftMax()\nval input = Tensor(3)\ninput.apply1(_ =\n 1.0f * 10)\nval gradOutput = Tensor(T(\n1.0f,\n0.0f,\n0.0f\n))\nval output = layer.forward(input)\nval gradient = layer.backward(input, gradOutput)\n-\n print(output)\n0.33333334\n0.33333334\n0.33333334\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n-\n print(gradient)\n0.22222221\n-0.11111112\n-0.11111112\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nlayer = SoftMax()\ninput = np.ones(3)*10\ngrad_output = np.array([1.0, 0.0, 0.0])\noutput = layer.forward(input)\ngradient = layer.backward(input, grad_output)\n-\n print output\n[ 0.33333334  0.33333334  0.33333334]\n-\n print gradient\n[ 0.22222221 -0.11111112 -0.11111112]\n\n\n\n\nPReLU\n\n\nScala:\n\n\nval module = PReLU(nOutputPlane = 0)\n\n\n\n\nPython:\n\n\nmodule = PReLU(nOutputPlane=0)\n\n\n\n\nApplies parametric ReLU, which parameter varies the slope of the negative part.\n\n\nPReLU: f(x) = max(0, x) + a * min(0, x)\n\n\n\n\nnOutputPlane's default value is 0, that means using PReLU in shared version and has\nonly one parameters. nOutputPlane is the input map number(Default is 0).\n\n\nNotice: Please don't use weight decay on this.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = PReLU(2)\nval input = Tensor(2, 2, 3).randn()\nval output = module.forward(input)\n\n\n input\n(1,.,.) =\n-0.17810068 -0.69607687 0.25582042\n-1.2140307  -1.5410945  1.0209005\n\n(2,.,.) =\n0.2826971   0.6370953   0.21471702\n-0.16203058 -0.5643519  0.816576\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x3]\n\n\n output\n(1,.,.) =\n-0.04452517 -0.17401922 0.25582042\n-0.3035077  -0.38527364 1.0209005\n\n(2,.,.) =\n0.2826971   0.6370953   0.21471702\n-0.040507644    -0.14108798 0.816576\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = PReLU(2)\ninput = np.random.randn(2, 2, 3)\noutput = module.forward(input)\n\n\n input\n[[[ 2.50596953 -0.06593339 -1.90273409]\n  [ 0.2464341   0.45941315 -0.41977094]]\n\n [[-0.8584367   2.19389229  0.93136755]\n  [-0.39209027  0.16507514 -0.35850447]]]\n\n\n output\n[array([[[ 2.50596952, -0.01648335, -0.47568351],\n         [ 0.24643411,  0.45941314, -0.10494273]],\n\n        [[-0.21460918,  2.19389224,  0.93136758],\n         [-0.09802257,  0.16507514, -0.08962612]]], dtype=float32)]\n\n\n\n\nReLU\n\n\nScala:\n\n\nval relu = ReLU(ip = false)\n\n\n\n\nPython:\n\n\nrelu = ReLU(ip)\n\n\n\n\nReLU applies the element-wise rectified linear unit (ReLU) function to the input\n\n\nip\n illustrate if the ReLU fuction is done on the origin input\n\n\nReLU function : `f(x) = max(0, x)`\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval relu = ReLU(false)\n\nval input = Tensor(3, 3).rand()\n\n print(input)\n0.13486342  0.8986828   0.2648762   \n0.56467545  0.7727274   0.65959305  \n0.01554346  0.9552375   0.2434533   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n print(relu.forward(input))\n0.13486342  0.8986828   0.2648762   \n0.56467545  0.7727274   0.65959305  \n0.01554346  0.9552375   0.2434533   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nrelu = ReLU(False)\n\n relu.forward(np.array([[-1, -2, -3], [0, 0, 0], [1, 2, 3]]))\n[array([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],\n       [ 1.,  2.,  3.]], dtype=float32)]\n\n\n\n\n\nSoftMin\n\n\nScala:\n\n\nval sm = SoftMin()\n\n\n\n\nPython:\n\n\nsm = SoftMin()\n\n\n\n\nApplies the SoftMin function to an n-dimensional input Tensor, rescaling them so that the\nelements of the n-dimensional output Tensor lie in the range (0,1) and sum to 1.\nSoftmin is defined as: f_i(x) = exp(-x_i - shift) / sum_j exp(-x_j - shift)\nwhere shift = max_i(-x_i).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.SoftMin\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval sm = SoftMin()\nval input = Tensor(3, 3).range(1, 3 * 3)\n\nval output = sm.forward(input)\n\nval gradOutput = Tensor(3, 3).range(1, 3 * 3).apply1(x =\n (x / 10.0).toFloat)\nval gradInput = sm.backward(input, gradOutput)\n\n\n\n\n\nThe output will be,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.66524094      0.24472848      0.09003057\n0.66524094      0.24472848      0.09003057\n0.66524094      0.24472848      0.09003057\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nThe gradInput will be,\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.02825874      -0.014077038    -0.014181711\n0.028258756     -0.01407703     -0.01418171\n0.028258756     -0.014077038    -0.014181707\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nsm = SoftMin()\n\ninput = np.arange(1, 10, 1).astype(\nfloat32\n)\ninput = input.reshape(3, 3)\n\noutput = sm.forward(input)\nprint output\n\ngradOutput = np.arange(1, 10, 1).astype(\nfloat32\n)\ngradOutput = np.vectorize(lambda t: t / 10)(gradOutput)\ngradOutput = gradOutput.reshape(3, 3)\n\ngradInput = sm.backward(input, gradOutput)\nprint gradInput\n\n\n\n\n\nELU\n\n\nScala:\n\n\nval m = ELU(alpha = 1.0, inplace = false)\n\n\n\n\nPython:\n\n\nm = ELU(alpha=1.0, inplace=False)\n\n\n\n\nApplies exponential linear unit (\nELU\n), which parameter a varies the convergence value of the exponential function below zero:\n\n\nELU\n is defined as:\n\n\nf(x) = max(0, x) + min(0, alpha * (exp(x) - 1))\n\n\n\n\nThe output dimension is always equal to input dimension.\n\n\nFor reference see \nFast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval xs = Tensor(4).randn()\nprintln(xs)\nprintln(ELU(4).forward(xs))\n\n\n\n\n1.0217569\n-0.17189966\n1.4164596\n0.69361746\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n1.0217569\n-0.63174534\n1.4164596\n0.69361746\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\n\nxs = np.linspace(-3, 3, num=200)\ngo = np.ones(200)\n\ndef f(a):\n    return ELU(a).forward(xs)[0]\ndef df(a):\n    m = ELU(a)\n    m.forward(xs)\n    return m.backward(xs, go)[0]\n\nplt.plot(xs, f(0.1), '-', label='fw ELU, alpha = 0.1')\nplt.plot(xs, f(1.0), '-', label='fw ELU, alpha = 0.1')\nplt.plot(xs, df(0.1), '-', label='dw ELU, alpha = 0.1')\nplt.plot(xs, df(1.0), '-', label='dw ELU, alpha = 0.1')\n\nplt.legend(loc='best', shadow=True, fancybox=True)\nplt.show()\n\n\n\n\n\n\n\nSoftShrink\n\n\nScala:\n\n\nval layer = SoftShrink(lambda = 0.5)\n\n\n\n\nPython:\n\n\nlayer = SoftShrink(the_lambda=0.5)\n\n\n\n\nApply the soft shrinkage function element-wise to the input Tensor\n\n\nSoftShrinkage operator:\n\n\n       \u23a7 x - lambda, if x \n  lambda\nf(x) = \u23a8 x + lambda, if x \n -lambda\n       \u23a9 0, otherwise\n\n\n\n\nParameters:\n\n\nlambda\n     - a factor, default is 0.5\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.SoftShrink\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = SoftShrink()\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-0.5    1.5 2.5\n-1.5    2.5 3.5\n-2.5    3.5 4.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n3.0 4.0 5.0\n2.0 3.0 4.0\n1.0 2.0 3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nScala example:\n\n\nactivation = SoftShrink()\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-0.5  1.5  2.5]\n [-1.5  2.5  3.5]\n [-2.5  3.5  4.5]]\n\nprint grad\n[[ 3.  4.  5.]\n [ 2.  3.  4.]\n [ 1.  2.  5.]]\n\n\n\n\nSigmoid\n\n\nScala:\n\n\nval module = Sigmoid()\n\n\n\n\nPython:\n\n\nmodule = Sigmoid()\n\n\n\n\nApplies the Sigmoid function element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension.\n\n\nSigmoid is defined as: f(x) = 1 / (1 + exp(-x))\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = new Sigmoid()\nval input = Tensor(2, 3)\nvar i = 0\ninput.apply1(_ =\n {i += 1; i})\n\n print(layer.forward(input))\n0.7310586   0.880797    0.95257413  \n0.98201376  0.9933072   0.9975274   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = Sigmoid()\ninput = np.array([[1, 2, 3], [4, 5, 6]])\n\nlayer.forward(input)\narray([[ 0.7310586 ,  0.88079703,  0.95257413],\n       [ 0.98201376,  0.99330717,  0.99752742]], dtype=float32)\n\n\n\n\nTanh\n\n\nScala:\n\n\nval activation = Tanh()\n\n\n\n\nPython:\n\n\nactivation = Tanh()\n\n\n\n\nApplies the Tanh function element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension.\nTanh is defined as\n\n\nf(x) = (exp(x)-exp(-x))/(exp(x)+exp(-x)).\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Tanh\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = Tanh()\nval input = Tensor(T(\n  T(1f, 2f, 3f),\n  T(2f, 3f, 4f),\n  T(3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n0.7615942   0.9640276   0.9950548\n0.9640276   0.9950548   0.9993293\n0.9950548   0.9993293   0.9999092\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n1.259923    0.28260326  0.049329996\n0.14130163  0.029597998 0.0053634644\n0.009865999 0.0026817322    5.4466724E-4\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nactivation = Tanh()\ninput = np.array([\n  [1.0, 2.0, 3.0],\n  [2.0, 3.0, 4.0],\n  [3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[ 0.76159418  0.96402758  0.99505478]\n [ 0.96402758  0.99505478  0.99932933]\n [ 0.99505478  0.99932933  0.99990922]]\n\nprint grad\n[[  1.25992298e+00   2.82603264e-01   4.93299961e-02]\n [  1.41301632e-01   2.95979977e-02   5.36346436e-03]\n [  9.86599922e-03   2.68173218e-03   9.07778740e-04]]\n\n\n\n\nSoftPlus\n\n\nScala:\n\n\nval model = SoftPlus(beta = 1.0)\n\n\n\n\nPython:\n\n\nmodel = SoftPlus(beta = 1.0)\n\n\n\n\nApply the SoftPlus function to an n-dimensional input tensor.\nSoftPlus function: \n\n\nf_i(x) = 1/beta * log(1 + exp(beta * x_i))\n\n\n\n\n\n\nparam beta Controls sharpness of transfer function\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = SoftPlus()\nval input = Tensor(2, 3, 4).rand()\nval output = model.forward(input)\n\nscala\n println(input)\n(1,.,.) =\n0.9812126   0.7044107   0.0657767   0.9173636   \n0.20853543  0.76482195  0.60774535  0.47837523  \n0.62954164  0.56440496  0.28893307  0.40742245  \n\n(2,.,.) =\n0.18701692  0.7700966   0.98496467  0.8958407   \n0.037015386 0.34626052  0.36459026  0.8460807   \n0.051016055 0.6742781   0.14469075  0.07565566  \n\nscala\n println(output)\n(1,.,.) =\n1.2995617   1.1061354   0.7265762   1.2535294   \n0.80284095  1.1469617   1.0424956   0.9606715   \n1.0566612   1.0146512   0.8480129   0.91746557  \n\n(2,.,.) =\n0.7910212   1.1505641   1.3022922   1.2381986   \n0.71182615  0.88119024  0.8919668   1.203121    \n0.7189805   1.0860726   0.7681072   0.7316903   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodel = SoftPlus()\ninput = np.random.randn(2, 3, 4)\noutput = model.forward(input)\n\n\n print(input)\n[[[ 0.82634972 -0.09853824  0.97570235  1.84464617]\n  [ 0.38466503  0.08963732  1.29438774  1.25204527]\n  [-0.01910449 -0.19560752 -0.81769143 -1.06365733]]\n\n [[-0.56284365 -0.28473239 -0.58206869 -1.97350909]\n  [-0.28303919 -0.59735361  0.73282102  0.0176838 ]\n  [ 0.63439133  1.84904987 -1.24073643  2.13275833]]]\n\n print(output)\n[[[ 1.18935537  0.6450913   1.2955569   1.99141073]\n  [ 0.90386271  0.73896986  1.53660071  1.50351918]\n  [ 0.68364054  0.60011864  0.36564925  0.29653603]]\n\n [[ 0.45081255  0.56088102  0.44387865  0.1301229 ]\n  [ 0.56160825  0.43842646  1.12523568  0.70202816]\n  [ 1.0598278   1.99521446  0.2539995   2.24475574]]]\n\n\n\n\nL1Penalty\n\n\nScala:\n\n\nval l1Penalty = L1Penalty(l1weight, sizeAverage = false, provideOutput = true)\n\n\n\n\nPython:\n\n\nl1Penalty = L1Penalty( l1weight, size_average=False, provide_output=True)\n\n\n\n\nL1Penalty adds an L1 penalty to an input \nFor forward, the output is the same as input and a L1 loss of the latent state will be calculated each time\nFor backward, gradInput = gradOutput + gradLoss\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval l1Penalty = L1Penalty(1, true, true)\nval input = Tensor(3, 3).rand()\n\n\n print(input)\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n\n print(l1Penalty.forward(input))\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]   \n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nl1Penalty = L1Penalty(1, True, True)\n\n\n l1Penalty.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.],\n       [ 7.,  8.,  9.]], dtype=float32)]\n\n\n\n\n\nHardShrink\n\n\nScala:\n\n\nval m = HardShrink(lambda = 0.5)\n\n\n\n\nPython:\n\n\nm = HardShrink(the_lambda=0.5)\n\n\n\n\nApplies the hard shrinkage function element-wise to the input Tensor. lambda is set to 0.5 by default.\n\n\nHardShrinkage operator is defined as:\n\n\n       \u23a7 x, if x \n  lambda\nf(x) = \u23a8 x, if x \n -lambda\n       \u23a9 0, otherwise\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nimport com.intel.analytics.bigdl.utils._\n\ndef randomn(): Float = RandomGenerator.RNG.uniform(-10, 10)\nval input = Tensor(3, 4)\ninput.apply1(x =\n randomn().toFloat)\n\nval layer = new HardShrink(8)\nprintln(\ninput:\n)\nprintln(input)\nprintln(\noutput:\n)\nprintln(layer.forward(input))\n\n\n\n\ninput:\n8.53746839798987    -2.25314284209162   2.838596091605723   0.7181660132482648  \n0.8278933027759194  8.986027473583817   -3.6885232804343104 -2.4018199276179075 \n-9.51015486381948   2.6402589259669185  5.438693333417177   -6.577442386187613  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\noutput:\n8.53746839798987    0.0 0.0 0.0 \n0.0 8.986027473583817   0.0 0.0 \n-9.51015486381948   0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\n\ninput = np.linspace(-5, 5, num=10)\nlayer = HardShrink(the_lambda=3.0)\nprint(\ninput:\n)\nprint(input)\nprint(\noutput: \n)\nprint(layer.forward(input))\n\n\n\n\ncreating: createHardShrink\ninput:\n[-5.         -3.88888889 -2.77777778 -1.66666667 -0.55555556  0.55555556\n  1.66666667  2.77777778  3.88888889  5.        ]\noutput: \n[-5.         -3.88888884  0.          0.          0.          0.          0.\n  0.          3.88888884  5.        ]\n\n\n\n\n\nRReLU\n\n\nScala:\n\n\nval layer = RReLU(lower, upper, inPlace)\n\n\n\n\nPython:\n\n\nlayer = RReLU(lower, upper, inPlace)\n\n\n\n\nApplies the randomized leaky rectified linear unit (RReLU) element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension. Informally the RReLU is also known as 'insanity' layer.\n\n\nRReLU is defined as: f(x) = max(0,x) + a * min(0, x) where a ~ U(l, u).\n\n\nIn training mode negative inputs are multiplied by a factor drawn from a uniform random\ndistribution U(l, u). In evaluation mode a RReLU behaves like a LeakyReLU with a constant mean\nfactor a = (l + u) / 2.\n\n\nBy default, l = 1/8 and u = 1/3. If l == u a RReLU effectively becomes a LeakyReLU.\n\n\nRegardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs.\n\n\nThe backward() operation assumes that forward() has been called before.\n\n\nFor reference see \nEmpirical Evaluation of Rectified Activations in Convolutional Network\n.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = RReLU()\nlayer.forward(Tensor(T(1.0f, 2.0f, -1.0f, -2.0f)))\nlayer.backward(Tensor(T(1.0f, 2.0f, -1.0f, -2.0f)),Tensor(T(0.1f, 0.2f, -0.1f, -0.2f)))\n\n\n\n\nThere's random factor. An output is like\n\n\n1.0\n2.0\n-0.24342789\n-0.43175703\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n0.1\n0.2\n-0.024342788\n-0.043175705\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import RReLU\nimport numpy as np\n\nlayer = RReLU()\nlayer.forward(np.array([1.0, 2.0, -1.0, -2.0]))\nlayer.backward(np.array([1.0, 2.0, -1.0, -2.0]),\n  np.array([0.1, 0.2, -0.1, -0.2]))\n\n\n\n\nThere's random factor. An output is like\n\n\narray([ 1.,  2., -0.15329693, -0.40423378], dtype=float32)\n\narray([ 0.1, 0.2, -0.01532969, -0.04042338], dtype=float32)\n\n\n\n\nHardTanh\n\n\nScala:\n\n\nval activation = HardTanh(\n    minValue = -1,\n    maxValue = 1,\n    inplace = false)\n\n\n\n\nPython:\n\n\nactivation = HardTanh(\n    min_value=-1.0,\n    max_value=1.0,\n    inplace=False)\n\n\n\n\nApplies non-linear function HardTanh to each element of input, HardTanh is defined:\n\n\n           \u23a7  maxValue, if x \n maxValue\n    f(x) = \u23a8  minValue, if x \n minValue\n           \u23a9  x, otherwise\n\n\n\n\nParameters:\n\n\nminValue\n - minValue in f(x), default is -1.\n\n\nmaxValue\n - maxValue in f(x), default is 1.\n\n\ninplace\n  - weather inplace update output from input. default is false.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.HardTanh\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = HardTanh()\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-1.0    1.0 1.0\n-1.0    1.0 1.0\n-1.0    1.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n0.0 0.0 0.0\n0.0 0.0 0.0\n0.0 0.0 0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nactivation = HardTanh()\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-1.  1.  1.]\n [-1.  1.  1.]\n [-1.  1.  1.]]\n\nprint grad\n[[ 0.  0.  0.]\n [ 0.  0.  0.]\n [ 0.  0.  0.]]\n\n\n\n\nLeakyReLU\n\n\nScala:\n\n\nlayer = LeakyReLU(negval=0.01,inplace=false)\n\n\n\n\nPython:\n\n\nlayer = LeakyReLU(negval=0.01,inplace=False,bigdl_type=\nfloat\n)\n\n\n\n\nIt is a transfer module that applies LeakyReLU, which parameter\nnegval sets the slope of the negative part:\n LeakyReLU is defined as:\n  f(x) = max(0, x) + negval * min(0, x)\n\n\n\n\n@param negval sets the slope of the negative partl, default is 0.01\n\n\n@param inplace if it is true, doing the operation in-place without\n                using extra state memory, default is false\n\n\n\n\nScala example:\n\n\nval layer = LeakyReLU(negval=0.01,inplace=false)\nval input = Tensor(3, 2).rand(-1, 1)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.6923256      -0.14086828\n0.029539397     0.477964\n0.5202874       0.10458552\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nlayer.forward(input)\nres7: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.006923256    -0.0014086828\n0.029539397     0.477964\n0.5202874       0.10458552\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n\n\n\n\nPython example:\n\n\nlayer = LeakyReLU(negval=0.01,inplace=False,bigdl_type=\nfloat\n)\ninput = np.random.rand(3, 2)\narray([[ 0.19502378,  0.40498206],\n       [ 0.97056004,  0.35643192],\n       [ 0.25075111,  0.18904582]])\n\nlayer.forward(input)\narray([[ 0.19502378,  0.40498206],\n       [ 0.97056001,  0.35643193],\n       [ 0.25075111,  0.18904583]], dtype=float32)\n\n\n\n\nLogSigmoid\n\n\nScala:\n\n\nval activation = LogSigmoid()\n\n\n\n\nPython:\n\n\nactivation = LogSigmoid()\n\n\n\n\nThis class is a activation layer corresponding to the non-linear function sigmoid function:\n\n\nf(x) = Log(1 / (1 + e ^ (-x)))\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.LogSigmoid\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = LogSigmoid()\nval input = Tensor(T(\n  T(1f, 2f, 3f),\n  T(2f, 3f, 4f),\n  T(3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-0.3132617  -0.12692802 -0.04858735\n-0.12692802 -0.04858735 -0.01814993\n-0.04858735 -0.01814993 -0.0067153485\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n0.8068244   0.47681168  0.23712938\n0.23840584  0.14227761  0.07194484\n0.047425874 0.03597242  0.020078553\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nactivation = LogSigmoid()\ninput = np.array([\n  [1.0, 2.0, 3.0],\n  [2.0, 3.0, 4.0],\n  [3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-0.31326169 -0.12692802 -0.04858735]\n [-0.12692802 -0.04858735 -0.01814993]\n [-0.04858735 -0.01814993 -0.00671535]]\n\nprint grad\n[[ 0.80682439  0.47681168  0.23712938]\n [ 0.23840584  0.14227761  0.07194484]\n [ 0.04742587  0.03597242  0.03346425]]\n\n\n\n\nLogSoftMax\n\n\nScala:\n\n\nval model = LogSoftMax()\n\n\n\n\nPython:\n\n\nmodel = LogSoftMax()\n\n\n\n\nThe LogSoftMax module applies a LogSoftMax transformation to the input data\nwhich is defined as:\n\n\nf_i(x) = log(1 / a exp(x_i))\nwhere a = sum_j[exp(x_j)]\n\n\n\n\nThe input given in \nforward(input)\n must be either\na vector (1D tensor) or matrix (2D tensor).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = LogSoftMax()\nval input = Tensor(2, 5).rand()\nval output = model.forward(input)\n\nscala\n print(input)\n0.4434036   0.64535594  0.7516194   0.11752353  0.5216674   \n0.57294756  0.744955    0.62644184  0.0052207764    0.900162    \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x5]\n\nscala\n print(output)\n-1.6841899  -1.4822376  -1.3759742  -2.01007    -1.605926   \n-1.6479948  -1.4759872  -1.5945004  -2.2157214  -1.3207803  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]\n\n\n\n\nPython example:\n\n\nmodel = LogSoftMax()\ninput = np.random.randn(4, 10)\noutput = model.forward(input)\n\n\n print(input)\n[[ 0.10805365  0.11392282  1.31891713 -0.62910637 -0.80532589  0.57976863\n  -0.44454368  0.26292944  0.8338328   0.32305099]\n [-0.16443839  0.12010763  0.62978233 -1.57224143 -2.16133614 -0.60932395\n  -0.22722708  0.23268273  0.00313597  0.34585582]\n [ 0.55913444 -0.7560615   0.12170887  1.40628806  0.97614582  1.20417145\n  -1.60619173 -0.54483025  1.12227399 -0.79976189]\n [-0.05540945  0.86954458  0.34586427  2.52004267  0.6998163  -1.61315173\n  -0.76276874  0.38332142  0.66351792 -0.30111399]]\n\n\n print(output)\n[[-2.55674744 -2.55087829 -1.34588397 -3.2939074  -3.47012711 -2.08503246\n  -3.10934472 -2.40187168 -1.83096838 -2.34175014]\n [-2.38306785 -2.09852171 -1.58884704 -3.79087067 -4.37996578 -2.82795334\n  -2.44585633 -1.98594666 -2.21549344 -1.87277353]\n [-2.31549931 -3.63069534 -2.75292492 -1.46834576 -1.89848804 -1.67046237\n  -4.48082542 -3.41946411 -1.75235975 -3.67439556]\n [-3.23354769 -2.30859375 -2.83227396 -0.6580956  -2.47832203 -4.79128981\n  -3.940907   -2.79481697 -2.5146203  -3.47925234]]\n\n\n\n\nThreshold\n\n\nScala:\n\n\nval module = Threshold(threshold, value, ip)\n\n\n\n\nPython:\n\n\nmodule = Threshold(threshold, value, ip)\n\n\n\n\nThresholds each element of the input Tensor.\nThreshold is defined as:\n\n\n     \u23a7 x        if x \n= threshold\n y = \u23a8 \n     \u23a9 value    if x \n  threshold\n\n\n\n\n\n\nthreshold: The value to threshold at\n\n\nvalue: The value to replace with\n\n\nip: can optionally do the operation in-place\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Threshold(1, 0.8)\nval input = Tensor(2, 2, 2).randn()\nval output = module.forward(input)\n\n\n input\n(1,.,.) =\n2.0502799   -0.37522468\n-1.2704345  -0.22533786\n\n(2,.,.) =\n1.1959263   1.6670992\n-0.24333914 1.4424673\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n output\n(1,.,.) =\n(1,.,.) =\n2.0502799   0.8\n0.8 0.8\n\n(2,.,.) =\n1.1959263   1.6670992\n0.8 1.4424673\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Threshold(1.0, 0.8)\ninput = np.random.randn(2, 2, 2)\noutput = module.forward(input)\n\n\n input\n[[[-0.43226865 -1.09160093]\n  [-0.20280088  0.68196767]]\n\n [[ 2.32017942  1.00003307]\n  [-0.46618767  0.57057167]]]\n\n\n output\n[array([[[ 0.80000001,  0.80000001],\n        [ 0.80000001,  0.80000001]],\n\n       [[ 2.32017946,  1.00003302],\n        [ 0.80000001,  0.80000001]]], dtype=float32)]", 
            "title": "Activations"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#softsign", 
            "text": "Scala:  val softSign = SoftSign()  Python:  softSign = SoftSign()  SoftSign applies SoftSign function to the input tensor  SoftSign function:  f_i(x) = x_i / (1+|x_i|)  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval softSign = SoftSign()\nval input = Tensor(3, 3).rand()  print(input)\n0.6733504   0.7566517   0.43793806  \n0.09683273  0.05829774  0.4567967   \n0.20021072  0.11158377  0.31668025  print(softSign.forward(input))\n0.40239656  0.4307352   0.30455974  \n0.08828395  0.05508633  0.31356242  \n0.16681297  0.10038269  0.24051417  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nsoftSign=SoftSign()  softSign.forward(np.array([[1, 2, 4],[-1, -2, -4]]))\n[array([[ 0.5       ,  0.66666669,  0.80000001],\n       [-0.5       , -0.66666669, -0.80000001]], dtype=float32)]", 
            "title": "SoftSign"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#relu6", 
            "text": "Scala:  val module = ReLU6(inplace = false)  Python:  module = ReLU6(inplace=False)  Same as ReLU except that the rectifying function f(x) saturates at x = 6 \nReLU6 is defined as: f(x) = min(max(0, x), 6)  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = ReLU6()\n\nprintln(module.forward(Tensor.range(-2, 8, 1)))  Output is  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0\n0.0\n0.0\n1.0\n2.0\n3.0\n4.0\n5.0\n6.0\n6.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 11]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = ReLU6()\n\nprint(module.forward(np.arange(-2, 9, 1)))  Output is  [array([ 0.,  0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  6.,  6.], dtype=float32)]", 
            "title": "ReLU6"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#tanhshrink", 
            "text": "Scala:  val tanhShrink = TanhShrink()  Python:  tanhShrink = TanhShrink()  TanhShrink applies element-wise Tanh and Shrink function to the input  TanhShrink function :  f(x) = scala.math.tanh(x) - 1  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval tanhShrink = TanhShrink()\nval input = Tensor(3, 3).rand()  print(input)\n0.7056571   0.25239098  0.75746965  \n0.89736927  0.31193605  0.23842576  \n0.69492024  0.7512544   0.8386124   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(tanhShrink.forward(input))\n0.09771085  0.0052260756    0.11788553  \n0.18235475  0.009738684 0.004417494 \n0.09378672  0.1153577   0.153539    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\ntanhShrink = TanhShrink()   tanhShrink.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 0.23840582,  1.03597236,  2.00494528],\n       [ 3.00067067,  4.0000906 ,  5.0000124 ],\n       [ 6.00000191,  7.        ,  8.        ]], dtype=float32)]", 
            "title": "TanhShrink"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#softmax", 
            "text": "Scala:  val layer = SoftMax()  Python:  layer = SoftMax()  Applies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the\nelements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1.\nSoftmax is defined as: f_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift)\nwhere shift = max_i(x_i).  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SoftMax()\nval input = Tensor(3)\ninput.apply1(_ =  1.0f * 10)\nval gradOutput = Tensor(T(\n1.0f,\n0.0f,\n0.0f\n))\nval output = layer.forward(input)\nval gradient = layer.backward(input, gradOutput)\n-  print(output)\n0.33333334\n0.33333334\n0.33333334\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n-  print(gradient)\n0.22222221\n-0.11111112\n-0.11111112\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nlayer = SoftMax()\ninput = np.ones(3)*10\ngrad_output = np.array([1.0, 0.0, 0.0])\noutput = layer.forward(input)\ngradient = layer.backward(input, grad_output)\n-  print output\n[ 0.33333334  0.33333334  0.33333334]\n-  print gradient\n[ 0.22222221 -0.11111112 -0.11111112]", 
            "title": "SoftMax"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#prelu", 
            "text": "Scala:  val module = PReLU(nOutputPlane = 0)  Python:  module = PReLU(nOutputPlane=0)  Applies parametric ReLU, which parameter varies the slope of the negative part.  PReLU: f(x) = max(0, x) + a * min(0, x)  nOutputPlane's default value is 0, that means using PReLU in shared version and has\nonly one parameters. nOutputPlane is the input map number(Default is 0).  Notice: Please don't use weight decay on this.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = PReLU(2)\nval input = Tensor(2, 2, 3).randn()\nval output = module.forward(input)  input\n(1,.,.) =\n-0.17810068 -0.69607687 0.25582042\n-1.2140307  -1.5410945  1.0209005\n\n(2,.,.) =\n0.2826971   0.6370953   0.21471702\n-0.16203058 -0.5643519  0.816576\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x3]  output\n(1,.,.) =\n-0.04452517 -0.17401922 0.25582042\n-0.3035077  -0.38527364 1.0209005\n\n(2,.,.) =\n0.2826971   0.6370953   0.21471702\n-0.040507644    -0.14108798 0.816576\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = PReLU(2)\ninput = np.random.randn(2, 2, 3)\noutput = module.forward(input)  input\n[[[ 2.50596953 -0.06593339 -1.90273409]\n  [ 0.2464341   0.45941315 -0.41977094]]\n\n [[-0.8584367   2.19389229  0.93136755]\n  [-0.39209027  0.16507514 -0.35850447]]]  output\n[array([[[ 2.50596952, -0.01648335, -0.47568351],\n         [ 0.24643411,  0.45941314, -0.10494273]],\n\n        [[-0.21460918,  2.19389224,  0.93136758],\n         [-0.09802257,  0.16507514, -0.08962612]]], dtype=float32)]", 
            "title": "PReLU"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#relu", 
            "text": "Scala:  val relu = ReLU(ip = false)  Python:  relu = ReLU(ip)  ReLU applies the element-wise rectified linear unit (ReLU) function to the input  ip  illustrate if the ReLU fuction is done on the origin input  ReLU function : `f(x) = max(0, x)`  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval relu = ReLU(false)\n\nval input = Tensor(3, 3).rand()  print(input)\n0.13486342  0.8986828   0.2648762   \n0.56467545  0.7727274   0.65959305  \n0.01554346  0.9552375   0.2434533   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(relu.forward(input))\n0.13486342  0.8986828   0.2648762   \n0.56467545  0.7727274   0.65959305  \n0.01554346  0.9552375   0.2434533   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nrelu = ReLU(False)  relu.forward(np.array([[-1, -2, -3], [0, 0, 0], [1, 2, 3]]))\n[array([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],\n       [ 1.,  2.,  3.]], dtype=float32)]", 
            "title": "ReLU"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#softmin", 
            "text": "Scala:  val sm = SoftMin()  Python:  sm = SoftMin()  Applies the SoftMin function to an n-dimensional input Tensor, rescaling them so that the\nelements of the n-dimensional output Tensor lie in the range (0,1) and sum to 1.\nSoftmin is defined as: f_i(x) = exp(-x_i - shift) / sum_j exp(-x_j - shift)\nwhere shift = max_i(-x_i).  Scala example:  import com.intel.analytics.bigdl.nn.SoftMin\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval sm = SoftMin()\nval input = Tensor(3, 3).range(1, 3 * 3)\n\nval output = sm.forward(input)\n\nval gradOutput = Tensor(3, 3).range(1, 3 * 3).apply1(x =  (x / 10.0).toFloat)\nval gradInput = sm.backward(input, gradOutput)  The output will be,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.66524094      0.24472848      0.09003057\n0.66524094      0.24472848      0.09003057\n0.66524094      0.24472848      0.09003057\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  The gradInput will be,  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.02825874      -0.014077038    -0.014181711\n0.028258756     -0.01407703     -0.01418171\n0.028258756     -0.014077038    -0.014181707\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nsm = SoftMin()\n\ninput = np.arange(1, 10, 1).astype( float32 )\ninput = input.reshape(3, 3)\n\noutput = sm.forward(input)\nprint output\n\ngradOutput = np.arange(1, 10, 1).astype( float32 )\ngradOutput = np.vectorize(lambda t: t / 10)(gradOutput)\ngradOutput = gradOutput.reshape(3, 3)\n\ngradInput = sm.backward(input, gradOutput)\nprint gradInput", 
            "title": "SoftMin"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#elu", 
            "text": "Scala:  val m = ELU(alpha = 1.0, inplace = false)  Python:  m = ELU(alpha=1.0, inplace=False)  Applies exponential linear unit ( ELU ), which parameter a varies the convergence value of the exponential function below zero:  ELU  is defined as:  f(x) = max(0, x) + min(0, alpha * (exp(x) - 1))  The output dimension is always equal to input dimension.  For reference see  Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) .  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval xs = Tensor(4).randn()\nprintln(xs)\nprintln(ELU(4).forward(xs))  1.0217569\n-0.17189966\n1.4164596\n0.69361746\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n1.0217569\n-0.63174534\n1.4164596\n0.69361746\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\n\nxs = np.linspace(-3, 3, num=200)\ngo = np.ones(200)\n\ndef f(a):\n    return ELU(a).forward(xs)[0]\ndef df(a):\n    m = ELU(a)\n    m.forward(xs)\n    return m.backward(xs, go)[0]\n\nplt.plot(xs, f(0.1), '-', label='fw ELU, alpha = 0.1')\nplt.plot(xs, f(1.0), '-', label='fw ELU, alpha = 0.1')\nplt.plot(xs, df(0.1), '-', label='dw ELU, alpha = 0.1')\nplt.plot(xs, df(1.0), '-', label='dw ELU, alpha = 0.1')\n\nplt.legend(loc='best', shadow=True, fancybox=True)\nplt.show()", 
            "title": "ELU"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#softshrink", 
            "text": "Scala:  val layer = SoftShrink(lambda = 0.5)  Python:  layer = SoftShrink(the_lambda=0.5)  Apply the soft shrinkage function element-wise to the input Tensor  SoftShrinkage operator:         \u23a7 x - lambda, if x    lambda\nf(x) = \u23a8 x + lambda, if x   -lambda\n       \u23a9 0, otherwise  Parameters:  lambda      - a factor, default is 0.5  Scala example:  import com.intel.analytics.bigdl.nn.SoftShrink\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = SoftShrink()\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-0.5    1.5 2.5\n-1.5    2.5 3.5\n-2.5    3.5 4.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n3.0 4.0 5.0\n2.0 3.0 4.0\n1.0 2.0 3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Scala example:  activation = SoftShrink()\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-0.5  1.5  2.5]\n [-1.5  2.5  3.5]\n [-2.5  3.5  4.5]]\n\nprint grad\n[[ 3.  4.  5.]\n [ 2.  3.  4.]\n [ 1.  2.  5.]]", 
            "title": "SoftShrink"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#sigmoid", 
            "text": "Scala:  val module = Sigmoid()  Python:  module = Sigmoid()  Applies the Sigmoid function element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension.  Sigmoid is defined as: f(x) = 1 / (1 + exp(-x))  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = new Sigmoid()\nval input = Tensor(2, 3)\nvar i = 0\ninput.apply1(_ =  {i += 1; i})  print(layer.forward(input))\n0.7310586   0.880797    0.95257413  \n0.98201376  0.9933072   0.9975274   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  from bigdl.nn.layer import *\n\nlayer = Sigmoid()\ninput = np.array([[1, 2, 3], [4, 5, 6]]) layer.forward(input)\narray([[ 0.7310586 ,  0.88079703,  0.95257413],\n       [ 0.98201376,  0.99330717,  0.99752742]], dtype=float32)", 
            "title": "Sigmoid"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#tanh", 
            "text": "Scala:  val activation = Tanh()  Python:  activation = Tanh()  Applies the Tanh function element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension.\nTanh is defined as  f(x) = (exp(x)-exp(-x))/(exp(x)+exp(-x)).  Scala example:  import com.intel.analytics.bigdl.nn.Tanh\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = Tanh()\nval input = Tensor(T(\n  T(1f, 2f, 3f),\n  T(2f, 3f, 4f),\n  T(3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n0.7615942   0.9640276   0.9950548\n0.9640276   0.9950548   0.9993293\n0.9950548   0.9993293   0.9999092\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n1.259923    0.28260326  0.049329996\n0.14130163  0.029597998 0.0053634644\n0.009865999 0.0026817322    5.4466724E-4\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  activation = Tanh()\ninput = np.array([\n  [1.0, 2.0, 3.0],\n  [2.0, 3.0, 4.0],\n  [3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[ 0.76159418  0.96402758  0.99505478]\n [ 0.96402758  0.99505478  0.99932933]\n [ 0.99505478  0.99932933  0.99990922]]\n\nprint grad\n[[  1.25992298e+00   2.82603264e-01   4.93299961e-02]\n [  1.41301632e-01   2.95979977e-02   5.36346436e-03]\n [  9.86599922e-03   2.68173218e-03   9.07778740e-04]]", 
            "title": "Tanh"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#softplus", 
            "text": "Scala:  val model = SoftPlus(beta = 1.0)  Python:  model = SoftPlus(beta = 1.0)  Apply the SoftPlus function to an n-dimensional input tensor.\nSoftPlus function:   f_i(x) = 1/beta * log(1 + exp(beta * x_i))   param beta Controls sharpness of transfer function   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = SoftPlus()\nval input = Tensor(2, 3, 4).rand()\nval output = model.forward(input)\n\nscala  println(input)\n(1,.,.) =\n0.9812126   0.7044107   0.0657767   0.9173636   \n0.20853543  0.76482195  0.60774535  0.47837523  \n0.62954164  0.56440496  0.28893307  0.40742245  \n\n(2,.,.) =\n0.18701692  0.7700966   0.98496467  0.8958407   \n0.037015386 0.34626052  0.36459026  0.8460807   \n0.051016055 0.6742781   0.14469075  0.07565566  \n\nscala  println(output)\n(1,.,.) =\n1.2995617   1.1061354   0.7265762   1.2535294   \n0.80284095  1.1469617   1.0424956   0.9606715   \n1.0566612   1.0146512   0.8480129   0.91746557  \n\n(2,.,.) =\n0.7910212   1.1505641   1.3022922   1.2381986   \n0.71182615  0.88119024  0.8919668   1.203121    \n0.7189805   1.0860726   0.7681072   0.7316903   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodel = SoftPlus()\ninput = np.random.randn(2, 3, 4)\noutput = model.forward(input)  print(input)\n[[[ 0.82634972 -0.09853824  0.97570235  1.84464617]\n  [ 0.38466503  0.08963732  1.29438774  1.25204527]\n  [-0.01910449 -0.19560752 -0.81769143 -1.06365733]]\n\n [[-0.56284365 -0.28473239 -0.58206869 -1.97350909]\n  [-0.28303919 -0.59735361  0.73282102  0.0176838 ]\n  [ 0.63439133  1.84904987 -1.24073643  2.13275833]]]  print(output)\n[[[ 1.18935537  0.6450913   1.2955569   1.99141073]\n  [ 0.90386271  0.73896986  1.53660071  1.50351918]\n  [ 0.68364054  0.60011864  0.36564925  0.29653603]]\n\n [[ 0.45081255  0.56088102  0.44387865  0.1301229 ]\n  [ 0.56160825  0.43842646  1.12523568  0.70202816]\n  [ 1.0598278   1.99521446  0.2539995   2.24475574]]]", 
            "title": "SoftPlus"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#l1penalty", 
            "text": "Scala:  val l1Penalty = L1Penalty(l1weight, sizeAverage = false, provideOutput = true)  Python:  l1Penalty = L1Penalty( l1weight, size_average=False, provide_output=True)  L1Penalty adds an L1 penalty to an input \nFor forward, the output is the same as input and a L1 loss of the latent state will be calculated each time\nFor backward, gradInput = gradOutput + gradLoss  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval l1Penalty = L1Penalty(1, true, true)\nval input = Tensor(3, 3).rand()  print(input)\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(l1Penalty.forward(input))\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]     Python example:  from bigdl.nn.layer import *\nl1Penalty = L1Penalty(1, True, True)  l1Penalty.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.],\n       [ 7.,  8.,  9.]], dtype=float32)]", 
            "title": "L1Penalty"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#hardshrink", 
            "text": "Scala:  val m = HardShrink(lambda = 0.5)  Python:  m = HardShrink(the_lambda=0.5)  Applies the hard shrinkage function element-wise to the input Tensor. lambda is set to 0.5 by default.  HardShrinkage operator is defined as:         \u23a7 x, if x    lambda\nf(x) = \u23a8 x, if x   -lambda\n       \u23a9 0, otherwise  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nimport com.intel.analytics.bigdl.utils._\n\ndef randomn(): Float = RandomGenerator.RNG.uniform(-10, 10)\nval input = Tensor(3, 4)\ninput.apply1(x =  randomn().toFloat)\n\nval layer = new HardShrink(8)\nprintln( input: )\nprintln(input)\nprintln( output: )\nprintln(layer.forward(input))  input:\n8.53746839798987    -2.25314284209162   2.838596091605723   0.7181660132482648  \n0.8278933027759194  8.986027473583817   -3.6885232804343104 -2.4018199276179075 \n-9.51015486381948   2.6402589259669185  5.438693333417177   -6.577442386187613  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\noutput:\n8.53746839798987    0.0 0.0 0.0 \n0.0 8.986027473583817   0.0 0.0 \n-9.51015486381948   0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\n\ninput = np.linspace(-5, 5, num=10)\nlayer = HardShrink(the_lambda=3.0)\nprint( input: )\nprint(input)\nprint( output:  )\nprint(layer.forward(input))  creating: createHardShrink\ninput:\n[-5.         -3.88888889 -2.77777778 -1.66666667 -0.55555556  0.55555556\n  1.66666667  2.77777778  3.88888889  5.        ]\noutput: \n[-5.         -3.88888884  0.          0.          0.          0.          0.\n  0.          3.88888884  5.        ]", 
            "title": "HardShrink"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#rrelu", 
            "text": "Scala:  val layer = RReLU(lower, upper, inPlace)  Python:  layer = RReLU(lower, upper, inPlace)  Applies the randomized leaky rectified linear unit (RReLU) element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension. Informally the RReLU is also known as 'insanity' layer.  RReLU is defined as: f(x) = max(0,x) + a * min(0, x) where a ~ U(l, u).  In training mode negative inputs are multiplied by a factor drawn from a uniform random\ndistribution U(l, u). In evaluation mode a RReLU behaves like a LeakyReLU with a constant mean\nfactor a = (l + u) / 2.  By default, l = 1/8 and u = 1/3. If l == u a RReLU effectively becomes a LeakyReLU.  Regardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs.  The backward() operation assumes that forward() has been called before.  For reference see  Empirical Evaluation of Rectified Activations in Convolutional Network .  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = RReLU()\nlayer.forward(Tensor(T(1.0f, 2.0f, -1.0f, -2.0f)))\nlayer.backward(Tensor(T(1.0f, 2.0f, -1.0f, -2.0f)),Tensor(T(0.1f, 0.2f, -0.1f, -0.2f)))  There's random factor. An output is like  1.0\n2.0\n-0.24342789\n-0.43175703\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n0.1\n0.2\n-0.024342788\n-0.043175705\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  Python example:  from bigdl.nn.layer import RReLU\nimport numpy as np\n\nlayer = RReLU()\nlayer.forward(np.array([1.0, 2.0, -1.0, -2.0]))\nlayer.backward(np.array([1.0, 2.0, -1.0, -2.0]),\n  np.array([0.1, 0.2, -0.1, -0.2]))  There's random factor. An output is like  array([ 1.,  2., -0.15329693, -0.40423378], dtype=float32)\n\narray([ 0.1, 0.2, -0.01532969, -0.04042338], dtype=float32)", 
            "title": "RReLU"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#hardtanh", 
            "text": "Scala:  val activation = HardTanh(\n    minValue = -1,\n    maxValue = 1,\n    inplace = false)  Python:  activation = HardTanh(\n    min_value=-1.0,\n    max_value=1.0,\n    inplace=False)  Applies non-linear function HardTanh to each element of input, HardTanh is defined:             \u23a7  maxValue, if x   maxValue\n    f(x) = \u23a8  minValue, if x   minValue\n           \u23a9  x, otherwise  Parameters:  minValue  - minValue in f(x), default is -1.  maxValue  - maxValue in f(x), default is 1.  inplace   - weather inplace update output from input. default is false.  Scala example:  import com.intel.analytics.bigdl.nn.HardTanh\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = HardTanh()\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-1.0    1.0 1.0\n-1.0    1.0 1.0\n-1.0    1.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n0.0 0.0 0.0\n0.0 0.0 0.0\n0.0 0.0 0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  activation = HardTanh()\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-1.  1.  1.]\n [-1.  1.  1.]\n [-1.  1.  1.]]\n\nprint grad\n[[ 0.  0.  0.]\n [ 0.  0.  0.]\n [ 0.  0.  0.]]", 
            "title": "HardTanh"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#leakyrelu", 
            "text": "Scala:  layer = LeakyReLU(negval=0.01,inplace=false)  Python:  layer = LeakyReLU(negval=0.01,inplace=False,bigdl_type= float )  It is a transfer module that applies LeakyReLU, which parameter\nnegval sets the slope of the negative part:\n LeakyReLU is defined as:\n  f(x) = max(0, x) + negval * min(0, x)   @param negval sets the slope of the negative partl, default is 0.01  @param inplace if it is true, doing the operation in-place without\n                using extra state memory, default is false   Scala example:  val layer = LeakyReLU(negval=0.01,inplace=false)\nval input = Tensor(3, 2).rand(-1, 1)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.6923256      -0.14086828\n0.029539397     0.477964\n0.5202874       0.10458552\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nlayer.forward(input)\nres7: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.006923256    -0.0014086828\n0.029539397     0.477964\n0.5202874       0.10458552\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]  Python example:  layer = LeakyReLU(negval=0.01,inplace=False,bigdl_type= float )\ninput = np.random.rand(3, 2)\narray([[ 0.19502378,  0.40498206],\n       [ 0.97056004,  0.35643192],\n       [ 0.25075111,  0.18904582]])\n\nlayer.forward(input)\narray([[ 0.19502378,  0.40498206],\n       [ 0.97056001,  0.35643193],\n       [ 0.25075111,  0.18904583]], dtype=float32)", 
            "title": "LeakyReLU"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#logsigmoid", 
            "text": "Scala:  val activation = LogSigmoid()  Python:  activation = LogSigmoid()  This class is a activation layer corresponding to the non-linear function sigmoid function:  f(x) = Log(1 / (1 + e ^ (-x)))  Scala example:  import com.intel.analytics.bigdl.nn.LogSigmoid\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = LogSigmoid()\nval input = Tensor(T(\n  T(1f, 2f, 3f),\n  T(2f, 3f, 4f),\n  T(3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-0.3132617  -0.12692802 -0.04858735\n-0.12692802 -0.04858735 -0.01814993\n-0.04858735 -0.01814993 -0.0067153485\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n0.8068244   0.47681168  0.23712938\n0.23840584  0.14227761  0.07194484\n0.047425874 0.03597242  0.020078553\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  activation = LogSigmoid()\ninput = np.array([\n  [1.0, 2.0, 3.0],\n  [2.0, 3.0, 4.0],\n  [3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-0.31326169 -0.12692802 -0.04858735]\n [-0.12692802 -0.04858735 -0.01814993]\n [-0.04858735 -0.01814993 -0.00671535]]\n\nprint grad\n[[ 0.80682439  0.47681168  0.23712938]\n [ 0.23840584  0.14227761  0.07194484]\n [ 0.04742587  0.03597242  0.03346425]]", 
            "title": "LogSigmoid"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#logsoftmax", 
            "text": "Scala:  val model = LogSoftMax()  Python:  model = LogSoftMax()  The LogSoftMax module applies a LogSoftMax transformation to the input data\nwhich is defined as:  f_i(x) = log(1 / a exp(x_i))\nwhere a = sum_j[exp(x_j)]  The input given in  forward(input)  must be either\na vector (1D tensor) or matrix (2D tensor).  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = LogSoftMax()\nval input = Tensor(2, 5).rand()\nval output = model.forward(input)\n\nscala  print(input)\n0.4434036   0.64535594  0.7516194   0.11752353  0.5216674   \n0.57294756  0.744955    0.62644184  0.0052207764    0.900162    \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x5]\n\nscala  print(output)\n-1.6841899  -1.4822376  -1.3759742  -2.01007    -1.605926   \n-1.6479948  -1.4759872  -1.5945004  -2.2157214  -1.3207803  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]  Python example:  model = LogSoftMax()\ninput = np.random.randn(4, 10)\noutput = model.forward(input)  print(input)\n[[ 0.10805365  0.11392282  1.31891713 -0.62910637 -0.80532589  0.57976863\n  -0.44454368  0.26292944  0.8338328   0.32305099]\n [-0.16443839  0.12010763  0.62978233 -1.57224143 -2.16133614 -0.60932395\n  -0.22722708  0.23268273  0.00313597  0.34585582]\n [ 0.55913444 -0.7560615   0.12170887  1.40628806  0.97614582  1.20417145\n  -1.60619173 -0.54483025  1.12227399 -0.79976189]\n [-0.05540945  0.86954458  0.34586427  2.52004267  0.6998163  -1.61315173\n  -0.76276874  0.38332142  0.66351792 -0.30111399]]  print(output)\n[[-2.55674744 -2.55087829 -1.34588397 -3.2939074  -3.47012711 -2.08503246\n  -3.10934472 -2.40187168 -1.83096838 -2.34175014]\n [-2.38306785 -2.09852171 -1.58884704 -3.79087067 -4.37996578 -2.82795334\n  -2.44585633 -1.98594666 -2.21549344 -1.87277353]\n [-2.31549931 -3.63069534 -2.75292492 -1.46834576 -1.89848804 -1.67046237\n  -4.48082542 -3.41946411 -1.75235975 -3.67439556]\n [-3.23354769 -2.30859375 -2.83227396 -0.6580956  -2.47832203 -4.79128981\n  -3.940907   -2.79481697 -2.5146203  -3.47925234]]", 
            "title": "LogSoftMax"
        }, 
        {
            "location": "/APIdocs/Layers/Activations/#threshold", 
            "text": "Scala:  val module = Threshold(threshold, value, ip)  Python:  module = Threshold(threshold, value, ip)  Thresholds each element of the input Tensor.\nThreshold is defined as:       \u23a7 x        if x  = threshold\n y = \u23a8 \n     \u23a9 value    if x    threshold   threshold: The value to threshold at  value: The value to replace with  ip: can optionally do the operation in-place   Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Threshold(1, 0.8)\nval input = Tensor(2, 2, 2).randn()\nval output = module.forward(input)  input\n(1,.,.) =\n2.0502799   -0.37522468\n-1.2704345  -0.22533786\n\n(2,.,.) =\n1.1959263   1.6670992\n-0.24333914 1.4424673\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  output\n(1,.,.) =\n(1,.,.) =\n2.0502799   0.8\n0.8 0.8\n\n(2,.,.) =\n1.1959263   1.6670992\n0.8 1.4424673\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Threshold(1.0, 0.8)\ninput = np.random.randn(2, 2, 2)\noutput = module.forward(input)  input\n[[[-0.43226865 -1.09160093]\n  [-0.20280088  0.68196767]]\n\n [[ 2.32017942  1.00003307]\n  [-0.46618767  0.57057167]]]  output\n[array([[[ 0.80000001,  0.80000001],\n        [ 0.80000001,  0.80000001]],\n\n       [[ 2.32017946,  1.00003302],\n        [ 0.80000001,  0.80000001]]], dtype=float32)]", 
            "title": "Threshold"
        }, 
        {
            "location": "/APIdocs/Layers/Embedding-Layers/", 
            "text": "LookupTable\n\n\nScala:\n\n\nval layer = LookupTable(nIndex: Int, nOutput: Int, paddingValue: Double = 0,\n                                 maxNorm: Double = Double.MaxValue,\n                                 normType: Double = 2.0,\n                                 shouldScaleGradByFreq: Boolean = false,\n                                 wRegularizer: Regularizer[T] = null)\n\n\n\n\nPython:\n\n\nlayer = LookupTable(nIndex, nOutput, paddingValue, maxNorm, normType, shouldScaleGradByFreq)\n\n\n\n\nThis layer is a particular case of a convolution, where the width of the convolution would be 1.\nInput should be a 1D or 2D tensor filled with indices. Indices are corresponding to the position\nin weight. For each index element of input, it outputs the selected index part of weight.\nThis layer is often used in word embedding. In collaborative filtering, it can be used together with Select to create embeddings for users or items. \n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = LookupTable(9, 4, 2, 0.1, 2.0, true)\nval input = Tensor(Storage(Array(5.0f, 2.0f, 6.0f, 9.0f, 4.0f)), 1, Array(5))\n\nval output = layer.forward(input)\nval gradInput = layer.backward(input, output)\n\n\n println(layer.weight)\nres6: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.2949163      -0.8240777      -0.9440595      -0.8326071\n-0.025108865    -0.025346711    0.09046136      -0.023320194\n-1.7525806      0.7305201       0.3349018       0.03952092\n-0.0048129847   0.023922665     0.005595926     -0.09681542\n-0.01619357     -0.030372608    0.07217587      -0.060049288\n0.014426847     -0.09052222     0.019132217     -0.035093457\n-0.7002858      1.1149521       0.9869375       1.2580993\n0.36649692      -0.6583153      0.90005803      0.12671651\n0.048913725     0.033388995     -0.07938445     0.01381052\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9x4]\n\n\n println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n5.0\n2.0\n6.0\n9.0\n4.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n println(output)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.01619357     -0.030372608    0.07217587      -0.060049288\n-0.025108865    -0.025346711    0.09046136      -0.023320194\n0.014426847     -0.09052222     0.019132217     -0.035093457\n0.048913725     0.033388995     -0.07938445     0.01381052\n-0.0048129847   0.023922665     0.005595926     -0.09681542\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x4]\n\n\n println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n\n\n\nPython example:\n\n\nlayer = LookupTable(9, 4, 2.0, 0.1, 2.0, True)\ninput = np.array([5.0, 2.0, 6.0, 9.0, 4.0]).astype(\nfloat32\n)\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, output)\n\n\n output\n[array([[-0.00704637,  0.07495038,  0.06465427,  0.01235369],\n        [ 0.00350313,  0.02751033, -0.02163727,  0.0936095 ],\n        [ 0.02330465, -0.05696457,  0.0081728 ,  0.07839092],\n        [ 0.06580321, -0.0743262 , -0.00414508, -0.01133001],\n        [-0.00382435, -0.04677011,  0.02839171, -0.08361723]], dtype=float32)]\n\n\n gradInput\n[array([ 0.,  0.,  0.,  0.,  0.], dtype=float32)]", 
            "title": "Embedding Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Embedding-Layers/#lookuptable", 
            "text": "Scala:  val layer = LookupTable(nIndex: Int, nOutput: Int, paddingValue: Double = 0,\n                                 maxNorm: Double = Double.MaxValue,\n                                 normType: Double = 2.0,\n                                 shouldScaleGradByFreq: Boolean = false,\n                                 wRegularizer: Regularizer[T] = null)  Python:  layer = LookupTable(nIndex, nOutput, paddingValue, maxNorm, normType, shouldScaleGradByFreq)  This layer is a particular case of a convolution, where the width of the convolution would be 1.\nInput should be a 1D or 2D tensor filled with indices. Indices are corresponding to the position\nin weight. For each index element of input, it outputs the selected index part of weight.\nThis layer is often used in word embedding. In collaborative filtering, it can be used together with Select to create embeddings for users or items.   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = LookupTable(9, 4, 2, 0.1, 2.0, true)\nval input = Tensor(Storage(Array(5.0f, 2.0f, 6.0f, 9.0f, 4.0f)), 1, Array(5))\n\nval output = layer.forward(input)\nval gradInput = layer.backward(input, output)  println(layer.weight)\nres6: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.2949163      -0.8240777      -0.9440595      -0.8326071\n-0.025108865    -0.025346711    0.09046136      -0.023320194\n-1.7525806      0.7305201       0.3349018       0.03952092\n-0.0048129847   0.023922665     0.005595926     -0.09681542\n-0.01619357     -0.030372608    0.07217587      -0.060049288\n0.014426847     -0.09052222     0.019132217     -0.035093457\n-0.7002858      1.1149521       0.9869375       1.2580993\n0.36649692      -0.6583153      0.90005803      0.12671651\n0.048913725     0.033388995     -0.07938445     0.01381052\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9x4]  println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n5.0\n2.0\n6.0\n9.0\n4.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  println(output)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.01619357     -0.030372608    0.07217587      -0.060049288\n-0.025108865    -0.025346711    0.09046136      -0.023320194\n0.014426847     -0.09052222     0.019132217     -0.035093457\n0.048913725     0.033388995     -0.07938445     0.01381052\n-0.0048129847   0.023922665     0.005595926     -0.09681542\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x4]  println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  Python example:  layer = LookupTable(9, 4, 2.0, 0.1, 2.0, True)\ninput = np.array([5.0, 2.0, 6.0, 9.0, 4.0]).astype( float32 )\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, output)  output\n[array([[-0.00704637,  0.07495038,  0.06465427,  0.01235369],\n        [ 0.00350313,  0.02751033, -0.02163727,  0.0936095 ],\n        [ 0.02330465, -0.05696457,  0.0081728 ,  0.07839092],\n        [ 0.06580321, -0.0743262 , -0.00414508, -0.01133001],\n        [-0.00382435, -0.04677011,  0.02839171, -0.08361723]], dtype=float32)]  gradInput\n[array([ 0.,  0.,  0.,  0.,  0.], dtype=float32)]", 
            "title": "LookupTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/", 
            "text": "Pack\n\n\nScala:\n\n\nval module = Pack(dim)\n\n\n\n\nPython:\n\n\nmodule = Pack(dim)\n\n\n\n\nPack is used to stack a list of n-dimensional tensors into one (n+1)-dimensional tensor.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Pack(2)\nval input1 = Tensor(2, 2).randn()\nval input2 = Tensor(2, 2).randn()\nval input = T()\ninput(1) = input1\ninput(2) = input2\n\nval output = module.forward(input)\n\n\n input\n {\n    2: -0.8737048   -0.7337217\n       0.7268678    -0.53470045\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1: -1.3062215   -0.58756566\n       0.8921608    -1.8087773\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }\n\n\n\n output\n(1,.,.) =\n-1.3062215  -0.58756566\n-0.8737048  -0.7337217\n\n(2,.,.) =\n0.8921608   -1.8087773\n0.7268678   -0.53470045\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Pack(2)\ninput1 = np.random.randn(2, 2)\ninput2 = np.random.randn(2, 2)\ninput = [input1, input2]\noutput = module.forward(input)\n\n\n input\n[array([[ 0.92741416, -3.29826586],\n       [-0.03147819, -0.10049306]]), array([[-0.27146461, -0.25729802],\n       [ 0.1316149 ,  1.27620145]])]\n\n\n output\narray([[[ 0.92741418, -3.29826593],\n        [-0.27146462, -0.25729802]],\n\n       [[-0.03147819, -0.10049306],\n        [ 0.13161489,  1.27620149]]], dtype=float32)\n\n\n\n\nMM\n\n\nScala:\n\n\nval m = MM(transA=false,transB=false)\n\n\n\n\nPython:\n\n\nm = MM(trans_a=False,trans_b=False)\n\n\n\n\nMM is a module that performs matrix multiplication on two mini-batch inputs, producing one mini-batch.\n\n\nScala example:\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval input = T(1 -\n Tensor(3, 3).randn(), 2 -\n Tensor(3, 3).randn())\nval m1 = MM()\nval output1 = m1.forward(input)\nval m2 = MM(true,true)\nval output2 = m2.forward(input)\n\nscala\n print(input)\n {\n        2: -0.62020904  -0.18690863     0.34132162\n           -0.5359324   -0.09937895     0.86147165\n           -2.6607985   -1.426654       2.3428898\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n        1: -1.3087689   0.048720464     0.69583243\n           -0.52055264  -1.5275089      -1.1569321\n           0.28093573   -0.29353273     -0.9505267\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n }\n\nscala\n print(output1)\n-1.0658705      -0.7529337      1.225519\n4.2198563       1.8996398       -4.204146\n2.512235        1.3327343       -2.38396\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nscala\n print(output2)\n1.0048954       0.99516183      4.8832207\n0.15509865      -0.12717877     1.3618765\n-0.5397563      -1.0767963      -2.4279075\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput1=np.random.rand(3,3)\ninput2=np.random.rand(3,3)\ninput = [input1,input2]\nprint \ninput is :\n,input\nout = MM().forward(input)\nprint \noutput is :\n,out\n\n\n\n\nproduces output:\n\n\ninput is : [array([[ 0.13696046,  0.92653165,  0.73585328],\n       [ 0.28167852,  0.06431783,  0.15710073],\n       [ 0.21896166,  0.00780161,  0.25780671]]), array([[ 0.11232797,  0.17023931,  0.92430042],\n       [ 0.86629537,  0.07630215,  0.08584417],\n       [ 0.47087278,  0.22992833,  0.59257503]])]\ncreating: createMM\noutput is : [array([[ 1.16452789,  0.26320592,  0.64217824],\n       [ 0.16133308,  0.08898225,  0.35897085],\n       [ 0.15274818,  0.09714822,  0.3558259 ]], dtype=float32)]\n\n\n\n\nCMaxTable\n\n\nScala:\n\n\nval m = CMaxTable()\n\n\n\n\nPython:\n\n\nm = CMaxTable()\n\n\n\n\nCMaxTable is a module that takes a table of Tensors and outputs the max of all of them.\n\n\nScala example:\n\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor(3).randn()\nval input2 =  Tensor(3).randn()\nval input = T(input1, input2)\nval m = CMaxTable()\nval output = m.forward(input)\nval gradOut = Tensor(3).randn()\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n {\n        2: -0.38613814\n           0.74074316\n           -1.753783\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n        1: -1.6037064\n           -2.3297918\n           -0.7160026\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\nscala\n print(output)\n-0.38613814\n0.74074316\n-0.7160026\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\nscala\n print(gradOut)\n-1.4526331\n0.7070323\n0.29294914\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\nscala\n print(gradIn)\n {\n        2: -1.4526331\n           0.7070323\n           0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: 0.0\n           0.0\n           0.29294914\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput1 = np.random.rand(3)\ninput2 = np.random.rand(3)\nprint \ninput is :\n,input1,input2\n\nm = CMaxTable()\nout = m.forward([input1,input2])\nprint \noutput of m is :\n,out\n\ngrad_out = np.random.rand(3)\ngrad_in = m.backward([input1, input2],grad_out)\nprint \ngrad input of m is :\n,grad_in\n\n\n\n\nproduces output:\n\n\ninput is : [ 0.48649797  0.22131348  0.45667796] [ 0.73207053  0.74290136  0.03169769]\ncreating: createCMaxTable\noutput of m is : [array([ 0.73207051,  0.74290138,  0.45667794], dtype=float32)]\ngrad input of m is : [array([ 0.        ,  0.        ,  0.86938971], dtype=float32), array([ 0.04140199,  0.4787094 ,  0.        ], dtype=float32)]\n\n\n\n\nSplitTable\n\n\nScala:\n\n\nval layer = SplitTable(dim)\n\n\n\n\nPython:\n\n\nlayer = SplitTable(dim)\n\n\n\n\nSplitTable takes a Tensor as input and outputs several tables,\nsplitting the Tensor along the specified dimension \ndimension\n. Please note\nthe dimension starts from 1.\n\n\nThe input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user needs to specify the number of dimensions of each sample tensor in a\nbatch using \nnInputDims\n.\n\n\n    +----------+         +-----------+\n    | input[1] +---------\n {member1, |\n  +----------+-+         |           |\n  | input[2] +-----------\n  member2, |\n+----------+-+           |           |\n| input[3] +-------------\n  member3} |\n+----------+             +-----------+\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SplitTable(2)\nlayer.forward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)))\nlayer.backward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)), T(\n  Tensor(T(0.1f, 0.2f, 0.3f)),\n  Tensor(T(0.4f, 0.5f, 0.6f)),\n  Tensor(T(0.7f, 0.8f, 0.9f))\n))\n\n\n\n\nIts output should be \n\n\n {\n        2: 2.0\n           5.0\n           8.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: 1.0\n           4.0\n           7.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        3: 3.0\n           6.0\n           9.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }\n\n0.1     0.4     0.7\n0.2     0.5     0.8\n0.3     0.6     0.9\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import SplitTable\nimport numpy as np\n\nlayer = SplitTable(2)\nlayer.forward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]))\n\nlayer.backward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]), [\n  np.array([0.1, 0.2, 0.3]),\n  np.array([0.4, 0.5, 0.6]),\n  np.array([0.7, 0.8, 0.9])\n])\n\n\n\n\nIts output should be\n\n\n[\n  array([ 1.,  4.,  7.], dtype=float32),\n  array([ 2.,  5.,  8.], dtype=float32),\n  array([ 3.,  6.,  9.], dtype=float32)\n]\n\narray([[ 0.1       ,  0.40000001,  0.69999999],\n       [ 0.2       ,  0.5       ,  0.80000001],\n       [ 0.30000001,  0.60000002,  0.89999998]], dtype=float32)\n\n\n\n\nDotProduct\n\n\nScala:\n\n\nval m = DotProduct()\n\n\n\n\nPython:\n\n\nm = DotProduct()\n\n\n\n\nOutputs the dot product (similarity) between inputs\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mlp = DotProduct()\nval x = Tensor(3).fill(1f)\nval y = Tensor(3).fill(2f)\nprintln(\ninput:\n)\nprintln(x)\nprintln(y)\nprintln(\noutput:\n)\nprintln(mlp.forward(T(x, y)))\n\n\n\n\ninput:\n1.0\n1.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n2.0\n2.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\noutput:\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\n\nmlp = DotProduct()\nx = np.array([1, 1, 1])\ny = np.array([2, 2, 2])\nprint(\ninput:\n)\nprint(x)\nprint(y)\nprint(\noutput:\n)\nprint(mlp.forward([x, y]))\n\n\n\n\n\ncreating: createDotProduct\ninput:\n[1 1 1]\n[2 2 2]\noutput:\n[ 6.]\n\n\n\n\nCSubTable\n\n\nScala:\n\n\nval model = CSubTable()\n\n\n\n\nPython:\n\n\nmodel = CSubTable()\n\n\n\n\nTakes a sequence with two Tensor and returns the component-wise subtraction between them.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CSubTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)\n\nscala\n print(input)\n {\n    2: 0.29122078\n       0.17347474\n       0.14127742\n       0.2249051\n       0.12171601\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1: 0.6202152\n       0.70417005\n       0.21334995\n       0.05191216\n       0.4209623\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\nscala\n print(output)\n0.3289944\n0.5306953\n0.072072536\n-0.17299294\n0.2992463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n\n\nPython example:\n\n\nmodel = CSubTable()\ninput1 = np.random.randn(5)\ninput2 = np.random.randn(5)\ninput = [input1, input2]\noutput = model.forward(input)\n\n\n\n\noutput is\n\n\narray([-1.15087152,  0.6169951 ,  2.41840839,  1.34374809,  1.39436531], dtype=float32)\n\n\n\n\nCDivTable\n\n\nScala:\n\n\nval module = CDivTable()\n\n\n\n\nPython:\n\n\nmodule = CDivTable()\n\n\n\n\nTakes a table with two Tensor and returns the component-wise division between them.\n\n\nScala example:\n\n\nval module = CDivTable()\nval input = T(1 -\n Tensor(2,3).rand(), 2 -\n Tensor(2,3).rand())\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: 0.802295     0.7113872       0.29395157\n           0.6562403    0.06519115      0.20099664\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n        1: 0.7435388    0.59126955      0.10225375\n           0.46819785   0.10572237      0.9861797\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n }\n\nmodule.forward(input)\nres6: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9267648       0.8311501       0.34785917\n0.7134549       1.6217289       4.906449\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nmodule = CDivTable()\ninput = [np.array([[1, 2, 3],[4, 5, 6]]), np.array([[1, 4, 9],[6, 10, 3]])]\nmodule.forward(input)\n[array([\n[ 1.,                   0.5     ,    0.33333334],\n[ 0.66666669, 0.5       ,  2.        ]], dtype=float32)]\n\n\n\n\nJoinTable\n\n\nScala:\n\n\nval layer = JoinTable(dimension, nInputDims)\n\n\n\n\nPython:\n\n\nlayer = JoinTable(dimension, n_input_dims)\n\n\n\n\nIt is a table module which takes a table of Tensors as input and\noutputs a Tensor by joining them together along the dimension \ndimension\n.\n\n\nThe input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user need to specify the number of dimensions of each sample tensor in the\nbatch using \nnInputDims\n.\n\n\nParameters:\n\n\ndimension\n  - to be join in this dimension\n\n\nnInputDims\n - specify the number of dimensions that this module will receiveIf it is more than the dimension of input tensors, the first dimensionwould be considered as batch size\n\n\n+----------+             +-----------+\n| {input1, +-------------\n output[1] |\n|          |           +-----------+-+\n|  input2, +-----------\n output[2] |\n|          |         +-----------+-+\n|  input3} +---------\n output[3] |\n+----------+         +-----------+\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.JoinTable\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = JoinTable(2, 2)\nval input1 = Tensor(T(\n  T(\n    T(1f, 2f, 3f),\n    T(2f, 3f, 4f),\n    T(3f, 4f, 5f))\n))\n\nval input2 = Tensor(T(\n  T(\n    T(3f, 4f, 5f),\n    T(2f, 3f, 4f),\n    T(1f, 2f, 3f))\n))\n\nval input = T(input1, input2)\n\nval gradOutput = Tensor(T(\n  T(\n    T(1f, 2f, 3f, 3f, 4f, 5f),\n    T(2f, 3f, 4f, 2f, 3f, 4f),\n    T(3f, 4f, 5f, 1f, 2f, 3f)\n)))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n(1,.,.) =\n1.0 2.0 3.0 3.0 4.0 5.0\n2.0 3.0 4.0 2.0 3.0 4.0\n3.0 4.0 5.0 1.0 2.0 3.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x6]\n\nprintln(grad)\n {\n    2: (1,.,.) =\n       3.0  4.0 5.0\n       2.0  3.0 4.0\n       1.0  2.0 3.0\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n    1: (1,.,.) =\n       1.0  2.0 3.0\n       2.0  3.0 4.0\n       3.0  4.0 5.0\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n }\n\n\n\n\nPython example:\n\n\nlayer = JoinTable(2, 2)\ninput1 = np.array([\n [\n    [1.0, 2.0, 3.0],\n    [2.0, 3.0, 4.0],\n    [3.0, 4.0, 5.0]\n  ]\n])\n\ninput2 = np.array([\n  [\n    [3.0, 4.0, 5.0],\n    [2.0, 3.0, 4.0],\n    [1.0, 2.0, 3.0]\n  ]\n])\n\ninput = [input1, input2]\n\ngradOutput = np.array([\n  [\n    [1.0, 2.0, 3.0, 3.0, 4.0, 5.0],\n    [2.0, 3.0, 4.0, 2.0, 3.0, 4.0],\n    [3.0, 4.0, 5.0, 1.0, 2.0, 3.0]\n  ]\n])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[[ 1.  2.  3.  3.  4.  5.]\n  [ 2.  3.  4.  2.  3.  4.]\n  [ 3.  4.  5.  1.  2.  3.]]]\n\nprint grad\n[array([[[ 1.,  2.,  3.],\n        [ 2.,  3.,  4.],\n        [ 3.,  4.,  5.]]], dtype=float32), array([[[ 3.,  4.,  5.],\n        [ 2.,  3.,  4.],\n        [ 1.,  2.,  3.]]], dtype=float32)]\n\n\n\n\nSelectTable\n\n\nScala:\n\n\nval m = SelectTable(index: Int)\n\n\n\n\nPython:\n\n\nm = SelectTable(dimension)\n\n\n\n\nSelect one element from a table by a given index.\nIn Scala API, table is kind of like HashMap with one-base index as the key.\nIn python, table is a just a list.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = T(Tensor(2,3).randn(), Tensor(2,3).randn())\n\nprintln(\ninput: \n)\nprintln(input)\nprintln(\noutput:\n)\nprintln(SelectTable(1).forward(input)) // Select and output the first element of the input which shape is (2, 3)\nprintln(SelectTable(2).forward(input)) // Select and output the second element of the input which shape is (2, 3)\n\n\n\n\n\ninput: \n {\n    2: 2.005436370849835    0.09670211785545313 1.186779895312918   \n       2.238415300857082    0.241626512721254   0.15765709974113828 \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    1: 0.5668905654052705   -1.3205159007397167 -0.5431464848526197 \n       -0.11582559521074104 0.7671830693813515  -0.39992781407893574    \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\noutput:\n0.5668905654052705  -1.3205159007397167 -0.5431464848526197 \n-0.11582559521074104    0.7671830693813515  -0.39992781407893574    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n2.005436370849835   0.09670211785545313 1.186779895312918   \n2.238415300857082   0.241626512721254   0.15765709974113828 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\n\ninput = [np.random.random((2,3)), np.random.random((2, 1))]\nprint(\ninput:\n)\nprint(input)\nprint(\noutput:\n)\nprint(SelectTable(1).forward(input)) # Select and output the first element of the input which shape is (2, 3)\n\n\n\n\ninput:\n[array([[ 0.07185111,  0.26140439,  0.9437582 ],\n       [ 0.50278191,  0.83923974,  0.06396735]]), array([[ 0.84955122],\n       [ 0.16053703]])]\noutput:\ncreating: createSelectTable\n[[ 0.07185111  0.2614044   0.94375819]\n [ 0.50278193  0.83923972  0.06396735]]\n\n\n\n\n\nNarrowTable\n\n\nScala:\n\n\nval narrowTable = NarrowTable(offset, length = 1)\n\n\n\n\nPython:\n\n\nnarrowTable = NarrowTable(offset, length = 1)\n\n\n\n\nNarrowTable takes a table as input and returns a subtable starting from index \noffset\n having \nlength\n elements\n\n\nNegative \nlength\n means the last element is located at Abs|length| to the last element of input\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\nval narrowTable = NarrowTable(1, 1)\n\nval input = T()\ninput(1.0) = Tensor(2, 2).rand()\ninput(2.0) = Tensor(2, 2).rand()\ninput(3.0) = Tensor(2, 2).rand()\n\n print(input)\n {\n    2.0: 0.27686104 0.9040761   \n         0.75969505 0.8008061   \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1.0: 0.94122535 0.46173728  \n         0.43302807 0.1670979   \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    3.0: 0.43944374 0.49336782  \n         0.7274511  0.67777634  \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }\n\n  print(narrowTable.forward(input))\n {\n    1: 0.94122535   0.46173728  \n       0.43302807   0.1670979   \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nnarrowTable = NarrowTable(1, 1)\n\n narrowTable.forward([np.array([1, 2, 3]), np.array([4, 5, 6])])\n[array([ 1.,  2.,  3.], dtype=float32)]\n\n\n\n\n\nCAddTable\n\n\nScala:\n\n\nval module = CAddTable(inplace = false)\n\n\n\n\nPython:\n\n\nmodule = CAddTable(inplace=False)\n\n\n\n\nCAddTable merges the input tensors in the input table by element-wise adding. The input table is actually an array of tensor with same size.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mlp = Sequential()\nmlp.add(ConcatTable().add(Identity()).add(Identity()))\nmlp.add(CAddTable())\n\nprintln(mlp.forward(Tensor.range(1, 3, 1)))\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.0\n4.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmlp = Sequential()\nmlp.add(ConcatTable().add(Identity()).add(Identity()))\nmlp.add(CAddTable())\n\nprint(mlp.forward(np.arange(1, 4, 1)))\n\n\n\n\nOutput is\n\n\n[array([ 2.,  4.,  6.], dtype=float32)]\n\n\n\n\nCMulTable\n\n\nScala:\n\n\nval model = CMulTable()\n\n\n\n\nPython:\n\n\nmodel = CMulTable()\n\n\n\n\nTakes a sequence of Tensors and outputs the multiplication of all of them.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CMulTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)\n\nscala\n print(input)\n {\n    2: 0.13224044\n       0.5460452\n       0.33032498\n       0.6317603\n       0.6665052\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1: 0.28694472\n       0.45169437\n       0.36891535\n       0.9126049\n       0.41318864\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n }\n\nscala\n print(output)\n0.037945695\n0.24664554\n0.12186196\n0.57654756\n0.27539238\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n\n\nPython example:\n\n\nmodel = CMulTable()\ninput1 = np.random.randn(5)\ninput2 = np.random.randn(5)\ninput = [input1, input2]\noutput = model.forward(input)\n\n\n print(input)\n[array([ 0.28183274, -0.6477487 , -0.21279841,  0.22725124,  0.54748552]), array([-0.78673028, -1.08337196, -0.62710066,  0.37332587, -1.40708162])]\n\n\n print(output)\n[-0.22172636  0.70175284  0.13344601  0.08483877 -0.77035683]\n\n\n\n\nMV\n\n\nScala:\n\n\nval module = MV(trans = false)\n\n\n\n\nPython:\n\n\nmodule = MV(trans=False)\n\n\n\n\nIt is a module to perform matrix vector multiplication on two mini-batch inputs, producing a mini-batch.\n\n\ntrans\n means whether make matrix transpose before multiplication.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval module = MV()\n\nprintln(module.forward(T(Tensor.range(1, 12, 1).resize(2, 2, 3), Tensor.range(1, 6, 1).resize(2, 3))))\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n14.0    32.0\n122.0   167.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nmodule = MV()\n\nprint(module.forward([np.arange(1, 13, 1).reshape(2, 2, 3), np.arange(1, 7, 1).reshape(2, 3)]))\n\n\n\n\nOutput is\n\n\n[array([ 0.31657887, -1.11062765, -1.16235781, -0.67723978,  0.74650359], dtype=float32)]\n\n\n\n\nFlattenTable\n\n\nScala:\n\n\nval module = FlattenTable()\n\n\n\n\nPython:\n\n\nmodule = FlattenTable()\n\n\n\n\nFlattenTable takes an arbitrarily deep table of Tensors (potentially nested) as input and a table of Tensors without any nested table will be produced\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = FlattenTable()\nval t1 = Tensor(3).randn()\nval t2 = Tensor(3).randn()\nval t3 = Tensor(3).randn()\nval input = T(t1, T(t2, T(t3)))\n\nval output = module.forward(input)\n\n\n input\n {\n    2:  {\n        2:  {\n            1: 0.5521984\n               -0.4160644\n               -0.698762\n               [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n            }\n        1: -1.7380241\n           0.60336906\n           -0.8751049\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n        }\n    1: 1.0529885\n       -0.792229\n       0.8395628\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\n\n\n output\n{\n    2: -1.7380241\n       0.60336906\n       -0.8751049\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    1: 1.0529885\n       -0.792229\n       0.8395628\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    3: 0.5521984\n       -0.4160644\n       -0.698762\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Sequential()\n# this will create a nested table\nnested = ConcatTable().add(Identity()).add(Identity())\nmodule.add(nested).add(FlattenTable())\nt1 = np.random.randn(3)\nt2 = np.random.randn(3)\ninput = [t1, t2]\noutput = module.forward(input)\n\n\n input\n[array([-2.21080689, -0.48928043, -0.26122161]), array([-0.8499716 ,  1.63694575, -0.31109292])]\n\n\n output\n[array([-2.21080685, -0.48928043, -0.26122162], dtype=float32),\n array([-0.84997159,  1.63694572, -0.31109291], dtype=float32),\n array([-2.21080685, -0.48928043, -0.26122162], dtype=float32),\n array([-0.84997159,  1.63694572, -0.31109291], dtype=float32)]\n\n\n\n\n\nCMinTable\n\n\nScala:\n\n\nval layer = CMinTable()\n\n\n\n\nPython:\n\n\nlayer = CMinTable()\n\n\n\n\nCMinTable takes a bunch of tensors as inputs. These tensors must have\nsame shape. This layer will merge them by doing an element-wise comparision\nand use the min value.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = CMinTable()\nlayer.forward(T(\n  Tensor(T(1.0f, 5.0f, 2.0f)),\n  Tensor(T(3.0f, 4.0f, -1.0f)),\n  Tensor(T(5.0f, 7.0f, -5.0f))\n))\nlayer.backward(T(\n  Tensor(T(1.0f, 5.0f, 2.0f)),\n  Tensor(T(3.0f, 4.0f, -1.0f)),\n  Tensor(T(5.0f, 7.0f, -5.0f))\n), Tensor(T(0.1f, 0.2f, 0.3f)))\n\n\n\n\nIts output should be\n\n\n1.0\n4.0\n-5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n{\n  2: 0.0\n     0.2\n     0.0\n     [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n  1: 0.1\n     0.0\n     0.0\n     [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n  3: 0.0\n     0.0\n     0.3\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n}\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import CMinTable\nimport numpy as np\n\nlayer = CMinTable()\nlayer.forward([\n  np.array([1.0, 5.0, 2.0]),\n  np.array([3.0, 4.0, -1.0]),\n  np.array([5.0, 7.0, -5.0])\n])\n\nlayer.backward([\n  np.array([1.0, 5.0, 2.0]),\n  np.array([3.0, 4.0, -1.0]),\n  np.array([5.0, 7.0, -5.0])\n], np.array([0.1, 0.2, 0.3]))\n\n\n\n\n\nIts output should be\n\n\narray([ 1.,  4., -5.], dtype=float32)\n\n[array([ 0.1, 0., 0.], dtype=float32),\narray([ 0., 0.2, 0.], dtype=float32),\narray([ 0., 0., 0.30000001], dtype=float32)]", 
            "title": "Merge/Split Layers"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#pack", 
            "text": "Scala:  val module = Pack(dim)  Python:  module = Pack(dim)  Pack is used to stack a list of n-dimensional tensors into one (n+1)-dimensional tensor.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Pack(2)\nval input1 = Tensor(2, 2).randn()\nval input2 = Tensor(2, 2).randn()\nval input = T()\ninput(1) = input1\ninput(2) = input2\n\nval output = module.forward(input)  input\n {\n    2: -0.8737048   -0.7337217\n       0.7268678    -0.53470045\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1: -1.3062215   -0.58756566\n       0.8921608    -1.8087773\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }  output\n(1,.,.) =\n-1.3062215  -0.58756566\n-0.8737048  -0.7337217\n\n(2,.,.) =\n0.8921608   -1.8087773\n0.7268678   -0.53470045\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Pack(2)\ninput1 = np.random.randn(2, 2)\ninput2 = np.random.randn(2, 2)\ninput = [input1, input2]\noutput = module.forward(input)  input\n[array([[ 0.92741416, -3.29826586],\n       [-0.03147819, -0.10049306]]), array([[-0.27146461, -0.25729802],\n       [ 0.1316149 ,  1.27620145]])]  output\narray([[[ 0.92741418, -3.29826593],\n        [-0.27146462, -0.25729802]],\n\n       [[-0.03147819, -0.10049306],\n        [ 0.13161489,  1.27620149]]], dtype=float32)", 
            "title": "Pack"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#mm", 
            "text": "Scala:  val m = MM(transA=false,transB=false)  Python:  m = MM(trans_a=False,trans_b=False)  MM is a module that performs matrix multiplication on two mini-batch inputs, producing one mini-batch.  Scala example:  scala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval input = T(1 -  Tensor(3, 3).randn(), 2 -  Tensor(3, 3).randn())\nval m1 = MM()\nval output1 = m1.forward(input)\nval m2 = MM(true,true)\nval output2 = m2.forward(input)\n\nscala  print(input)\n {\n        2: -0.62020904  -0.18690863     0.34132162\n           -0.5359324   -0.09937895     0.86147165\n           -2.6607985   -1.426654       2.3428898\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n        1: -1.3087689   0.048720464     0.69583243\n           -0.52055264  -1.5275089      -1.1569321\n           0.28093573   -0.29353273     -0.9505267\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n }\n\nscala  print(output1)\n-1.0658705      -0.7529337      1.225519\n4.2198563       1.8996398       -4.204146\n2.512235        1.3327343       -2.38396\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nscala  print(output2)\n1.0048954       0.99516183      4.8832207\n0.15509865      -0.12717877     1.3618765\n-0.5397563      -1.0767963      -2.4279075\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput1=np.random.rand(3,3)\ninput2=np.random.rand(3,3)\ninput = [input1,input2]\nprint  input is : ,input\nout = MM().forward(input)\nprint  output is : ,out  produces output:  input is : [array([[ 0.13696046,  0.92653165,  0.73585328],\n       [ 0.28167852,  0.06431783,  0.15710073],\n       [ 0.21896166,  0.00780161,  0.25780671]]), array([[ 0.11232797,  0.17023931,  0.92430042],\n       [ 0.86629537,  0.07630215,  0.08584417],\n       [ 0.47087278,  0.22992833,  0.59257503]])]\ncreating: createMM\noutput is : [array([[ 1.16452789,  0.26320592,  0.64217824],\n       [ 0.16133308,  0.08898225,  0.35897085],\n       [ 0.15274818,  0.09714822,  0.3558259 ]], dtype=float32)]", 
            "title": "MM"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#cmaxtable", 
            "text": "Scala:  val m = CMaxTable()  Python:  m = CMaxTable()  CMaxTable is a module that takes a table of Tensors and outputs the max of all of them.  Scala example:  \nscala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor(3).randn()\nval input2 =  Tensor(3).randn()\nval input = T(input1, input2)\nval m = CMaxTable()\nval output = m.forward(input)\nval gradOut = Tensor(3).randn()\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n {\n        2: -0.38613814\n           0.74074316\n           -1.753783\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n        1: -1.6037064\n           -2.3297918\n           -0.7160026\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\nscala  print(output)\n-0.38613814\n0.74074316\n-0.7160026\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\nscala  print(gradOut)\n-1.4526331\n0.7070323\n0.29294914\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\nscala  print(gradIn)\n {\n        2: -1.4526331\n           0.7070323\n           0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: 0.0\n           0.0\n           0.29294914\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput1 = np.random.rand(3)\ninput2 = np.random.rand(3)\nprint  input is : ,input1,input2\n\nm = CMaxTable()\nout = m.forward([input1,input2])\nprint  output of m is : ,out\n\ngrad_out = np.random.rand(3)\ngrad_in = m.backward([input1, input2],grad_out)\nprint  grad input of m is : ,grad_in  produces output:  input is : [ 0.48649797  0.22131348  0.45667796] [ 0.73207053  0.74290136  0.03169769]\ncreating: createCMaxTable\noutput of m is : [array([ 0.73207051,  0.74290138,  0.45667794], dtype=float32)]\ngrad input of m is : [array([ 0.        ,  0.        ,  0.86938971], dtype=float32), array([ 0.04140199,  0.4787094 ,  0.        ], dtype=float32)]", 
            "title": "CMaxTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#splittable", 
            "text": "Scala:  val layer = SplitTable(dim)  Python:  layer = SplitTable(dim)  SplitTable takes a Tensor as input and outputs several tables,\nsplitting the Tensor along the specified dimension  dimension . Please note\nthe dimension starts from 1.  The input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user needs to specify the number of dimensions of each sample tensor in a\nbatch using  nInputDims .      +----------+         +-----------+\n    | input[1] +---------  {member1, |\n  +----------+-+         |           |\n  | input[2] +-----------   member2, |\n+----------+-+           |           |\n| input[3] +-------------   member3} |\n+----------+             +-----------+  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SplitTable(2)\nlayer.forward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)))\nlayer.backward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)), T(\n  Tensor(T(0.1f, 0.2f, 0.3f)),\n  Tensor(T(0.4f, 0.5f, 0.6f)),\n  Tensor(T(0.7f, 0.8f, 0.9f))\n))  Its output should be    {\n        2: 2.0\n           5.0\n           8.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: 1.0\n           4.0\n           7.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        3: 3.0\n           6.0\n           9.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }\n\n0.1     0.4     0.7\n0.2     0.5     0.8\n0.3     0.6     0.9\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import SplitTable\nimport numpy as np\n\nlayer = SplitTable(2)\nlayer.forward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]))\n\nlayer.backward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]), [\n  np.array([0.1, 0.2, 0.3]),\n  np.array([0.4, 0.5, 0.6]),\n  np.array([0.7, 0.8, 0.9])\n])  Its output should be  [\n  array([ 1.,  4.,  7.], dtype=float32),\n  array([ 2.,  5.,  8.], dtype=float32),\n  array([ 3.,  6.,  9.], dtype=float32)\n]\n\narray([[ 0.1       ,  0.40000001,  0.69999999],\n       [ 0.2       ,  0.5       ,  0.80000001],\n       [ 0.30000001,  0.60000002,  0.89999998]], dtype=float32)", 
            "title": "SplitTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#dotproduct", 
            "text": "Scala:  val m = DotProduct()  Python:  m = DotProduct()  Outputs the dot product (similarity) between inputs  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mlp = DotProduct()\nval x = Tensor(3).fill(1f)\nval y = Tensor(3).fill(2f)\nprintln( input: )\nprintln(x)\nprintln(y)\nprintln( output: )\nprintln(mlp.forward(T(x, y)))  input:\n1.0\n1.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n2.0\n2.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\noutput:\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\n\nmlp = DotProduct()\nx = np.array([1, 1, 1])\ny = np.array([2, 2, 2])\nprint( input: )\nprint(x)\nprint(y)\nprint( output: )\nprint(mlp.forward([x, y]))  creating: createDotProduct\ninput:\n[1 1 1]\n[2 2 2]\noutput:\n[ 6.]", 
            "title": "DotProduct"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#csubtable", 
            "text": "Scala:  val model = CSubTable()  Python:  model = CSubTable()  Takes a sequence with two Tensor and returns the component-wise subtraction between them.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CSubTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)\n\nscala  print(input)\n {\n    2: 0.29122078\n       0.17347474\n       0.14127742\n       0.2249051\n       0.12171601\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1: 0.6202152\n       0.70417005\n       0.21334995\n       0.05191216\n       0.4209623\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\nscala  print(output)\n0.3289944\n0.5306953\n0.072072536\n-0.17299294\n0.2992463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  Python example:  model = CSubTable()\ninput1 = np.random.randn(5)\ninput2 = np.random.randn(5)\ninput = [input1, input2]\noutput = model.forward(input)  output is  array([-1.15087152,  0.6169951 ,  2.41840839,  1.34374809,  1.39436531], dtype=float32)", 
            "title": "CSubTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#cdivtable", 
            "text": "Scala:  val module = CDivTable()  Python:  module = CDivTable()  Takes a table with two Tensor and returns the component-wise division between them.  Scala example:  val module = CDivTable()\nval input = T(1 -  Tensor(2,3).rand(), 2 -  Tensor(2,3).rand())\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: 0.802295     0.7113872       0.29395157\n           0.6562403    0.06519115      0.20099664\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n        1: 0.7435388    0.59126955      0.10225375\n           0.46819785   0.10572237      0.9861797\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n }\n\nmodule.forward(input)\nres6: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9267648       0.8311501       0.34785917\n0.7134549       1.6217289       4.906449\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  module = CDivTable()\ninput = [np.array([[1, 2, 3],[4, 5, 6]]), np.array([[1, 4, 9],[6, 10, 3]])]\nmodule.forward(input)\n[array([\n[ 1.,                   0.5     ,    0.33333334],\n[ 0.66666669, 0.5       ,  2.        ]], dtype=float32)]", 
            "title": "CDivTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#jointable", 
            "text": "Scala:  val layer = JoinTable(dimension, nInputDims)  Python:  layer = JoinTable(dimension, n_input_dims)  It is a table module which takes a table of Tensors as input and\noutputs a Tensor by joining them together along the dimension  dimension .  The input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user need to specify the number of dimensions of each sample tensor in the\nbatch using  nInputDims .  Parameters:  dimension   - to be join in this dimension  nInputDims  - specify the number of dimensions that this module will receiveIf it is more than the dimension of input tensors, the first dimensionwould be considered as batch size  +----------+             +-----------+\n| {input1, +-------------  output[1] |\n|          |           +-----------+-+\n|  input2, +-----------  output[2] |\n|          |         +-----------+-+\n|  input3} +---------  output[3] |\n+----------+         +-----------+  Scala example:  import com.intel.analytics.bigdl.nn.JoinTable\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = JoinTable(2, 2)\nval input1 = Tensor(T(\n  T(\n    T(1f, 2f, 3f),\n    T(2f, 3f, 4f),\n    T(3f, 4f, 5f))\n))\n\nval input2 = Tensor(T(\n  T(\n    T(3f, 4f, 5f),\n    T(2f, 3f, 4f),\n    T(1f, 2f, 3f))\n))\n\nval input = T(input1, input2)\n\nval gradOutput = Tensor(T(\n  T(\n    T(1f, 2f, 3f, 3f, 4f, 5f),\n    T(2f, 3f, 4f, 2f, 3f, 4f),\n    T(3f, 4f, 5f, 1f, 2f, 3f)\n)))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n(1,.,.) =\n1.0 2.0 3.0 3.0 4.0 5.0\n2.0 3.0 4.0 2.0 3.0 4.0\n3.0 4.0 5.0 1.0 2.0 3.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x6]\n\nprintln(grad)\n {\n    2: (1,.,.) =\n       3.0  4.0 5.0\n       2.0  3.0 4.0\n       1.0  2.0 3.0\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n    1: (1,.,.) =\n       1.0  2.0 3.0\n       2.0  3.0 4.0\n       3.0  4.0 5.0\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n }  Python example:  layer = JoinTable(2, 2)\ninput1 = np.array([\n [\n    [1.0, 2.0, 3.0],\n    [2.0, 3.0, 4.0],\n    [3.0, 4.0, 5.0]\n  ]\n])\n\ninput2 = np.array([\n  [\n    [3.0, 4.0, 5.0],\n    [2.0, 3.0, 4.0],\n    [1.0, 2.0, 3.0]\n  ]\n])\n\ninput = [input1, input2]\n\ngradOutput = np.array([\n  [\n    [1.0, 2.0, 3.0, 3.0, 4.0, 5.0],\n    [2.0, 3.0, 4.0, 2.0, 3.0, 4.0],\n    [3.0, 4.0, 5.0, 1.0, 2.0, 3.0]\n  ]\n])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[[ 1.  2.  3.  3.  4.  5.]\n  [ 2.  3.  4.  2.  3.  4.]\n  [ 3.  4.  5.  1.  2.  3.]]]\n\nprint grad\n[array([[[ 1.,  2.,  3.],\n        [ 2.,  3.,  4.],\n        [ 3.,  4.,  5.]]], dtype=float32), array([[[ 3.,  4.,  5.],\n        [ 2.,  3.,  4.],\n        [ 1.,  2.,  3.]]], dtype=float32)]", 
            "title": "JoinTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#selecttable", 
            "text": "Scala:  val m = SelectTable(index: Int)  Python:  m = SelectTable(dimension)  Select one element from a table by a given index.\nIn Scala API, table is kind of like HashMap with one-base index as the key.\nIn python, table is a just a list.  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = T(Tensor(2,3).randn(), Tensor(2,3).randn())\n\nprintln( input:  )\nprintln(input)\nprintln( output: )\nprintln(SelectTable(1).forward(input)) // Select and output the first element of the input which shape is (2, 3)\nprintln(SelectTable(2).forward(input)) // Select and output the second element of the input which shape is (2, 3)  input: \n {\n    2: 2.005436370849835    0.09670211785545313 1.186779895312918   \n       2.238415300857082    0.241626512721254   0.15765709974113828 \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    1: 0.5668905654052705   -1.3205159007397167 -0.5431464848526197 \n       -0.11582559521074104 0.7671830693813515  -0.39992781407893574    \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\noutput:\n0.5668905654052705  -1.3205159007397167 -0.5431464848526197 \n-0.11582559521074104    0.7671830693813515  -0.39992781407893574    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n2.005436370849835   0.09670211785545313 1.186779895312918   \n2.238415300857082   0.241626512721254   0.15765709974113828 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\n\ninput = [np.random.random((2,3)), np.random.random((2, 1))]\nprint( input: )\nprint(input)\nprint( output: )\nprint(SelectTable(1).forward(input)) # Select and output the first element of the input which shape is (2, 3)  input:\n[array([[ 0.07185111,  0.26140439,  0.9437582 ],\n       [ 0.50278191,  0.83923974,  0.06396735]]), array([[ 0.84955122],\n       [ 0.16053703]])]\noutput:\ncreating: createSelectTable\n[[ 0.07185111  0.2614044   0.94375819]\n [ 0.50278193  0.83923972  0.06396735]]", 
            "title": "SelectTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#narrowtable", 
            "text": "Scala:  val narrowTable = NarrowTable(offset, length = 1)  Python:  narrowTable = NarrowTable(offset, length = 1)  NarrowTable takes a table as input and returns a subtable starting from index  offset  having  length  elements  Negative  length  means the last element is located at Abs|length| to the last element of input  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\nval narrowTable = NarrowTable(1, 1)\n\nval input = T()\ninput(1.0) = Tensor(2, 2).rand()\ninput(2.0) = Tensor(2, 2).rand()\ninput(3.0) = Tensor(2, 2).rand()  print(input)\n {\n    2.0: 0.27686104 0.9040761   \n         0.75969505 0.8008061   \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1.0: 0.94122535 0.46173728  \n         0.43302807 0.1670979   \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    3.0: 0.43944374 0.49336782  \n         0.7274511  0.67777634  \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }   print(narrowTable.forward(input))\n {\n    1: 0.94122535   0.46173728  \n       0.43302807   0.1670979   \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }  Python example:  from bigdl.nn.layer import *\nnarrowTable = NarrowTable(1, 1)  narrowTable.forward([np.array([1, 2, 3]), np.array([4, 5, 6])])\n[array([ 1.,  2.,  3.], dtype=float32)]", 
            "title": "NarrowTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#caddtable", 
            "text": "Scala:  val module = CAddTable(inplace = false)  Python:  module = CAddTable(inplace=False)  CAddTable merges the input tensors in the input table by element-wise adding. The input table is actually an array of tensor with same size.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mlp = Sequential()\nmlp.add(ConcatTable().add(Identity()).add(Identity()))\nmlp.add(CAddTable())\n\nprintln(mlp.forward(Tensor.range(1, 3, 1)))  Output is  com.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.0\n4.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmlp = Sequential()\nmlp.add(ConcatTable().add(Identity()).add(Identity()))\nmlp.add(CAddTable())\n\nprint(mlp.forward(np.arange(1, 4, 1)))  Output is  [array([ 2.,  4.,  6.], dtype=float32)]", 
            "title": "CAddTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#cmultable", 
            "text": "Scala:  val model = CMulTable()  Python:  model = CMulTable()  Takes a sequence of Tensors and outputs the multiplication of all of them.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CMulTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)\n\nscala  print(input)\n {\n    2: 0.13224044\n       0.5460452\n       0.33032498\n       0.6317603\n       0.6665052\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1: 0.28694472\n       0.45169437\n       0.36891535\n       0.9126049\n       0.41318864\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n }\n\nscala  print(output)\n0.037945695\n0.24664554\n0.12186196\n0.57654756\n0.27539238\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  Python example:  model = CMulTable()\ninput1 = np.random.randn(5)\ninput2 = np.random.randn(5)\ninput = [input1, input2]\noutput = model.forward(input)  print(input)\n[array([ 0.28183274, -0.6477487 , -0.21279841,  0.22725124,  0.54748552]), array([-0.78673028, -1.08337196, -0.62710066,  0.37332587, -1.40708162])]  print(output)\n[-0.22172636  0.70175284  0.13344601  0.08483877 -0.77035683]", 
            "title": "CMulTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#mv", 
            "text": "Scala:  val module = MV(trans = false)  Python:  module = MV(trans=False)  It is a module to perform matrix vector multiplication on two mini-batch inputs, producing a mini-batch.  trans  means whether make matrix transpose before multiplication.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval module = MV()\n\nprintln(module.forward(T(Tensor.range(1, 12, 1).resize(2, 2, 3), Tensor.range(1, 6, 1).resize(2, 3))))  Output is  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n14.0    32.0\n122.0   167.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  module = MV()\n\nprint(module.forward([np.arange(1, 13, 1).reshape(2, 2, 3), np.arange(1, 7, 1).reshape(2, 3)]))  Output is  [array([ 0.31657887, -1.11062765, -1.16235781, -0.67723978,  0.74650359], dtype=float32)]", 
            "title": "MV"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#flattentable", 
            "text": "Scala:  val module = FlattenTable()  Python:  module = FlattenTable()  FlattenTable takes an arbitrarily deep table of Tensors (potentially nested) as input and a table of Tensors without any nested table will be produced  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = FlattenTable()\nval t1 = Tensor(3).randn()\nval t2 = Tensor(3).randn()\nval t3 = Tensor(3).randn()\nval input = T(t1, T(t2, T(t3)))\n\nval output = module.forward(input)  input\n {\n    2:  {\n        2:  {\n            1: 0.5521984\n               -0.4160644\n               -0.698762\n               [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n            }\n        1: -1.7380241\n           0.60336906\n           -0.8751049\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n        }\n    1: 1.0529885\n       -0.792229\n       0.8395628\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }  output\n{\n    2: -1.7380241\n       0.60336906\n       -0.8751049\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    1: 1.0529885\n       -0.792229\n       0.8395628\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    3: 0.5521984\n       -0.4160644\n       -0.698762\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Sequential()\n# this will create a nested table\nnested = ConcatTable().add(Identity()).add(Identity())\nmodule.add(nested).add(FlattenTable())\nt1 = np.random.randn(3)\nt2 = np.random.randn(3)\ninput = [t1, t2]\noutput = module.forward(input)  input\n[array([-2.21080689, -0.48928043, -0.26122161]), array([-0.8499716 ,  1.63694575, -0.31109292])]  output\n[array([-2.21080685, -0.48928043, -0.26122162], dtype=float32),\n array([-0.84997159,  1.63694572, -0.31109291], dtype=float32),\n array([-2.21080685, -0.48928043, -0.26122162], dtype=float32),\n array([-0.84997159,  1.63694572, -0.31109291], dtype=float32)]", 
            "title": "FlattenTable"
        }, 
        {
            "location": "/APIdocs/Layers/MergeSplit-Layers/#cmintable", 
            "text": "Scala:  val layer = CMinTable()  Python:  layer = CMinTable()  CMinTable takes a bunch of tensors as inputs. These tensors must have\nsame shape. This layer will merge them by doing an element-wise comparision\nand use the min value.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = CMinTable()\nlayer.forward(T(\n  Tensor(T(1.0f, 5.0f, 2.0f)),\n  Tensor(T(3.0f, 4.0f, -1.0f)),\n  Tensor(T(5.0f, 7.0f, -5.0f))\n))\nlayer.backward(T(\n  Tensor(T(1.0f, 5.0f, 2.0f)),\n  Tensor(T(3.0f, 4.0f, -1.0f)),\n  Tensor(T(5.0f, 7.0f, -5.0f))\n), Tensor(T(0.1f, 0.2f, 0.3f)))  Its output should be  1.0\n4.0\n-5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n{\n  2: 0.0\n     0.2\n     0.0\n     [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n  1: 0.1\n     0.0\n     0.0\n     [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n  3: 0.0\n     0.0\n     0.3\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n}  Python example:  from bigdl.nn.layer import CMinTable\nimport numpy as np\n\nlayer = CMinTable()\nlayer.forward([\n  np.array([1.0, 5.0, 2.0]),\n  np.array([3.0, 4.0, -1.0]),\n  np.array([5.0, 7.0, -5.0])\n])\n\nlayer.backward([\n  np.array([1.0, 5.0, 2.0]),\n  np.array([3.0, 4.0, -1.0]),\n  np.array([5.0, 7.0, -5.0])\n], np.array([0.1, 0.2, 0.3]))  Its output should be  array([ 1.,  4., -5.], dtype=float32)\n\n[array([ 0.1, 0., 0.], dtype=float32),\narray([ 0., 0.2, 0.], dtype=float32),\narray([ 0., 0., 0.30000001], dtype=float32)]", 
            "title": "CMinTable"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/", 
            "text": "Scale\n\n\nScala:\n\n\nval m = Scale(Array(2, 1))\n\n\n\n\nPython:\n\n\nm = scale = Scale([2, 1])\n\n\n\n\nScale is the combination of cmul and cadd. \nScale(size).forward(input) == CAdd(size).forward(CMul(size).forward(input))\n\nComputes the elementwise product of input and weight, with the shape of the weight \"expand\" to\nmatch the shape of the input.Similarly, perform a expand cdd bias and perform an elementwise add.\n\noutput = input .* weight .+ bias (element wise)\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(2, 3).fill(1f)\nprintln(\ninput:\n)\nprintln(input)\nval scale = Scale(Array(2, 1))\nval weight = Tensor(2, 1).fill(2f)\nval bias = Tensor(2, 1).fill(3f)\nscale.setWeightsBias(Array(weight, bias))\nprintln(\nWeight:\n)\nprintln(weight)\nprintln(\nbias:\n)\nprintln(bias)\nprintln(\noutput:\n)\nprint(scale.forward(input))\n\n\n\n\ninput:\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\nWeight:\n2.0 \n2.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1]\nbias:\n3.0 \n3.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1]\noutput:\n5.0 5.0 5.0 \n5.0 5.0 5.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\ninput = np.ones([2, 3])\nprint(\ninput:\n)\nprint(input)\nscale = Scale([2, 1])\nweight = np.full([2, 1], 2)\nbias = np.full([2, 1], 3)\nprint(\nweight: \n)\nprint(weight)\nprint(\nbias: \n)\nprint(bias)\nscale.set_weights([weight, bias])\nprint(\noutput: \n)\nprint(scale.forward(input))\n\n\n\n\n\ninput:\n[[ 1.  1.  1.]\n [ 1.  1.  1.]]\ncreating: createScale\nweight: \n[[2]\n [2]]\nbias: \n[[3]\n [3]]\noutput: \n[[ 5.  5.  5.]\n [ 5.  5.  5.]]\n\n\n\n\nMin\n\n\nScala:\n\n\nval min = Min(dim, numInputDims)\n\n\n\n\nPython:\n\n\nmin = Min(dim, num_input_dims)\n\n\n\n\nApplies a min operation over dimension \ndim\n.\n\n\nParameters:\n\n\n \ndim\n - A integer. The dimension to min along.\n\n \nnumInputDims\n - An optional integer indicating the number of input dimensions.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval min = Min(2)\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval gradOutput = Tensor(T(\n 1.0f,\n 1.0f\n))\nval output = min.forward(input)\nval gradient = min.backward(input, gradOutput)\n-\n print(output)\n1.0\n3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n-\n print(gradient)\n1.0     0.0     \n1.0     0.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nmin = Min(2)\ninput = np.array([\n  [1.0, 2.0],\n  [3.0, 4.0]\n])\n\ngrad_output = np.array([1.0, 1.0])\noutput = min.forward(input)\ngradient = min.backward(input, grad_output)\n-\n print output\n[ 1.  3.]\n-\n print gradient\n[[ 1.  0.]\n [ 1.  0.]]\n\n\n\n\nAdd\n\n\nScala:\n\n\nval addLayer = Add(inputSize)\n\n\n\n\nPython:\n\n\nadd_layer = Add(input_size)\n\n\n\n\nA.K.A BiasAdd. This layer adds input tensor with a parameter tensor and output the result.\nIf the input is 1D, this layer just do a element-wise add. If the input has multiple dimentions,\nthis layer will treat the first dimension as batch dimension, resize the input tensor to a 2D \ntensor(batch-dimension x input_size) and do a broadcast add between the 2D tensor and the \nparameter.\n\n\nPlease note that the parameter will be trained in the back propagation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval addLayer = Add(4)\naddLayer.bias.set(Tensor(T(1.0f, 2.0f, 3.0f, 4.0f)))\naddLayer.forward(Tensor(T(T(1.0f, 1.0f, 1.0f, 1.0f), T(3.0f, 3.0f, 3.0f, 3.0f))))\naddLayer.backward(Tensor(T(T(1.0f, 1.0f, 1.0f, 1.0f), T(3.0f, 3.0f, 3.0f, 3.0f))),\n    Tensor(T(T(0.1f, 0.1f, 0.1f, 0.1f), T(0.3f, 0.3f, 0.3f, 0.3f))))\n\n\n\n\nIts output should be\n\n\n2.0     3.0     4.0     5.0\n4.0     5.0     6.0     7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n0.1     0.1     0.1     0.1\n0.3     0.3     0.3     0.3\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import Add\nimport numpy as np\n\nadd_layer = Add(4)\nadd_layer.set_weights([np.array([1.0, 2.0, 3.0, 4.0])])\nadd_layer.forward(np.array([[1.0, 1.0, 1.0, 1.0], [3.0, 3.0, 3.0, 3.0]]))\nadd_layer.backward(np.array([[1.0, 1.0, 1.0, 1.0], [3.0, 3.0, 3.0, 3.0]]),\n    np.array([[0.1, 0.1, 0.1, 0.1], [0.3, 0.3, 0.3, 0.3]]))\n\n\n\n\nIts output should be\n\n\narray([[ 2.,  3.,  4.,  5.],\n       [ 4.,  5.,  6.,  7.]], dtype=float32)\n\narray([[ 0.1       ,  0.1       ,  0.1       ,  0.1       ],\n       [ 0.30000001,  0.30000001,  0.30000001,  0.30000001]], dtype=float32)   \n\n\n\n\nBiLinear\n\n\nScala:\n\n\nval layer = BiLinear(\n  inputSize1,\n  inputSize2,\n  outputSize,\n  biasRes = true,\n  wRegularizer = null,\n  bRegularizer = null)\n\n\n\n\nPython:\n\n\nlayer = BiLinear(\n    input_size1,\n    input_size2,\n    output_size,\n    bias_res=True,\n    wRegularizer=None,\n    bRegularizer=None)\n\n\n\n\nA bilinear transformation with sparse inputs.\nThe input tensor given in forward(input) is a table containing both inputs x_1 and x_2,\nwhich are tensors of size N x inputDimension1 and N x inputDimension2, respectively.\n\n\nParameters:\n\n\ninputSize1\n   dimension of input x_1\n\n\ninputSize2\n   dimension of input x_2\n\n\noutputSize\n   output dimension\n\n\nbiasRes\n  The layer can be trained without biases by setting bias = false. otherwise true\n\n\nwRegularizer\n : instance of \nRegularizer\n\n             (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nbRegularizer\n : instance of \nRegularizer\n\n             applied to the bias.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Bilinear\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Bilinear(3, 2, 3)\nval input1 = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\nval input2 = Tensor(T(\n  T(-2f, 3f),\n  T(-1f, 2f),\n  T(-3f, 4f)\n))\nval input = T(input1, input2)\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n-0.14168167 -8.697224   -10.097688\n-0.20962894 -7.114827   -8.568602\n0.16706467  -19.751905  -24.516418\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n {\n    2: 13.411718    -18.695072\n       14.674414    -19.503393\n       13.9599  -17.271534\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n    1: -5.3747015   -17.803686  -17.558662\n       -2.413877    -8.373887   -8.346823\n       -2.239298    -11.249412  -14.537216\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }\n\n\n\n\nPython example:\n\n\nlayer = Bilinear(3, 2, 3)\ninput_1 = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ninput_2 = np.array([\n  [-3.0, 4.0],\n  [-2.0, 3.0],\n  [-1.0, 2.0]\n])\n\ninput = [input_1, input_2]\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[-0.5  1.5  2.5]\n [-1.5  2.5  3.5]\n [-2.5  3.5  4.5]]\n[[ 3.  4.  5.]\n [ 2.  3.  4.]\n [ 1.  2.  5.]]\n\nprint grad\n[array([[ 11.86168194, -14.02727222,  -6.16624403],\n       [  6.72984409,  -7.96572971,  -2.89302039],\n       [  5.52902842,  -5.76724434,  -1.46646953]], dtype=float32), array([[ 13.22105694,  -4.6879468 ],\n       [ 14.39296341,  -6.71434498],\n       [ 20.93929482, -13.02455521]], dtype=float32)]\n\n\n\n\nClamp\n\n\nScala:\n\n\nval model = Clamp(min, max)\n\n\n\n\nPython:\n\n\nmodel = Clamp(min, max)\n\n\n\n\nA kind of hard tanh activition function with integer min and max\n- param min min value\n- param max max value\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Clamp(-10, 10)\nval input = Tensor(2, 2, 2).rand()\nval output = model.forward(input)\n\nscala\n print(input)\n(1,.,.) =\n0.95979714  0.27654588  \n0.35592428  0.49355772  \n\n(2,.,.) =\n0.2624511   0.78833413  \n0.967827    0.59160346  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala\n print(output)\n(1,.,.) =\n0.95979714  0.27654588  \n0.35592428  0.49355772  \n\n(2,.,.) =\n0.2624511   0.78833413  \n0.967827    0.59160346  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n\n\n\nPython example:\n\n\nmodel = Clamp(-10, 10)\ninput = np.random.randn(2, 2, 2)\noutput = model.forward(input)\n\n\n print(input)\n[[[-0.66763755  1.15392566]\n  [-2.10846048  0.46931736]]\n\n [[ 1.74174638 -1.04323311]\n  [-1.91858729  0.12624046]]]\n\n\n print(output)\n[[[-0.66763753  1.15392566]\n  [-2.10846043  0.46931735]]\n\n [[ 1.74174643 -1.04323316]\n  [-1.91858733  0.12624046]]\n\n\n\n\nSquare\n\n\nScala:\n\n\nval module = Square()\n\n\n\n\nPython:\n\n\nmodule = Square()\n\n\n\n\nSquare apply an element-wise square operation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Square()\n\nprintln(module.forward(Tensor.range(1, 6, 1)))\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n4.0\n9.0\n16.0\n25.0\n36.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 6]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Square()\nprint(module.forward(np.arange(1, 7, 1)))\n\n\n\n\nOutput is\n\n\n[array([  1.,   4.,   9.,  16.,  25.,  36.], dtype=float32)]\n\n\n\n\nMean\n\n\nScala:\n\n\nval m = Mean(dimension=1, nInputDims=-1, squeeze=true)\n\n\n\n\nPython:\n\n\nm = Mean(dimension=1,n_input_dims=-1, squeeze=True)\n\n\n\n\nMean is a module that simply applies a mean operation over the given dimension - specified by \ndimension\n (starting from 1).\n\n\nThe input is expected to be either one tensor, or a batch of tensors (in mini-batch processing). If the input is a batch of tensors, you need to specify the number of dimensions of each tensor in the batch using \nnInputDims\n.  When input is one tensor, do not specify \nnInputDims\n or set it = -1, otherwise input will be interpreted as batch of tensors. \n\n\nScala example:\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(2, 2, 2).randn()\nval m1 = Mean()\nval output1 = m1.forward(input)\nval m2 = Mean(2,1,true)\nval output2 = m2.forward(input)\n\nscala\n print(input)\n(1,.,.) =\n-0.52021635     -1.8250599\n-0.2321481      -2.5672712\n\n(2,.,.) =\n4.007425        -0.8705412\n1.6506456       -0.2470611\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala\n print(output1)\n1.7436042       -1.3478005\n0.7092488       -1.4071661\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala\n print(output2)\n-0.37618223     -2.1961656\n2.8290353       -0.5588012\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(2,2,2)\nprint \ninput is :\n,input\n\nm1 = Mean()\nout = m1.forward(input)\nprint \noutput m1 is :\n,out\n\nm2 = Mean(2,1,True)\nout = m2.forward(input)\nprint \noutput m2 is :\n,out\n\n\n\n\nproduces output:\n\n\ninput is : [[[ 0.01990713  0.37740696]\n  [ 0.67689963  0.67715705]]\n\n [[ 0.45685026  0.58995121]\n  [ 0.33405769  0.86351324]]]\ncreating: createMean\noutput m1 is : [array([[ 0.23837869,  0.48367909],\n       [ 0.50547862,  0.77033514]], dtype=float32)]\ncreating: createMean\noutput m2 is : [array([[ 0.34840336,  0.527282  ],\n       [ 0.39545399,  0.72673225]], dtype=float32)]\n\n\n\n\nPower\n\n\nScala:\n\n\nval module = Power(power, scale=1, shift=0)\n\n\n\n\nPython:\n\n\nmodule = Power(power, scale=1.0, shift=0.0)\n\n\n\n\nApply an element-wise power operation with scale and shift.\n\n\nf(x) = (shift + scale * x)^power^\n\n\npower\n the exponent.\n \nscale\n Default is 1.\n \nshift\n Default is 0.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval power = Power(2, 1, 1)\nval input = Tensor(Storage(Array(0.0, 1, 2, 3, 4, 5)), 1, Array(2, 3))\n\n print(power.forward(input))\n1.0     4.0      9.0    \n16.0        25.0     36.0   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\npower = Power(2.0, 1.0, 1.0)\ninput = np.array([[0.0, 1, 2], [3, 4, 5]])\n\npower.forward(input)\narray([[  1.,   4.,   9.],\n       [ 16.,  25.,  36.]], dtype=float32)\n\n\n\n\n\nCMul\n\n\nScala:\n\n\nval module = CMul(size, wRegularizer = null)\n\n\n\n\nPython:\n\n\nmodule = CMul(size, wRegularizer=None)\n\n\n\n\nThis layer has a weight tensor with given size. The weight will be multiplied element wise to\nthe input tensor. If the element number of the weight tensor match the input tensor, a simply\nelement wise multiply will be done. Or the bias will be expanded to the same size of the input.\nThe expand means repeat on unmatched singleton dimension(if some unmatched dimension isn't\nsingleton dimension, it will report an error). If the input is a batch, a singleton dimension\nwill be add to the first dimension before the expand.\n\n\nsize\n the size of the bias, which is an array of bias shape\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = CMul(Array(2, 1))\nval input = Tensor(2, 3)\nvar i = 0\ninput.apply1(_ =\n {i += 1; i})\n\n print(layer.forward(input))\n-0.29362988     -0.58725977     -0.88088965\n1.9482219       2.4352775       2.9223328\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = CMul([2,1])\ninput = np.array([[1, 2, 3], [4, 5, 6]])\n\nlayer.forward(input)\narray([[-0.17618844, -0.35237688, -0.52856529],\n       [ 0.85603124,  1.07003903,  1.28404689]], dtype=float32)\n\n\n\n\nAddConstant\n\n\nScala:\n\n\nval module = AddConstant(constant_scalar,inplace= false)\n\n\n\n\nPython:\n\n\nmodule = AddConstant(constant_scalar,inplace=False,bigdl_type=\nfloat\n)\n\n\n\n\nElement wise add a constant scalar to input tensor\n\n @param constant_scalar constant value\n\n @param inplace Can optionally do its operation in-place without using extra state memory\n\n\nScala example:\n\n\nval module = AddConstant(3.0)\nval input = Tensor(2,3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.40684703      0.077655114     0.42314094\n0.55392265      0.8650696       0.3621729\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres11: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n3.406847        3.077655        3.423141\n3.5539227       3.8650696       3.3621728\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\n\nPython example:\n\n\nmodule = AddConstant(3.0,inplace=False,bigdl_type=\nfloat\n)\ninput = np.array([[1, 2, 3],[4, 5, 6]])\nmodule.forward(input)\n[array([\n[ 4.,  5.,  6.],\n[ 7.,  8.,  9.]], dtype=float32)]\n\n\n\n\nAbs\n\n\nScala:\n\n\nval m = Abs()\n\n\n\n\nPython:\n\n\nm = Abs()\n\n\n\n\nAn element-wise abs operation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval abs = new Abs\nval input = Tensor(2)\ninput(1) = 21f\ninput(2) = -29f\nprint(abs.forward(input))\n\n\n\n\noutput is:\u300021.0\u300029.0\n\n\nPython example:\n\n\nabs = Abs()\ninput = np.array([21, -29, 30])\nprint(abs.forward(input))\n\n\n\n\noutput is: [array([ 21.,  29.,  30.], dtype=float32)]\n\n\nLog\n\n\nScala:\n\n\nval log = Log()\n\n\n\n\nPython:\n\n\nlog = Log()\n\n\n\n\nThe Log module applies a log transformation to the input data\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval log = Log()\nval input = Tensor(T(1.0f, Math.E.toFloat))\nval gradOutput = Tensor(T(1.0f, 1.0f))\nval output = log.forward(input)\nval gradient = log.backward(input, gradOutput)\n-\n print(output)\n0.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n-\n print(gradient)\n1.0\n0.36787945\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nimport math\nlog = Log()\ninput = np.array([1.0, math.e])\ngrad_output = np.array([1.0, 1.0])\noutput = log.forward(input)\ngradient = log.backward(input, grad_output)\n\n-\n print output\n[ 0.  1.]\n\n-\n print gradient\n[ 1.          0.36787945]\n\n\n\n\nSum\n\n\nScala:\n\n\nval m = Sum(dimension=1,nInputDims=-1,sizeAverage=false,squeeze=true)\n\n\n\n\nPython:\n\n\nm = Sum(dimension=1,n_input_dims=-1,size_average=False,squeeze=True)\n\n\n\n\nSum is a module that simply applies a sum operation over the given dimension - specified by the argument \ndimension\n (starting from 1). \n\n\nThe input is expected to be either one tensor, or a batch of tensors (in mini-batch processing). If the input is a batch of tensors, you need to specify the number of dimensions of each tensor in the batch using \nnInputDims\n.  When input is one tensor, do not specify \nnInputDims\n or set it = -1, otherwise input will be interpreted as batch of tensors. \n\n\nScala example:\n\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(2, 2, 2).randn()\nval m1 = Sum(2)\nval output1 = m1.forward(input)\nval m2 = Sum(2, 1, true)\nval output2 = m2.forward(input)\n\nscala\n print(input)\n(1,.,.) =\n-0.003314678    0.96401167\n0.79000163      0.78624517\n\n(2,.,.) =\n-0.29975495     0.24742787\n0.8709072       0.4381108\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala\n print(output1)\n0.78668696      1.7502568\n0.5711522       0.68553865\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala\n print(output2)\n0.39334348      0.8751284\n0.2855761       0.34276932\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput=np.random.rand(2,2,2)\nprint \ninput is :\n,input\nmodule = Sum(2)\nout = module.forward(input)\nprint \noutput 1 is :\n,out\nmodule = Sum(2,1,True)\nout = module.forward(input)\nprint \noutput 2 is :\n,out\n\n\n\n\nproduces output:\n\n\ninput is : [[[ 0.7194801   0.99120677]\n  [ 0.07446639  0.056318  ]]\n\n [[ 0.08639016  0.17173268]\n  [ 0.71686986  0.30503663]]]\ncreating: createSum\noutput 1 is : [array([[ 0.7939465 ,  1.04752481],\n       [ 0.80325997,  0.47676933]], dtype=float32)]\ncreating: createSum\noutput 2 is : [array([[ 0.39697325,  0.5237624 ],\n       [ 0.40162998,  0.23838466]], dtype=float32)]\n\n\n\n\nSqrt\n\n\nApply an element-wise sqrt operation.\n\n\nScala:\n\n\nval sqrt = new Sqrt\n\n\n\n\nPython:\n\n\nsqrt = Sqrt()\n\n\n\n\nApply an element-wise sqrt operation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Sqrt\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(3, 5).range(1, 15, 1)\nval sqrt = new Sqrt\nval output = sqrt.forward(input)\nprintln(output)\n\nval gradOutput = Tensor(3, 5).range(2, 16, 1)\nval gradInput = sqrt.backward(input, gradOutput)\nprintln(gradOutput\n\n\n\n\nThe output will be,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.4142135       1.7320508       2.0     2.236068\n2.4494898       2.6457512       2.828427        3.0     3.1622777\n3.3166249       3.4641016       3.6055512       3.7416575       3.8729835\n\n\n\n\nThe gradInput will be,\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0606601       1.1547005       1.25    1.3416407\n1.428869        1.5118579       1.5909902       1.6666667       1.7392527\n1.8090681       1.8763883       1.9414507       2.0044594       2.065591\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nsqrt = Sqrt()\n\ninput = np.arange(1, 16, 1).astype(\nfloat32\n)\ninput = input.reshape(3, 5)\n\noutput = sqrt.forward(input)\nprint output\n\ngradOutput = np.arange(2, 17, 1).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(3, 5)\n\ngradInput = sqrt.backward(input, gradOutput)\nprint gradInput\n\n\n\n\nThe output will be:\n\n\n[array([[ 1.        ,  1.41421354,  1.73205078,  2.        ,  2.23606801],\n       [ 2.44948983,  2.64575124,  2.82842708,  3.        ,  3.1622777 ],\n       [ 3.31662488,  3.46410155,  3.60555124,  3.7416575 ,  3.87298346]], dtype=float32)]\n\n\n\n\nThe gradInput will be:\n\n\n[array([[ 1.        ,  1.06066012,  1.15470052,  1.25      ,  1.34164071],\n       [ 1.42886901,  1.51185787,  1.59099019,  1.66666675,  1.73925269],\n       [ 1.80906808,  1.87638831,  1.94145072,  2.00445938,  2.0655911 ]], dtype=float32)]\n\n\n\n\nExp\n\n\nScala:\n\n\nval exp = Exp()\n\n\n\n\nPython:\n\n\nexp = Exp()\n\n\n\n\nExp applies element-wise exp operation to input tensor\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval exp = Exp()\nval input = Tensor(3, 3).rand()\n\n print(input)\n0.0858663   0.28117087  0.85724664  \n0.62026995  0.29137492  0.07581586  \n0.22099794  0.45131826  0.78286386  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n print(exp.forward(input))\n1.0896606   1.32468     2.356663    \n1.85943     1.3382663   1.078764    \n1.2473209   1.5703809   2.1877286   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nexp = Exp()\n\n exp.forward(np.array([[1, 2, 3],[1, 2, 3]]))\n[array([[  2.71828175,   7.38905621,  20.08553696],\n       [  2.71828175,   7.38905621,  20.08553696]], dtype=float32)]\n\n\n\n\n\nMax\n\n\nScala:\n\n\nval layer = Max(dim = 1, numInputDims = Int.MinValue)\n\n\n\n\nPython:\n\n\nlayer = Max(dim, num_input_dims=INTMIN)\n\n\n\n\nApplies a max operation over dimension \ndim\n.\n\n\nParameters:\n\n\ndim\n max along this dimension\n\n\nnumInputDims\n Optional. If in a batch model, set to the inputDims.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Max\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Max(1, 1)\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(3f, 4f, 5f))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n3.0\n4.0\n5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\nprintln(grad)\n0.0 0.0 3.0\n0.0 0.0 4.0\n0.0 0.0 5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nlayer = Max(1, 1)\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([3.0, 4.0, 5.0])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[ 3.  4.  5.]\n\nprint grad\n[[ 0.  0.  3.]\n [ 0.  0.  4.]\n [ 0.  0.  5.]]\n``\n## CAdd ##\n\n**Scala:**\n```scala\nval module = CAdd(size,bRegularizer=null)\n\n\n\n\nPython:\n\n\nmodule = CAdd(size,bRegularizer=None,bigdl_type=\nfloat\n)\n\n\n\n\nThis layer has a bias tensor with given size. The bias will be added element wise to the input\ntensor. If the element number of the bias tensor match the input tensor, a simply element wise\nwill be done. Or the bias will be expanded to the same size of the input. The expand means\nrepeat on unmatched singleton dimension(if some unmatched dimension isn't singleton dimension,\nit will report an error). If the input is a batch, a singleton dimension will be add to the first\ndimension before the expand.\n\n\n\n\n@param size the size of the bias \n\n\n\n\nScala example:\n\n\nval module = CAdd(Array(2, 1),bRegularizer=null)\nval input = Tensor(2, 3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.52146345      0.86262375      0.74210143\n0.15882674      0.026310394     0.28394955\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres12: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.97027373      1.311434        1.1909117\n-0.047433108    -0.17994945     0.07768971\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nmodule = CAdd([2, 1],bRegularizer=None,bigdl_type=\nfloat\n)\ninput = np.random.rand(2, 3)\narray([[ 0.71239789,  0.65869477,  0.50425182],\n       [ 0.40333312,  0.64843273,  0.07286636]])\n\nmodule.forward(input)\narray([[ 0.89537328,  0.84167016,  0.68722725],\n       [ 0.1290929 ,  0.37419251, -0.20137388]], dtype=float32)\n\n\n\n\nCosine\n\n\nScala:\n\n\nval m = Cosine(inputSize, outputSize)\n\n\n\n\nPython:\n\n\nm = Cosine(input_size, output_size)\n\n\n\n\nCosine is a module used to  calculate the \ncosine similarity\n of the input to \noutputSize\n centers, i.e. this layer has the weights \nw_j\n, for \nj = 1,..,outputSize\n, where \nw_j\n are vectors of dimension \ninputSize\n.\n\n\nThe distance \ny_j\n between center \nj\n and input \nx\n is formulated as \ny_j = (x \u00b7 w_j) / ( || w_j || * || x || )\n.\n\n\nThe input given in \nforward(input)\n must be either a vector (1D tensor) or matrix (2D tensor). If the input is a\nvector, it must have the size of \ninputSize\n. If it is a matrix, then each row is assumed to be an input sample of given batch (the number of rows means the batch size and the number of columns should be equal to the \ninputSize\n).\n\n\nScala example:\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval m = Cosine(2, 3)\nval input = Tensor(3, 2).rand()\nval output = m.forward(input)\n\nscala\n print(input)\n0.48958543      0.38529378\n0.28814933      0.66979927\n0.3581584       0.67365724\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nscala\n print(output)\n0.998335        0.9098057       -0.71862763\n0.8496431       0.99756527      -0.2993874\n0.8901594       0.9999207       -0.37689084\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput=np.random.rand(2,3)\nprint \ninput is :\n,input\nmodule = Cosine(3,3)\nmodule.forward(input)\nprint \noutput is :\n,out\n\n\n\n\nproduces output:\n\n\ninput is : [[ 0.31156943  0.85577626  0.4274042 ]\n [ 0.79744055  0.66431136  0.05657437]]\ncreating: createCosine\noutput is : [array([[-0.73284394, -0.28076306, -0.51965958],\n       [-0.9563939 , -0.42036989, -0.08060561]], dtype=float32)]\n\n\n\n\n\n\nMul\n\n\nScala:\n\n\nval module = Mul()\n\n\n\n\nPython:\n\n\nmodule = Mul()\n\n\n\n\nMultiply a singla scalar factor to the incoming data\n\n\n                 +----Mul----+\n input -----+---\n input * weight -----+----\n output\n\n\n\n\nScala example:\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mul = Mul()\n\n\n print(mul.forward(Tensor(1, 5).rand()))\n-0.03212923     -0.019040342    -9.136753E-4    -0.014459004    -0.04096878\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmul = Mul()\ninput = np.random.uniform(0, 1, (1, 5)).astype(\nfloat32\n)\n\n\n mul.forward(input)\n[array([[ 0.72429317,  0.7377845 ,  0.09136307,  0.40439236,  0.29011244]], dtype=float32)]\n\n\n\n\n\nMulConstant\n\n\nScala:\n\n\nval layer = MulConstant(scalar, inplace)\n\n\n\n\nPython:\n\n\nlayer = MulConstant(const, inplace)\n\n\n\n\nMultiplies input Tensor by a (non-learnable) scalar constant.\nThis module is sometimes useful for debugging purposes.\n\n\nParameters:\n\n\n \nconstant\n - scalar constant\n\n \ninplace\n - Can optionally do its operation in-place without using extra state memory. Default: false\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval gradOutput = Tensor(T(\n T(1.0f, 1.0f),\n T(1.0f, 1.0f))\n)\nval scalar = 2.0\nval module = MulConstant(scalar)\nval output = module.forward(input)\nval gradient = module.backward(input, gradOutput)\n-\n print(output)\n2.0     4.0     \n6.0     8.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n-\n print(gradient)\n2.0     2.0     \n2.0     2.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ngrad_output = np.array([\n           [1.0, 1.0],\n           [1.0, 1.0]\n         ])\nscalar = 2.0\nmodule = MulConstant(scalar)\noutput = module.forward(input)\ngradient = module.backward(input, grad_output)\n-\n print output\n[[ 2.  4.]\n [ 6.  8.]]\n-\n print gradient\n[[ 2.  2.]\n [ 2.  2.]]", 
            "title": "Math Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#scale", 
            "text": "Scala:  val m = Scale(Array(2, 1))  Python:  m = scale = Scale([2, 1])  Scale is the combination of cmul and cadd.  Scale(size).forward(input) == CAdd(size).forward(CMul(size).forward(input)) \nComputes the elementwise product of input and weight, with the shape of the weight \"expand\" to\nmatch the shape of the input.Similarly, perform a expand cdd bias and perform an elementwise add. output = input .* weight .+ bias (element wise)  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(2, 3).fill(1f)\nprintln( input: )\nprintln(input)\nval scale = Scale(Array(2, 1))\nval weight = Tensor(2, 1).fill(2f)\nval bias = Tensor(2, 1).fill(3f)\nscale.setWeightsBias(Array(weight, bias))\nprintln( Weight: )\nprintln(weight)\nprintln( bias: )\nprintln(bias)\nprintln( output: )\nprint(scale.forward(input))  input:\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\nWeight:\n2.0 \n2.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1]\nbias:\n3.0 \n3.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1]\noutput:\n5.0 5.0 5.0 \n5.0 5.0 5.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\ninput = np.ones([2, 3])\nprint( input: )\nprint(input)\nscale = Scale([2, 1])\nweight = np.full([2, 1], 2)\nbias = np.full([2, 1], 3)\nprint( weight:  )\nprint(weight)\nprint( bias:  )\nprint(bias)\nscale.set_weights([weight, bias])\nprint( output:  )\nprint(scale.forward(input))  input:\n[[ 1.  1.  1.]\n [ 1.  1.  1.]]\ncreating: createScale\nweight: \n[[2]\n [2]]\nbias: \n[[3]\n [3]]\noutput: \n[[ 5.  5.  5.]\n [ 5.  5.  5.]]", 
            "title": "Scale"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#min", 
            "text": "Scala:  val min = Min(dim, numInputDims)  Python:  min = Min(dim, num_input_dims)  Applies a min operation over dimension  dim .  Parameters:    dim  - A integer. The dimension to min along.   numInputDims  - An optional integer indicating the number of input dimensions.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval min = Min(2)\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval gradOutput = Tensor(T(\n 1.0f,\n 1.0f\n))\nval output = min.forward(input)\nval gradient = min.backward(input, gradOutput)\n-  print(output)\n1.0\n3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n-  print(gradient)\n1.0     0.0     \n1.0     0.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nmin = Min(2)\ninput = np.array([\n  [1.0, 2.0],\n  [3.0, 4.0]\n])\n\ngrad_output = np.array([1.0, 1.0])\noutput = min.forward(input)\ngradient = min.backward(input, grad_output)\n-  print output\n[ 1.  3.]\n-  print gradient\n[[ 1.  0.]\n [ 1.  0.]]", 
            "title": "Min"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#add", 
            "text": "Scala:  val addLayer = Add(inputSize)  Python:  add_layer = Add(input_size)  A.K.A BiasAdd. This layer adds input tensor with a parameter tensor and output the result.\nIf the input is 1D, this layer just do a element-wise add. If the input has multiple dimentions,\nthis layer will treat the first dimension as batch dimension, resize the input tensor to a 2D \ntensor(batch-dimension x input_size) and do a broadcast add between the 2D tensor and the \nparameter.  Please note that the parameter will be trained in the back propagation.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval addLayer = Add(4)\naddLayer.bias.set(Tensor(T(1.0f, 2.0f, 3.0f, 4.0f)))\naddLayer.forward(Tensor(T(T(1.0f, 1.0f, 1.0f, 1.0f), T(3.0f, 3.0f, 3.0f, 3.0f))))\naddLayer.backward(Tensor(T(T(1.0f, 1.0f, 1.0f, 1.0f), T(3.0f, 3.0f, 3.0f, 3.0f))),\n    Tensor(T(T(0.1f, 0.1f, 0.1f, 0.1f), T(0.3f, 0.3f, 0.3f, 0.3f))))  Its output should be  2.0     3.0     4.0     5.0\n4.0     5.0     6.0     7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n0.1     0.1     0.1     0.1\n0.3     0.3     0.3     0.3\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]  Python example:  from bigdl.nn.layer import Add\nimport numpy as np\n\nadd_layer = Add(4)\nadd_layer.set_weights([np.array([1.0, 2.0, 3.0, 4.0])])\nadd_layer.forward(np.array([[1.0, 1.0, 1.0, 1.0], [3.0, 3.0, 3.0, 3.0]]))\nadd_layer.backward(np.array([[1.0, 1.0, 1.0, 1.0], [3.0, 3.0, 3.0, 3.0]]),\n    np.array([[0.1, 0.1, 0.1, 0.1], [0.3, 0.3, 0.3, 0.3]]))  Its output should be  array([[ 2.,  3.,  4.,  5.],\n       [ 4.,  5.,  6.,  7.]], dtype=float32)\n\narray([[ 0.1       ,  0.1       ,  0.1       ,  0.1       ],\n       [ 0.30000001,  0.30000001,  0.30000001,  0.30000001]], dtype=float32)", 
            "title": "Add"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#bilinear", 
            "text": "Scala:  val layer = BiLinear(\n  inputSize1,\n  inputSize2,\n  outputSize,\n  biasRes = true,\n  wRegularizer = null,\n  bRegularizer = null)  Python:  layer = BiLinear(\n    input_size1,\n    input_size2,\n    output_size,\n    bias_res=True,\n    wRegularizer=None,\n    bRegularizer=None)  A bilinear transformation with sparse inputs.\nThe input tensor given in forward(input) is a table containing both inputs x_1 and x_2,\nwhich are tensors of size N x inputDimension1 and N x inputDimension2, respectively.  Parameters:  inputSize1    dimension of input x_1  inputSize2    dimension of input x_2  outputSize    output dimension  biasRes   The layer can be trained without biases by setting bias = false. otherwise true  wRegularizer  : instance of  Regularizer \n             (eg. L1 or L2 regularization), applied to the input weights matrices.  bRegularizer  : instance of  Regularizer \n             applied to the bias.  Scala example:  import com.intel.analytics.bigdl.nn.Bilinear\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Bilinear(3, 2, 3)\nval input1 = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\nval input2 = Tensor(T(\n  T(-2f, 3f),\n  T(-1f, 2f),\n  T(-3f, 4f)\n))\nval input = T(input1, input2)\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n-0.14168167 -8.697224   -10.097688\n-0.20962894 -7.114827   -8.568602\n0.16706467  -19.751905  -24.516418\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n {\n    2: 13.411718    -18.695072\n       14.674414    -19.503393\n       13.9599  -17.271534\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n    1: -5.3747015   -17.803686  -17.558662\n       -2.413877    -8.373887   -8.346823\n       -2.239298    -11.249412  -14.537216\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }  Python example:  layer = Bilinear(3, 2, 3)\ninput_1 = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ninput_2 = np.array([\n  [-3.0, 4.0],\n  [-2.0, 3.0],\n  [-1.0, 2.0]\n])\n\ninput = [input_1, input_2]\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[-0.5  1.5  2.5]\n [-1.5  2.5  3.5]\n [-2.5  3.5  4.5]]\n[[ 3.  4.  5.]\n [ 2.  3.  4.]\n [ 1.  2.  5.]]\n\nprint grad\n[array([[ 11.86168194, -14.02727222,  -6.16624403],\n       [  6.72984409,  -7.96572971,  -2.89302039],\n       [  5.52902842,  -5.76724434,  -1.46646953]], dtype=float32), array([[ 13.22105694,  -4.6879468 ],\n       [ 14.39296341,  -6.71434498],\n       [ 20.93929482, -13.02455521]], dtype=float32)]", 
            "title": "BiLinear"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#clamp", 
            "text": "Scala:  val model = Clamp(min, max)  Python:  model = Clamp(min, max)  A kind of hard tanh activition function with integer min and max\n- param min min value\n- param max max value  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Clamp(-10, 10)\nval input = Tensor(2, 2, 2).rand()\nval output = model.forward(input)\n\nscala  print(input)\n(1,.,.) =\n0.95979714  0.27654588  \n0.35592428  0.49355772  \n\n(2,.,.) =\n0.2624511   0.78833413  \n0.967827    0.59160346  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala  print(output)\n(1,.,.) =\n0.95979714  0.27654588  \n0.35592428  0.49355772  \n\n(2,.,.) =\n0.2624511   0.78833413  \n0.967827    0.59160346  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  Python example:  model = Clamp(-10, 10)\ninput = np.random.randn(2, 2, 2)\noutput = model.forward(input)  print(input)\n[[[-0.66763755  1.15392566]\n  [-2.10846048  0.46931736]]\n\n [[ 1.74174638 -1.04323311]\n  [-1.91858729  0.12624046]]]  print(output)\n[[[-0.66763753  1.15392566]\n  [-2.10846043  0.46931735]]\n\n [[ 1.74174643 -1.04323316]\n  [-1.91858733  0.12624046]]", 
            "title": "Clamp"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#square", 
            "text": "Scala:  val module = Square()  Python:  module = Square()  Square apply an element-wise square operation.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Square()\n\nprintln(module.forward(Tensor.range(1, 6, 1)))  Output is  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n4.0\n9.0\n16.0\n25.0\n36.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 6]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Square()\nprint(module.forward(np.arange(1, 7, 1)))  Output is  [array([  1.,   4.,   9.,  16.,  25.,  36.], dtype=float32)]", 
            "title": "Square"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#mean", 
            "text": "Scala:  val m = Mean(dimension=1, nInputDims=-1, squeeze=true)  Python:  m = Mean(dimension=1,n_input_dims=-1, squeeze=True)  Mean is a module that simply applies a mean operation over the given dimension - specified by  dimension  (starting from 1).  The input is expected to be either one tensor, or a batch of tensors (in mini-batch processing). If the input is a batch of tensors, you need to specify the number of dimensions of each tensor in the batch using  nInputDims .  When input is one tensor, do not specify  nInputDims  or set it = -1, otherwise input will be interpreted as batch of tensors.   Scala example:  scala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(2, 2, 2).randn()\nval m1 = Mean()\nval output1 = m1.forward(input)\nval m2 = Mean(2,1,true)\nval output2 = m2.forward(input)\n\nscala  print(input)\n(1,.,.) =\n-0.52021635     -1.8250599\n-0.2321481      -2.5672712\n\n(2,.,.) =\n4.007425        -0.8705412\n1.6506456       -0.2470611\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala  print(output1)\n1.7436042       -1.3478005\n0.7092488       -1.4071661\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala  print(output2)\n-0.37618223     -2.1961656\n2.8290353       -0.5588012\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(2,2,2)\nprint  input is : ,input\n\nm1 = Mean()\nout = m1.forward(input)\nprint  output m1 is : ,out\n\nm2 = Mean(2,1,True)\nout = m2.forward(input)\nprint  output m2 is : ,out  produces output:  input is : [[[ 0.01990713  0.37740696]\n  [ 0.67689963  0.67715705]]\n\n [[ 0.45685026  0.58995121]\n  [ 0.33405769  0.86351324]]]\ncreating: createMean\noutput m1 is : [array([[ 0.23837869,  0.48367909],\n       [ 0.50547862,  0.77033514]], dtype=float32)]\ncreating: createMean\noutput m2 is : [array([[ 0.34840336,  0.527282  ],\n       [ 0.39545399,  0.72673225]], dtype=float32)]", 
            "title": "Mean"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#power", 
            "text": "Scala:  val module = Power(power, scale=1, shift=0)  Python:  module = Power(power, scale=1.0, shift=0.0)  Apply an element-wise power operation with scale and shift.  f(x) = (shift + scale * x)^power^  power  the exponent.\n  scale  Default is 1.\n  shift  Default is 0.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval power = Power(2, 1, 1)\nval input = Tensor(Storage(Array(0.0, 1, 2, 3, 4, 5)), 1, Array(2, 3))  print(power.forward(input))\n1.0     4.0      9.0    \n16.0        25.0     36.0   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  from bigdl.nn.layer import *\n\npower = Power(2.0, 1.0, 1.0)\ninput = np.array([[0.0, 1, 2], [3, 4, 5]]) power.forward(input)\narray([[  1.,   4.,   9.],\n       [ 16.,  25.,  36.]], dtype=float32)", 
            "title": "Power"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#cmul", 
            "text": "Scala:  val module = CMul(size, wRegularizer = null)  Python:  module = CMul(size, wRegularizer=None)  This layer has a weight tensor with given size. The weight will be multiplied element wise to\nthe input tensor. If the element number of the weight tensor match the input tensor, a simply\nelement wise multiply will be done. Or the bias will be expanded to the same size of the input.\nThe expand means repeat on unmatched singleton dimension(if some unmatched dimension isn't\nsingleton dimension, it will report an error). If the input is a batch, a singleton dimension\nwill be add to the first dimension before the expand.  size  the size of the bias, which is an array of bias shape  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = CMul(Array(2, 1))\nval input = Tensor(2, 3)\nvar i = 0\ninput.apply1(_ =  {i += 1; i})  print(layer.forward(input))\n-0.29362988     -0.58725977     -0.88088965\n1.9482219       2.4352775       2.9223328\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  from bigdl.nn.layer import *\n\nlayer = CMul([2,1])\ninput = np.array([[1, 2, 3], [4, 5, 6]]) layer.forward(input)\narray([[-0.17618844, -0.35237688, -0.52856529],\n       [ 0.85603124,  1.07003903,  1.28404689]], dtype=float32)", 
            "title": "CMul"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#addconstant", 
            "text": "Scala:  val module = AddConstant(constant_scalar,inplace= false)  Python:  module = AddConstant(constant_scalar,inplace=False,bigdl_type= float )  Element wise add a constant scalar to input tensor  @param constant_scalar constant value  @param inplace Can optionally do its operation in-place without using extra state memory  Scala example:  val module = AddConstant(3.0)\nval input = Tensor(2,3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.40684703      0.077655114     0.42314094\n0.55392265      0.8650696       0.3621729\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres11: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n3.406847        3.077655        3.423141\n3.5539227       3.8650696       3.3621728\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  module = AddConstant(3.0,inplace=False,bigdl_type= float )\ninput = np.array([[1, 2, 3],[4, 5, 6]])\nmodule.forward(input)\n[array([\n[ 4.,  5.,  6.],\n[ 7.,  8.,  9.]], dtype=float32)]", 
            "title": "AddConstant"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#abs", 
            "text": "Scala:  val m = Abs()  Python:  m = Abs()  An element-wise abs operation.  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval abs = new Abs\nval input = Tensor(2)\ninput(1) = 21f\ninput(2) = -29f\nprint(abs.forward(input))  output is:\u300021.0\u300029.0  Python example:  abs = Abs()\ninput = np.array([21, -29, 30])\nprint(abs.forward(input))  output is: [array([ 21.,  29.,  30.], dtype=float32)]", 
            "title": "Abs"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#log", 
            "text": "Scala:  val log = Log()  Python:  log = Log()  The Log module applies a log transformation to the input data  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval log = Log()\nval input = Tensor(T(1.0f, Math.E.toFloat))\nval gradOutput = Tensor(T(1.0f, 1.0f))\nval output = log.forward(input)\nval gradient = log.backward(input, gradOutput)\n-  print(output)\n0.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n-  print(gradient)\n1.0\n0.36787945\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nimport math\nlog = Log()\ninput = np.array([1.0, math.e])\ngrad_output = np.array([1.0, 1.0])\noutput = log.forward(input)\ngradient = log.backward(input, grad_output)\n\n-  print output\n[ 0.  1.]\n\n-  print gradient\n[ 1.          0.36787945]", 
            "title": "Log"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#sum", 
            "text": "Scala:  val m = Sum(dimension=1,nInputDims=-1,sizeAverage=false,squeeze=true)  Python:  m = Sum(dimension=1,n_input_dims=-1,size_average=False,squeeze=True)  Sum is a module that simply applies a sum operation over the given dimension - specified by the argument  dimension  (starting from 1).   The input is expected to be either one tensor, or a batch of tensors (in mini-batch processing). If the input is a batch of tensors, you need to specify the number of dimensions of each tensor in the batch using  nInputDims .  When input is one tensor, do not specify  nInputDims  or set it = -1, otherwise input will be interpreted as batch of tensors.   Scala example:  \nscala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(2, 2, 2).randn()\nval m1 = Sum(2)\nval output1 = m1.forward(input)\nval m2 = Sum(2, 1, true)\nval output2 = m2.forward(input)\n\nscala  print(input)\n(1,.,.) =\n-0.003314678    0.96401167\n0.79000163      0.78624517\n\n(2,.,.) =\n-0.29975495     0.24742787\n0.8709072       0.4381108\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala  print(output1)\n0.78668696      1.7502568\n0.5711522       0.68553865\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala  print(output2)\n0.39334348      0.8751284\n0.2855761       0.34276932\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput=np.random.rand(2,2,2)\nprint  input is : ,input\nmodule = Sum(2)\nout = module.forward(input)\nprint  output 1 is : ,out\nmodule = Sum(2,1,True)\nout = module.forward(input)\nprint  output 2 is : ,out  produces output:  input is : [[[ 0.7194801   0.99120677]\n  [ 0.07446639  0.056318  ]]\n\n [[ 0.08639016  0.17173268]\n  [ 0.71686986  0.30503663]]]\ncreating: createSum\noutput 1 is : [array([[ 0.7939465 ,  1.04752481],\n       [ 0.80325997,  0.47676933]], dtype=float32)]\ncreating: createSum\noutput 2 is : [array([[ 0.39697325,  0.5237624 ],\n       [ 0.40162998,  0.23838466]], dtype=float32)]", 
            "title": "Sum"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#sqrt", 
            "text": "Apply an element-wise sqrt operation.  Scala:  val sqrt = new Sqrt  Python:  sqrt = Sqrt()  Apply an element-wise sqrt operation.  Scala example:  import com.intel.analytics.bigdl.nn.Sqrt\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(3, 5).range(1, 15, 1)\nval sqrt = new Sqrt\nval output = sqrt.forward(input)\nprintln(output)\n\nval gradOutput = Tensor(3, 5).range(2, 16, 1)\nval gradInput = sqrt.backward(input, gradOutput)\nprintln(gradOutput  The output will be,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.4142135       1.7320508       2.0     2.236068\n2.4494898       2.6457512       2.828427        3.0     3.1622777\n3.3166249       3.4641016       3.6055512       3.7416575       3.8729835  The gradInput will be,  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0606601       1.1547005       1.25    1.3416407\n1.428869        1.5118579       1.5909902       1.6666667       1.7392527\n1.8090681       1.8763883       1.9414507       2.0044594       2.065591  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nsqrt = Sqrt()\n\ninput = np.arange(1, 16, 1).astype( float32 )\ninput = input.reshape(3, 5)\n\noutput = sqrt.forward(input)\nprint output\n\ngradOutput = np.arange(2, 17, 1).astype( float32 )\ngradOutput = gradOutput.reshape(3, 5)\n\ngradInput = sqrt.backward(input, gradOutput)\nprint gradInput  The output will be:  [array([[ 1.        ,  1.41421354,  1.73205078,  2.        ,  2.23606801],\n       [ 2.44948983,  2.64575124,  2.82842708,  3.        ,  3.1622777 ],\n       [ 3.31662488,  3.46410155,  3.60555124,  3.7416575 ,  3.87298346]], dtype=float32)]  The gradInput will be:  [array([[ 1.        ,  1.06066012,  1.15470052,  1.25      ,  1.34164071],\n       [ 1.42886901,  1.51185787,  1.59099019,  1.66666675,  1.73925269],\n       [ 1.80906808,  1.87638831,  1.94145072,  2.00445938,  2.0655911 ]], dtype=float32)]", 
            "title": "Sqrt"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#exp", 
            "text": "Scala:  val exp = Exp()  Python:  exp = Exp()  Exp applies element-wise exp operation to input tensor  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval exp = Exp()\nval input = Tensor(3, 3).rand()  print(input)\n0.0858663   0.28117087  0.85724664  \n0.62026995  0.29137492  0.07581586  \n0.22099794  0.45131826  0.78286386  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(exp.forward(input))\n1.0896606   1.32468     2.356663    \n1.85943     1.3382663   1.078764    \n1.2473209   1.5703809   2.1877286   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nexp = Exp()  exp.forward(np.array([[1, 2, 3],[1, 2, 3]]))\n[array([[  2.71828175,   7.38905621,  20.08553696],\n       [  2.71828175,   7.38905621,  20.08553696]], dtype=float32)]", 
            "title": "Exp"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#max", 
            "text": "Scala:  val layer = Max(dim = 1, numInputDims = Int.MinValue)  Python:  layer = Max(dim, num_input_dims=INTMIN)  Applies a max operation over dimension  dim .  Parameters:  dim  max along this dimension  numInputDims  Optional. If in a batch model, set to the inputDims.  Scala example:  import com.intel.analytics.bigdl.nn.Max\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Max(1, 1)\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(3f, 4f, 5f))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n3.0\n4.0\n5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\nprintln(grad)\n0.0 0.0 3.0\n0.0 0.0 4.0\n0.0 0.0 5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  layer = Max(1, 1)\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([3.0, 4.0, 5.0])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[ 3.  4.  5.]\n\nprint grad\n[[ 0.  0.  3.]\n [ 0.  0.  4.]\n [ 0.  0.  5.]]\n``\n## CAdd ##\n\n**Scala:**\n```scala\nval module = CAdd(size,bRegularizer=null)  Python:  module = CAdd(size,bRegularizer=None,bigdl_type= float )  This layer has a bias tensor with given size. The bias will be added element wise to the input\ntensor. If the element number of the bias tensor match the input tensor, a simply element wise\nwill be done. Or the bias will be expanded to the same size of the input. The expand means\nrepeat on unmatched singleton dimension(if some unmatched dimension isn't singleton dimension,\nit will report an error). If the input is a batch, a singleton dimension will be add to the first\ndimension before the expand.   @param size the size of the bias    Scala example:  val module = CAdd(Array(2, 1),bRegularizer=null)\nval input = Tensor(2, 3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.52146345      0.86262375      0.74210143\n0.15882674      0.026310394     0.28394955\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres12: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.97027373      1.311434        1.1909117\n-0.047433108    -0.17994945     0.07768971\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  module = CAdd([2, 1],bRegularizer=None,bigdl_type= float )\ninput = np.random.rand(2, 3)\narray([[ 0.71239789,  0.65869477,  0.50425182],\n       [ 0.40333312,  0.64843273,  0.07286636]])\n\nmodule.forward(input)\narray([[ 0.89537328,  0.84167016,  0.68722725],\n       [ 0.1290929 ,  0.37419251, -0.20137388]], dtype=float32)", 
            "title": "Max"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#cosine", 
            "text": "Scala:  val m = Cosine(inputSize, outputSize)  Python:  m = Cosine(input_size, output_size)  Cosine is a module used to  calculate the  cosine similarity  of the input to  outputSize  centers, i.e. this layer has the weights  w_j , for  j = 1,..,outputSize , where  w_j  are vectors of dimension  inputSize .  The distance  y_j  between center  j  and input  x  is formulated as  y_j = (x \u00b7 w_j) / ( || w_j || * || x || ) .  The input given in  forward(input)  must be either a vector (1D tensor) or matrix (2D tensor). If the input is a\nvector, it must have the size of  inputSize . If it is a matrix, then each row is assumed to be an input sample of given batch (the number of rows means the batch size and the number of columns should be equal to the  inputSize ).  Scala example:  scala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval m = Cosine(2, 3)\nval input = Tensor(3, 2).rand()\nval output = m.forward(input)\n\nscala  print(input)\n0.48958543      0.38529378\n0.28814933      0.66979927\n0.3581584       0.67365724\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nscala  print(output)\n0.998335        0.9098057       -0.71862763\n0.8496431       0.99756527      -0.2993874\n0.8901594       0.9999207       -0.37689084\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput=np.random.rand(2,3)\nprint  input is : ,input\nmodule = Cosine(3,3)\nmodule.forward(input)\nprint  output is : ,out  produces output:  input is : [[ 0.31156943  0.85577626  0.4274042 ]\n [ 0.79744055  0.66431136  0.05657437]]\ncreating: createCosine\noutput is : [array([[-0.73284394, -0.28076306, -0.51965958],\n       [-0.9563939 , -0.42036989, -0.08060561]], dtype=float32)]", 
            "title": "Cosine"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#mul", 
            "text": "Scala:  val module = Mul()  Python:  module = Mul()  Multiply a singla scalar factor to the incoming data                   +----Mul----+\n input -----+---  input * weight -----+----  output  Scala example:  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mul = Mul()  print(mul.forward(Tensor(1, 5).rand()))\n-0.03212923     -0.019040342    -9.136753E-4    -0.014459004    -0.04096878\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmul = Mul()\ninput = np.random.uniform(0, 1, (1, 5)).astype( float32 )  mul.forward(input)\n[array([[ 0.72429317,  0.7377845 ,  0.09136307,  0.40439236,  0.29011244]], dtype=float32)]", 
            "title": "Mul"
        }, 
        {
            "location": "/APIdocs/Layers/Math-Layers/#mulconstant", 
            "text": "Scala:  val layer = MulConstant(scalar, inplace)  Python:  layer = MulConstant(const, inplace)  Multiplies input Tensor by a (non-learnable) scalar constant.\nThis module is sometimes useful for debugging purposes.  Parameters:    constant  - scalar constant   inplace  - Can optionally do its operation in-place without using extra state memory. Default: false  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval gradOutput = Tensor(T(\n T(1.0f, 1.0f),\n T(1.0f, 1.0f))\n)\nval scalar = 2.0\nval module = MulConstant(scalar)\nval output = module.forward(input)\nval gradient = module.backward(input, gradOutput)\n-  print(output)\n2.0     4.0     \n6.0     8.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n-  print(gradient)\n2.0     2.0     \n2.0     2.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ngrad_output = np.array([\n           [1.0, 1.0],\n           [1.0, 1.0]\n         ])\nscalar = 2.0\nmodule = MulConstant(scalar)\noutput = module.forward(input)\ngradient = module.backward(input, grad_output)\n-  print output\n[[ 2.  4.]\n [ 6.  8.]]\n-  print gradient\n[[ 2.  2.]\n [ 2.  2.]]", 
            "title": "MulConstant"
        }, 
        {
            "location": "/APIdocs/Layers/Padding-Layers/", 
            "text": "SpatialZeroPadding\n\n\nScala:\n\n\nval spatialZeroPadding = SpatialZeroPadding(padLeft, padRight, padTop, padBottom)\n\n\n\n\nPython:\n\n\nspatialZeroPadding = SpatialZeroPadding(pad_left, pad_right, pad_top, pad_bottom)\n\n\n\n\nEach feature map of a given input is padded with specified number of zeros.\n\n\nIf padding values are negative, then input will be cropped.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialZeroPadding = SpatialZeroPadding(1, 0, -1, 0)\nval input = Tensor(3, 3, 3).rand()\n\n print(input)\n(1,.,.) =\n0.9494078   0.31556255  0.8432871   \n0.0064580487    0.6487367   0.151881    \n0.8822722   0.3634125   0.7034494   \n\n(2,.,.) =\n0.32691675  0.07487922  0.08813124  \n0.4564806   0.37191486  0.05507739  \n0.10097649  0.6589037   0.8721945   \n\n(3,.,.) =\n0.068939745 0.040364727 0.4893642   \n0.39481318  0.17923461  0.15748173  \n0.87117475  0.9933199   0.6097995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3x3]\n\n\n  print(spatialZeroPadding.forward(input))\n(1,.,.) =\n0.0 0.0064580487    0.6487367   0.151881    \n0.0 0.8822722   0.3634125   0.7034494   \n\n(2,.,.) =\n0.0 0.4564806   0.37191486  0.05507739  \n0.0 0.10097649  0.6589037   0.8721945   \n\n(3,.,.) =\n0.0 0.39481318  0.17923461  0.15748173  \n0.0 0.87117475  0.9933199   0.6097995   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2x4]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nspatialZeroPadding = SpatialZeroPadding(1, 0, -1, 0)\n\n spatialZeroPadding.forward(np.array([[[1, 2],[3, 4]],[[1, 2],[3, 4]]]))\n[array([[[ 0.,  3.,  4.]],\n       [[ 0.,  3.,  4.]]], dtype=float32)]\n\n\n\n\n\nPadding\n\n\nScala:\n\n\nval module = Padding(dim,pad,nInputDim,value=0.0,nIndex=1)\n\n\n\n\nPython:\n\n\nmodule = Padding(dim,pad,n_input_dim,value=0.0,n_index=1,bigdl_type=\nfloat\n)\n\n\n\n\nThis module adds pad units of padding to dimension dim of the input. If pad is negative,\npadding is added to the left, otherwise, it is added to the right of the dimension.\nThe input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user need to specify the number of dimensions of each sample tensor in the\nbatch using nInputDims.\n\n\n\n\n@param dim the dimension to be applied padding operation\n\n\n@param pad num of the pad units\n\n\n@param nInputDim specify the number of dimensions that this module will receive\n                  If it is more than the dimension of input tensors, the first dimension\n                  would be considered as batch size\n\n\n@param value padding value, default is 0\n\n\n\n\nScala example:\n\n\nval module = Padding(1,-1,3,value=0.0,nIndex=1)\nval input = Tensor(3,2,1).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.673425\n0.9350421\n\n(2,.,.) =\n0.35407698\n0.52607465\n\n(3,.,.) =\n0.7226349\n0.70645845\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2x1]\n\nmodule.forward(input)\nres14: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.0\n0.0\n\n(2,.,.) =\n0.673425\n0.9350421\n\n(3,.,.) =\n0.35407698\n0.52607465\n\n(4,.,.) =\n0.7226349\n0.70645845\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4x2x1]\n\n\n\n\n\nPython example:\n\n\nmodule = Padding(1, -1, 3, value=0.0,n_index=1,bigdl_type=\nfloat\n)\ninput = np.random.rand(3, 2, 1)\narray([[[ 0.81505274],\n        [ 0.55769512]],\n\n       [[ 0.13193961],\n        [ 0.32610741]],\n\n       [[ 0.29855582],\n        [ 0.47394154]]])\n\nmodule.forward(input)\narray([[[ 0.        ],\n        [ 0.        ]],\n\n       [[ 0.81505275],\n        [ 0.55769515]],\n\n       [[ 0.1319396 ],\n        [ 0.32610741]],\n\n       [[ 0.29855582],\n        [ 0.47394153]]], dtype=float32)", 
            "title": "Padding Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Padding-Layers/#spatialzeropadding", 
            "text": "Scala:  val spatialZeroPadding = SpatialZeroPadding(padLeft, padRight, padTop, padBottom)  Python:  spatialZeroPadding = SpatialZeroPadding(pad_left, pad_right, pad_top, pad_bottom)  Each feature map of a given input is padded with specified number of zeros.  If padding values are negative, then input will be cropped.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialZeroPadding = SpatialZeroPadding(1, 0, -1, 0)\nval input = Tensor(3, 3, 3).rand()  print(input)\n(1,.,.) =\n0.9494078   0.31556255  0.8432871   \n0.0064580487    0.6487367   0.151881    \n0.8822722   0.3634125   0.7034494   \n\n(2,.,.) =\n0.32691675  0.07487922  0.08813124  \n0.4564806   0.37191486  0.05507739  \n0.10097649  0.6589037   0.8721945   \n\n(3,.,.) =\n0.068939745 0.040364727 0.4893642   \n0.39481318  0.17923461  0.15748173  \n0.87117475  0.9933199   0.6097995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3x3]   print(spatialZeroPadding.forward(input))\n(1,.,.) =\n0.0 0.0064580487    0.6487367   0.151881    \n0.0 0.8822722   0.3634125   0.7034494   \n\n(2,.,.) =\n0.0 0.4564806   0.37191486  0.05507739  \n0.0 0.10097649  0.6589037   0.8721945   \n\n(3,.,.) =\n0.0 0.39481318  0.17923461  0.15748173  \n0.0 0.87117475  0.9933199   0.6097995   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2x4]  Python example:  from bigdl.nn.layer import *\nspatialZeroPadding = SpatialZeroPadding(1, 0, -1, 0)  spatialZeroPadding.forward(np.array([[[1, 2],[3, 4]],[[1, 2],[3, 4]]]))\n[array([[[ 0.,  3.,  4.]],\n       [[ 0.,  3.,  4.]]], dtype=float32)]", 
            "title": "SpatialZeroPadding"
        }, 
        {
            "location": "/APIdocs/Layers/Padding-Layers/#padding", 
            "text": "Scala:  val module = Padding(dim,pad,nInputDim,value=0.0,nIndex=1)  Python:  module = Padding(dim,pad,n_input_dim,value=0.0,n_index=1,bigdl_type= float )  This module adds pad units of padding to dimension dim of the input. If pad is negative,\npadding is added to the left, otherwise, it is added to the right of the dimension.\nThe input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user need to specify the number of dimensions of each sample tensor in the\nbatch using nInputDims.   @param dim the dimension to be applied padding operation  @param pad num of the pad units  @param nInputDim specify the number of dimensions that this module will receive\n                  If it is more than the dimension of input tensors, the first dimension\n                  would be considered as batch size  @param value padding value, default is 0   Scala example:  val module = Padding(1,-1,3,value=0.0,nIndex=1)\nval input = Tensor(3,2,1).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.673425\n0.9350421\n\n(2,.,.) =\n0.35407698\n0.52607465\n\n(3,.,.) =\n0.7226349\n0.70645845\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2x1]\n\nmodule.forward(input)\nres14: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.0\n0.0\n\n(2,.,.) =\n0.673425\n0.9350421\n\n(3,.,.) =\n0.35407698\n0.52607465\n\n(4,.,.) =\n0.7226349\n0.70645845\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4x2x1]  Python example:  module = Padding(1, -1, 3, value=0.0,n_index=1,bigdl_type= float )\ninput = np.random.rand(3, 2, 1)\narray([[[ 0.81505274],\n        [ 0.55769512]],\n\n       [[ 0.13193961],\n        [ 0.32610741]],\n\n       [[ 0.29855582],\n        [ 0.47394154]]])\n\nmodule.forward(input)\narray([[[ 0.        ],\n        [ 0.        ]],\n\n       [[ 0.81505275],\n        [ 0.55769515]],\n\n       [[ 0.1319396 ],\n        [ 0.32610741]],\n\n       [[ 0.29855582],\n        [ 0.47394153]]], dtype=float32)", 
            "title": "Padding"
        }, 
        {
            "location": "/APIdocs/Layers/Normalization-Layers/", 
            "text": "SpatialSubtractiveNormalization\n\n\nScala:\n\n\nval spatialSubtractiveNormalization = SpatialSubtractiveNormalization(nInputPlane = 1, kernel = null)\n\n\n\n\nPython:\n\n\nspatialSubtractiveNormalization = SpatialSubtractiveNormalization(n_input_plane=1, kernel=None)\n\n\n\n\nSpatialSubtractiveNormalization applies a spatial subtraction operation on a series of 2D inputs using kernel for computing the weighted average in a neighborhood.The neighborhood is defined for a local spatial region that is the size as kernel and across all features. For an input image, since there is only one feature, the region is only spatial. For an RGB image, the weighted average is taken over RGB channels and a spatial region.\n\n\nIf the kernel is 1D, then it will be used for constructing and separable 2D kernel.\nThe operations will be much more efficient in this case.\n\n\nThe kernel is generally chosen as a gaussian when it is believed that the correlation\nof two pixel locations decrease with increasing distance. On the feature dimension,\na uniform average is used since the weighting across features is not known.\n\n\nnInputPlane : number of input plane, default is 1.\nkernel : kernel tensor, default is a 9 x 9 tensor.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval kernel = Tensor(3, 3).rand()\n\n\n print(kernel)\n0.56141114  0.76815456  0.29409808  \n0.3599753   0.17142025  0.5243272   \n0.62450963  0.28084084  0.17154165  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\nval spatialSubtractiveNormalization = SpatialSubtractiveNormalization(1, kernel)\n\nval input = Tensor(1, 1, 1, 5).rand()\n\n\n print(input)\n(1,1,.,.) =\n0.122356184 0.44442436  0.6394927   0.9349956   0.8226007   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x1x5]\n\n\n print(spatialSubtractiveNormalization.forward(input))\n(1,1,.,.) =\n-0.2427161  0.012936085 -0.08024883 0.15658027  -0.07613802 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x5]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nkernel=np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9]])\nspatialSubtractiveNormalization = SpatialSubtractiveNormalization(1, kernel)\n\n  spatialSubtractiveNormalization.forward(np.array([[[[1, 2, 3, 4, 5]]]]))\n[array([[[[ 0.,  0.,  0.,  0.,  0.]]]], dtype=float32)]\n\n\n\n\n\n\nNormalize\n\n\nScala:\n\n\nval module = Normalize(p,eps=1e-10)\n\n\n\n\nPython:\n\n\nmodule = Normalize(p,eps=1e-10,bigdl_type=\nfloat\n)\n\n\n\n\nNormalizes the input Tensor to have unit L_p norm. The smoothing parameter eps prevents\ndivision by zero when the input contains all zero elements (default = 1e-10).\nThe input can be 1d, 2d or 4d. If the input is 4d, it should follow the format (n, c, h, w) where n is the batch number,\nc is the channel number, h is the height and w is the width\n * @param p L_p norm\n * @param eps smoothing parameter\n\n\nScala example:\n\n\nval module = Normalize(2.0,eps=1e-10)\nval input = Tensor(2,3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.7075603       0.084298864     0.91339105\n0.22373432      0.8704987       0.6936567\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres8: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6107763       0.072768        0.7884524\n0.19706465      0.76673317      0.61097115\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nmodule = Normalize(2.0,eps=1e-10,bigdl_type=\nfloat\n)\ninput = np.array([[1, 2, 3],[4, 5, 6]])\nmodule.forward(input)\n[array([\n[ 0.26726124,  0.53452247,  0.80178368],\n[ 0.45584232,  0.56980288,  0.68376344]], dtype=float32)]\n\n\n\n\nSpatialBatchNormalization\n\n\nScala:\n\n\nval module = SpatialBatchNormalization(nOutput, eps=1e-5, momentum=0.1, affine=true,\n                                           initWeight=null, initBias=null, initGradWeight=null, initGradBias=null)\n\n\n\n\nPython:\n\n\nmodule = SpatialBatchNormalization(nOutput, eps=1e-5, momentum=0.1, affine=True)\n\n\n\n\n\nThis file implements Batch Normalization as described in the paper:\n\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\"\nby Sergey Ioffe, Christian Szegedy.\n\n\nThis implementation is useful for inputs coming from convolution layers.\nFor non-convolutional layers, see \nBatchNormalization\n\nThe operation implemented is:\n ``` \n        ( x - mean(x) )\n  y = -------------------- * gamma + beta\n       standard-deviation(x)\n\n\nwhere gamma and beta are learnable parameters.\n  The learning of gamma and beta is optional.\n\n\n`nOutput` output feature map number\n\n`eps` avoid divide zero\n\n`momentum` momentum for weight update\n\n`affine` affine operation on output or not\n\n`initWeight` initial weight tensor\n\n`initBias`  initial bias tensor\n\n`initGradWeight` initial gradient weight \n\n`initGradBias` initial gradient bias\n\n\n**Scala example:**\n```scala\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SpatialBatchNormalization(3, 1e-3)\nval input = Tensor(2, 3, 2, 2).randn()\n\n print(layer.forward(input))\n(1,1,.,.) =\n-0.21939678 -0.64394164 \n-0.03280549 0.13889995  \n\n(1,2,.,.) =\n0.48519397  0.40222475  \n-0.9339038  0.4131121   \n\n(1,3,.,.) =\n0.39790314  -0.040012743    \n-0.009540742    0.21598668  \n\n(2,1,.,.) =\n0.32008895  -0.23125978 \n0.4053611   0.26305377  \n\n(2,2,.,.) =\n-0.3810518  -0.34581286 \n0.14797378  0.21226381  \n\n(2,3,.,.) =\n0.2558251   -0.2211882  \n-0.59388477 -0.00508846 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = SpatialBatchNormalization(3, 1e-3)\ninput = np.random.rand(2,3,2,2)\n\nlayer.forward(input)\narray([[[[  5.70826093e-03,   9.06338100e-05],\n         [ -3.49177676e-03,   1.10401707e-02]],\n\n        [[  1.80168569e-01,  -8.87815133e-02],\n         [  2.11335659e-01,   2.11817324e-01]],\n\n        [[ -1.02916014e+00,   4.02444333e-01],\n         [ -1.72453150e-01,   5.31806648e-01]]],\n\n\n       [[[ -3.46255396e-03,  -1.37512591e-02],\n         [  3.84721952e-03,   1.93112865e-05]],\n\n        [[  4.65962708e-01,  -5.29752195e-01],\n         [ -2.28064612e-01,  -2.22685724e-01]],\n\n        [[  8.49217057e-01,  -9.03094828e-01],\n         [  8.56826544e-01,  -5.35586655e-01]]]], dtype=float32)\n\n\n\n\nSpatialDivisiveNormalization\n\n\nScala:\n\n\nval layer = SpatialDivisiveNormalization()\n\n\n\n\nPython:\n\n\nlayer = SpatialDivisiveNormalization()\n\n\n\n\nApplies a spatial division operation on a series of 2D inputs using kernel for\ncomputing the weighted average in a neighborhood. The neighborhood is defined for\na local spatial region that is the size as kernel and across all features. For\nan input image, since there is only one feature, the region is only spatial. For\nan RGB image, the weighted average is taken over RGB channels and a spatial region.\n\n\nIf the kernel is 1D, then it will be used for constructing and separable 2D kernel.\nThe operations will be much more efficient in this case.\n\n\nThe kernel is generally chosen as a gaussian when it is believed that the correlation\nof two pixel locations decrease with increasing distance. On the feature dimension,\na uniform average is used since the weighting across features is not known.\n\n\nScala example:\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = SpatialDivisiveNormalization()\nval input = Tensor(1, 5, 5).rand\nval gradOutput = Tensor(1, 5, 5).rand\n\nval output = layer.forward(input)\nval gradInput = layer.backward(input, gradOutput)\n\n\n println(input)\nres19: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.4022106       0.6872489       0.9712838       0.7769542       0.771034\n0.97930336      0.61022973      0.65092266      0.9507807       0.3158211\n0.12607759      0.320569        0.9267993       0.47579524      0.63989824\n0.713135        0.30836385      0.009723447     0.67723924      0.24405171\n0.51036286      0.115807846     0.123513035     0.28398398      0.271164\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]\n\n\n println(output)\nres20: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.37849638      0.6467289       0.91401714      0.73114514      0.725574\n0.9215639       0.57425076      0.6125444       0.89472294      0.29720038\n0.11864409      0.30166835      0.8721555       0.4477425       0.60217\n0.67108876      0.2901828       0.009150156     0.6373094       0.2296625\n0.480272        0.10897984      0.11623074      0.26724035      0.25517625\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]\n\n\n println(gradInput)\nres21: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.09343022     -0.25612304     0.25756648      -0.66132677     -0.44575396\n0.052990615     0.7899354       0.27205157      0.028260134     0.23150417\n-0.115425855    0.21133065      0.53093016      -0.36421964     -0.102551565\n0.7222408       0.46287358      0.0010696054    0.26336592      -0.050598443\n0.03733714      0.2775169       -0.21430963     0.3175013       0.6600435\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nlayer = SpatialDivisiveNormalization()\ninput = np.random.uniform(0, 1, (1, 5, 5)).astype(\nfloat32\n)\ngradOutput = np.random.uniform(0, 1, (1, 5, 5)).astype(\nfloat32\n)\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, gradOutput)\n\n\n output\n[array([[[ 0.30657911,  0.75221181,  0.2318386 ,  0.84053135,  0.24818985],\n         [ 0.32852787,  0.43504578,  0.0219258 ,  0.47856906,  0.31112722],\n         [ 0.12381417,  0.61807972,  0.90043157,  0.57342309,  0.65450585],\n         [ 0.00401461,  0.33700454,  0.79859954,  0.64382601,  0.51768768],\n         [ 0.38087726,  0.8963666 ,  0.7982524 ,  0.78525543,  0.09658573]]], dtype=float32)]\n\n gradInput\n[array([[[ 0.08059166, -0.4616771 ,  0.11626807,  0.30253756,  0.7333734 ],\n         [ 0.2633073 , -0.01641282,  0.40653706,  0.07766753, -0.0237394 ],\n         [ 0.10733987,  0.23385212, -0.3291783 , -0.12808481,  0.4035565 ],\n         [ 0.56126803,  0.49945205, -0.40531909, -0.18559581,  0.27156472],\n         [ 0.28016835,  0.03791744, -0.17803842, -0.27817759,  0.42473239]]], dtype=float32)]\n\n\n\n\nSpatialCrossMapLRN\n\n\nScala:\n\n\nval spatialCrossMapLRN = SpatialCrossMapLRN(size = 5, alpha  = 1.0, beta = 0.75, k = 1.0)\n\n\n\n\nPython:\n\n\nspatialCrossMapLRN = SpatialCrossMapLRN(size=5, alpha=1.0, beta=0.75, k=1.0)\n\n\n\n\nSpatialCrossMapLRN applies Spatial Local Response Normalization between different feature maps\n\n\n                             x_f\n  y_f =  -------------------------------------------------\n          (k+(alpha/size)* sum_{l=l1 to l2} (x_l^2^))^beta^\n\nwhere  l1 corresponds to `max(0,f-ceil(size/2))` and l2 to `min(F, f-ceil(size/2) + size)`, `F` is the number  of feature maps       \n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialCrossMapLRN = SpatialCrossMapLRN(5, 0.01, 0.75, 1.0)\n\nval input = Tensor(2, 2, 2, 2).rand()\n\n\n print(input)\n(1,1,.,.) =\n0.42596373  0.20075735  \n0.10307904  0.7486494   \n\n(1,2,.,.) =\n0.9887414   0.3554662   \n0.6291069   0.53952795  \n\n(2,1,.,.) =\n0.41220918  0.5463298   \n0.40766734  0.08064394  \n\n(2,2,.,.) =\n0.58255607  0.027811589 \n0.47811228  0.3082057   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]\n\n\n print(spatialCrossMapLRN.forward(input))\n(1,1,.,.) =\n0.42522463  0.20070718  \n0.10301625  0.74769455  \n\n(1,2,.,.) =\n0.98702586  0.35537735  \n0.6287237   0.5388398   \n\n(2,1,.,.) =\n0.41189456  0.5460847   \n0.4074261   0.08063166  \n\n(2,2,.,.) =\n0.5821114   0.02779911  \n0.47782937  0.3081588   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nspatialCrossMapLRN = SpatialCrossMapLRN(5, 0.01, 0.75, 1.0)\n\n spatialCrossMapLRN.forward(np.array([[[[1, 2],[3, 4]],[[5, 6],[7, 8]]],[[[9, 10],[11, 12]],[[13, 14],[15, 16]]]]))\n[array([[[[  0.96269381,   1.88782692],\n         [  2.76295042,   3.57862759]],\n\n        [[  4.81346893,   5.66348076],\n         [  6.44688463,   7.15725517]]],\n\n\n       [[[  6.6400919 ,   7.05574226],\n         [  7.41468   ,   7.72194815]],\n\n        [[  9.59124374,   9.87803936],\n         [ 10.11092758,  10.29593086]]]], dtype=float32)]\n\n\n\n\n\n\nBatchNormalization\n\n\nScala:\n\n\nval bn = BatchNormalization(nOutput, eps, momentum, affine)\n\n\n\n\nPython:\n\n\nbn = BatchNormalization(n_output, eps, momentum, affine)\n\n\n\n\nThis layer implements Batch Normalization as described in the paper:\n\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n\nby Sergey Ioffe, Christian Szegedy\n\n\nThis implementation is useful for inputs NOT coming from convolution layers. For convolution layers, use nn.SpatialBatchNormalization.\n\n\nThe operation implemented is:\n\n\n              ( x - mean(x) )\n      y =  -------------------- * gamma + beta\n              standard-deviation(x)\n\n\n\n\nwhere gamma and beta are learnable parameters.The learning of gamma and beta is optional.\n\n\nParameters:\n\n\n \nnOutput\n - feature map number\n\n \neps\n - avoid divide zero. Default: 1e-5\n\n \nmomentum\n - momentum for weight update. Default: 0.1\n\n \naffine\n - affine operation on output or not. Default: true\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval bn = BatchNormalization(2)\nval input = Tensor(T(\n             T(1.0f, 2.0f),\n             T(3.0f, 6.0f))\n            )\nval gradOutput = Tensor(T(\n             T(1.0f, 2.0f),\n             T(3.0f, 6.0f))\n)\nval output = bn.forward(input)\nval gradient = bn.backward(input, gradOutput)\n-\n print(output) \n# There's random factor. An output could be\n-0.46433213     -0.2762179      \n0.46433213      0.2762179       \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n-\n print(gradient)\n# There's random factor. An output could be\n-4.649627E-6    -6.585548E-7    \n4.649627E-6     6.585548E-7     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nbn = BatchNormalization(2)\ninput = np.array([\n  [1.0, 2.0],\n  [3.0, 6.0]\n])\ngrad_output = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = bn.forward(input)\ngradient = bn.backward(input, grad_output)\n-\n print output\n# There's random factor. An output could be\n[[-0.99583918 -0.13030811]\n [ 0.99583918  0.13030811]]\n-\n print gradient\n# There's random factor. An output could be\n[[ -9.97191637e-06  -1.55339364e-07]\n [  9.97191637e-06   1.55339364e-07]]", 
            "title": "Normalization Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Normalization-Layers/#spatialsubtractivenormalization", 
            "text": "Scala:  val spatialSubtractiveNormalization = SpatialSubtractiveNormalization(nInputPlane = 1, kernel = null)  Python:  spatialSubtractiveNormalization = SpatialSubtractiveNormalization(n_input_plane=1, kernel=None)  SpatialSubtractiveNormalization applies a spatial subtraction operation on a series of 2D inputs using kernel for computing the weighted average in a neighborhood.The neighborhood is defined for a local spatial region that is the size as kernel and across all features. For an input image, since there is only one feature, the region is only spatial. For an RGB image, the weighted average is taken over RGB channels and a spatial region.  If the kernel is 1D, then it will be used for constructing and separable 2D kernel.\nThe operations will be much more efficient in this case.  The kernel is generally chosen as a gaussian when it is believed that the correlation\nof two pixel locations decrease with increasing distance. On the feature dimension,\na uniform average is used since the weighting across features is not known.  nInputPlane : number of input plane, default is 1.\nkernel : kernel tensor, default is a 9 x 9 tensor.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval kernel = Tensor(3, 3).rand()  print(kernel)\n0.56141114  0.76815456  0.29409808  \n0.3599753   0.17142025  0.5243272   \n0.62450963  0.28084084  0.17154165  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\nval spatialSubtractiveNormalization = SpatialSubtractiveNormalization(1, kernel)\n\nval input = Tensor(1, 1, 1, 5).rand()  print(input)\n(1,1,.,.) =\n0.122356184 0.44442436  0.6394927   0.9349956   0.8226007   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x1x5]  print(spatialSubtractiveNormalization.forward(input))\n(1,1,.,.) =\n-0.2427161  0.012936085 -0.08024883 0.15658027  -0.07613802 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x5]  Python example:  from bigdl.nn.layer import *\nkernel=np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9]])\nspatialSubtractiveNormalization = SpatialSubtractiveNormalization(1, kernel)   spatialSubtractiveNormalization.forward(np.array([[[[1, 2, 3, 4, 5]]]]))\n[array([[[[ 0.,  0.,  0.,  0.,  0.]]]], dtype=float32)]", 
            "title": "SpatialSubtractiveNormalization"
        }, 
        {
            "location": "/APIdocs/Layers/Normalization-Layers/#normalize", 
            "text": "Scala:  val module = Normalize(p,eps=1e-10)  Python:  module = Normalize(p,eps=1e-10,bigdl_type= float )  Normalizes the input Tensor to have unit L_p norm. The smoothing parameter eps prevents\ndivision by zero when the input contains all zero elements (default = 1e-10).\nThe input can be 1d, 2d or 4d. If the input is 4d, it should follow the format (n, c, h, w) where n is the batch number,\nc is the channel number, h is the height and w is the width\n * @param p L_p norm\n * @param eps smoothing parameter  Scala example:  val module = Normalize(2.0,eps=1e-10)\nval input = Tensor(2,3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.7075603       0.084298864     0.91339105\n0.22373432      0.8704987       0.6936567\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres8: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6107763       0.072768        0.7884524\n0.19706465      0.76673317      0.61097115\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  module = Normalize(2.0,eps=1e-10,bigdl_type= float )\ninput = np.array([[1, 2, 3],[4, 5, 6]])\nmodule.forward(input)\n[array([\n[ 0.26726124,  0.53452247,  0.80178368],\n[ 0.45584232,  0.56980288,  0.68376344]], dtype=float32)]", 
            "title": "Normalize"
        }, 
        {
            "location": "/APIdocs/Layers/Normalization-Layers/#spatialbatchnormalization", 
            "text": "Scala:  val module = SpatialBatchNormalization(nOutput, eps=1e-5, momentum=0.1, affine=true,\n                                           initWeight=null, initBias=null, initGradWeight=null, initGradBias=null)  Python:  module = SpatialBatchNormalization(nOutput, eps=1e-5, momentum=0.1, affine=True)  This file implements Batch Normalization as described in the paper:\n\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\"\nby Sergey Ioffe, Christian Szegedy.  This implementation is useful for inputs coming from convolution layers.\nFor non-convolutional layers, see  BatchNormalization \nThe operation implemented is:\n ``` \n        ( x - mean(x) )\n  y = -------------------- * gamma + beta\n       standard-deviation(x)  where gamma and beta are learnable parameters.\n  The learning of gamma and beta is optional.  `nOutput` output feature map number\n\n`eps` avoid divide zero\n\n`momentum` momentum for weight update\n\n`affine` affine operation on output or not\n\n`initWeight` initial weight tensor\n\n`initBias`  initial bias tensor\n\n`initGradWeight` initial gradient weight \n\n`initGradBias` initial gradient bias\n\n\n**Scala example:**\n```scala\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SpatialBatchNormalization(3, 1e-3)\nval input = Tensor(2, 3, 2, 2).randn()  print(layer.forward(input))\n(1,1,.,.) =\n-0.21939678 -0.64394164 \n-0.03280549 0.13889995  \n\n(1,2,.,.) =\n0.48519397  0.40222475  \n-0.9339038  0.4131121   \n\n(1,3,.,.) =\n0.39790314  -0.040012743    \n-0.009540742    0.21598668  \n\n(2,1,.,.) =\n0.32008895  -0.23125978 \n0.4053611   0.26305377  \n\n(2,2,.,.) =\n-0.3810518  -0.34581286 \n0.14797378  0.21226381  \n\n(2,3,.,.) =\n0.2558251   -0.2211882  \n-0.59388477 -0.00508846 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2x2]  Python example:  from bigdl.nn.layer import *\n\nlayer = SpatialBatchNormalization(3, 1e-3)\ninput = np.random.rand(2,3,2,2) layer.forward(input)\narray([[[[  5.70826093e-03,   9.06338100e-05],\n         [ -3.49177676e-03,   1.10401707e-02]],\n\n        [[  1.80168569e-01,  -8.87815133e-02],\n         [  2.11335659e-01,   2.11817324e-01]],\n\n        [[ -1.02916014e+00,   4.02444333e-01],\n         [ -1.72453150e-01,   5.31806648e-01]]],\n\n\n       [[[ -3.46255396e-03,  -1.37512591e-02],\n         [  3.84721952e-03,   1.93112865e-05]],\n\n        [[  4.65962708e-01,  -5.29752195e-01],\n         [ -2.28064612e-01,  -2.22685724e-01]],\n\n        [[  8.49217057e-01,  -9.03094828e-01],\n         [  8.56826544e-01,  -5.35586655e-01]]]], dtype=float32)", 
            "title": "SpatialBatchNormalization"
        }, 
        {
            "location": "/APIdocs/Layers/Normalization-Layers/#spatialdivisivenormalization", 
            "text": "Scala:  val layer = SpatialDivisiveNormalization()  Python:  layer = SpatialDivisiveNormalization()  Applies a spatial division operation on a series of 2D inputs using kernel for\ncomputing the weighted average in a neighborhood. The neighborhood is defined for\na local spatial region that is the size as kernel and across all features. For\nan input image, since there is only one feature, the region is only spatial. For\nan RGB image, the weighted average is taken over RGB channels and a spatial region.  If the kernel is 1D, then it will be used for constructing and separable 2D kernel.\nThe operations will be much more efficient in this case.  The kernel is generally chosen as a gaussian when it is believed that the correlation\nof two pixel locations decrease with increasing distance. On the feature dimension,\na uniform average is used since the weighting across features is not known.  Scala example:  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = SpatialDivisiveNormalization()\nval input = Tensor(1, 5, 5).rand\nval gradOutput = Tensor(1, 5, 5).rand\n\nval output = layer.forward(input)\nval gradInput = layer.backward(input, gradOutput)  println(input)\nres19: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.4022106       0.6872489       0.9712838       0.7769542       0.771034\n0.97930336      0.61022973      0.65092266      0.9507807       0.3158211\n0.12607759      0.320569        0.9267993       0.47579524      0.63989824\n0.713135        0.30836385      0.009723447     0.67723924      0.24405171\n0.51036286      0.115807846     0.123513035     0.28398398      0.271164\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]  println(output)\nres20: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.37849638      0.6467289       0.91401714      0.73114514      0.725574\n0.9215639       0.57425076      0.6125444       0.89472294      0.29720038\n0.11864409      0.30166835      0.8721555       0.4477425       0.60217\n0.67108876      0.2901828       0.009150156     0.6373094       0.2296625\n0.480272        0.10897984      0.11623074      0.26724035      0.25517625\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]  println(gradInput)\nres21: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.09343022     -0.25612304     0.25756648      -0.66132677     -0.44575396\n0.052990615     0.7899354       0.27205157      0.028260134     0.23150417\n-0.115425855    0.21133065      0.53093016      -0.36421964     -0.102551565\n0.7222408       0.46287358      0.0010696054    0.26336592      -0.050598443\n0.03733714      0.2775169       -0.21430963     0.3175013       0.6600435\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nlayer = SpatialDivisiveNormalization()\ninput = np.random.uniform(0, 1, (1, 5, 5)).astype( float32 )\ngradOutput = np.random.uniform(0, 1, (1, 5, 5)).astype( float32 )\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, gradOutput)  output\n[array([[[ 0.30657911,  0.75221181,  0.2318386 ,  0.84053135,  0.24818985],\n         [ 0.32852787,  0.43504578,  0.0219258 ,  0.47856906,  0.31112722],\n         [ 0.12381417,  0.61807972,  0.90043157,  0.57342309,  0.65450585],\n         [ 0.00401461,  0.33700454,  0.79859954,  0.64382601,  0.51768768],\n         [ 0.38087726,  0.8963666 ,  0.7982524 ,  0.78525543,  0.09658573]]], dtype=float32)]  gradInput\n[array([[[ 0.08059166, -0.4616771 ,  0.11626807,  0.30253756,  0.7333734 ],\n         [ 0.2633073 , -0.01641282,  0.40653706,  0.07766753, -0.0237394 ],\n         [ 0.10733987,  0.23385212, -0.3291783 , -0.12808481,  0.4035565 ],\n         [ 0.56126803,  0.49945205, -0.40531909, -0.18559581,  0.27156472],\n         [ 0.28016835,  0.03791744, -0.17803842, -0.27817759,  0.42473239]]], dtype=float32)]", 
            "title": "SpatialDivisiveNormalization"
        }, 
        {
            "location": "/APIdocs/Layers/Normalization-Layers/#spatialcrossmaplrn", 
            "text": "Scala:  val spatialCrossMapLRN = SpatialCrossMapLRN(size = 5, alpha  = 1.0, beta = 0.75, k = 1.0)  Python:  spatialCrossMapLRN = SpatialCrossMapLRN(size=5, alpha=1.0, beta=0.75, k=1.0)  SpatialCrossMapLRN applies Spatial Local Response Normalization between different feature maps                               x_f\n  y_f =  -------------------------------------------------\n          (k+(alpha/size)* sum_{l=l1 to l2} (x_l^2^))^beta^\n\nwhere  l1 corresponds to `max(0,f-ceil(size/2))` and l2 to `min(F, f-ceil(size/2) + size)`, `F` is the number  of feature maps         Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialCrossMapLRN = SpatialCrossMapLRN(5, 0.01, 0.75, 1.0)\n\nval input = Tensor(2, 2, 2, 2).rand()  print(input)\n(1,1,.,.) =\n0.42596373  0.20075735  \n0.10307904  0.7486494   \n\n(1,2,.,.) =\n0.9887414   0.3554662   \n0.6291069   0.53952795  \n\n(2,1,.,.) =\n0.41220918  0.5463298   \n0.40766734  0.08064394  \n\n(2,2,.,.) =\n0.58255607  0.027811589 \n0.47811228  0.3082057   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]  print(spatialCrossMapLRN.forward(input))\n(1,1,.,.) =\n0.42522463  0.20070718  \n0.10301625  0.74769455  \n\n(1,2,.,.) =\n0.98702586  0.35537735  \n0.6287237   0.5388398   \n\n(2,1,.,.) =\n0.41189456  0.5460847   \n0.4074261   0.08063166  \n\n(2,2,.,.) =\n0.5821114   0.02779911  \n0.47782937  0.3081588   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2]  Python example:  from bigdl.nn.layer import *\nspatialCrossMapLRN = SpatialCrossMapLRN(5, 0.01, 0.75, 1.0)  spatialCrossMapLRN.forward(np.array([[[[1, 2],[3, 4]],[[5, 6],[7, 8]]],[[[9, 10],[11, 12]],[[13, 14],[15, 16]]]]))\n[array([[[[  0.96269381,   1.88782692],\n         [  2.76295042,   3.57862759]],\n\n        [[  4.81346893,   5.66348076],\n         [  6.44688463,   7.15725517]]],\n\n\n       [[[  6.6400919 ,   7.05574226],\n         [  7.41468   ,   7.72194815]],\n\n        [[  9.59124374,   9.87803936],\n         [ 10.11092758,  10.29593086]]]], dtype=float32)]", 
            "title": "SpatialCrossMapLRN"
        }, 
        {
            "location": "/APIdocs/Layers/Normalization-Layers/#batchnormalization", 
            "text": "Scala:  val bn = BatchNormalization(nOutput, eps, momentum, affine)  Python:  bn = BatchNormalization(n_output, eps, momentum, affine)  This layer implements Batch Normalization as described in the paper: Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift \nby Sergey Ioffe, Christian Szegedy  This implementation is useful for inputs NOT coming from convolution layers. For convolution layers, use nn.SpatialBatchNormalization.  The operation implemented is:                ( x - mean(x) )\n      y =  -------------------- * gamma + beta\n              standard-deviation(x)  where gamma and beta are learnable parameters.The learning of gamma and beta is optional.  Parameters:    nOutput  - feature map number   eps  - avoid divide zero. Default: 1e-5   momentum  - momentum for weight update. Default: 0.1   affine  - affine operation on output or not. Default: true  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval bn = BatchNormalization(2)\nval input = Tensor(T(\n             T(1.0f, 2.0f),\n             T(3.0f, 6.0f))\n            )\nval gradOutput = Tensor(T(\n             T(1.0f, 2.0f),\n             T(3.0f, 6.0f))\n)\nval output = bn.forward(input)\nval gradient = bn.backward(input, gradOutput)\n-  print(output) \n# There's random factor. An output could be\n-0.46433213     -0.2762179      \n0.46433213      0.2762179       \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n-  print(gradient)\n# There's random factor. An output could be\n-4.649627E-6    -6.585548E-7    \n4.649627E-6     6.585548E-7     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nbn = BatchNormalization(2)\ninput = np.array([\n  [1.0, 2.0],\n  [3.0, 6.0]\n])\ngrad_output = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = bn.forward(input)\ngradient = bn.backward(input, grad_output)\n-  print output\n# There's random factor. An output could be\n[[-0.99583918 -0.13030811]\n [ 0.99583918  0.13030811]]\n-  print gradient\n# There's random factor. An output could be\n[[ -9.97191637e-06  -1.55339364e-07]\n [  9.97191637e-06   1.55339364e-07]]", 
            "title": "BatchNormalization"
        }, 
        {
            "location": "/APIdocs/Layers/Dropout-Layers/", 
            "text": "Dropout\n\n\nScala:\n\n\nval module = Dropout(\n  initP = 0.5,\n  inplace = false,\n  scale = true)\n\n\n\n\nPython:\n\n\nmodule = Dropout(\n  init_p=0.5,\n  inplace=False,\n  scale=True)\n\n\n\n\nDropout masks(set to zero) parts of input using a bernoulli distribution.\nEach input element has a probability \ninitP\n of being dropped. If \nscale\n is\ntrue(true by default), the outputs are scaled by a factor of \n1/(1-initP)\n during training.\nDuring evaluating, output is the same as input.\n\n\nIt has been proven an effective approach for regularization and preventing\nco-adaptation of feature detectors. For more details, plese see\n[Improving neural networks by preventing co-adaptation of feature detectors]\n(https://arxiv.org/abs/1207.0580)\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Dropout()\nval x = Tensor.range(1, 8, 1).resize(2, 4)\n\nprintln(module.forward(x))\nprintln(module.backward(x, x.clone().mul(0.5f))) // backward drops out the gradients at the same location.\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0     4.0     6.0     0.0\n10.0    12.0    0.0     16.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0    2.0    3.0    0.0\n5.0    6.0    0.0    8.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Dropout()\nx = np.arange(1, 9, 1).reshape(2, 4)\n\nprint(module.forward(x))\nprint(module.backward(x, x.copy() * 0.5)) # backward drops out the gradients at the same location.\n\n\n\n\nOutput is\n\n\n[array([[ 0.,  4.,  6.,  0.],\n       [ 0.,  0.,  0.,  0.]], dtype=float32)]\n\n[array([[ 0.,  2.,  3.,  0.],\n       [ 0.,  0.,  0.,  0.]], dtype=float32)]", 
            "title": "Dropout Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Dropout-Layers/#dropout", 
            "text": "Scala:  val module = Dropout(\n  initP = 0.5,\n  inplace = false,\n  scale = true)  Python:  module = Dropout(\n  init_p=0.5,\n  inplace=False,\n  scale=True)  Dropout masks(set to zero) parts of input using a bernoulli distribution.\nEach input element has a probability  initP  of being dropped. If  scale  is\ntrue(true by default), the outputs are scaled by a factor of  1/(1-initP)  during training.\nDuring evaluating, output is the same as input.  It has been proven an effective approach for regularization and preventing\nco-adaptation of feature detectors. For more details, plese see\n[Improving neural networks by preventing co-adaptation of feature detectors]\n(https://arxiv.org/abs/1207.0580)  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Dropout()\nval x = Tensor.range(1, 8, 1).resize(2, 4)\n\nprintln(module.forward(x))\nprintln(module.backward(x, x.clone().mul(0.5f))) // backward drops out the gradients at the same location.  Output is  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0     4.0     6.0     0.0\n10.0    12.0    0.0     16.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0    2.0    3.0    0.0\n5.0    6.0    0.0    8.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Dropout()\nx = np.arange(1, 9, 1).reshape(2, 4)\n\nprint(module.forward(x))\nprint(module.backward(x, x.copy() * 0.5)) # backward drops out the gradients at the same location.  Output is  [array([[ 0.,  4.,  6.,  0.],\n       [ 0.,  0.,  0.,  0.]], dtype=float32)]\n\n[array([[ 0.,  2.,  3.,  0.],\n       [ 0.,  0.,  0.,  0.]], dtype=float32)]", 
            "title": "Dropout"
        }, 
        {
            "location": "/APIdocs/Layers/Distance-Layers/", 
            "text": "PairwiseDistance\n\n\nScala:\n\n\nval pd = PairwiseDistance(norm=2)\n\n\n\n\nPython:\n\n\npd = PairwiseDistance(norm=2)\n\n\n\n\nIt is a module that takes a table of two vectors as input and outputs\nthe distance between them using the p-norm.\nThe input given in \nforward(input)\n is a [[Table]] that contains two tensors which\nmust be either a vector (1D tensor) or matrix (2D tensor). If the input is a vector,\nit must have the size of \ninputSize\n. If it is a matrix, then each row is assumed to be\nan input sample of the given batch (the number of rows means the batch size and\nthe number of columns should be equal to the \ninputSize\n).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.PairwiseDistance\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval pd = PairwiseDistance()\nval input1 = Tensor(3, 3).randn()\nval input2 = Tensor(3, 3).randn()\nval input = T(1 -\n input1, 2 -\n input2)\n\nval output = pd.forward(input)\n\nval gradOutput = Tensor(3).randn()\nval gradInput = pd.backward(input, gradOutput)\n\n\n\n\n\nThe ouotput is,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n4.155246\n1.1267666\n2.1415536\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.32565984\n-1.0108998\n-0.030873261\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\n\n\n\nThe gradInput is,\n\n\ngradInput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: 0.012723052  0.31482473      0.08232752\n           0.7552968    -0.27292773     -0.6139655\n           0.0062761847 -0.018232936    -0.024110721\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n        1: -0.012723052 -0.31482473     -0.08232752\n           -0.7552968   0.27292773      0.6139655\n           -0.0062761847        0.018232936     0.024110721\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\npd = PairwiseDistance()\n\ninput1 = np.random.uniform(0, 1, [3, 3]).astype(\nfloat32\n)\ninput2 = np.random.uniform(0, 1, [3, 3]).astype(\nfloat32\n)\ninput1 = input1.reshape(3, 3)\ninput2 = input2.reshape(3, 3)\n\ninput = [input1, input2]\n\noutput = pd.forward(input)\nprint output\n\ngradOutput = np.random.uniform(0, 1, [3]).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(3)\n\ngradInput = pd.backward(input, gradOutput)\nprint gradInput\n\n\n\n\nThe output is,\n\n\n[ 0.99588805  0.65620303  1.11735415]\n\n\n\n\nThe gradInput is,\n\n\n[array([[-0.27412388,  0.32756016, -0.02032043],\n       [-0.16920818,  0.60189474,  0.21347123],\n       [ 0.57771122,  0.28602061,  0.58044904]], dtype=float32), array([[ 0.27412388, -0.32756016,  0.02032043],\n       [ 0.16920818, -0.60189474, -0.21347123],\n       [-0.57771122, -0.28602061, -0.58044904]], dtype=float32)]\n\n\n\n\nCosineDistance\n\n\nScala:\n\n\nval module = CosineDistance()\n\n\n\n\nPython:\n\n\nmodule = CosineDistance()\n\n\n\n\nCosineDistance creates a module that takes a table of two vectors (or matrices if in batch mode) as input and outputs the cosine distance between them.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = CosineDistance()\nval t1 = Tensor().range(1, 3)\nval t2 = Tensor().range(4, 6)\nval input = T(t1, t2)\nval output = module.forward(input)\n\n\n input\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n    2: 4.0\n       5.0\n       6.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    1: 1.0\n       2.0\n       3.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\n\n output\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9746319\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = CosineDistance()\nt1 = np.array([1.0, 2.0, 3.0])\nt2 = np.array([4.0, 5.0, 6.0])\ninput = [t1, t2]\noutput = module.forward(input)\n\n\n input\n[array([ 1.,  2.,  3.]), array([ 4.,  5.,  6.])]\n\n\n output\n[ 0.97463191]\n\n\n\n\nEuclidean\n\n\nScala:\n\n\nval module = Euclidean(\n  inputSize,\n  outputSize,\n  fastBackward = true)\n\n\n\n\nPython:\n\n\nmodule = Euclidean(\n  input_size,\n  output_size,\n  fast_backward=True)\n\n\n\n\nOutputs the Euclidean distance of the input to \noutputSize\n centers.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Euclidean(3, 3)\n\nprintln(module.forward(Tensor.range(1, 3, 1)))\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n4.0323668\n3.7177157\n3.8736997\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Euclidean(3, 3)\n\nprint(module.forward(np.arange(1, 4, 1)))\n\n\n\n\nOutput is\n\n\n[array([ 3.86203027,  4.02212906,  3.2648952 ], dtype=float32)]", 
            "title": "Distance Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Distance-Layers/#pairwisedistance", 
            "text": "Scala:  val pd = PairwiseDistance(norm=2)  Python:  pd = PairwiseDistance(norm=2)  It is a module that takes a table of two vectors as input and outputs\nthe distance between them using the p-norm.\nThe input given in  forward(input)  is a [[Table]] that contains two tensors which\nmust be either a vector (1D tensor) or matrix (2D tensor). If the input is a vector,\nit must have the size of  inputSize . If it is a matrix, then each row is assumed to be\nan input sample of the given batch (the number of rows means the batch size and\nthe number of columns should be equal to the  inputSize ).  Scala example:  import com.intel.analytics.bigdl.nn.PairwiseDistance\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval pd = PairwiseDistance()\nval input1 = Tensor(3, 3).randn()\nval input2 = Tensor(3, 3).randn()\nval input = T(1 -  input1, 2 -  input2)\n\nval output = pd.forward(input)\n\nval gradOutput = Tensor(3).randn()\nval gradInput = pd.backward(input, gradOutput)  The ouotput is,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n4.155246\n1.1267666\n2.1415536\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.32565984\n-1.0108998\n-0.030873261\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]  The gradInput is,  gradInput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: 0.012723052  0.31482473      0.08232752\n           0.7552968    -0.27292773     -0.6139655\n           0.0062761847 -0.018232936    -0.024110721\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n        1: -0.012723052 -0.31482473     -0.08232752\n           -0.7552968   0.27292773      0.6139655\n           -0.0062761847        0.018232936     0.024110721\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\npd = PairwiseDistance()\n\ninput1 = np.random.uniform(0, 1, [3, 3]).astype( float32 )\ninput2 = np.random.uniform(0, 1, [3, 3]).astype( float32 )\ninput1 = input1.reshape(3, 3)\ninput2 = input2.reshape(3, 3)\n\ninput = [input1, input2]\n\noutput = pd.forward(input)\nprint output\n\ngradOutput = np.random.uniform(0, 1, [3]).astype( float32 )\ngradOutput = gradOutput.reshape(3)\n\ngradInput = pd.backward(input, gradOutput)\nprint gradInput  The output is,  [ 0.99588805  0.65620303  1.11735415]  The gradInput is,  [array([[-0.27412388,  0.32756016, -0.02032043],\n       [-0.16920818,  0.60189474,  0.21347123],\n       [ 0.57771122,  0.28602061,  0.58044904]], dtype=float32), array([[ 0.27412388, -0.32756016,  0.02032043],\n       [ 0.16920818, -0.60189474, -0.21347123],\n       [-0.57771122, -0.28602061, -0.58044904]], dtype=float32)]", 
            "title": "PairwiseDistance"
        }, 
        {
            "location": "/APIdocs/Layers/Distance-Layers/#cosinedistance", 
            "text": "Scala:  val module = CosineDistance()  Python:  module = CosineDistance()  CosineDistance creates a module that takes a table of two vectors (or matrices if in batch mode) as input and outputs the cosine distance between them.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = CosineDistance()\nval t1 = Tensor().range(1, 3)\nval t2 = Tensor().range(4, 6)\nval input = T(t1, t2)\nval output = module.forward(input)  input\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n    2: 4.0\n       5.0\n       6.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    1: 1.0\n       2.0\n       3.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }  output\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9746319\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = CosineDistance()\nt1 = np.array([1.0, 2.0, 3.0])\nt2 = np.array([4.0, 5.0, 6.0])\ninput = [t1, t2]\noutput = module.forward(input)  input\n[array([ 1.,  2.,  3.]), array([ 4.,  5.,  6.])]  output\n[ 0.97463191]", 
            "title": "CosineDistance"
        }, 
        {
            "location": "/APIdocs/Layers/Distance-Layers/#euclidean", 
            "text": "Scala:  val module = Euclidean(\n  inputSize,\n  outputSize,\n  fastBackward = true)  Python:  module = Euclidean(\n  input_size,\n  output_size,\n  fast_backward=True)  Outputs the Euclidean distance of the input to  outputSize  centers.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Euclidean(3, 3)\n\nprintln(module.forward(Tensor.range(1, 3, 1)))  Output is  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n4.0323668\n3.7177157\n3.8736997\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Euclidean(3, 3)\n\nprint(module.forward(np.arange(1, 4, 1)))  Output is  [array([ 3.86203027,  4.02212906,  3.2648952 ], dtype=float32)]", 
            "title": "Euclidean"
        }, 
        {
            "location": "/APIdocs/Layers/Recurrent-Layers/", 
            "text": "RNN\n\n\nScala:\n\n\nval rnnCell = RnnCell[Double](inputSize, hiddenSize, activation, wRegularizer, uRegularizer, bRegularizer)\n\n\n\n\nPython:\n\n\nrnnCell = RnnCell(input_size, hidden_size, Tanh(), w_regularizer, u_regularizer, b_regularizer)\n\n\n\n\nImplementation of vanilla recurrent neural network cell\ni2h: weight matrix of input to hidden units\nh2h: weight matrix of hidden units to themselves through time\nThe updating is defined as:\nh_t = f(i2h * x_t + h2h * h_{t-1})\n\n\nParameters:\n\n\n \ninputSize\n - input size. Default: 4\n\n \nhiddenSize\n - hidden layer size. Default: 3\n\n \nactivation\n - activation function f for non-linearity\n\n \nwRegularizer\n - instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the input weights matrices. Default: null\n\n \nuRegularizer\n - instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default: null\n\n \nbRegularizer\n - instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the bias. Default: null\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval outputSize = 2\nval seqLength = 2\nval input = Tensor(T(\n  T(1.0f, 2.0f),\n  T(2.0f, 3.0f)\n)).resize(Array(1, seqLength, inputSize))\nval gradOutput = Tensor(T(\n  T(2.0f, 3.0f),\n  T(4.0f, 5.0f)\n)).resize(Array(1, seqLength, inputSize))\nval rec = Recurrent()\n\nval model = Sequential()\n    .add(rec.add(RnnCell(inputSize, hiddenSize, Tanh())))\n    .add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input)\nval gradient = model.backward(input, gradOutput)\n-\n print(output)\n# There's random factor. An output could be\n(1,.,.) =\n0.41442442      0.1663357       \n0.5339842       0.57332826      \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n-\n print(gradient)\n# There's random factor. An output could be\n(1,.,.) =\n1.1512008       2.181274        \n-0.4805725      1.6620052       \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nhidden_size = 2\ninput_size = 2\noutput_size = 2\nseq_length = 2\ninput = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0]\n]])\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\nrec = Recurrent()\n\nmodel = Sequential() \\\n    .add(rec.add(RnnCell(input_size, hidden_size, Tanh()))) \\\n    .add(TimeDistributed(Linear(hidden_size, output_size)))\noutput = model.forward(input)\ngradient = model.backward(input, grad_output)\n-\n print output\n# There's random factor. An output could be\n[[[-0.67860311  0.80307233]\n  [-0.77462083  0.97191858]]]\n\n-\n print gradient\n# There's random factor. An output could be\n[[[-0.90771425  1.24791598]\n  [-0.70141178  0.97821164]]]\n\n\n\n\nRecurrent\n\n\nScala:\n\n\nval module = Recurrent()\n\n\n\n\nPython:\n\n\nmodule = Recurrent()\n\n\n\n\nRecurrent module is a container of rnn cells. Different types of rnn cells can be added using add() function.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 5\nval module = Recurrent().add(RnnCell(inputSize, hiddenSize, Tanh()))\nval input = Tensor(Array(1, 5, inputSize))\nfor (i \n- 1 to 5) {\n  val rdmInput = Math.ceil(RNG.uniform(0.0, 1.0)*inputSize).toInt\n  input.setValue(1, i, rdmInput, 1.0f)\n}\n\nval output = module.forward(input)\n\n\n input\n(1,.,.) =\n0.0 1.0 0.0 0.0 0.0\n0.0 1.0 0.0 0.0 0.0\n0.0 0.0 1.0 0.0 0.0\n0.0 1.0 0.0 0.0 0.0\n0.0 0.0 1.0 0.0 0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x5]\n\n\n output\n(1,.,.) =\n-0.44992247 -0.50529593 -0.033753205    -0.29562786\n-0.19734861 -0.5647412  0.07520321  -0.35515767\n-0.6771096  -0.4985356  -0.5806829  -0.47552463\n-0.06949129 -0.53153497 0.11510986  -0.34098053\n-0.71635246 -0.5226476  -0.5929389  -0.46533492\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nhiddenSize = 4\ninputSize = 5\nmodule = Recurrent().add(RnnCell(inputSize, hiddenSize, Tanh()))\ninput = np.zeros((1, 5, 5))\ninput[0][0][4] = 1\ninput[0][1][0] = 1\ninput[0][2][4] = 1\ninput[0][3][3] = 1\ninput[0][4][0] = 1\n\noutput = module.forward(input)\n\n\n output\n[array([[[ 0.7526533 ,  0.29162994, -0.28749418, -0.11243925],\n         [ 0.33291328, -0.07243762, -0.38017112,  0.53216213],\n         [ 0.83854133,  0.07213539, -0.34503224,  0.33690596],\n         [ 0.44095358,  0.27467242, -0.05471399,  0.46601957],\n         [ 0.451913  , -0.33519334, -0.61357468,  0.56650752]]], dtype=float32)]\n\n\n\n\nBiRecurrent\n\n\nScala:\n\n\nval module = BiRecurrent(merge=null)\n\n\n\n\nPython:\n\n\nmodule = BiRecurrent(merge=None,bigdl_type=\nfloat\n)\n\n\n\n\nThis layer implement a bidirectional recurrent neural network\n * @param merge concat or add the output tensor of the two RNNs. Default is add\n\n\nScala example:\n\n\nval module = BiRecurrent(CAddTable())\n.add(RnnCell(6, 4, Sigmoid()))\nval input = Tensor(Array(1, 2, 6)).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.55511624      0.44330198      0.9025551       0.26096714      0.3434667       0.20060952\n0.24903035      0.24026379      0.89252585      0.23025699      0.8131796       0.4013688\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x6]\n\nmodule.forward(input)\nres10: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.3577285       0.8861933       0.52908427      0.86278\n1.2850789       0.82549953      0.5560188       0.81468254\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4]\n\n\n\n\nPython example:\n\n\nmodule = BiRecurrent(CAddTable()).add(RnnCell(6, 4, Sigmoid()))\ninput = np.random.rand(1, 2, 6)\narray([[[ 0.75637438,  0.2642816 ,  0.61973312,  0.68565282,  0.73571443,\n          0.17167681],\n        [ 0.16439321,  0.06853251,  0.42257202,  0.42814042,  0.15706152,\n          0.57866659]]])\n\nmodule.forward(input)\narray([[[ 0.69091094,  0.97150528,  0.9562254 ,  1.14894259],\n        [ 0.83814102,  1.11358368,  0.96752423,  1.00913286]]], dtype=float32)\n\n\n\n\nLSTMPeephole\n\n\nScala:\n\n\nval model = LSTMPeephole(\n  inputSize = 4,\n  hiddenSize = 3,\n  p = 0.0,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)\n\n\n\n\nPython:\n\n\nmodel = LSTMPeephole(\n  input_size,\n  hidden_size,\n  p=0.0,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)\n\n\n\n\nLong Short Term Memory architecture with peephole.\nRef. A.: http://arxiv.org/pdf/1303.5778v1 (blueprint for this module)\nB. http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf\nC. http://arxiv.org/pdf/1503.04069v1.pdf\nD. https://github.com/wojzaremba/lstm\n\n\n\n\nparam inputSize the size of each input vector\n\n\nparam hiddenSize Hidden unit size in the LSTM\n\n\nparam  p is used for [[Dropout]] probability. For more details about\n           RNN dropouts, please refer to\n           [RnnDrop: A Novel Dropout for RNNs in ASR]\n           (http://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf)\n           [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks]\n           (https://arxiv.org/pdf/1512.05287.pdf)\n\n\nparam wRegularizer: instance of [[Regularizer]]\n                   (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nparam uRegularizer: instance [[Regularizer]]\n          (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n\n\nparam bRegularizer: instance of [[Regularizer]]\n          applied to the bias.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval hiddenSize = 4\nval inputSize = 6\nval outputSize = 5\nval seqLength = 5\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize))\nfor (b \n- 1 to batchSize) {\n  for (i \n- 1 to seqLength) {\n    val rdmInput = Math.ceil(RNG.uniform(0.0, 1.0) * inputSize).toInt\n    input.setValue(b, i, rdmInput, 1.0f)\n  }\n}\n\nval rec = Recurrent(hiddenSize)\nval model = Sequential().add(rec.add(LSTMPeephole(inputSize, hiddenSize))).add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input).toTensor\n\nscala\n print(input)\n(1,.,.) =\n1.0 0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 1.0 \n0.0 1.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 1.0 \n1.0 0.0 0.0 0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x6]\n\nscala\n print(output)\n(1,.,.) =\n0.34764957  -0.31453514 -0.45646006 -0.42966008 -0.13651063 \n0.3624894   -0.2926056  -0.4347164  -0.40951455 -0.1775867  \n0.33391106  -0.29304913 -0.4748538  -0.45285955 -0.14919288 \n0.35499972  -0.29385415 -0.4419502  -0.42135617 -0.17544147 \n0.32911295  -0.30237123 -0.47175884 -0.4409852  -0.15733294 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nhiddenSize = 4\ninputSize = 6\noutputSize = 5\nseqLength = 5\nbatchSize = 1\n\ninput = np.random.randn(batchSize, seqLength, inputSize)\nrec = Recurrent(hiddenSize)\nmodel = Sequential().add(rec.add(LSTMPeephole(inputSize, hiddenSize))).add(TimeDistributed(Linear(hiddenSize, outputSize)))\noutput = model.forward(input)\n\n\n print(input)\n[[[ 0.73624017 -0.91135209 -0.30627796 -1.07902111 -1.13549159  0.52868762]\n  [-0.07251559 -0.45596589  1.64020513  0.53218623  1.37993166 -0.47724947]\n  [-1.24958366 -1.22220259 -0.52454306  0.17382396  1.77666173 -1.2961758 ]\n  [ 0.45407533  0.82944329  0.02155243  1.82168093 -0.06022129  2.23823013]\n  [ 1.09100802  0.28555387 -0.94312648  0.55774033 -0.54895792  0.79885853]]]\n\n\n print(output)\n[[[ 0.4034881  -0.26156989  0.46799076  0.06283229  0.11794794]\n  [ 0.37359846 -0.17925361  0.31623816  0.06038529  0.10813089]\n  [ 0.34150451 -0.16565879  0.25264332  0.1187657   0.05118144]\n  [ 0.40773875 -0.2028828   0.24765283  0.0986848   0.12132661]\n  [ 0.40263647 -0.22403356  0.38489845  0.04720671  0.1686969 ]]]\n\n\n\n\nConvLSTMPeephole\n\n\nScala:\n\n\nval model = ConvLSTMPeephole(\n  inputSize = 2,\n  outputSize = 4,\n  kernelI = 3,\n  kernelC = 3,\n  stride = 1,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null,\n  withPeephole = true)\n\n\n\n\nPython:\n\n\nmodel = ConvLSTMPeephole(\n  input_size = 2,\n  output_size = 4,\n  kernel_i = 3,\n  kernel_c = 3,\n  stride = 1,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None,\n  with_peephole = True)\n\n\n\n\nConvolution Long Short Term Memory architecture with peephole.\nRef. A.: https://arxiv.org/abs/1506.04214 (blueprint for this module)\nB. https://github.com/viorik/ConvLSTM\n\n\n\n\nparam inputSize: number of input planes in the image given into forward()\n\n\nparam outputSize: number of output planes the convolution layer will produce\n\n\nparam kernelI: convolutional filter size to convolve input\n\n\nparam kernelC: convolutional filter size to convolve cell\n\n\nparam stride: step of the convolution\n\n\nparam wRegularizer: instance of [[Regularizer]]\n                   (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nparam uRegularizer: instance [[Regularizer]]\n          (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n\n\nparam bRegularizer: instance of [[Regularizer]]\n          applied to the bias.\n\n\nparam withPeephole: whether use last cell status control a gate\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval outputSize = 4\nval inputSize = 3\nval seqLength = 2\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize, 3, 3)).rand()\n\nval rec = Recurrent()\n    val model = Sequential()\n      .add(rec\n        .add(ConvLSTMPeephole(inputSize, outputSize, 3, 3, 1, withPeephole = false)))\n\nval output = model.forward(input).toTensor\n\nscala\n print(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.32810056      0.23436882      0.1387327\n0.98273766      0.76427716      0.73554766\n0.47947738      0.72805804      0.43982902\n\n(1,1,2,.,.) =\n0.58144385      0.7534736       0.94412255\n0.05087549      0.021427812     0.91333073\n0.6844351       0.62977004      0.68027127\n\n(1,1,3,.,.) =\n0.48504198      0.16233416      0.7612549\n0.5387952       0.8391377       0.3687795\n0.85271466      0.71726906      0.79466575\n\n(1,2,1,.,.) =\n0.727532        0.05341824      0.32531977\n0.79593664      0.60162276      0.99931896\n0.7534103       0.71214366      0.031062916\n\n(1,2,2,.,.) =\n0.7343414       0.053005006     0.7448063\n0.2277985       0.47414783      0.21945253\n0.0034818714    0.11545401      0.73085403\n\n(1,2,3,.,.) =\n0.9644807       0.30755267      0.42099005\n0.6831594       0.50683653      0.14237563\n0.65172654      0.86954886      0.5077393\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3x3]\n\nscala\n print(output)\n(1,1,1,.,.) =\n-0.04460164     -0.023752786    -0.014343993\n0.0067705153    0.08542874      0.020885356\n-0.042719357    -0.012113815    -0.030324051\n\n(1,1,2,.,.) =\n-0.038318213    -0.056998547    -0.02303889\n0.027873239     -0.040311974    -0.03261278\n0.015056128     0.11064132      0.0034682436\n\n(1,1,3,.,.) =\n0.006952648     0.011758738     -0.047590334\n0.052022297     0.040250845     -0.046224136\n-0.0084472215   -0.02629062     -0.0737972\n\n(1,1,4,.,.) =\n-0.087721705    0.0382758       0.027436329\n-0.030658737    -0.022953996    0.15838619\n0.055106055     0.004877564     0.098199464\n\n(1,2,1,.,.) =\n-0.069991425    -0.022071177    -0.06291955\n-0.006841902    0.010781053     0.05410414\n-0.03933395     -0.003422904    -0.106903486\n\n(1,2,2,.,.) =\n-0.059429795    -0.098534085    -0.068920344\n0.008100101     0.01948546      -0.040567685\n0.048763007     0.06001041      0.003068042\n\n(1,2,3,.,.) =\n0.02817994      0.006684172     -0.0962587\n0.022453573     0.014425971     -0.06118475\n-0.013392928    -0.04574135     -0.12722406\n\n(1,2,4,.,.) =\n-0.074006446    -0.028510522    0.06808455\n-0.021926142    0.036675904     0.18708621\n0.08240187      0.12469789      0.17341805\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\noutput_size = 4\ninput_size= 3\nseq_len = 2\nbatch_size = 1\n\ninput = np.random.randn(batch_size, seq_len, input_size, 3, 3)\nrec = Recurrent()\nmodel = Sequential().add(\n    rec.add(ConvLSTMPeephole(input_size, output_size, 3, 3, 1, with_peephole = False)))\noutput = model.forward(input)\n\n\n print(input)\n[[[[[ 2.39979422  0.75647109  0.88928214]\n    [-0.07132477 -0.4348564   0.38270011]\n    [-1.03522309  0.38399781  0.20369625]]\n\n   [[-0.48392771  0.54371842 -1.42064221]\n    [-0.3711481  -0.16019682  0.82116693]\n    [ 0.15922215  1.79676148  0.38362552]]\n\n   [[-0.69402482  1.11930766 -1.29138064]\n    [ 0.92755002 -0.31138235  0.34953374]\n    [-0.0176643   1.13839126  0.02133309]]]\n\n\n  [[[-0.40704988  0.1819258  -0.21400335]\n    [ 0.65717965  0.75912824  1.49077775]\n    [-0.74917913 -1.48460681  1.06098727]]\n\n   [[ 1.04942415  1.2558929  -1.24367776]\n    [-0.13452707  0.01485188  2.41215047]\n    [ 0.59776321 -0.38602613  0.57937933]]\n\n   [[ 0.55007301  1.22571134  0.11656841]\n    [-0.4722457   1.79801493  0.59698431]\n    [ 0.25119458 -0.27323404  1.5516505 ]]]]]\n\n\n print(output)\n[[[[[-0.22908808 -0.08243818 -0.10530333]\n    [ 0.04545299  0.0347576   0.06448466]\n    [ 0.00148075 -0.01422587 -0.04424585]]\n\n   [[-0.08625289  0.00121372  0.00961097]\n    [-0.08068027  0.2389598  -0.08875058]\n    [-0.10860988 -0.08109165  0.05274875]]\n\n   [[ 0.01545026 -0.14079301  0.0162897 ]\n    [ 0.0114354   0.01696588  0.09375648]\n    [ 0.06766916  0.16015787 -0.01530124]]\n\n   [[-0.00311095  0.07033439  0.05258823]\n    [-0.04846094 -0.11335927 -0.22434352]\n    [-0.09923813 -0.064981   -0.05341392]]]\n\n\n  [[[-0.01070079  0.01705431 -0.10199456]\n    [-0.19023973 -0.1359819   0.11552753]\n    [ 0.04331793  0.00603994 -0.19059387]]\n\n   [[-0.12100818 -0.01191896  0.08049219]\n    [-0.10134248  0.02910084 -0.00024394]\n    [-0.09548382 -0.18623565  0.18261637]]\n\n   [[-0.00644266  0.03494127  0.09105418]\n    [ 0.03467004 -0.1236406   0.23844369]\n    [ 0.12281432  0.09469442  0.04526915]]\n\n   [[ 0.00190313  0.01997324 -0.17609949]\n    [-0.0937     -0.03763293 -0.04860835]\n    [-0.15700462 -0.17341313 -0.06551415]]]]]\n\n\n\n\nGRU\n\n\nScala:\n\n\nval gru = GRU(inputSize, outputSize, p, wRegularizer, uRegularizer, bRegularizer)\n\n\n\n\nPython:\n\n\ngru = GRU(inputSize, outputSize, p, w_regularizer, u_regularizer, b_regularizer)\n\n\n\n\nGated Recurrent Units architecture. The first input in sequence uses zero value for cell and hidden state.\n\n\nRef.\n 1. http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/\n 2. https://github.com/Element-Research/rnn/blob/master/GRU.lua\n\n\nParameters:\n\n\n \ninputSize\n - the size of each input vector\n\n \noutputSize\n - hidden unit size in GRU\n\n \np\n - is used for [[Dropout]] probability. For more details about\n          RNN dropouts, please refer to\n           \nRnnDrop: A Novel Dropout for RNNs in ASR\n\n            and \nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks\n. Default: 0.0\n\n \nwRegularizer\n - instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the input weights matrices. Default: null\n\n \nuRegularizer\n - instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default: null\n\n \nbRegularizer\n - instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the bias. Default: null\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval outputSize = 2\nval seqLength = 2\nval input = Tensor(T(\n  T(1.0f, 2.0f),\n  T(2.0f, 3.0f)\n)).resize(Array(1, seqLength, inputSize))\nval gradOutput = Tensor(T(\n  T(2.0f, 3.0f),\n  T(4.0f, 5.0f)\n)).resize(Array(1, seqLength, inputSize))\nval rec = Recurrent()\n\nval model = Sequential()\n    .add(rec.add(GRU(inputSize, hiddenSize)))\n    .add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input)\nval gradient = model.backward(input, gradOutput)\n\n-\n print(output)\n# There's random factor. An output could be\n(1,.,.) =\n0.3833429       0.0082434565    \n-0.041063666    -0.08152798     \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n\n-\n print(gradient)\n# There's random factor. An output could be\n(1,.,.) =\n-0.7684499      -0.49320614     \n-0.98002595     -0.47857404     \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nhidden_size = 2\ninput_size = 2\noutput_size = 2\nseq_length = 2\ninput = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0]\n]])\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\nrec = Recurrent()\n\nmodel = Sequential() \\\n    .add(rec.add(GRU(input_size, hidden_size))) \\\n    .add(TimeDistributed(Linear(hidden_size, output_size)))\noutput = model.forward(input)\ngradient = model.backward(input, grad_output)\n-\n print output\n# There's random factor. An output could be\n[[[ 0.27857888  0.20263115]\n  [ 0.29470384  0.22594413]]]\n-\n print gradient\n[[[-0.32956457  0.27405274]\n  [-0.32718879  0.32963118]]]\n\n\n\n\nLSTM\n\n\nScala:\n\n\nval lstm = LSTM(inputSize, hiddenSize)\n\n\n\n\nPython:\n\n\nlstm = LSTM(input_size, hidden_size)\n\n\n\n\nLong Short Term Memory architecture.\n\n\nRef:\n\n\n\n\nhttp://arxiv.org/pdf/1303.5778v1 (blueprint for this module)\n\n\nhttp://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf\n\n\nhttp://arxiv.org/pdf/1503.04069v1.pdf\n\n\nhttps://github.com/wojzaremba/lstm\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.optim.SGD\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\nimport com.intel.analytics.bigdl.tensor.{Storage, Tensor}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 6\nval outputSize = 5\nval seqLength = 5\nval seed = 100\n\nRNG.setSeed(seed)\nval input = Tensor(Array(1, seqLength, inputSize))\nval labels = Tensor(Array(1, seqLength))\nfor (i \n- 1 to seqLength) {\n  val rdmLabel = Math.ceil(RNG.uniform(0, 1) * outputSize).toInt\n  val rdmInput = Math.ceil(RNG.uniform(0, 1) * inputSize).toInt\n  input.setValue(1, i, rdmInput, 1.0f)\n  labels.setValue(1, i, rdmLabel)\n}\n\nprintln(input)\nval rec = Recurrent(hiddenSize)\nval model = Sequential().add(\n  rec.add(\n      LSTM(inputSize, hiddenSize))).add(\n        TimeDistributed(Linear(hiddenSize, outputSize)))\n\nval criterion = TimeDistributedCriterion(\n  CrossEntropyCriterion(), false)\n\nval sgd = new SGD(learningRate=0.1, learningRateDecay=5e-7, weightDecay=0.1, momentum=0.002)\n\nval (weight, grad) = model.getParameters()\n\nval output = model.forward(input).toTensor\nval _loss = criterion.forward(output, labels)\nmodel.zeroGradParameters()\nval gradInput = criterion.backward(output, labels)\nmodel.backward(input, gradInput)\n\ndef feval(x: Tensor[Float]): (Float, Tensor[Float]) = {\n  val output = model.forward(input).toTensor\n  val _loss = criterion.forward(output, labels)\n  model.zeroGradParameters()\n  val gradInput = criterion.backward(output, labels)\n  model.backward(input, gradInput)\n  (_loss, grad)\n}\n\nvar loss: Array[Float] = null\nfor (i \n- 1 to 100) {\n  loss = sgd.optimize(feval, weight)._2\n  println(s\n${i}-th loss = ${loss(0)}\n)\n}\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nhidden_size = 4\ninput_size = 6\noutput_size = 5\nseq_length = 5\n\ninput = np.random.uniform(0, 1, [1, seq_length, input_size]).astype(\nfloat32\n)\nlabels = np.random.uniform(1, 5, [1, seq_length]).astype(\nint\n)\n\nprint labels\nprint input\n\nrec = Recurrent()\nrec.add(LSTM(input_size, hidden_size))\n\nmodel = Sequential()\nmodel.add(rec)\nmodel.add(TimeDistributed(Linear(hidden_size, output_size)))\n\ncriterion = TimeDistributedCriterion(CrossEntropyCriterion(), False)\n\nsgd = SGD(learningrate=0.1, learningrate_decay=5e-7)\n\nweight, grad = model.parameters()\n\noutput = model.forward(input)\nloss = criterion.forward(input, labels)\ngradInput = criterion.backward(output, labels)\nmodel.backward(input, gradInput)", 
            "title": "Recurrent Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Recurrent-Layers/#rnn", 
            "text": "Scala:  val rnnCell = RnnCell[Double](inputSize, hiddenSize, activation, wRegularizer, uRegularizer, bRegularizer)  Python:  rnnCell = RnnCell(input_size, hidden_size, Tanh(), w_regularizer, u_regularizer, b_regularizer)  Implementation of vanilla recurrent neural network cell\ni2h: weight matrix of input to hidden units\nh2h: weight matrix of hidden units to themselves through time\nThe updating is defined as:\nh_t = f(i2h * x_t + h2h * h_{t-1})  Parameters:    inputSize  - input size. Default: 4   hiddenSize  - hidden layer size. Default: 3   activation  - activation function f for non-linearity   wRegularizer  - instance of  Regularizer (eg. L1 or L2 regularization), applied to the input weights matrices. Default: null   uRegularizer  - instance of  Regularizer (eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default: null   bRegularizer  - instance of  Regularizer (eg. L1 or L2 regularization), applied to the bias. Default: null  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval outputSize = 2\nval seqLength = 2\nval input = Tensor(T(\n  T(1.0f, 2.0f),\n  T(2.0f, 3.0f)\n)).resize(Array(1, seqLength, inputSize))\nval gradOutput = Tensor(T(\n  T(2.0f, 3.0f),\n  T(4.0f, 5.0f)\n)).resize(Array(1, seqLength, inputSize))\nval rec = Recurrent()\n\nval model = Sequential()\n    .add(rec.add(RnnCell(inputSize, hiddenSize, Tanh())))\n    .add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input)\nval gradient = model.backward(input, gradOutput)\n-  print(output)\n# There's random factor. An output could be\n(1,.,.) =\n0.41442442      0.1663357       \n0.5339842       0.57332826      \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n-  print(gradient)\n# There's random factor. An output could be\n(1,.,.) =\n1.1512008       2.181274        \n-0.4805725      1.6620052       \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nhidden_size = 2\ninput_size = 2\noutput_size = 2\nseq_length = 2\ninput = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0]\n]])\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\nrec = Recurrent()\n\nmodel = Sequential() \\\n    .add(rec.add(RnnCell(input_size, hidden_size, Tanh()))) \\\n    .add(TimeDistributed(Linear(hidden_size, output_size)))\noutput = model.forward(input)\ngradient = model.backward(input, grad_output)\n-  print output\n# There's random factor. An output could be\n[[[-0.67860311  0.80307233]\n  [-0.77462083  0.97191858]]]\n\n-  print gradient\n# There's random factor. An output could be\n[[[-0.90771425  1.24791598]\n  [-0.70141178  0.97821164]]]", 
            "title": "RNN"
        }, 
        {
            "location": "/APIdocs/Layers/Recurrent-Layers/#recurrent", 
            "text": "Scala:  val module = Recurrent()  Python:  module = Recurrent()  Recurrent module is a container of rnn cells. Different types of rnn cells can be added using add() function.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 5\nval module = Recurrent().add(RnnCell(inputSize, hiddenSize, Tanh()))\nval input = Tensor(Array(1, 5, inputSize))\nfor (i  - 1 to 5) {\n  val rdmInput = Math.ceil(RNG.uniform(0.0, 1.0)*inputSize).toInt\n  input.setValue(1, i, rdmInput, 1.0f)\n}\n\nval output = module.forward(input)  input\n(1,.,.) =\n0.0 1.0 0.0 0.0 0.0\n0.0 1.0 0.0 0.0 0.0\n0.0 0.0 1.0 0.0 0.0\n0.0 1.0 0.0 0.0 0.0\n0.0 0.0 1.0 0.0 0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x5]  output\n(1,.,.) =\n-0.44992247 -0.50529593 -0.033753205    -0.29562786\n-0.19734861 -0.5647412  0.07520321  -0.35515767\n-0.6771096  -0.4985356  -0.5806829  -0.47552463\n-0.06949129 -0.53153497 0.11510986  -0.34098053\n-0.71635246 -0.5226476  -0.5929389  -0.46533492\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nhiddenSize = 4\ninputSize = 5\nmodule = Recurrent().add(RnnCell(inputSize, hiddenSize, Tanh()))\ninput = np.zeros((1, 5, 5))\ninput[0][0][4] = 1\ninput[0][1][0] = 1\ninput[0][2][4] = 1\ninput[0][3][3] = 1\ninput[0][4][0] = 1\n\noutput = module.forward(input)  output\n[array([[[ 0.7526533 ,  0.29162994, -0.28749418, -0.11243925],\n         [ 0.33291328, -0.07243762, -0.38017112,  0.53216213],\n         [ 0.83854133,  0.07213539, -0.34503224,  0.33690596],\n         [ 0.44095358,  0.27467242, -0.05471399,  0.46601957],\n         [ 0.451913  , -0.33519334, -0.61357468,  0.56650752]]], dtype=float32)]", 
            "title": "Recurrent"
        }, 
        {
            "location": "/APIdocs/Layers/Recurrent-Layers/#birecurrent", 
            "text": "Scala:  val module = BiRecurrent(merge=null)  Python:  module = BiRecurrent(merge=None,bigdl_type= float )  This layer implement a bidirectional recurrent neural network\n * @param merge concat or add the output tensor of the two RNNs. Default is add  Scala example:  val module = BiRecurrent(CAddTable())\n.add(RnnCell(6, 4, Sigmoid()))\nval input = Tensor(Array(1, 2, 6)).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.55511624      0.44330198      0.9025551       0.26096714      0.3434667       0.20060952\n0.24903035      0.24026379      0.89252585      0.23025699      0.8131796       0.4013688\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x6]\n\nmodule.forward(input)\nres10: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.3577285       0.8861933       0.52908427      0.86278\n1.2850789       0.82549953      0.5560188       0.81468254\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4]  Python example:  module = BiRecurrent(CAddTable()).add(RnnCell(6, 4, Sigmoid()))\ninput = np.random.rand(1, 2, 6)\narray([[[ 0.75637438,  0.2642816 ,  0.61973312,  0.68565282,  0.73571443,\n          0.17167681],\n        [ 0.16439321,  0.06853251,  0.42257202,  0.42814042,  0.15706152,\n          0.57866659]]])\n\nmodule.forward(input)\narray([[[ 0.69091094,  0.97150528,  0.9562254 ,  1.14894259],\n        [ 0.83814102,  1.11358368,  0.96752423,  1.00913286]]], dtype=float32)", 
            "title": "BiRecurrent"
        }, 
        {
            "location": "/APIdocs/Layers/Recurrent-Layers/#lstmpeephole", 
            "text": "Scala:  val model = LSTMPeephole(\n  inputSize = 4,\n  hiddenSize = 3,\n  p = 0.0,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)  Python:  model = LSTMPeephole(\n  input_size,\n  hidden_size,\n  p=0.0,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)  Long Short Term Memory architecture with peephole.\nRef. A.: http://arxiv.org/pdf/1303.5778v1 (blueprint for this module)\nB. http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf\nC. http://arxiv.org/pdf/1503.04069v1.pdf\nD. https://github.com/wojzaremba/lstm   param inputSize the size of each input vector  param hiddenSize Hidden unit size in the LSTM  param  p is used for [[Dropout]] probability. For more details about\n           RNN dropouts, please refer to\n           [RnnDrop: A Novel Dropout for RNNs in ASR]\n           (http://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf)\n           [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks]\n           (https://arxiv.org/pdf/1512.05287.pdf)  param wRegularizer: instance of [[Regularizer]]\n                   (eg. L1 or L2 regularization), applied to the input weights matrices.  param uRegularizer: instance [[Regularizer]]\n          (eg. L1 or L2 regularization), applied to the recurrent weights matrices.  param bRegularizer: instance of [[Regularizer]]\n          applied to the bias.   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval hiddenSize = 4\nval inputSize = 6\nval outputSize = 5\nval seqLength = 5\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize))\nfor (b  - 1 to batchSize) {\n  for (i  - 1 to seqLength) {\n    val rdmInput = Math.ceil(RNG.uniform(0.0, 1.0) * inputSize).toInt\n    input.setValue(b, i, rdmInput, 1.0f)\n  }\n}\n\nval rec = Recurrent(hiddenSize)\nval model = Sequential().add(rec.add(LSTMPeephole(inputSize, hiddenSize))).add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input).toTensor\n\nscala  print(input)\n(1,.,.) =\n1.0 0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 1.0 \n0.0 1.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 1.0 \n1.0 0.0 0.0 0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x6]\n\nscala  print(output)\n(1,.,.) =\n0.34764957  -0.31453514 -0.45646006 -0.42966008 -0.13651063 \n0.3624894   -0.2926056  -0.4347164  -0.40951455 -0.1775867  \n0.33391106  -0.29304913 -0.4748538  -0.45285955 -0.14919288 \n0.35499972  -0.29385415 -0.4419502  -0.42135617 -0.17544147 \n0.32911295  -0.30237123 -0.47175884 -0.4409852  -0.15733294 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nhiddenSize = 4\ninputSize = 6\noutputSize = 5\nseqLength = 5\nbatchSize = 1\n\ninput = np.random.randn(batchSize, seqLength, inputSize)\nrec = Recurrent(hiddenSize)\nmodel = Sequential().add(rec.add(LSTMPeephole(inputSize, hiddenSize))).add(TimeDistributed(Linear(hiddenSize, outputSize)))\noutput = model.forward(input)  print(input)\n[[[ 0.73624017 -0.91135209 -0.30627796 -1.07902111 -1.13549159  0.52868762]\n  [-0.07251559 -0.45596589  1.64020513  0.53218623  1.37993166 -0.47724947]\n  [-1.24958366 -1.22220259 -0.52454306  0.17382396  1.77666173 -1.2961758 ]\n  [ 0.45407533  0.82944329  0.02155243  1.82168093 -0.06022129  2.23823013]\n  [ 1.09100802  0.28555387 -0.94312648  0.55774033 -0.54895792  0.79885853]]]  print(output)\n[[[ 0.4034881  -0.26156989  0.46799076  0.06283229  0.11794794]\n  [ 0.37359846 -0.17925361  0.31623816  0.06038529  0.10813089]\n  [ 0.34150451 -0.16565879  0.25264332  0.1187657   0.05118144]\n  [ 0.40773875 -0.2028828   0.24765283  0.0986848   0.12132661]\n  [ 0.40263647 -0.22403356  0.38489845  0.04720671  0.1686969 ]]]", 
            "title": "LSTMPeephole"
        }, 
        {
            "location": "/APIdocs/Layers/Recurrent-Layers/#convlstmpeephole", 
            "text": "Scala:  val model = ConvLSTMPeephole(\n  inputSize = 2,\n  outputSize = 4,\n  kernelI = 3,\n  kernelC = 3,\n  stride = 1,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null,\n  withPeephole = true)  Python:  model = ConvLSTMPeephole(\n  input_size = 2,\n  output_size = 4,\n  kernel_i = 3,\n  kernel_c = 3,\n  stride = 1,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None,\n  with_peephole = True)  Convolution Long Short Term Memory architecture with peephole.\nRef. A.: https://arxiv.org/abs/1506.04214 (blueprint for this module)\nB. https://github.com/viorik/ConvLSTM   param inputSize: number of input planes in the image given into forward()  param outputSize: number of output planes the convolution layer will produce  param kernelI: convolutional filter size to convolve input  param kernelC: convolutional filter size to convolve cell  param stride: step of the convolution  param wRegularizer: instance of [[Regularizer]]\n                   (eg. L1 or L2 regularization), applied to the input weights matrices.  param uRegularizer: instance [[Regularizer]]\n          (eg. L1 or L2 regularization), applied to the recurrent weights matrices.  param bRegularizer: instance of [[Regularizer]]\n          applied to the bias.  param withPeephole: whether use last cell status control a gate   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval outputSize = 4\nval inputSize = 3\nval seqLength = 2\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize, 3, 3)).rand()\n\nval rec = Recurrent()\n    val model = Sequential()\n      .add(rec\n        .add(ConvLSTMPeephole(inputSize, outputSize, 3, 3, 1, withPeephole = false)))\n\nval output = model.forward(input).toTensor\n\nscala  print(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.32810056      0.23436882      0.1387327\n0.98273766      0.76427716      0.73554766\n0.47947738      0.72805804      0.43982902\n\n(1,1,2,.,.) =\n0.58144385      0.7534736       0.94412255\n0.05087549      0.021427812     0.91333073\n0.6844351       0.62977004      0.68027127\n\n(1,1,3,.,.) =\n0.48504198      0.16233416      0.7612549\n0.5387952       0.8391377       0.3687795\n0.85271466      0.71726906      0.79466575\n\n(1,2,1,.,.) =\n0.727532        0.05341824      0.32531977\n0.79593664      0.60162276      0.99931896\n0.7534103       0.71214366      0.031062916\n\n(1,2,2,.,.) =\n0.7343414       0.053005006     0.7448063\n0.2277985       0.47414783      0.21945253\n0.0034818714    0.11545401      0.73085403\n\n(1,2,3,.,.) =\n0.9644807       0.30755267      0.42099005\n0.6831594       0.50683653      0.14237563\n0.65172654      0.86954886      0.5077393\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3x3]\n\nscala  print(output)\n(1,1,1,.,.) =\n-0.04460164     -0.023752786    -0.014343993\n0.0067705153    0.08542874      0.020885356\n-0.042719357    -0.012113815    -0.030324051\n\n(1,1,2,.,.) =\n-0.038318213    -0.056998547    -0.02303889\n0.027873239     -0.040311974    -0.03261278\n0.015056128     0.11064132      0.0034682436\n\n(1,1,3,.,.) =\n0.006952648     0.011758738     -0.047590334\n0.052022297     0.040250845     -0.046224136\n-0.0084472215   -0.02629062     -0.0737972\n\n(1,1,4,.,.) =\n-0.087721705    0.0382758       0.027436329\n-0.030658737    -0.022953996    0.15838619\n0.055106055     0.004877564     0.098199464\n\n(1,2,1,.,.) =\n-0.069991425    -0.022071177    -0.06291955\n-0.006841902    0.010781053     0.05410414\n-0.03933395     -0.003422904    -0.106903486\n\n(1,2,2,.,.) =\n-0.059429795    -0.098534085    -0.068920344\n0.008100101     0.01948546      -0.040567685\n0.048763007     0.06001041      0.003068042\n\n(1,2,3,.,.) =\n0.02817994      0.006684172     -0.0962587\n0.022453573     0.014425971     -0.06118475\n-0.013392928    -0.04574135     -0.12722406\n\n(1,2,4,.,.) =\n-0.074006446    -0.028510522    0.06808455\n-0.021926142    0.036675904     0.18708621\n0.08240187      0.12469789      0.17341805\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\noutput_size = 4\ninput_size= 3\nseq_len = 2\nbatch_size = 1\n\ninput = np.random.randn(batch_size, seq_len, input_size, 3, 3)\nrec = Recurrent()\nmodel = Sequential().add(\n    rec.add(ConvLSTMPeephole(input_size, output_size, 3, 3, 1, with_peephole = False)))\noutput = model.forward(input)  print(input)\n[[[[[ 2.39979422  0.75647109  0.88928214]\n    [-0.07132477 -0.4348564   0.38270011]\n    [-1.03522309  0.38399781  0.20369625]]\n\n   [[-0.48392771  0.54371842 -1.42064221]\n    [-0.3711481  -0.16019682  0.82116693]\n    [ 0.15922215  1.79676148  0.38362552]]\n\n   [[-0.69402482  1.11930766 -1.29138064]\n    [ 0.92755002 -0.31138235  0.34953374]\n    [-0.0176643   1.13839126  0.02133309]]]\n\n\n  [[[-0.40704988  0.1819258  -0.21400335]\n    [ 0.65717965  0.75912824  1.49077775]\n    [-0.74917913 -1.48460681  1.06098727]]\n\n   [[ 1.04942415  1.2558929  -1.24367776]\n    [-0.13452707  0.01485188  2.41215047]\n    [ 0.59776321 -0.38602613  0.57937933]]\n\n   [[ 0.55007301  1.22571134  0.11656841]\n    [-0.4722457   1.79801493  0.59698431]\n    [ 0.25119458 -0.27323404  1.5516505 ]]]]]  print(output)\n[[[[[-0.22908808 -0.08243818 -0.10530333]\n    [ 0.04545299  0.0347576   0.06448466]\n    [ 0.00148075 -0.01422587 -0.04424585]]\n\n   [[-0.08625289  0.00121372  0.00961097]\n    [-0.08068027  0.2389598  -0.08875058]\n    [-0.10860988 -0.08109165  0.05274875]]\n\n   [[ 0.01545026 -0.14079301  0.0162897 ]\n    [ 0.0114354   0.01696588  0.09375648]\n    [ 0.06766916  0.16015787 -0.01530124]]\n\n   [[-0.00311095  0.07033439  0.05258823]\n    [-0.04846094 -0.11335927 -0.22434352]\n    [-0.09923813 -0.064981   -0.05341392]]]\n\n\n  [[[-0.01070079  0.01705431 -0.10199456]\n    [-0.19023973 -0.1359819   0.11552753]\n    [ 0.04331793  0.00603994 -0.19059387]]\n\n   [[-0.12100818 -0.01191896  0.08049219]\n    [-0.10134248  0.02910084 -0.00024394]\n    [-0.09548382 -0.18623565  0.18261637]]\n\n   [[-0.00644266  0.03494127  0.09105418]\n    [ 0.03467004 -0.1236406   0.23844369]\n    [ 0.12281432  0.09469442  0.04526915]]\n\n   [[ 0.00190313  0.01997324 -0.17609949]\n    [-0.0937     -0.03763293 -0.04860835]\n    [-0.15700462 -0.17341313 -0.06551415]]]]]", 
            "title": "ConvLSTMPeephole"
        }, 
        {
            "location": "/APIdocs/Layers/Recurrent-Layers/#gru", 
            "text": "Scala:  val gru = GRU(inputSize, outputSize, p, wRegularizer, uRegularizer, bRegularizer)  Python:  gru = GRU(inputSize, outputSize, p, w_regularizer, u_regularizer, b_regularizer)  Gated Recurrent Units architecture. The first input in sequence uses zero value for cell and hidden state.  Ref.\n 1. http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/\n 2. https://github.com/Element-Research/rnn/blob/master/GRU.lua  Parameters:    inputSize  - the size of each input vector   outputSize  - hidden unit size in GRU   p  - is used for [[Dropout]] probability. For more details about\n          RNN dropouts, please refer to\n            RnnDrop: A Novel Dropout for RNNs in ASR \n            and  A Theoretically Grounded Application of Dropout in Recurrent Neural Networks . Default: 0.0   wRegularizer  - instance of  Regularizer (eg. L1 or L2 regularization), applied to the input weights matrices. Default: null   uRegularizer  - instance of  Regularizer (eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default: null   bRegularizer  - instance of  Regularizer (eg. L1 or L2 regularization), applied to the bias. Default: null  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval outputSize = 2\nval seqLength = 2\nval input = Tensor(T(\n  T(1.0f, 2.0f),\n  T(2.0f, 3.0f)\n)).resize(Array(1, seqLength, inputSize))\nval gradOutput = Tensor(T(\n  T(2.0f, 3.0f),\n  T(4.0f, 5.0f)\n)).resize(Array(1, seqLength, inputSize))\nval rec = Recurrent()\n\nval model = Sequential()\n    .add(rec.add(GRU(inputSize, hiddenSize)))\n    .add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input)\nval gradient = model.backward(input, gradOutput)\n\n-  print(output)\n# There's random factor. An output could be\n(1,.,.) =\n0.3833429       0.0082434565    \n-0.041063666    -0.08152798     \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n\n-  print(gradient)\n# There's random factor. An output could be\n(1,.,.) =\n-0.7684499      -0.49320614     \n-0.98002595     -0.47857404     \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nhidden_size = 2\ninput_size = 2\noutput_size = 2\nseq_length = 2\ninput = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0]\n]])\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\nrec = Recurrent()\n\nmodel = Sequential() \\\n    .add(rec.add(GRU(input_size, hidden_size))) \\\n    .add(TimeDistributed(Linear(hidden_size, output_size)))\noutput = model.forward(input)\ngradient = model.backward(input, grad_output)\n-  print output\n# There's random factor. An output could be\n[[[ 0.27857888  0.20263115]\n  [ 0.29470384  0.22594413]]]\n-  print gradient\n[[[-0.32956457  0.27405274]\n  [-0.32718879  0.32963118]]]", 
            "title": "GRU"
        }, 
        {
            "location": "/APIdocs/Layers/Recurrent-Layers/#lstm", 
            "text": "Scala:  val lstm = LSTM(inputSize, hiddenSize)  Python:  lstm = LSTM(input_size, hidden_size)  Long Short Term Memory architecture.  Ref:   http://arxiv.org/pdf/1303.5778v1 (blueprint for this module)  http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf  http://arxiv.org/pdf/1503.04069v1.pdf  https://github.com/wojzaremba/lstm   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.optim.SGD\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\nimport com.intel.analytics.bigdl.tensor.{Storage, Tensor}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 6\nval outputSize = 5\nval seqLength = 5\nval seed = 100\n\nRNG.setSeed(seed)\nval input = Tensor(Array(1, seqLength, inputSize))\nval labels = Tensor(Array(1, seqLength))\nfor (i  - 1 to seqLength) {\n  val rdmLabel = Math.ceil(RNG.uniform(0, 1) * outputSize).toInt\n  val rdmInput = Math.ceil(RNG.uniform(0, 1) * inputSize).toInt\n  input.setValue(1, i, rdmInput, 1.0f)\n  labels.setValue(1, i, rdmLabel)\n}\n\nprintln(input)\nval rec = Recurrent(hiddenSize)\nval model = Sequential().add(\n  rec.add(\n      LSTM(inputSize, hiddenSize))).add(\n        TimeDistributed(Linear(hiddenSize, outputSize)))\n\nval criterion = TimeDistributedCriterion(\n  CrossEntropyCriterion(), false)\n\nval sgd = new SGD(learningRate=0.1, learningRateDecay=5e-7, weightDecay=0.1, momentum=0.002)\n\nval (weight, grad) = model.getParameters()\n\nval output = model.forward(input).toTensor\nval _loss = criterion.forward(output, labels)\nmodel.zeroGradParameters()\nval gradInput = criterion.backward(output, labels)\nmodel.backward(input, gradInput)\n\ndef feval(x: Tensor[Float]): (Float, Tensor[Float]) = {\n  val output = model.forward(input).toTensor\n  val _loss = criterion.forward(output, labels)\n  model.zeroGradParameters()\n  val gradInput = criterion.backward(output, labels)\n  model.backward(input, gradInput)\n  (_loss, grad)\n}\n\nvar loss: Array[Float] = null\nfor (i  - 1 to 100) {\n  loss = sgd.optimize(feval, weight)._2\n  println(s ${i}-th loss = ${loss(0)} )\n}  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nhidden_size = 4\ninput_size = 6\noutput_size = 5\nseq_length = 5\n\ninput = np.random.uniform(0, 1, [1, seq_length, input_size]).astype( float32 )\nlabels = np.random.uniform(1, 5, [1, seq_length]).astype( int )\n\nprint labels\nprint input\n\nrec = Recurrent()\nrec.add(LSTM(input_size, hidden_size))\n\nmodel = Sequential()\nmodel.add(rec)\nmodel.add(TimeDistributed(Linear(hidden_size, output_size)))\n\ncriterion = TimeDistributedCriterion(CrossEntropyCriterion(), False)\n\nsgd = SGD(learningrate=0.1, learningrate_decay=5e-7)\n\nweight, grad = model.parameters()\n\noutput = model.forward(input)\nloss = criterion.forward(input, labels)\ngradInput = criterion.backward(output, labels)\nmodel.backward(input, gradInput)", 
            "title": "LSTM"
        }, 
        {
            "location": "/APIdocs/Layers/Recursive-Layers/", 
            "text": "TensorTree\n\n\nTensorTree class is used to decode a tensor to a tree structure.\nThe given input \ncontent\n is a tensor which encodes a constituency parse tree.\nThe tensor should have the following structure:\n\n\nEach row of the tensor represents a tree node and the row number is node number.\nFor each row, except the last column, all other columns represent the children\nnode number of this node. Assume the value of a certain column of the row is not zero,\nthe value \np\n means this node has a child whose node number is \np\n (lies in the \np\n-th)\nrow. Each leaf has a leaf number, in the tensor, the last column represents the leaf number.\nEach leaf does not have any children, so all the columns of a leaf except the last should\nbe zero. If a node is the root, the last column should equal to \n-1\n.\n\n\nNote: if any row for padding, the padding rows should be placed at the last rows with all\nelements equal to \n-1\n.\n\n\neg. a tensor represents a binary tree:\n\n\n[11, 10, -1;\n 0, 0, 1;\n 0, 0, 2;\n 0, 0, 3;\n 0, 0, 4;\n 0, 0, 5;\n 0, 0, 6;\n 4, 5, 0;\n 6, 7, 0;\n 8, 9, 0;\n 2, 3, 0;\n -1, -1, -1;\n -1, -1, -1]\n\n\n\n\nParameters:\n\n* \ncontent\n the tensor to be encoded\n\n\nTreeLSTM\n\n\nTreeLSTM is a base class of all other kinds of tree lstms,\n, as described in the paper \n\nImproved Semantic Representations From Tree-Structured Long Short-Term Memory Networks\n\n by Kai Sheng Tai, Richard Socher, and Christopher Manning.\n\n\nBinaryTreeLSTM\n\n\nScala:\n\n\nval treeLSTM = BinaryTreeLSTM(\n  inputSize,\n  hiddenSize,\n  gateOutput,\n  withGraph)\n\n\n\n\nPython:\n\n\ntree_lstm = BinaryTreeLSTM(\n  input_size,\n  hidden_size,\n  gate_output,\n  with_graph)\n\n\n\n\nThis class is an implementation of Binary TreeLSTM (Constituency Tree LSTM)\nreceiving \nConstituency-based parse trees\n.\nTree-LSTM is a kind of recursive neural networks, as described in the paper \n\nImproved Semantic Representations From Tree-Structured Long Short-Term Memory Networks\n\n by Kai Sheng Tai, Richard Socher, and Christopher Manning.\n\n\nParameters:\n\n\n \ninputSize\n - the size of each input vector\n\n \nhiddenSize\n - hidden unit size in GRU\n\n \ngateOutput\n - whether gate the output. Default is \ntrue\n\n\n \nwithGraph\n - whether create lstms with \ncom.intel.analytics.bigdl.nn.Graph\n. Default is \ntrue\n.\n\n\nScala example:\n\n\n    import com.intel.analytics.bigdl.numeric.NumericFloat\n    import com.intel.analytics.bigdl.utils.RandomGenerator.RNG\n\n    RNG.setSeed(100)\n\n    val hiddenSize = 2\n    val inputSize = 2\n\n    val inputs =\n      Tensor(\n        T(T(T(1f, 2f),\n          T(2f, 3f),\n          T(4f, 5f))))\n\n    val tree =\n      Tensor(\n        T(T(T(2f, 5f, -1f),\n          T(0f, 0f, 1f),\n          T(0f, 0f, 2f),\n          T(0f, 0f, 3f),\n          T(3f, 4f, 0f))))\n\n    val input = T(inputs, tree)\n\n    val gradOutput =\n      Tensor(\n        T(T(T(2f, 5f),\n          T(2f, 3f),\n          T(4f, 5f),\n          T(2f, 3f),\n          T(4f, 5f),\n          T(6f, 7f))))\n\n    val model = BinaryTreeLSTM(inputSize, hiddenSize)\n\n    val output = model.forward(input)\n    println(output)\n    (1,.,.) =\n    -0.07799375 -0.14419462 \n    -0.23495524 -0.04679072 \n    -0.15945151 -0.026039641    \n    -0.0454074  -0.007066241    \n    -0.058696028    -0.13559057 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x2]\n\n    val gradInput = model.backward(input, gradOutput)\n    println(gradInput)\n      {\n        2: (1,.,.) =\n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x3]\n        1: (1,.,.) =\n           0.56145966   -0.3383652  \n           0.81720364   -0.46767634 \n           0.37739626   -0.23355529 \n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x2]\n      }\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\nhidden_size = 2\ninput_size = 2\ninputs = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\n\ntree = np.array([[\n  [2.0, 5.0, -1.0],\n  [0.0, 0.0, 1.0],\n  [0.0, 0.0, 2.0],\n  [0.0, 0.0, 3.0],\n  [3.0, 4.0, 0.0]\n]])\n\ninput = [inputs, tree]\n\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0],\n  [2.0, 3.0],\n  [4.0, 5.0],\n  [6.0, 7.0]\n]])\n\nmodel = BinaryTreeLSTM(input_size, hidden_size)\noutput = model.forward(input)\nprint output\n[[[-0.08113038 -0.0289295 ]\n  [ 0.1378704   0.00550814]\n  [ 0.33053339 -0.02395477]\n  [ 0.26895314 -0.02019646]\n  [ 0.34085754 -0.12480961]]]\n\ngradient = model.backward(input, grad_output)\nprint gradient\n[array([[[ 0.43623093,  0.97416967],\n        [-0.02283204,  0.99245077],\n        [-1.11290622,  0.84173977]]], dtype=float32), array([[[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]]], dtype=float32)]", 
            "title": "Recursive Layers"
        }, 
        {
            "location": "/APIdocs/Layers/Recursive-Layers/#tensortree", 
            "text": "TensorTree class is used to decode a tensor to a tree structure.\nThe given input  content  is a tensor which encodes a constituency parse tree.\nThe tensor should have the following structure:  Each row of the tensor represents a tree node and the row number is node number.\nFor each row, except the last column, all other columns represent the children\nnode number of this node. Assume the value of a certain column of the row is not zero,\nthe value  p  means this node has a child whose node number is  p  (lies in the  p -th)\nrow. Each leaf has a leaf number, in the tensor, the last column represents the leaf number.\nEach leaf does not have any children, so all the columns of a leaf except the last should\nbe zero. If a node is the root, the last column should equal to  -1 .  Note: if any row for padding, the padding rows should be placed at the last rows with all\nelements equal to  -1 .  eg. a tensor represents a binary tree:  [11, 10, -1;\n 0, 0, 1;\n 0, 0, 2;\n 0, 0, 3;\n 0, 0, 4;\n 0, 0, 5;\n 0, 0, 6;\n 4, 5, 0;\n 6, 7, 0;\n 8, 9, 0;\n 2, 3, 0;\n -1, -1, -1;\n -1, -1, -1]  Parameters: \n*  content  the tensor to be encoded", 
            "title": "TensorTree"
        }, 
        {
            "location": "/APIdocs/Layers/Recursive-Layers/#treelstm", 
            "text": "TreeLSTM is a base class of all other kinds of tree lstms,\n, as described in the paper  Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks \n by Kai Sheng Tai, Richard Socher, and Christopher Manning.", 
            "title": "TreeLSTM"
        }, 
        {
            "location": "/APIdocs/Layers/Recursive-Layers/#binarytreelstm", 
            "text": "Scala:  val treeLSTM = BinaryTreeLSTM(\n  inputSize,\n  hiddenSize,\n  gateOutput,\n  withGraph)  Python:  tree_lstm = BinaryTreeLSTM(\n  input_size,\n  hidden_size,\n  gate_output,\n  with_graph)  This class is an implementation of Binary TreeLSTM (Constituency Tree LSTM)\nreceiving  Constituency-based parse trees .\nTree-LSTM is a kind of recursive neural networks, as described in the paper  Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks \n by Kai Sheng Tai, Richard Socher, and Christopher Manning.  Parameters:    inputSize  - the size of each input vector   hiddenSize  - hidden unit size in GRU   gateOutput  - whether gate the output. Default is  true    withGraph  - whether create lstms with  com.intel.analytics.bigdl.nn.Graph . Default is  true .  Scala example:      import com.intel.analytics.bigdl.numeric.NumericFloat\n    import com.intel.analytics.bigdl.utils.RandomGenerator.RNG\n\n    RNG.setSeed(100)\n\n    val hiddenSize = 2\n    val inputSize = 2\n\n    val inputs =\n      Tensor(\n        T(T(T(1f, 2f),\n          T(2f, 3f),\n          T(4f, 5f))))\n\n    val tree =\n      Tensor(\n        T(T(T(2f, 5f, -1f),\n          T(0f, 0f, 1f),\n          T(0f, 0f, 2f),\n          T(0f, 0f, 3f),\n          T(3f, 4f, 0f))))\n\n    val input = T(inputs, tree)\n\n    val gradOutput =\n      Tensor(\n        T(T(T(2f, 5f),\n          T(2f, 3f),\n          T(4f, 5f),\n          T(2f, 3f),\n          T(4f, 5f),\n          T(6f, 7f))))\n\n    val model = BinaryTreeLSTM(inputSize, hiddenSize)\n\n    val output = model.forward(input)\n    println(output)\n    (1,.,.) =\n    -0.07799375 -0.14419462 \n    -0.23495524 -0.04679072 \n    -0.15945151 -0.026039641    \n    -0.0454074  -0.007066241    \n    -0.058696028    -0.13559057 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x2]\n\n    val gradInput = model.backward(input, gradOutput)\n    println(gradInput)\n      {\n        2: (1,.,.) =\n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x3]\n        1: (1,.,.) =\n           0.56145966   -0.3383652  \n           0.81720364   -0.46767634 \n           0.37739626   -0.23355529 \n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x2]\n      }  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\nhidden_size = 2\ninput_size = 2\ninputs = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\n\ntree = np.array([[\n  [2.0, 5.0, -1.0],\n  [0.0, 0.0, 1.0],\n  [0.0, 0.0, 2.0],\n  [0.0, 0.0, 3.0],\n  [3.0, 4.0, 0.0]\n]])\n\ninput = [inputs, tree]\n\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0],\n  [2.0, 3.0],\n  [4.0, 5.0],\n  [6.0, 7.0]\n]])\n\nmodel = BinaryTreeLSTM(input_size, hidden_size)\noutput = model.forward(input)\nprint output\n[[[-0.08113038 -0.0289295 ]\n  [ 0.1378704   0.00550814]\n  [ 0.33053339 -0.02395477]\n  [ 0.26895314 -0.02019646]\n  [ 0.34085754 -0.12480961]]]\n\ngradient = model.backward(input, grad_output)\nprint gradient\n[array([[[ 0.43623093,  0.97416967],\n        [-0.02283204,  0.99245077],\n        [-1.11290622,  0.84173977]]], dtype=float32), array([[[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]]], dtype=float32)]", 
            "title": "BinaryTreeLSTM"
        }, 
        {
            "location": "/APIdocs/Layers/Utilities/", 
            "text": "Input\n\n\nScala:\n\n\nval input = Input()\n\n\n\n\nPython:\n\n\ninput = Input()\n\n\n\n\nInput layer do nothing to the input tensors, just passing them through.\nIt is used as input to the \nGraph container\n when the first layer of the graph container accepts multiple tensors as inputs.\n\n\nEach input node of the graph container should accept one tensor as input. If you want a module\naccepting multiple tensors as input, you should add some Input module before it and connect\nthe outputs of the Input nodes to it. Please see the example of the Graph document.\n\n\nPlease note that the return is not a layer but a Node containing input layer.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Input()\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.93366385      0.82551944\n0.71642804      0.4798109\n0.83710635      0.068483874\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nmodule.element.forward(input)\n com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.93366385      0.82551944\n0.71642804      0.4798109\n0.83710635      0.068483874\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Input()\ninput = np.random.rand(3,2)\narray([[ 0.7006678 ,  0.29719472],\n       [ 0.76668255,  0.59518023],\n       [ 0.65543809,  0.41172803]])\n\nmodule.element().forward(input)\narray([[ 0.7006678 ,  0.29719472],\n       [ 0.76668257,  0.59518021],\n       [ 0.65543807,  0.41172802]], dtype=float32)\n\n\n\n\n\nEcho\n\n\nScala:\n\n\nval module = Echo()\n\n\n\n\nPython:\n\n\nmodule = Echo()\n\n\n\n\nThis module is for debug purpose, which can print activation and gradient size in your model topology\n\n\nScala example:\n\n\nval module = Echo()\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.24058184      0.22737113\n0.0028103297    0.18359558\n0.80443156      0.07047854\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nmodule.forward(input)\nres13: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.24058184      0.22737113\n0.0028103297    0.18359558\n0.80443156      0.07047854\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\n\n\n\nPython example:\n\n\nmodule = Echo()\ninput = np.random.rand(3,2)\n[array([\n[ 0.87273163,  0.59974301],\n[ 0.09416127,  0.135765  ],\n[ 0.11577505,  0.46095625]], dtype=float32)]\n\nmodule.forward(input)\ncom.intel.analytics.bigdl.nn.Echo@535c681 : Activation size is 3x2\n[array([\n[ 0.87273163,  0.59974301],\n[ 0.09416127,  0.135765  ],\n[ 0.11577505,  0.46095625]], dtype=float32)]", 
            "title": "Utilities"
        }, 
        {
            "location": "/APIdocs/Layers/Utilities/#input", 
            "text": "Scala:  val input = Input()  Python:  input = Input()  Input layer do nothing to the input tensors, just passing them through.\nIt is used as input to the  Graph container  when the first layer of the graph container accepts multiple tensors as inputs.  Each input node of the graph container should accept one tensor as input. If you want a module\naccepting multiple tensors as input, you should add some Input module before it and connect\nthe outputs of the Input nodes to it. Please see the example of the Graph document.  Please note that the return is not a layer but a Node containing input layer.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Input()\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.93366385      0.82551944\n0.71642804      0.4798109\n0.83710635      0.068483874\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nmodule.element.forward(input)\n com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.93366385      0.82551944\n0.71642804      0.4798109\n0.83710635      0.068483874\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Input()\ninput = np.random.rand(3,2)\narray([[ 0.7006678 ,  0.29719472],\n       [ 0.76668255,  0.59518023],\n       [ 0.65543809,  0.41172803]])\n\nmodule.element().forward(input)\narray([[ 0.7006678 ,  0.29719472],\n       [ 0.76668257,  0.59518021],\n       [ 0.65543807,  0.41172802]], dtype=float32)", 
            "title": "Input"
        }, 
        {
            "location": "/APIdocs/Layers/Utilities/#echo", 
            "text": "Scala:  val module = Echo()  Python:  module = Echo()  This module is for debug purpose, which can print activation and gradient size in your model topology  Scala example:  val module = Echo()\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.24058184      0.22737113\n0.0028103297    0.18359558\n0.80443156      0.07047854\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nmodule.forward(input)\nres13: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.24058184      0.22737113\n0.0028103297    0.18359558\n0.80443156      0.07047854\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]  Python example:  module = Echo()\ninput = np.random.rand(3,2)\n[array([\n[ 0.87273163,  0.59974301],\n[ 0.09416127,  0.135765  ],\n[ 0.11577505,  0.46095625]], dtype=float32)]\n\nmodule.forward(input)\ncom.intel.analytics.bigdl.nn.Echo@535c681 : Activation size is 3x2\n[array([\n[ 0.87273163,  0.59974301],\n[ 0.09416127,  0.135765  ],\n[ 0.11577505,  0.46095625]], dtype=float32)]", 
            "title": "Echo"
        }, 
        {
            "location": "/APIdocs/Losses/", 
            "text": "L1Cost\n\n\nScala:\n\n\nval layer = L1Cost[Float]()\n\n\n\n\nPython:\n\n\nlayer = L1Cost()\n\n\n\n\nCompute L1 norm for input, and sign of input\n\n\nScala example:\n\n\nval layer = L1Cost[Float]()\nval input = Tensor[Float](2, 2).rand\nval target = Tensor[Float](2, 2).rand\n\nval output = layer.forward(input, target)\nval gradInput = layer.backward(input, target)\n\n\n println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.48145306      0.476887\n0.23729686      0.5169516\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n println(target)\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.42999148      0.22272833\n0.49723643      0.17884709\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n println(output)\noutput: Float = 1.7125885\n\n println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0\n1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nlayer = L1Cost()\n\ninput = np.random.uniform(0, 1, (2, 2)).astype(\nfloat32\n)\ntarget = np.random.uniform(0, 1, (2, 2)).astype(\nfloat32\n)\n\noutput = layer.forward(input, target)\ngradInput = layer.backward(input, target)\n\n\n output\n2.522411\n\n gradInput\n[array([[ 1.,  1.],\n        [ 1.,  1.]], dtype=float32)]\n\n\n\n\nTimeDistributedCriterion\n\n\nScala:\n\n\nval module = TimeDistributedCriterion(critrn, sizeAverage)\n\n\n\n\nPython:\n\n\nmodule = TimeDistributedCriterion(critrn, sizeAverage)\n\n\n\n\nThis class is intended to support inputs with 3 or more dimensions.\nApply Any Provided Criterion to every temporal slice of an input.\n\n\ncritrn\n embedded criterion\n\n\nsizeAverage\n whether to divide the sequence length. Default is false.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval criterion = ClassNLLCriterion[Double]()\nval layer = TimeDistributedCriterion[Double](criterion, true)\nval input = Tensor[Double](Storage(Array(\n    1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404))).resize(3, 2, 3)\nval target = Tensor[Double](3, 2)\n    target(Array(1, 1)) = 1\n    target(Array(1, 2)) = 1\n    target(Array(2, 1)) = 2\n    target(Array(2, 2)) = 2\n    target(Array(3, 1)) = 3\n    target(Array(3, 2)) = 3\n\n print(layer.forward(input, target))\n0.8793184268272332\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\n\ncriterion = ClassNLLCriterion()\nlayer = TimeDistributedCriterion(criterion, True)\ninput = np.array([1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404]).reshape(3,2,3)\ntarget = np.array([[1,1],[2,2],[3,3]])                      \n\nlayer.forward(input, target)\n0.8793184\n\n\n\n\nMarginRankingCriterion\n\n\nScala:\n\n\nval mse = new MarginRankingCriterion(margin=1.0, sizeAverage=true)\n\n\n\n\nPython:\n\n\nmse = MarginRankingCriterion(margin=1.0, size_average=true)\n\n\n\n\nCreates a criterion that measures the loss given an input x = {x1, x2},\na table of two Tensors of size 1 (they contain only scalars), and a label y (1 or -1).\nIn batch mode, x is a table of two Tensors of size batchsize, and y is a Tensor of size\nbatchsize containing 1 or -1 for each corresponding pair of elements in the input Tensor.\nIf y == 1 then it assumed the first input should be ranked higher (have a larger value) than\nthe second input, and vice-versa for y == -1.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.MarginRankingCriterion\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nimport scala.util.Random\n\nval input1Arr = Array(1, 2, 3, 4, 5)\nval input2Arr = Array(5, 4, 3, 2, 1)\n\nval target1Arr = Array(-1, 1, -1, 1, 1)\n\nval input1 = Tensor(Storage(input1Arr.map(x =\n x.toFloat)))\nval input2 = Tensor(Storage(input2Arr.map(x =\n x.toFloat)))\n\nval input = T((1.toFloat, input1), (2.toFloat, input2))\n\nval target1 = Tensor(Storage(target1Arr.map(x =\n x.toFloat)))\nval target = T((1.toFloat, target1))\n\nval mse = new MarginRankingCriterion()\n\nval output = mse.forward(input, target)\nval gradInput = mse.backward(input, target)\n\nprintln(output)\nprintln(gradInput)\n\n\n\n\nThe output will be,\n\n\noutput: Float = 0.8                                                                                                                                                                    [21/154]\n\n\n\n\nThe gradInput will be,\n\n\ngradInput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: -0.0\n           0.2\n           -0.2\n           0.0\n           0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n        1: 0.0\n           -0.2\n           0.2\n           -0.0\n           -0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n }\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nmse = MarginRankingCriterion()\n\ninput1 = np.array([1, 2, 3, 4, 5]).astype(\nfloat32\n)\ninput2 = np.array([5, 4, 3, 2, 1]).astype(\nfloat32\n)\ninput = [input1, input2]\n\ntarget1 = np.array([-1, 1, -1, 1, 1]).astype(\nfloat32\n)\ntarget = [target1, target1]\n\noutput = mse.forward(input, target)\ngradInput = mse.backward(input, target)\n\nprint output\nprint gradInput\n\n\n\n\nThe output will be,\n\n\n0.8\n\n\n\n\nThe gradInput will be,\n\n\n[array([ 0. , -0.2,  0.2, -0. , -0. ], dtype=float32), array([-0. ,  0.2, -0.2,  0. ,  0. ], dtype=float32)] \n\n\n\n\nClassNLLCriterion\n\n\nScala:\n\n\nval criterion = ClassNLLCriterion(weights = null, sizeAverage = true)\n\n\n\n\nPython:\n\n\ncriterion = ClassNLLCriterion(weights=None, size_average=True)\n\n\n\n\nThe negative log likelihood criterion. It is useful to train a classification problem with n\nclasses. If provided, the optional argument weights should be a 1D Tensor assigning weight to\neach of the classes. This is particularly useful when you have an unbalanced training set.\n\n\nThe input given through a \nforward()\n is expected to contain log-probabilities of each class:\ninput has to be a 1D Tensor of size \nn\n. Obtaining log-probabilities in a neural network is easily\nachieved by adding a \nLogSoftMax\n layer in the last layer of your neural network. You may use\n\nCrossEntropyCriterion\n instead, if you prefer not to add an extra layer to your network. This\ncriterion expects a class index (1 to the number of class) as target when calling\n\nforward(input, target)\n and \nbackward(input, target)\n.\n\n\nThe loss can be described as:\n     loss(x, class) = -x[class]\n or in the case of the weights argument it is specified as follows:\n     loss(x, class) = -weights[class] * x[class]\n Due to the behaviour of the backend code, it is necessary to set sizeAverage to false when\n calculating losses in non-batch mode.\n\n\nNote that if the target is \n-1\n, the training process will skip this sample.\n In other words, the forward process will return zero output and the backward process\n will also return zero \ngradInput\n.\n\n\nBy default, the losses are averaged over observations for each minibatch. However, if the field\n \nsizeAverage\n is set to false, the losses are instead summed for each minibatch.\n\n\nParameters:\n\n\nweights\n     - weights of each element of the input\n\n\nsizeAverage\n - A boolean indicating whether normalizing by the number of elements in the input.\n                  Default: true\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.ClassNLLCriterion\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = ClassNLLCriterion()\nval input = Tensor(T(\n              T(1f, 2f, 3f),\n              T(2f, 3f, 4f),\n              T(3f, 4f, 5f)\n          ))\n\nval target = Tensor(T(1f, 2f, 3f))\n\nval loss = criterion.forward(input, target)\nval grad = criterion.backward(input, target)\n\nprint(loss)\n-3.0\nprintln(grad)\n-0.33333334 0.0 0.0\n0.0 -0.33333334 0.0\n0.0 0.0 -0.33333334\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\n\ncriterion = ClassNLLCriterion()\ninput = np.array([\n              [1.0, 2.0, 3.0],\n              [2.0, 3.0, 4.0],\n              [3.0, 4.0, 5.0]\n          ])\n\ntarget = np.array([1.0, 2.0, 3.0])\n\nloss = criterion.forward(input, target)\ngradient= criterion.backward(input, target)\n\nprint loss\n-3.0\nprint gradient\n-3.0\n[[-0.33333334  0.          0.        ]\n [ 0.         -0.33333334  0.        ]\n [ 0.          0.         -0.33333334]]\n\n\n\n\nSoftmaxWithCriterion\n\n\nScala:\n\n\nval model = SoftmaxWithCriterion(ignoreLabel, normalizeMode)\n\n\n\n\nPython:\n\n\nmodel = SoftmaxWithCriterion(ignoreLabel, normalizeMode)\n\n\n\n\nComputes the multinomial logistic loss for a one-of-many classification task, passing real-valued predictions through a softmax to\nget a probability distribution over classes. It should be preferred over separate SoftmaxLayer + MultinomialLogisticLossLayer as \nits gradient computation is more numerically stable.\n\n\n\n\nparam ignoreLabel   (optional) Specify a label value that should be ignored when computing the loss.\n\n\nparam normalizeMode How to normalize the output loss.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.{Storage, Tensor}\n\nval input = Tensor(1, 5, 2, 3).rand()\nval target = Tensor(Storage(Array(2.0f, 4.0f, 2.0f, 4.0f, 1.0f, 2.0f))).resize(1, 1, 2, 3)\n\nval model = SoftmaxWithCriterion[Float]()\nval output = model.forward(input, target)\n\nscala\n print(input)\n(1,1,.,.) =\n0.65131104  0.9332143   0.5618989   \n0.9965054   0.9370902   0.108070895 \n\n(1,2,.,.) =\n0.46066576  0.9636703   0.8123812   \n0.31076035  0.16386998  0.37894428  \n\n(1,3,.,.) =\n0.49111295  0.3704862   0.9938375   \n0.87996656  0.8695406   0.53354675  \n\n(1,4,.,.) =\n0.8502225   0.9033509   0.8518651   \n0.0692618   0.10121379  0.970959    \n\n(1,5,.,.) =\n0.9397213   0.49688303  0.75739735  \n0.25074655  0.11416598  0.6594504   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x2x3]\n\nscala\n print(output)\n1.6689054\n\n\n\n\nPython example:\n\n\ninput = np.random.randn(1, 5, 2, 3)\ntarget = np.array([[[[2.0, 4.0, 2.0], [4.0, 1.0, 2.0]]]])\n\nmodel = SoftmaxWithCriterion()\noutput = model.forward(input, target)\n\n\n print input\n[[[[ 0.78455689  0.01402084  0.82539628]\n   [-1.06448238  2.58168413  0.60053703]]\n\n  [[-0.48617618  0.44538094  0.46611658]\n   [-1.41509329  0.40038991 -0.63505732]]\n\n  [[ 0.91266769  1.68667933  0.92423611]\n   [ 0.1465411   0.84637557  0.14917515]]\n\n  [[-0.7060493  -2.02544114  0.89070726]\n   [ 0.14535539  0.73980064 -0.33130613]]\n\n  [[ 0.64538791 -0.44384233 -0.40112523]\n   [ 0.44346658 -2.22303621  0.35715986]]]]\n\n\n print output\n2.1002123\n\n\n\n\n\nSmoothL1Criterion\n\n\nScala:\n\n\nval slc = SmoothL1Criterion(sizeAverage=true)\n\n\n\n\nPython:\n\n\nslc = SmoothL1Criterion(size_average=True)\n\n\n\n\nCreates a criterion that can be thought of as a smooth version of the AbsCriterion.\nIt uses a squared term if the absolute element-wise error falls below 1.\nIt is less sensitive to outliers than the MSECriterion and in some\ncases prevents exploding gradients (e.g. see \"Fast R-CNN\" paper by Ross Girshick).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.{Tensor, Storage}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.SmoothL1Criterion\n\nval slc = SmoothL1Criterion()\n\nval inputArr = Array(\n  0.17503996845335,\n  0.83220188552514,\n  0.48450597329065,\n  0.64701424003579,\n  0.62694586534053,\n  0.34398410236463,\n  0.55356747563928,\n  0.20383032318205\n)\nval targetArr = Array(\n  0.69956525065936,\n  0.86074831243604,\n  0.54923197557218,\n  0.57388074393384,\n  0.63334444304928,\n  0.99680578662083,\n  0.49997645849362,\n  0.23869121982716\n)\n\nval input = Tensor(Storage(inputArr.map(x =\n x.toFloat))).reshape(Array(2, 2, 2))\nval target = Tensor(Storage(targetArr.map(x =\n x.toFloat))).reshape(Array(2, 2, 2))\n\nval output = slc.forward(input, target)\nval gradInput = slc.backward(input, target)\n\n\n\n\nThe output is,\n\n\noutput: Float = 0.0447365\n\n\n\n\nThe gradInput is,\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.06556566     -0.003568299\n-0.008090746    0.009141691\n\n(2,.,.) =\n-7.998273E-4    -0.08160271\n0.0066988766    -0.0043576136\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nslc = SmoothL1Criterion()\n\ninput = np.array([\n    0.17503996845335,\n    0.83220188552514,\n    0.48450597329065,\n    0.64701424003579,\n    0.62694586534053,\n    0.34398410236463,\n    0.55356747563928,\n    0.20383032318205\n])\ninput.reshape(2, 2, 2)\n\ntarget = np.array([\n    0.69956525065936,\n    0.86074831243604,\n    0.54923197557218,\n    0.57388074393384,\n    0.63334444304928,\n    0.99680578662083,\n    0.49997645849362,\n    0.23869121982716\n])\n\ntarget.reshape(2, 2, 2)\n\noutput = slc.forward(input, target)\ngradInput = slc.backward(input, target)\n\nprint output\nprint gradInput\n\n\n\n\nSmoothL1CriterionWithWeights\n\n\nScala:\n\n\nval smcod = SmoothL1CriterionWithWeights[Float](sigma: Float = 2.4f, num: Int = 2)\n\n\n\n\nPython:\n\n\nsmcod = SmoothL1CriterionWithWeights(sigma, num)\n\n\n\n\na smooth version of the AbsCriterion\nIt uses a squared term if the absolute element-wise error falls below 1.\nIt is less sensitive to outliers than the MSECriterion and in some cases\nprevents exploding gradients (e.g. see \"Fast R-CNN\" paper by Ross Girshick).\n\n\n   d = (x - y) * w_in\n\n  loss(x, y, w_in, w_out)\n              | 0.5 * (sigma * d_i)^2 * w_out          if |d_i| \n 1 / sigma / sigma\n   = 1/n \\sum |\n              | (|d_i| - 0.5 / sigma / sigma) * w_out   otherwise\n\n\n\n\nScala example:\n\n\nval smcod = SmoothL1CriterionWithWeights[Float](2.4f, 2)\n\nval inputArr = Array(1.1, -0.8, 0.1, 0.4, 1.3, 0.2, 0.2, 0.03)\nval targetArr = Array(0.9, 1.5, -0.08, -1.68, -0.68, -1.17, -0.92, 1.58)\nval inWArr = Array(-0.1, 1.7, -0.8, -1.9, 1.0, 1.4, 0.8, 0.8)\nval outWArr = Array(-1.9, -0.5, 1.9, -1.0, -0.2, 0.1, 0.3, 1.1)\n\nval input = Tensor(Storage(inputArr.map(x =\n x.toFloat)))\nval target = T()\ntarget.insert(Tensor(Storage(targetArr.map(x =\n x.toFloat))))\ntarget.insert(Tensor(Storage(inWArr.map(x =\n x.toFloat))))\ntarget.insert(Tensor(Storage(outWArr.map(x =\n x.toFloat))))\n\nval output = smcod.forward(input, target)\nval gradInput = smcod.backward(input, target)\n\n\n println(output)\n  output: Float = -2.17488\n\n println(gradInput)\n-0.010944003\n0.425\n0.63037443\n-0.95\n-0.1\n0.07\n0.120000005\n-0.44000003\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 8]\n\n\n\n\nPython example:\n\n\nsmcod = SmoothL1CriterionWithWeights(2.4, 2)\n\ninput = np.array([1.1, -0.8, 0.1, 0.4, 1.3, 0.2, 0.2, 0.03]).astype(\nfloat32\n)\ntargetArr = np.array([0.9, 1.5, -0.08, -1.68, -0.68, -1.17, -0.92, 1.58]).astype(\nfloat32\n)\ninWArr = np.array([-0.1, 1.7, -0.8, -1.9, 1.0, 1.4, 0.8, 0.8]).astype(\nfloat32\n)\noutWArr = np.array([-1.9, -0.5, 1.9, -1.0, -0.2, 0.1, 0.3, 1.1]).astype(\nfloat32\n)\ntarget = [targetArr, inWArr, outWArr]\n\noutput = smcod.forward(input, target)\ngradInput = smcod.backward(input, target)\n\n\n output\n-2.17488\n\n gradInput\n[array([-0.010944  ,  0.42500001,  0.63037443, -0.94999999, -0.1       ,\n         0.07      ,  0.12      , -0.44000003], dtype=float32)]\n\n\n\n\nMultiMarginCriterion\n\n\nScala:\n\n\nval loss = MultiMarginCriterion(p=1,weights=null,margin=1.0,sizeAverage=true)\n\n\n\n\nPython:\n\n\nloss = MultiMarginCriterion(p=1,weights=None,margin=1.0,size_average=True)\n\n\n\n\nMultiMarginCriterion is a loss function that optimizes a multi-class classification hinge loss (margin-based loss) between input \nx\n and output \ny\n (\ny\n is the target class index).\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(3,2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f, 2.0f)))\nval loss = MultiMarginCriterion(1)\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala\n print(input)\n-0.45896783     -0.80141246\n0.22560088      -0.13517438\n0.2601126       0.35492152\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nscala\n print(target)\n2.0\n1.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\nscala\n print(output)\n0.4811434\n\nscala\n print(grad)\n0.16666667      -0.16666667\n-0.16666667     0.16666667\n0.16666667      -0.16666667\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(3,2)\ntarget = np.array([2,1,2])\nprint \ninput=\n,input\nprint \ntarget=\n,target\n\nloss = MultiMarginCriterion(1)\nout = loss.forward(input, target)\nprint \noutput of loss is : \n,out\n\ngrad_out = loss.backward(input,target)\nprint \ngrad out of loss is : \n,grad_out\n\n\n\n\nproduces output\n\n\ninput= [[ 0.46868305 -2.28562261]\n [ 0.8076243  -0.67809689]\n [-0.20342555 -0.66264743]]\ntarget= [2 1 2]\ncreating: createMultiMarginCriterion\noutput of loss is :  0.8689213\ngrad out of loss is :  [[ 0.16666667 -0.16666667]\n [ 0.          0.        ]\n [ 0.16666667 -0.16666667]]\n\n\n\n\n\n\nHingeEmbeddingCriterion\n\n\nScala:\n\n\nval m = HingeEmbeddingCriterion(margin = 1, sizeAverage = true)\n\n\n\n\nPython:\n\n\nm = HingeEmbeddingCriterion(margin=1, size_average=True)\n\n\n\n\nCreates a criterion that measures the loss given an input \nx\n which is a 1-dimensional vector and a label \ny\n (\n1\n or \n-1\n).\nThis is usually used for measuring whether two inputs are similar or dissimilar, e.g. using the L1 pairwise distance, and is typically used for learning nonlinear embeddings or semi-supervised learning.\n\n\n                 \u23a7 x_i,                  if y_i ==  1\nloss(x, y) = 1/n \u23a8\n                 \u23a9 max(0, margin - x_i), if y_i == -1\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils.{T}\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval loss = HingeEmbeddingCriterion(1, sizeAverage = false)\nval input = Tensor(T(0.1f, 2.0f, 2.0f, 2.0f))\nprintln(\ninput: \\n\n + input)\nprintln(\nouput: \n)\n\nprintln(\nTarget=1: \n + loss.forward(input, Tensor(4, 1).fill(1f)))\n\nprintln(\nTarget=-1: \n + loss.forward(input, Tensor(4, 1).fill(-1f)))\n\n\n\n\ninput: \n0.1\n2.0\n2.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\nouput: \nTarget=1: 6.1\nTarget=-1: 0.9\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\ninput = np.array([0.1, 2.0, 2.0, 2.0])\ntarget = np.full(4, 1)\nprint(\ninput: \n )\nprint(input)\nprint(\ntarget: \n)\nprint(target)\nprint(\noutput: \n)\nprint(HingeEmbeddingCriterion(1.0, size_average= False).forward(input, target))\nprint(HingeEmbeddingCriterion(1.0, size_average= False).forward(input, np.full(4, -1)))\n\n\n\n\ninput: \n[ 0.1  2.   2.   2. ]\ntarget: \n[1 1 1 1]\noutput: \ncreating: createHingeEmbeddingCriterion\n6.1\ncreating: createHingeEmbeddingCriterion\n0.9\n\n\n\n\nMarginCriterion\n\n\nScala:\n\n\ncriterion = MarginCriterion(margin=1.0, sizeAverage=true)\n\n\n\n\nPython:\n\n\ncriterion = MarginCriterion(margin=1.0, sizeAverage=true, bigdl_type=\nfloat\n)\n\n\n\n\nCreates a criterion that optimizes a two-class classification hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.\n * @param margin if unspecified, is by default 1.\n * @param sizeAverage whether to average the loss, is by default true\n\n\nScala example:\n\n\nval criterion = MarginCriterion(margin=1.0, sizeAverage=true)\n\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.33753583      0.3575501\n0.23477706      0.7240361\n0.92835575      0.4737949\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nval target = Tensor(3, 2).rand()\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.27280563      0.7022703\n0.3348442       0.43332106\n0.08935371      0.17876455\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\ncriterion.forward(input, target)\nres5: Float = 0.84946966\n\n\n\n\nPython example:\n\n\ncriterion = MarginCriterion(margin=1.0,size_average=True,bigdl_type=\nfloat\n)\ninput = np.random.rand(3, 2)\narray([[ 0.20824672,  0.67299837],\n       [ 0.80561452,  0.19564743],\n       [ 0.42501441,  0.19408184]])\n\ntarget = np.random.rand(3, 2)\narray([[ 0.67882632,  0.61257846],\n       [ 0.10111138,  0.75225082],\n       [ 0.60404296,  0.31373273]])\n\ncriterion.forward(input, target)\n0.8166871\n\n\n\n\nCosineEmbeddingCriterion\n\n\nScala:\n\n\nval cosineEmbeddingCriterion = CosineEmbeddingCriterion(margin  = 0.0, sizeAverage = true)\n\n\n\n\nPython:\n\n\ncosineEmbeddingCriterion = CosineEmbeddingCriterion( margin=0.0,size_average=True)\n\n\n\n\nCosineEmbeddingCriterion creates a criterion that measures the loss given an input x = {x1, x2},\na table of two Tensors, and a Tensor label y with values 1 or -1.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimpot com.intel.analytics.bigdl.utils.T\nval cosineEmbeddingCriterion = CosineEmbeddingCriterion(0.0, false)\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T()\ninput(1.0) = input1\ninput(2.0) = input2\nval target1 = Tensor(Storage(Array(-0.5f)))\nval target = T()\ntarget(1.0) = target1\n\n\n print(input)\n {\n    2.0: 0.4110882\n         0.57726574\n         0.1949834\n         0.67670715\n         0.16984987\n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1.0: 0.16878392\n         0.24124223\n         0.8964794\n         0.11156334\n         0.5101486\n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n }\n\n\n print(cosineEmbeddingCriterion.forward(input, target))\n0.49919847\n\n\n print(cosineEmbeddingCriterion.backward(input, target))\n {\n    2: -0.045381278\n       -0.059856333\n       0.72547954\n       -0.2268434\n       0.3842142\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n    1: 0.30369008\n       0.42463788\n       -0.20637506\n       0.5712836\n       -0.06355385\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\ncosineEmbeddingCriterion = CosineEmbeddingCriterion(0.0, False)\n\n cosineEmbeddingCriterion.forward([np.array([1.0, 2.0, 3.0, 4.0 ,5.0]),np.array([5.0, 4.0, 3.0, 2.0, 1.0])],[np.array(-0.5)])\n0.6363636\n\n cosineEmbeddingCriterion.backward([np.array([1.0, 2.0, 3.0, 4.0 ,5.0]),np.array([5.0, 4.0, 3.0, 2.0, 1.0])],[np.array(-0.5)])\n[array([ 0.07933884,  0.04958678,  0.01983471, -0.00991735, -0.03966942], dtype=float32), array([-0.03966942, -0.00991735,  0.01983471,  0.04958678,  0.07933884], dtype=float32)]\n\n\n\n\n\nBCECriterion\n\n\nScala:\n\n\nval criterion = BCECriterion[Float]()\n\n\n\n\nPython:\n\n\ncriterion = BCECriterion()\n\n\n\n\nThis loss function measures the Binary Cross Entropy between the target and the output\n\n\n loss(o, t) = - 1/n sum_i (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))\n\n\n\n\nor in the case of the weights argument being specified:\n\n\n loss(o, t) = - 1/n sum_i weights[i] * (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))\n\n\n\n\nBy default, the losses are averaged for each mini-batch over observations as well as over\n dimensions. However, if the field sizeAverage is set to false, the losses are instead summed.\n\n\nScala example:\n\n\n\nval criterion = BCECriterion[Float]()\nval input = Tensor[Float](3, 1).rand\n\nval target = Tensor[Float](3)\ntarget(1) = 1\ntarget(2) = 0\ntarget(3) = 1\n\nval output = criterion.forward(input, target)\nval gradInput = criterion.backward(input, target)\n\n\n println(target)\nres25: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n0.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n\n println(output)\noutput: Float = 0.9009579\n\n\n println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.5277504\n1.0736246\n-0.336957\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1]\n\n\n\n\n\nPython example:\n\n\n\ncriterion = BCECriterion()\ninput = np.random.uniform(0, 1, (3, 1)).astype(\nfloat32\n)\ntarget = np.array([1, 0, 1])\noutput = criterion.forward(input, target)\ngradInput = criterion.backward(input, target)\n\n\n output\n1.9218739\n\n gradInput\n[array([[-4.3074522 ],\n        [ 2.24244714],\n        [-1.22368968]], dtype=float32)]\n\n\n\n\n\nDiceCoefficientCriterion\n\n\nScala:\n\n\nval loss = DiceCoefficientCriterion(sizeAverage=true, epsilon=1.0f)\n\n\n\n\nPython:\n\n\nloss = DiceCoefficientCriterion(size_average=True,epsilon=1.0)\n\n\n\n\nDiceCoefficientCriterion is the Dice-Coefficient objective function. \n\n\nBoth \nforward\n and \nbackward\n accept two tensors : input and target. The \nforward\n result is formulated as \n          \n1 - (2 * (input intersection target) / (input union target))\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f)))\nval loss = DiceCoefficientCriterion(epsilon = 1.0f)\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala\n print(input)\n-0.50278\n0.51387966\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala\n print(target)\n2.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala\n print(output)\n0.9958517\n\nscala\n print(grad)\n-0.99619853     -0.49758217\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(2)\ntarget = np.array([2,1],dtype='float64')\n\nprint \ninput=\n, input\nprint \ntarget=\n, target\nloss = DiceCoefficientCriterion(size_average=True,epsilon=1.0)\nout = loss.forward(input,target)\nprint \noutput of loss is :\n,out\n\ngrad_out = loss.backward(input,target)\nprint \ngrad out of loss is :\n,grad_out\n\n\n\n\nproduces output:\n\n\ninput= [ 0.4440505  2.9430301]\ntarget= [ 2.  1.]\ncreating: createDiceCoefficientCriterion\noutput of loss is : -0.17262316\ngrad out of loss is : [[-0.38274616 -0.11200322]]\n\n\n\n\nMSECriterion\n\n\nScala:\n\n\nval criterion = MSECriterion()\n\n\n\n\nPython:\n\n\ncriterion = MSECriterion()\n\n\n\n\nThe mean squared error criterion e.g. input: a, target: b, total elements: n\n\n\nloss(a, b) = 1/n * sum(|a_i - b_i|^2)\n\n\n\n\nParameters:\n\n\n\n\nsizeAverage\n - a boolean indicating whether to divide the sum of squared error by n.\n Default: true\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MSECriterion()\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval target = Tensor(T(\n T(2.0f, 3.0f),\n T(4.0f, 5.0f))\n)\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-\n print(output)\n1.0\n-\n print(gradient)\n-0.5    -0.5    \n-0.5    -0.5    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = MSECriterion()\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ntarget = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = criterion.forward(input, target)\ngradient= criterion.backward(input, target)\n-\n print output\n1.0\n-\n print gradient\n[[-0.5 -0.5]\n [-0.5 -0.5]]\n\n\n\n\nSoftMarginCriterion\n\n\nScala:\n\n\nval criterion = SoftMarginCriterion(sizeAverage)\n\n\n\n\nPython:\n\n\ncriterion = SoftMarginCriterion(size_average)\n\n\n\n\nCreates a criterion that optimizes a two-class classification logistic loss between\ninput x (a Tensor of dimension 1) and output y (which is a tensor containing either\n1s or -1s).\n\n\nloss(x, y) = sum_i (log(1 + exp(-y[i]*x[i]))) / x:nElement()\n\n\n\n\nParameters:\n\n* \nsizeAverage\n - A boolean indicating whether normalizing by the number of elements in the input.\n                    Default: true\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = SoftMarginCriterion()\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval target = Tensor(T(\n T(1.0f, -1.0f),\n T(-1.0f, 1.0f))\n)\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-\n print(output)\n1.3767318\n-\n print(gradient)\n-0.06723536     0.22019927      \n0.23814353      -0.0044965525   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = SoftMarginCriterion()\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ntarget = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = criterion.forward(input, target)\ngradient = criterion.backward(input, target)\n-\n print output\n1.3767318\n-\n print gradient\n[[-0.06723536  0.22019927]\n [ 0.23814353 -0.00449655]]\n\n\n\n\nDistKLDivCriterion\n\n\nScala:\n\n\nval loss = DistKLDivCriterion[T](sizeAverage=true)\n\n\n\n\nPython:\n\n\nloss = DistKLDivCriterion(size_average=True)\n\n\n\n\nDistKLDivCriterion is the Kullback\u2013Leibler divergence loss.\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f)))\nval loss = DistKLDivCriterion()\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala\n print(input)\n-0.3854126\n-0.7707398\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala\n print(target)\n2.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala\n print(output)\n1.4639297\n\nscala\n print(grad)\n-1.0\n-0.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(2)\ntarget = np.array([2,1])\n\nprint \ninput=\n, input\nprint \ntarget=\n, target\nloss = DistKLDivCriterion()\nout = loss.forward(input,target)\nprint \noutput of loss is :\n,out\n\ngrad_out = loss.backward(input,target)\nprint \ngrad out of loss is :\n,grad_out\n\n\n\n\nproduces output:\n\n\ninput= [-1.14333924  0.97662296]\ntarget= [2 1]\ncreating: createDistKLDivCriterion\noutput of loss is : 1.348175\ngrad out of loss is : [-1.  -0.5]\n\n\n\n\nClassSimplexCriterion\n\n\nScala:\n\n\nval criterion = ClassSimplexCriterion(nClasses)\n\n\n\n\nPython:\n\n\ncriterion = ClassSimplexCriterion(nClasses)\n\n\n\n\nClassSimplexCriterion implements a criterion for classification.\nIt learns an embedding per class, where each class' embedding is a\npoint on an (N-1)-dimensional simplex, where N is the number of classes.\n\n\nParameters:\n\n* \nnClasses\n - An integer, the number of classes.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = ClassSimplexCriterion(5)\nval input = Tensor(T(\n T(1.0f, 2.0f, 3.0f, 4.0f, 5.0f),\n T(4.0f, 5.0f, 6.0f, 7.0f, 8.0f)\n))\nval target = Tensor(2)\ntarget(1) = 2.0f\ntarget(2) = 1.0f\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-\n print(output)\n23.562702\n-\n print(gradient)\n0.25    0.20635083      0.6     0.8     1.0     \n0.6     1.0     1.2     1.4     1.6     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = ClassSimplexCriterion(5)\ninput = np.array([\n   [1.0, 2.0, 3.0, 4.0, 5.0],\n   [4.0, 5.0, 6.0, 7.0, 8.0]\n])\ntarget = np.array([2.0, 1.0])\noutput = criterion.forward(input, target)\ngradient = criterion.backward(input, target)\n-\n print output\n23.562702\n-\n print gradient\n[[ 0.25        0.20635083  0.60000002  0.80000001  1.        ]\n [ 0.60000002  1.          1.20000005  1.39999998  1.60000002]]\n\n\n\n\nL1HingeEmbeddingCriterion\n\n\nScala:\n\n\nval model = L1HingeEmbeddingCriterion(margin)\n\n\n\n\nPython:\n\n\nmodel = L1HingeEmbeddingCriterion(margin)\n\n\n\n\nCreates a criterion that measures the loss given an input \nx = {x1, x2}\n, a table of two Tensors, and a label y (1 or -1).\nThis is used for measuring whether two inputs are similar or dissimilar, using the L1 distance, and is typically used for learning nonlinear embeddings or semi-supervised learning.\n\n\n             \u23a7 ||x1 - x2||_1,                  if y ==  1\nloss(x, y) = \u23a8\n             \u23a9 max(0, margin - ||x1 - x2||_1), if y == -1\n\n\n\n\nThe margin has a default value of 1, or can be set in the constructor.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = L1HingeEmbeddingCriterion(0.6)\nval input1 = Tensor(T(1.0f, -0.1f))\nval input2 = Tensor(T(2.0f, -0.2f))\nval input = T(input1, input2)\nval target = Tensor(1)\ntarget(Array(1)) = 1.0f\n\nval output = model.forward(input, target)\n\nscala\n print(output)\n1.1\n\n\n\n\nPython example:\n\n\nmodel = L1HingeEmbeddingCriterion(0.6)\ninput1 = np.array(1.0, -0.1)\ninput2 = np.array(2.0, -0.2)\ninput = [input1, input2]\ntarget = np.array([1.0])\n\noutput = model.forward(input, target)\n\n\n print output\n1.1\n\n\n\n\nCrossEntropyCriterion\n\n\nScala:\n\n\nval module = CrossEntropyCriterion(weights, sizeAverage)\n\n\n\n\nPython:\n\n\nmodule = CrossEntropyCriterion(weights, sizeAverage)\n\n\n\n\nThis criterion combines LogSoftMax and ClassNLLCriterion in one single class.\n\n\nweights\n A tensor assigning weight to each of the classes\n\n\nsizeAverage\n whether to divide the sequence length. Default is true.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval layer = CrossEntropyCriterion[Double]()\nval input = Tensor[Double](Storage(Array(\n    1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404\n    ))).resize(3, 3)\nval target = Tensor[Double](3)\n    target(Array(1)) = 1\n    target(Array(2)) = 2\n    target(Array(3)) = 3\n\n print(layer.forward(input, target))\n0.9483051199107635\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\n\nlayer = CrossEntropyCriterion()\ninput = np.array([1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404\n                      ]).reshape(3,3)\ntarget = np.array([1, 2, 3])                      \n\nlayer.forward(input, target)\n0.94830513\n\n\n\n\nParallelCriterion\n\n\nScala:\n\n\nval pc = ParallelCriterion(repeatTarget=false)\n\n\n\n\nPython:\n\n\npc = ParallelCriterion(repeat_target=False)\n\n\n\n\nParallelCriterion is a weighted sum of other criterions each applied to a different input\nand target. Set repeatTarget = true to share the target for criterions.\nUse add(criterion[, weight]) method to add criterion. Where weight is a scalar(default 1).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.{Tensor, Storage}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.{ParallelCriterion, ClassNLLCriterion, MSECriterion}\n\nval pc = ParallelCriterion()\n\nval input = T(Tensor(2, 10), Tensor(2, 10))\nvar i = 0\ninput[Tensor](1).apply1(_ =\n {i += 1; i})\ninput[Tensor](2).apply1(_ =\n {i -= 1; i})\nval target = T(Tensor(Storage(Array(1.0f, 8.0f))), Tensor(2, 10).fill(1.0f))\n\nval nll = ClassNLLCriterion()\nval mse = MSECriterion()\npc.add(nll, 0.5).add(mse)\n\nval output = pc.forward(input, target)\nval gradInput = pc.backward(input, target)\n\nprintln(output)\nprintln(gradInput)\n\n\n\n\n\nThe output is,\n\n\n100.75\n\n\n\n\n\nThe gradInput is,\n\n\n {\n        2: 1.8000001    1.7     1.6     1.5     1.4     1.3000001       1.2     1.1     1.0     0.90000004\n           0.8  0.7     0.6     0.5     0.4     0.3     0.2     0.1     0.0     -0.1\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n        1: -0.25        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n           0.0  0.0     0.0     0.0     0.0     0.0     0.0     -0.25   0.0     0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\npc = ParallelCriterion()\n\ninput1 = np.arange(1, 21, 1).astype(\nfloat32\n)\ninput2 = np.arange(0, 20, 1).astype(\nfloat32\n)[::-1]\ninput1 = input1.reshape(2, 10)\ninput2 = input2.reshape(2, 10)\n\ninput = [input1, input2]\n\ntarget1 = np.array([1.0, 8.0]).astype(\nfloat32\n)\ntarget1 = target1.reshape(2)\ntarget2 = np.full([2, 10], 1).astype(\nfloat32\n)\ntarget2 = target2.reshape(2, 10)\ntarget = [target1, target2]\n\nnll = ClassNLLCriterion()\nmse = MSECriterion()\n\npc.add(nll, weight = 0.5).add(mse)\n\nprint \ninput = \\n %s \n % input\nprint \ntarget = \\n %s\n % target\n\noutput = pc.forward(input, target)\ngradInput = pc.backward(input, target)\n\nprint \noutput = %s \n % output\nprint \ngradInput = %s \n % gradInput\n\n\n\n\nThe console will output,\n\n\ninput = \n [array([[  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.],\n       [ 11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.]], dtype=float32), array([[ 19.,  18.,  17.,  16.,  15.,  14.,  13.,  12.,  11.,  10.],\n       [  9.,   8.,   7.,   6.,   5.,   4.,   3.,   2.,   1.,   0.]], dtype=float32)] \ntarget = \n [array([ 1.,  8.], dtype=float32), array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32)]\noutput = 100.75 \ngradInput = [array([[-0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  , -0.25,  0.  ,  0.  ]], dtype=float32), array([[ 1.80000007,  1.70000005,  1.60000002,  1.5       ,  1.39999998,\n         1.30000007,  1.20000005,  1.10000002,  1.        ,  0.90000004],\n       [ 0.80000001,  0.69999999,  0.60000002,  0.5       ,  0.40000001,\n         0.30000001,  0.2       ,  0.1       ,  0.        , -0.1       ]], dtype=float32)]\n\n\n\n\nMultiLabelMarginCriterion\n\n\nScala:\n\n\nval multiLabelMarginCriterion = MultiLabelMarginCriterion(sizeAverage = true)\n\n\n\n\nPython:\n\n\nmultiLabelMarginCriterion = MultiLabelMarginCriterion(size_average=True)\n\n\n\n\nMultiLabelMarginCriterion creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input x and output y \n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval multiLabelMarginCriterion = MultiLabelMarginCriterion(false)\nval input = Tensor(4).rand()\nval target = Tensor(4)\ntarget(Array(1)) = 3\ntarget(Array(2)) = 2\ntarget(Array(3)) = 1\ntarget(Array(4)) = 0\n\n\n print(input)\n0.40267515\n0.5913795\n0.84936756\n0.05999674\n\n\n  print(multiLabelMarginCriterion.forward(input, target))\n0.33414197\n\n\n print(multiLabelMarginCriterion.backward(input, target))\n-0.25\n-0.25\n-0.25\n0.75\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nmultiLabelMarginCriterion = MultiLabelMarginCriterion(False)\n\n\n multiLabelMarginCriterion.forward(np.array([0.3, 0.4, 0.2, 0.6]), np.array([3, 2, 1, 0]))\n0.975\n\n\n multiLabelMarginCriterion.backward(np.array([0.3, 0.4, 0.2, 0.6]), np.array([3, 2, 1, 0]))\n[array([-0.25, -0.25, -0.25,  0.75], dtype=float32)]\n\n\n\n\n\nMultiLabelSoftMarginCriterion\n\n\nScala:\n\n\nval criterion = MultiLabelSoftMarginCriterion(weights = null, sizeAverage = true)\n\n\n\n\nPython:\n\n\ncriterion = MultiLabelSoftMarginCriterion(weights=None, size_average=True)\n\n\n\n\nMultiLabelSoftMarginCriterion is a multiLabel multiclass criterion based on sigmoid:\n\n\nl(x,y) = - sum_i y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i])\n\n\n\n\nwhere \np[i] = exp(x[i]) / (1 + exp(x[i]))\n\n\nIf with weights,\n \nl(x,y) = - sum_i weights[i] (y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i]))\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MultiLabelSoftMarginCriterion()\nval input = Tensor(3)\ninput(Array(1)) = 0.4f\ninput(Array(2)) = 0.5f\ninput(Array(3)) = 0.6f\nval target = Tensor(3)\ntarget(Array(1)) = 0\ntarget(Array(2)) = 1\ntarget(Array(3)) = 1\n\n\n criterion.forward(input, target)\nres0: Float = 0.6081934\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ncriterion = MultiLabelSoftMarginCriterion()\ninput = np.array([0.4, 0.5, 0.6])\ntarget = np.array([0, 1, 1])\n\n\n criterion.forward(input, target)\n0.6081934\n\n\n\n\nAbsCriterion\n\n\nScala:\n\n\nval criterion = AbsCriterion(sizeAverage)\n\n\n\n\nPython:\n\n\ncriterion = AbsCriterion(sizeAverage)\n\n\n\n\nMeasures the mean absolute value of the element-wise difference between input and target\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = AbsCriterion()\nval input = Tensor(T(1.0f, 2.0f, 3.0f))\nval target = Tensor(T(4.0f, 5.0f, 6.0f))\nval output = criterion.forward(input, target)\n\nscala\n print(output)\n3.0\n\n\n\n\nPython example:\n\n\ncriterion = AbsCriterion()\ninput = np.array([1.0, 2.0, 3.0])\ntarget = np.array([4.0, 5.0, 6.0])\noutput=criterion.forward(input, target)\n\n\n print output\n3.0\n\n\n\n\nMultiCriterion\n\n\nScala:\n\n\nval criterion = MultiCriterion()\n\n\n\n\nPython:\n\n\ncriterion = MultiCriterion()\n\n\n\n\nMultiCriterion is a weighted sum of other criterions each applied to the same input and target\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MultiCriterion()\nval nll = ClassNLLCriterion()\nval mse = MSECriterion()\ncriterion.add(nll, 0.5)\ncriterion.add(mse)\n\nval input = Tensor(5).randn()\nval target = Tensor(5)\ntarget(Array(1)) = 1\ntarget(Array(2)) = 2\ntarget(Array(3)) = 3\ntarget(Array(4)) = 2\ntarget(Array(5)) = 1\n\nval output = criterion.forward(input, target)\n\n\n input\n1.0641425\n-0.33507252\n1.2345984\n0.08065767\n0.531199\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\n\n\n output\nres7: Float = 1.9633228\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ncriterion = MultiCriterion()\nnll = ClassNLLCriterion()\nmse = MSECriterion()\ncriterion.add(nll, 0.5)\ncriterion.add(mse)\n\ninput = np.array([0.9682213801388531,\n0.35258855644097503,\n0.04584479998452568,\n-0.21781499692588918,\n-1.02721844006879])\ntarget = np.array([1, 2, 3, 2, 1])\n\noutput = criterion.forward(input, target)\n\n\n output\n3.6099546", 
            "title": "Losses"
        }, 
        {
            "location": "/APIdocs/Losses/#l1cost", 
            "text": "Scala:  val layer = L1Cost[Float]()  Python:  layer = L1Cost()  Compute L1 norm for input, and sign of input  Scala example:  val layer = L1Cost[Float]()\nval input = Tensor[Float](2, 2).rand\nval target = Tensor[Float](2, 2).rand\n\nval output = layer.forward(input, target)\nval gradInput = layer.backward(input, target)  println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.48145306      0.476887\n0.23729686      0.5169516\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  println(target)\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.42999148      0.22272833\n0.49723643      0.17884709\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  println(output)\noutput: Float = 1.7125885  println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0\n1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  layer = L1Cost()\n\ninput = np.random.uniform(0, 1, (2, 2)).astype( float32 )\ntarget = np.random.uniform(0, 1, (2, 2)).astype( float32 )\n\noutput = layer.forward(input, target)\ngradInput = layer.backward(input, target)  output\n2.522411  gradInput\n[array([[ 1.,  1.],\n        [ 1.,  1.]], dtype=float32)]", 
            "title": "L1Cost"
        }, 
        {
            "location": "/APIdocs/Losses/#timedistributedcriterion", 
            "text": "Scala:  val module = TimeDistributedCriterion(critrn, sizeAverage)  Python:  module = TimeDistributedCriterion(critrn, sizeAverage)  This class is intended to support inputs with 3 or more dimensions.\nApply Any Provided Criterion to every temporal slice of an input.  critrn  embedded criterion  sizeAverage  whether to divide the sequence length. Default is false.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval criterion = ClassNLLCriterion[Double]()\nval layer = TimeDistributedCriterion[Double](criterion, true)\nval input = Tensor[Double](Storage(Array(\n    1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404))).resize(3, 2, 3)\nval target = Tensor[Double](3, 2)\n    target(Array(1, 1)) = 1\n    target(Array(1, 2)) = 1\n    target(Array(2, 1)) = 2\n    target(Array(2, 2)) = 2\n    target(Array(3, 1)) = 3\n    target(Array(3, 2)) = 3  print(layer.forward(input, target))\n0.8793184268272332  Python example:  from bigdl.nn.criterion import *\n\ncriterion = ClassNLLCriterion()\nlayer = TimeDistributedCriterion(criterion, True)\ninput = np.array([1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404]).reshape(3,2,3)\ntarget = np.array([[1,1],[2,2],[3,3]])                       layer.forward(input, target)\n0.8793184", 
            "title": "TimeDistributedCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#marginrankingcriterion", 
            "text": "Scala:  val mse = new MarginRankingCriterion(margin=1.0, sizeAverage=true)  Python:  mse = MarginRankingCriterion(margin=1.0, size_average=true)  Creates a criterion that measures the loss given an input x = {x1, x2},\na table of two Tensors of size 1 (they contain only scalars), and a label y (1 or -1).\nIn batch mode, x is a table of two Tensors of size batchsize, and y is a Tensor of size\nbatchsize containing 1 or -1 for each corresponding pair of elements in the input Tensor.\nIf y == 1 then it assumed the first input should be ranked higher (have a larger value) than\nthe second input, and vice-versa for y == -1.  Scala example:  import com.intel.analytics.bigdl.nn.MarginRankingCriterion\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nimport scala.util.Random\n\nval input1Arr = Array(1, 2, 3, 4, 5)\nval input2Arr = Array(5, 4, 3, 2, 1)\n\nval target1Arr = Array(-1, 1, -1, 1, 1)\n\nval input1 = Tensor(Storage(input1Arr.map(x =  x.toFloat)))\nval input2 = Tensor(Storage(input2Arr.map(x =  x.toFloat)))\n\nval input = T((1.toFloat, input1), (2.toFloat, input2))\n\nval target1 = Tensor(Storage(target1Arr.map(x =  x.toFloat)))\nval target = T((1.toFloat, target1))\n\nval mse = new MarginRankingCriterion()\n\nval output = mse.forward(input, target)\nval gradInput = mse.backward(input, target)\n\nprintln(output)\nprintln(gradInput)  The output will be,  output: Float = 0.8                                                                                                                                                                    [21/154]  The gradInput will be,  gradInput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: -0.0\n           0.2\n           -0.2\n           0.0\n           0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n        1: 0.0\n           -0.2\n           0.2\n           -0.0\n           -0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n }  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nmse = MarginRankingCriterion()\n\ninput1 = np.array([1, 2, 3, 4, 5]).astype( float32 )\ninput2 = np.array([5, 4, 3, 2, 1]).astype( float32 )\ninput = [input1, input2]\n\ntarget1 = np.array([-1, 1, -1, 1, 1]).astype( float32 )\ntarget = [target1, target1]\n\noutput = mse.forward(input, target)\ngradInput = mse.backward(input, target)\n\nprint output\nprint gradInput  The output will be,  0.8  The gradInput will be,  [array([ 0. , -0.2,  0.2, -0. , -0. ], dtype=float32), array([-0. ,  0.2, -0.2,  0. ,  0. ], dtype=float32)]", 
            "title": "MarginRankingCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#classnllcriterion", 
            "text": "Scala:  val criterion = ClassNLLCriterion(weights = null, sizeAverage = true)  Python:  criterion = ClassNLLCriterion(weights=None, size_average=True)  The negative log likelihood criterion. It is useful to train a classification problem with n\nclasses. If provided, the optional argument weights should be a 1D Tensor assigning weight to\neach of the classes. This is particularly useful when you have an unbalanced training set.  The input given through a  forward()  is expected to contain log-probabilities of each class:\ninput has to be a 1D Tensor of size  n . Obtaining log-probabilities in a neural network is easily\nachieved by adding a  LogSoftMax  layer in the last layer of your neural network. You may use CrossEntropyCriterion  instead, if you prefer not to add an extra layer to your network. This\ncriterion expects a class index (1 to the number of class) as target when calling forward(input, target)  and  backward(input, target) .  The loss can be described as:\n     loss(x, class) = -x[class]\n or in the case of the weights argument it is specified as follows:\n     loss(x, class) = -weights[class] * x[class]\n Due to the behaviour of the backend code, it is necessary to set sizeAverage to false when\n calculating losses in non-batch mode.  Note that if the target is  -1 , the training process will skip this sample.\n In other words, the forward process will return zero output and the backward process\n will also return zero  gradInput .  By default, the losses are averaged over observations for each minibatch. However, if the field\n  sizeAverage  is set to false, the losses are instead summed for each minibatch.  Parameters:  weights      - weights of each element of the input  sizeAverage  - A boolean indicating whether normalizing by the number of elements in the input.\n                  Default: true  Scala example:  import com.intel.analytics.bigdl.nn.ClassNLLCriterion\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = ClassNLLCriterion()\nval input = Tensor(T(\n              T(1f, 2f, 3f),\n              T(2f, 3f, 4f),\n              T(3f, 4f, 5f)\n          ))\n\nval target = Tensor(T(1f, 2f, 3f))\n\nval loss = criterion.forward(input, target)\nval grad = criterion.backward(input, target)\n\nprint(loss)\n-3.0\nprintln(grad)\n-0.33333334 0.0 0.0\n0.0 -0.33333334 0.0\n0.0 0.0 -0.33333334\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\n\ncriterion = ClassNLLCriterion()\ninput = np.array([\n              [1.0, 2.0, 3.0],\n              [2.0, 3.0, 4.0],\n              [3.0, 4.0, 5.0]\n          ])\n\ntarget = np.array([1.0, 2.0, 3.0])\n\nloss = criterion.forward(input, target)\ngradient= criterion.backward(input, target)\n\nprint loss\n-3.0\nprint gradient\n-3.0\n[[-0.33333334  0.          0.        ]\n [ 0.         -0.33333334  0.        ]\n [ 0.          0.         -0.33333334]]", 
            "title": "ClassNLLCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#softmaxwithcriterion", 
            "text": "Scala:  val model = SoftmaxWithCriterion(ignoreLabel, normalizeMode)  Python:  model = SoftmaxWithCriterion(ignoreLabel, normalizeMode)  Computes the multinomial logistic loss for a one-of-many classification task, passing real-valued predictions through a softmax to\nget a probability distribution over classes. It should be preferred over separate SoftmaxLayer + MultinomialLogisticLossLayer as \nits gradient computation is more numerically stable.   param ignoreLabel   (optional) Specify a label value that should be ignored when computing the loss.  param normalizeMode How to normalize the output loss.   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.{Storage, Tensor}\n\nval input = Tensor(1, 5, 2, 3).rand()\nval target = Tensor(Storage(Array(2.0f, 4.0f, 2.0f, 4.0f, 1.0f, 2.0f))).resize(1, 1, 2, 3)\n\nval model = SoftmaxWithCriterion[Float]()\nval output = model.forward(input, target)\n\nscala  print(input)\n(1,1,.,.) =\n0.65131104  0.9332143   0.5618989   \n0.9965054   0.9370902   0.108070895 \n\n(1,2,.,.) =\n0.46066576  0.9636703   0.8123812   \n0.31076035  0.16386998  0.37894428  \n\n(1,3,.,.) =\n0.49111295  0.3704862   0.9938375   \n0.87996656  0.8695406   0.53354675  \n\n(1,4,.,.) =\n0.8502225   0.9033509   0.8518651   \n0.0692618   0.10121379  0.970959    \n\n(1,5,.,.) =\n0.9397213   0.49688303  0.75739735  \n0.25074655  0.11416598  0.6594504   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x2x3]\n\nscala  print(output)\n1.6689054  Python example:  input = np.random.randn(1, 5, 2, 3)\ntarget = np.array([[[[2.0, 4.0, 2.0], [4.0, 1.0, 2.0]]]])\n\nmodel = SoftmaxWithCriterion()\noutput = model.forward(input, target)  print input\n[[[[ 0.78455689  0.01402084  0.82539628]\n   [-1.06448238  2.58168413  0.60053703]]\n\n  [[-0.48617618  0.44538094  0.46611658]\n   [-1.41509329  0.40038991 -0.63505732]]\n\n  [[ 0.91266769  1.68667933  0.92423611]\n   [ 0.1465411   0.84637557  0.14917515]]\n\n  [[-0.7060493  -2.02544114  0.89070726]\n   [ 0.14535539  0.73980064 -0.33130613]]\n\n  [[ 0.64538791 -0.44384233 -0.40112523]\n   [ 0.44346658 -2.22303621  0.35715986]]]]  print output\n2.1002123", 
            "title": "SoftmaxWithCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#smoothl1criterion", 
            "text": "Scala:  val slc = SmoothL1Criterion(sizeAverage=true)  Python:  slc = SmoothL1Criterion(size_average=True)  Creates a criterion that can be thought of as a smooth version of the AbsCriterion.\nIt uses a squared term if the absolute element-wise error falls below 1.\nIt is less sensitive to outliers than the MSECriterion and in some\ncases prevents exploding gradients (e.g. see \"Fast R-CNN\" paper by Ross Girshick).  Scala example:  import com.intel.analytics.bigdl.tensor.{Tensor, Storage}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.SmoothL1Criterion\n\nval slc = SmoothL1Criterion()\n\nval inputArr = Array(\n  0.17503996845335,\n  0.83220188552514,\n  0.48450597329065,\n  0.64701424003579,\n  0.62694586534053,\n  0.34398410236463,\n  0.55356747563928,\n  0.20383032318205\n)\nval targetArr = Array(\n  0.69956525065936,\n  0.86074831243604,\n  0.54923197557218,\n  0.57388074393384,\n  0.63334444304928,\n  0.99680578662083,\n  0.49997645849362,\n  0.23869121982716\n)\n\nval input = Tensor(Storage(inputArr.map(x =  x.toFloat))).reshape(Array(2, 2, 2))\nval target = Tensor(Storage(targetArr.map(x =  x.toFloat))).reshape(Array(2, 2, 2))\n\nval output = slc.forward(input, target)\nval gradInput = slc.backward(input, target)  The output is,  output: Float = 0.0447365  The gradInput is,  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.06556566     -0.003568299\n-0.008090746    0.009141691\n\n(2,.,.) =\n-7.998273E-4    -0.08160271\n0.0066988766    -0.0043576136  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nslc = SmoothL1Criterion()\n\ninput = np.array([\n    0.17503996845335,\n    0.83220188552514,\n    0.48450597329065,\n    0.64701424003579,\n    0.62694586534053,\n    0.34398410236463,\n    0.55356747563928,\n    0.20383032318205\n])\ninput.reshape(2, 2, 2)\n\ntarget = np.array([\n    0.69956525065936,\n    0.86074831243604,\n    0.54923197557218,\n    0.57388074393384,\n    0.63334444304928,\n    0.99680578662083,\n    0.49997645849362,\n    0.23869121982716\n])\n\ntarget.reshape(2, 2, 2)\n\noutput = slc.forward(input, target)\ngradInput = slc.backward(input, target)\n\nprint output\nprint gradInput", 
            "title": "SmoothL1Criterion"
        }, 
        {
            "location": "/APIdocs/Losses/#smoothl1criterionwithweights", 
            "text": "Scala:  val smcod = SmoothL1CriterionWithWeights[Float](sigma: Float = 2.4f, num: Int = 2)  Python:  smcod = SmoothL1CriterionWithWeights(sigma, num)  a smooth version of the AbsCriterion\nIt uses a squared term if the absolute element-wise error falls below 1.\nIt is less sensitive to outliers than the MSECriterion and in some cases\nprevents exploding gradients (e.g. see \"Fast R-CNN\" paper by Ross Girshick).     d = (x - y) * w_in\n\n  loss(x, y, w_in, w_out)\n              | 0.5 * (sigma * d_i)^2 * w_out          if |d_i|   1 / sigma / sigma\n   = 1/n \\sum |\n              | (|d_i| - 0.5 / sigma / sigma) * w_out   otherwise  Scala example:  val smcod = SmoothL1CriterionWithWeights[Float](2.4f, 2)\n\nval inputArr = Array(1.1, -0.8, 0.1, 0.4, 1.3, 0.2, 0.2, 0.03)\nval targetArr = Array(0.9, 1.5, -0.08, -1.68, -0.68, -1.17, -0.92, 1.58)\nval inWArr = Array(-0.1, 1.7, -0.8, -1.9, 1.0, 1.4, 0.8, 0.8)\nval outWArr = Array(-1.9, -0.5, 1.9, -1.0, -0.2, 0.1, 0.3, 1.1)\n\nval input = Tensor(Storage(inputArr.map(x =  x.toFloat)))\nval target = T()\ntarget.insert(Tensor(Storage(targetArr.map(x =  x.toFloat))))\ntarget.insert(Tensor(Storage(inWArr.map(x =  x.toFloat))))\ntarget.insert(Tensor(Storage(outWArr.map(x =  x.toFloat))))\n\nval output = smcod.forward(input, target)\nval gradInput = smcod.backward(input, target)  println(output)\n  output: Float = -2.17488  println(gradInput)\n-0.010944003\n0.425\n0.63037443\n-0.95\n-0.1\n0.07\n0.120000005\n-0.44000003\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 8]  Python example:  smcod = SmoothL1CriterionWithWeights(2.4, 2)\n\ninput = np.array([1.1, -0.8, 0.1, 0.4, 1.3, 0.2, 0.2, 0.03]).astype( float32 )\ntargetArr = np.array([0.9, 1.5, -0.08, -1.68, -0.68, -1.17, -0.92, 1.58]).astype( float32 )\ninWArr = np.array([-0.1, 1.7, -0.8, -1.9, 1.0, 1.4, 0.8, 0.8]).astype( float32 )\noutWArr = np.array([-1.9, -0.5, 1.9, -1.0, -0.2, 0.1, 0.3, 1.1]).astype( float32 )\ntarget = [targetArr, inWArr, outWArr]\n\noutput = smcod.forward(input, target)\ngradInput = smcod.backward(input, target)  output\n-2.17488  gradInput\n[array([-0.010944  ,  0.42500001,  0.63037443, -0.94999999, -0.1       ,\n         0.07      ,  0.12      , -0.44000003], dtype=float32)]", 
            "title": "SmoothL1CriterionWithWeights"
        }, 
        {
            "location": "/APIdocs/Losses/#multimargincriterion", 
            "text": "Scala:  val loss = MultiMarginCriterion(p=1,weights=null,margin=1.0,sizeAverage=true)  Python:  loss = MultiMarginCriterion(p=1,weights=None,margin=1.0,size_average=True)  MultiMarginCriterion is a loss function that optimizes a multi-class classification hinge loss (margin-based loss) between input  x  and output  y  ( y  is the target class index).  Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(3,2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f, 2.0f)))\nval loss = MultiMarginCriterion(1)\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala  print(input)\n-0.45896783     -0.80141246\n0.22560088      -0.13517438\n0.2601126       0.35492152\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nscala  print(target)\n2.0\n1.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\nscala  print(output)\n0.4811434\n\nscala  print(grad)\n0.16666667      -0.16666667\n-0.16666667     0.16666667\n0.16666667      -0.16666667\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(3,2)\ntarget = np.array([2,1,2])\nprint  input= ,input\nprint  target= ,target\n\nloss = MultiMarginCriterion(1)\nout = loss.forward(input, target)\nprint  output of loss is :  ,out\n\ngrad_out = loss.backward(input,target)\nprint  grad out of loss is :  ,grad_out  produces output  input= [[ 0.46868305 -2.28562261]\n [ 0.8076243  -0.67809689]\n [-0.20342555 -0.66264743]]\ntarget= [2 1 2]\ncreating: createMultiMarginCriterion\noutput of loss is :  0.8689213\ngrad out of loss is :  [[ 0.16666667 -0.16666667]\n [ 0.          0.        ]\n [ 0.16666667 -0.16666667]]", 
            "title": "MultiMarginCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#hingeembeddingcriterion", 
            "text": "Scala:  val m = HingeEmbeddingCriterion(margin = 1, sizeAverage = true)  Python:  m = HingeEmbeddingCriterion(margin=1, size_average=True)  Creates a criterion that measures the loss given an input  x  which is a 1-dimensional vector and a label  y  ( 1  or  -1 ).\nThis is usually used for measuring whether two inputs are similar or dissimilar, e.g. using the L1 pairwise distance, and is typically used for learning nonlinear embeddings or semi-supervised learning.                   \u23a7 x_i,                  if y_i ==  1\nloss(x, y) = 1/n \u23a8\n                 \u23a9 max(0, margin - x_i), if y_i == -1  Scala example:  import com.intel.analytics.bigdl.utils.{T}\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval loss = HingeEmbeddingCriterion(1, sizeAverage = false)\nval input = Tensor(T(0.1f, 2.0f, 2.0f, 2.0f))\nprintln( input: \\n  + input)\nprintln( ouput:  )\n\nprintln( Target=1:   + loss.forward(input, Tensor(4, 1).fill(1f)))\n\nprintln( Target=-1:   + loss.forward(input, Tensor(4, 1).fill(-1f)))  input: \n0.1\n2.0\n2.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\nouput: \nTarget=1: 6.1\nTarget=-1: 0.9  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\ninput = np.array([0.1, 2.0, 2.0, 2.0])\ntarget = np.full(4, 1)\nprint( input:   )\nprint(input)\nprint( target:  )\nprint(target)\nprint( output:  )\nprint(HingeEmbeddingCriterion(1.0, size_average= False).forward(input, target))\nprint(HingeEmbeddingCriterion(1.0, size_average= False).forward(input, np.full(4, -1)))  input: \n[ 0.1  2.   2.   2. ]\ntarget: \n[1 1 1 1]\noutput: \ncreating: createHingeEmbeddingCriterion\n6.1\ncreating: createHingeEmbeddingCriterion\n0.9", 
            "title": "HingeEmbeddingCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#margincriterion", 
            "text": "Scala:  criterion = MarginCriterion(margin=1.0, sizeAverage=true)  Python:  criterion = MarginCriterion(margin=1.0, sizeAverage=true, bigdl_type= float )  Creates a criterion that optimizes a two-class classification hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.\n * @param margin if unspecified, is by default 1.\n * @param sizeAverage whether to average the loss, is by default true  Scala example:  val criterion = MarginCriterion(margin=1.0, sizeAverage=true)\n\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.33753583      0.3575501\n0.23477706      0.7240361\n0.92835575      0.4737949\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nval target = Tensor(3, 2).rand()\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.27280563      0.7022703\n0.3348442       0.43332106\n0.08935371      0.17876455\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\ncriterion.forward(input, target)\nres5: Float = 0.84946966  Python example:  criterion = MarginCriterion(margin=1.0,size_average=True,bigdl_type= float )\ninput = np.random.rand(3, 2)\narray([[ 0.20824672,  0.67299837],\n       [ 0.80561452,  0.19564743],\n       [ 0.42501441,  0.19408184]])\n\ntarget = np.random.rand(3, 2)\narray([[ 0.67882632,  0.61257846],\n       [ 0.10111138,  0.75225082],\n       [ 0.60404296,  0.31373273]])\n\ncriterion.forward(input, target)\n0.8166871", 
            "title": "MarginCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#cosineembeddingcriterion", 
            "text": "Scala:  val cosineEmbeddingCriterion = CosineEmbeddingCriterion(margin  = 0.0, sizeAverage = true)  Python:  cosineEmbeddingCriterion = CosineEmbeddingCriterion( margin=0.0,size_average=True)  CosineEmbeddingCriterion creates a criterion that measures the loss given an input x = {x1, x2},\na table of two Tensors, and a Tensor label y with values 1 or -1.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimpot com.intel.analytics.bigdl.utils.T\nval cosineEmbeddingCriterion = CosineEmbeddingCriterion(0.0, false)\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T()\ninput(1.0) = input1\ninput(2.0) = input2\nval target1 = Tensor(Storage(Array(-0.5f)))\nval target = T()\ntarget(1.0) = target1  print(input)\n {\n    2.0: 0.4110882\n         0.57726574\n         0.1949834\n         0.67670715\n         0.16984987\n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1.0: 0.16878392\n         0.24124223\n         0.8964794\n         0.11156334\n         0.5101486\n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n }  print(cosineEmbeddingCriterion.forward(input, target))\n0.49919847  print(cosineEmbeddingCriterion.backward(input, target))\n {\n    2: -0.045381278\n       -0.059856333\n       0.72547954\n       -0.2268434\n       0.3842142\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n    1: 0.30369008\n       0.42463788\n       -0.20637506\n       0.5712836\n       -0.06355385\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n }  Python example:  from bigdl.nn.layer import *\ncosineEmbeddingCriterion = CosineEmbeddingCriterion(0.0, False)  cosineEmbeddingCriterion.forward([np.array([1.0, 2.0, 3.0, 4.0 ,5.0]),np.array([5.0, 4.0, 3.0, 2.0, 1.0])],[np.array(-0.5)])\n0.6363636  cosineEmbeddingCriterion.backward([np.array([1.0, 2.0, 3.0, 4.0 ,5.0]),np.array([5.0, 4.0, 3.0, 2.0, 1.0])],[np.array(-0.5)])\n[array([ 0.07933884,  0.04958678,  0.01983471, -0.00991735, -0.03966942], dtype=float32), array([-0.03966942, -0.00991735,  0.01983471,  0.04958678,  0.07933884], dtype=float32)]", 
            "title": "CosineEmbeddingCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#bcecriterion", 
            "text": "Scala:  val criterion = BCECriterion[Float]()  Python:  criterion = BCECriterion()  This loss function measures the Binary Cross Entropy between the target and the output   loss(o, t) = - 1/n sum_i (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))  or in the case of the weights argument being specified:   loss(o, t) = - 1/n sum_i weights[i] * (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))  By default, the losses are averaged for each mini-batch over observations as well as over\n dimensions. However, if the field sizeAverage is set to false, the losses are instead summed.  Scala example:  \nval criterion = BCECriterion[Float]()\nval input = Tensor[Float](3, 1).rand\n\nval target = Tensor[Float](3)\ntarget(1) = 1\ntarget(2) = 0\ntarget(3) = 1\n\nval output = criterion.forward(input, target)\nval gradInput = criterion.backward(input, target)  println(target)\nres25: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n0.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]  println(output)\noutput: Float = 0.9009579  println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.5277504\n1.0736246\n-0.336957\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1]  Python example:  \ncriterion = BCECriterion()\ninput = np.random.uniform(0, 1, (3, 1)).astype( float32 )\ntarget = np.array([1, 0, 1])\noutput = criterion.forward(input, target)\ngradInput = criterion.backward(input, target)  output\n1.9218739  gradInput\n[array([[-4.3074522 ],\n        [ 2.24244714],\n        [-1.22368968]], dtype=float32)]", 
            "title": "BCECriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#dicecoefficientcriterion", 
            "text": "Scala:  val loss = DiceCoefficientCriterion(sizeAverage=true, epsilon=1.0f)  Python:  loss = DiceCoefficientCriterion(size_average=True,epsilon=1.0)  DiceCoefficientCriterion is the Dice-Coefficient objective function.   Both  forward  and  backward  accept two tensors : input and target. The  forward  result is formulated as \n           1 - (2 * (input intersection target) / (input union target))  Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f)))\nval loss = DiceCoefficientCriterion(epsilon = 1.0f)\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala  print(input)\n-0.50278\n0.51387966\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala  print(target)\n2.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala  print(output)\n0.9958517\n\nscala  print(grad)\n-0.99619853     -0.49758217\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(2)\ntarget = np.array([2,1],dtype='float64')\n\nprint  input= , input\nprint  target= , target\nloss = DiceCoefficientCriterion(size_average=True,epsilon=1.0)\nout = loss.forward(input,target)\nprint  output of loss is : ,out\n\ngrad_out = loss.backward(input,target)\nprint  grad out of loss is : ,grad_out  produces output:  input= [ 0.4440505  2.9430301]\ntarget= [ 2.  1.]\ncreating: createDiceCoefficientCriterion\noutput of loss is : -0.17262316\ngrad out of loss is : [[-0.38274616 -0.11200322]]", 
            "title": "DiceCoefficientCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#msecriterion", 
            "text": "Scala:  val criterion = MSECriterion()  Python:  criterion = MSECriterion()  The mean squared error criterion e.g. input: a, target: b, total elements: n  loss(a, b) = 1/n * sum(|a_i - b_i|^2)  Parameters:   sizeAverage  - a boolean indicating whether to divide the sum of squared error by n.\n Default: true   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MSECriterion()\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval target = Tensor(T(\n T(2.0f, 3.0f),\n T(4.0f, 5.0f))\n)\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-  print(output)\n1.0\n-  print(gradient)\n-0.5    -0.5    \n-0.5    -0.5    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = MSECriterion()\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ntarget = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = criterion.forward(input, target)\ngradient= criterion.backward(input, target)\n-  print output\n1.0\n-  print gradient\n[[-0.5 -0.5]\n [-0.5 -0.5]]", 
            "title": "MSECriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#softmargincriterion", 
            "text": "Scala:  val criterion = SoftMarginCriterion(sizeAverage)  Python:  criterion = SoftMarginCriterion(size_average)  Creates a criterion that optimizes a two-class classification logistic loss between\ninput x (a Tensor of dimension 1) and output y (which is a tensor containing either\n1s or -1s).  loss(x, y) = sum_i (log(1 + exp(-y[i]*x[i]))) / x:nElement()  Parameters: \n*  sizeAverage  - A boolean indicating whether normalizing by the number of elements in the input.\n                    Default: true  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = SoftMarginCriterion()\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval target = Tensor(T(\n T(1.0f, -1.0f),\n T(-1.0f, 1.0f))\n)\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-  print(output)\n1.3767318\n-  print(gradient)\n-0.06723536     0.22019927      \n0.23814353      -0.0044965525   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = SoftMarginCriterion()\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ntarget = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = criterion.forward(input, target)\ngradient = criterion.backward(input, target)\n-  print output\n1.3767318\n-  print gradient\n[[-0.06723536  0.22019927]\n [ 0.23814353 -0.00449655]]", 
            "title": "SoftMarginCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#distkldivcriterion", 
            "text": "Scala:  val loss = DistKLDivCriterion[T](sizeAverage=true)  Python:  loss = DistKLDivCriterion(size_average=True)  DistKLDivCriterion is the Kullback\u2013Leibler divergence loss.  Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f)))\nval loss = DistKLDivCriterion()\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala  print(input)\n-0.3854126\n-0.7707398\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala  print(target)\n2.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala  print(output)\n1.4639297\n\nscala  print(grad)\n-1.0\n-0.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(2)\ntarget = np.array([2,1])\n\nprint  input= , input\nprint  target= , target\nloss = DistKLDivCriterion()\nout = loss.forward(input,target)\nprint  output of loss is : ,out\n\ngrad_out = loss.backward(input,target)\nprint  grad out of loss is : ,grad_out  produces output:  input= [-1.14333924  0.97662296]\ntarget= [2 1]\ncreating: createDistKLDivCriterion\noutput of loss is : 1.348175\ngrad out of loss is : [-1.  -0.5]", 
            "title": "DistKLDivCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#classsimplexcriterion", 
            "text": "Scala:  val criterion = ClassSimplexCriterion(nClasses)  Python:  criterion = ClassSimplexCriterion(nClasses)  ClassSimplexCriterion implements a criterion for classification.\nIt learns an embedding per class, where each class' embedding is a\npoint on an (N-1)-dimensional simplex, where N is the number of classes.  Parameters: \n*  nClasses  - An integer, the number of classes.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = ClassSimplexCriterion(5)\nval input = Tensor(T(\n T(1.0f, 2.0f, 3.0f, 4.0f, 5.0f),\n T(4.0f, 5.0f, 6.0f, 7.0f, 8.0f)\n))\nval target = Tensor(2)\ntarget(1) = 2.0f\ntarget(2) = 1.0f\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-  print(output)\n23.562702\n-  print(gradient)\n0.25    0.20635083      0.6     0.8     1.0     \n0.6     1.0     1.2     1.4     1.6     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = ClassSimplexCriterion(5)\ninput = np.array([\n   [1.0, 2.0, 3.0, 4.0, 5.0],\n   [4.0, 5.0, 6.0, 7.0, 8.0]\n])\ntarget = np.array([2.0, 1.0])\noutput = criterion.forward(input, target)\ngradient = criterion.backward(input, target)\n-  print output\n23.562702\n-  print gradient\n[[ 0.25        0.20635083  0.60000002  0.80000001  1.        ]\n [ 0.60000002  1.          1.20000005  1.39999998  1.60000002]]", 
            "title": "ClassSimplexCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#l1hingeembeddingcriterion", 
            "text": "Scala:  val model = L1HingeEmbeddingCriterion(margin)  Python:  model = L1HingeEmbeddingCriterion(margin)  Creates a criterion that measures the loss given an input  x = {x1, x2} , a table of two Tensors, and a label y (1 or -1).\nThis is used for measuring whether two inputs are similar or dissimilar, using the L1 distance, and is typically used for learning nonlinear embeddings or semi-supervised learning.               \u23a7 ||x1 - x2||_1,                  if y ==  1\nloss(x, y) = \u23a8\n             \u23a9 max(0, margin - ||x1 - x2||_1), if y == -1  The margin has a default value of 1, or can be set in the constructor.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = L1HingeEmbeddingCriterion(0.6)\nval input1 = Tensor(T(1.0f, -0.1f))\nval input2 = Tensor(T(2.0f, -0.2f))\nval input = T(input1, input2)\nval target = Tensor(1)\ntarget(Array(1)) = 1.0f\n\nval output = model.forward(input, target)\n\nscala  print(output)\n1.1  Python example:  model = L1HingeEmbeddingCriterion(0.6)\ninput1 = np.array(1.0, -0.1)\ninput2 = np.array(2.0, -0.2)\ninput = [input1, input2]\ntarget = np.array([1.0])\n\noutput = model.forward(input, target)  print output\n1.1", 
            "title": "L1HingeEmbeddingCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#crossentropycriterion", 
            "text": "Scala:  val module = CrossEntropyCriterion(weights, sizeAverage)  Python:  module = CrossEntropyCriterion(weights, sizeAverage)  This criterion combines LogSoftMax and ClassNLLCriterion in one single class.  weights  A tensor assigning weight to each of the classes  sizeAverage  whether to divide the sequence length. Default is true.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval layer = CrossEntropyCriterion[Double]()\nval input = Tensor[Double](Storage(Array(\n    1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404\n    ))).resize(3, 3)\nval target = Tensor[Double](3)\n    target(Array(1)) = 1\n    target(Array(2)) = 2\n    target(Array(3)) = 3  print(layer.forward(input, target))\n0.9483051199107635  Python example:  from bigdl.nn.criterion import *\n\nlayer = CrossEntropyCriterion()\ninput = np.array([1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404\n                      ]).reshape(3,3)\ntarget = np.array([1, 2, 3])                       layer.forward(input, target)\n0.94830513", 
            "title": "CrossEntropyCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#parallelcriterion", 
            "text": "Scala:  val pc = ParallelCriterion(repeatTarget=false)  Python:  pc = ParallelCriterion(repeat_target=False)  ParallelCriterion is a weighted sum of other criterions each applied to a different input\nand target. Set repeatTarget = true to share the target for criterions.\nUse add(criterion[, weight]) method to add criterion. Where weight is a scalar(default 1).  Scala example:  import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.{Tensor, Storage}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.{ParallelCriterion, ClassNLLCriterion, MSECriterion}\n\nval pc = ParallelCriterion()\n\nval input = T(Tensor(2, 10), Tensor(2, 10))\nvar i = 0\ninput[Tensor](1).apply1(_ =  {i += 1; i})\ninput[Tensor](2).apply1(_ =  {i -= 1; i})\nval target = T(Tensor(Storage(Array(1.0f, 8.0f))), Tensor(2, 10).fill(1.0f))\n\nval nll = ClassNLLCriterion()\nval mse = MSECriterion()\npc.add(nll, 0.5).add(mse)\n\nval output = pc.forward(input, target)\nval gradInput = pc.backward(input, target)\n\nprintln(output)\nprintln(gradInput)  The output is,  100.75  The gradInput is,   {\n        2: 1.8000001    1.7     1.6     1.5     1.4     1.3000001       1.2     1.1     1.0     0.90000004\n           0.8  0.7     0.6     0.5     0.4     0.3     0.2     0.1     0.0     -0.1\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n        1: -0.25        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n           0.0  0.0     0.0     0.0     0.0     0.0     0.0     -0.25   0.0     0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n }  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\npc = ParallelCriterion()\n\ninput1 = np.arange(1, 21, 1).astype( float32 )\ninput2 = np.arange(0, 20, 1).astype( float32 )[::-1]\ninput1 = input1.reshape(2, 10)\ninput2 = input2.reshape(2, 10)\n\ninput = [input1, input2]\n\ntarget1 = np.array([1.0, 8.0]).astype( float32 )\ntarget1 = target1.reshape(2)\ntarget2 = np.full([2, 10], 1).astype( float32 )\ntarget2 = target2.reshape(2, 10)\ntarget = [target1, target2]\n\nnll = ClassNLLCriterion()\nmse = MSECriterion()\n\npc.add(nll, weight = 0.5).add(mse)\n\nprint  input = \\n %s   % input\nprint  target = \\n %s  % target\n\noutput = pc.forward(input, target)\ngradInput = pc.backward(input, target)\n\nprint  output = %s   % output\nprint  gradInput = %s   % gradInput  The console will output,  input = \n [array([[  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.],\n       [ 11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.]], dtype=float32), array([[ 19.,  18.,  17.,  16.,  15.,  14.,  13.,  12.,  11.,  10.],\n       [  9.,   8.,   7.,   6.,   5.,   4.,   3.,   2.,   1.,   0.]], dtype=float32)] \ntarget = \n [array([ 1.,  8.], dtype=float32), array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32)]\noutput = 100.75 \ngradInput = [array([[-0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  , -0.25,  0.  ,  0.  ]], dtype=float32), array([[ 1.80000007,  1.70000005,  1.60000002,  1.5       ,  1.39999998,\n         1.30000007,  1.20000005,  1.10000002,  1.        ,  0.90000004],\n       [ 0.80000001,  0.69999999,  0.60000002,  0.5       ,  0.40000001,\n         0.30000001,  0.2       ,  0.1       ,  0.        , -0.1       ]], dtype=float32)]", 
            "title": "ParallelCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#multilabelmargincriterion", 
            "text": "Scala:  val multiLabelMarginCriterion = MultiLabelMarginCriterion(sizeAverage = true)  Python:  multiLabelMarginCriterion = MultiLabelMarginCriterion(size_average=True)  MultiLabelMarginCriterion creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input x and output y   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval multiLabelMarginCriterion = MultiLabelMarginCriterion(false)\nval input = Tensor(4).rand()\nval target = Tensor(4)\ntarget(Array(1)) = 3\ntarget(Array(2)) = 2\ntarget(Array(3)) = 1\ntarget(Array(4)) = 0  print(input)\n0.40267515\n0.5913795\n0.84936756\n0.05999674   print(multiLabelMarginCriterion.forward(input, target))\n0.33414197  print(multiLabelMarginCriterion.backward(input, target))\n-0.25\n-0.25\n-0.25\n0.75\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  Python example:  from bigdl.nn.layer import *\nmultiLabelMarginCriterion = MultiLabelMarginCriterion(False)  multiLabelMarginCriterion.forward(np.array([0.3, 0.4, 0.2, 0.6]), np.array([3, 2, 1, 0]))\n0.975  multiLabelMarginCriterion.backward(np.array([0.3, 0.4, 0.2, 0.6]), np.array([3, 2, 1, 0]))\n[array([-0.25, -0.25, -0.25,  0.75], dtype=float32)]", 
            "title": "MultiLabelMarginCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#multilabelsoftmargincriterion", 
            "text": "Scala:  val criterion = MultiLabelSoftMarginCriterion(weights = null, sizeAverage = true)  Python:  criterion = MultiLabelSoftMarginCriterion(weights=None, size_average=True)  MultiLabelSoftMarginCriterion is a multiLabel multiclass criterion based on sigmoid:  l(x,y) = - sum_i y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i])  where  p[i] = exp(x[i]) / (1 + exp(x[i]))  If with weights,\n  l(x,y) = - sum_i weights[i] (y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i]))  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MultiLabelSoftMarginCriterion()\nval input = Tensor(3)\ninput(Array(1)) = 0.4f\ninput(Array(2)) = 0.5f\ninput(Array(3)) = 0.6f\nval target = Tensor(3)\ntarget(Array(1)) = 0\ntarget(Array(2)) = 1\ntarget(Array(3)) = 1  criterion.forward(input, target)\nres0: Float = 0.6081934  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ncriterion = MultiLabelSoftMarginCriterion()\ninput = np.array([0.4, 0.5, 0.6])\ntarget = np.array([0, 1, 1])  criterion.forward(input, target)\n0.6081934", 
            "title": "MultiLabelSoftMarginCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#abscriterion", 
            "text": "Scala:  val criterion = AbsCriterion(sizeAverage)  Python:  criterion = AbsCriterion(sizeAverage)  Measures the mean absolute value of the element-wise difference between input and target  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = AbsCriterion()\nval input = Tensor(T(1.0f, 2.0f, 3.0f))\nval target = Tensor(T(4.0f, 5.0f, 6.0f))\nval output = criterion.forward(input, target)\n\nscala  print(output)\n3.0  Python example:  criterion = AbsCriterion()\ninput = np.array([1.0, 2.0, 3.0])\ntarget = np.array([4.0, 5.0, 6.0])\noutput=criterion.forward(input, target)  print output\n3.0", 
            "title": "AbsCriterion"
        }, 
        {
            "location": "/APIdocs/Losses/#multicriterion", 
            "text": "Scala:  val criterion = MultiCriterion()  Python:  criterion = MultiCriterion()  MultiCriterion is a weighted sum of other criterions each applied to the same input and target  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MultiCriterion()\nval nll = ClassNLLCriterion()\nval mse = MSECriterion()\ncriterion.add(nll, 0.5)\ncriterion.add(mse)\n\nval input = Tensor(5).randn()\nval target = Tensor(5)\ntarget(Array(1)) = 1\ntarget(Array(2)) = 2\ntarget(Array(3)) = 3\ntarget(Array(4)) = 2\ntarget(Array(5)) = 1\n\nval output = criterion.forward(input, target)  input\n1.0641425\n-0.33507252\n1.2345984\n0.08065767\n0.531199\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]  output\nres7: Float = 1.9633228  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ncriterion = MultiCriterion()\nnll = ClassNLLCriterion()\nmse = MSECriterion()\ncriterion.add(nll, 0.5)\ncriterion.add(mse)\n\ninput = np.array([0.9682213801388531,\n0.35258855644097503,\n0.04584479998452568,\n-0.21781499692588918,\n-1.02721844006879])\ntarget = np.array([1, 2, 3, 2, 1])\n\noutput = criterion.forward(input, target)  output\n3.6099546", 
            "title": "MultiCriterion"
        }, 
        {
            "location": "/APIdocs/Initializers/", 
            "text": "Zeros\n\n\nScala:\n\n\nval initMethod = Zeros\n\n\n\n\n\nPython:\n\n\ninit_method = Zeros()\n\n\n\n\nInitialization method that set tensor to zeros.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Zeros\nval biasInitMethod = Zeros\nval model = Linear(3, 2).setName(\nlinear1\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n\n {\n    weight: 0.0 0.0 0.0 \n            0.0 0.0 0.0 \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.0\n          0.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = Zeros()\nbias_init = Zeros()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createZeros\ncreating: createZeros\ncreating: createLinear\nweight:\n[[ 0.  0.  0.]\n [ 0.  0.  0.]]\nbias: \n[ 0.  0.]\n\n\n\n\n\n\nOnes\n\n\nScala:\n\n\nval initMethod = Ones\n\n\n\n\n\nPython:\n\n\ninit_method = Ones()\n\n\n\n\nInitialization method that set tensor to be ones.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Ones\nval biasInitMethod = Ones\nval model = Linear(3, 2).setName(\nlinear1\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: 1.0 1.0 1.0 \n            1.0 1.0 1.0 \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 1.0\n          1.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = Ones()\nbias_init = Ones()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createOnes\ncreating: createOnes\ncreating: createLinear\nweight:\n[[ 1.  1.  1.]\n [ 1.  1.  1.]]\nbias: \n[ 1.  1.]\n\n\n\n\n\nConstInitMethod\n\n\nScala:\n\n\nval initMethod = ConstInitMethod(value: Double)\n\n\n\n\n\nPython:\n\n\ninit_method = ConstInitMethod(value)\n\n\n\n\nInitialization method that set tensor to the specified constant value.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\n\nval weightInitMethod = ConstInitMethod(0.2)\nval biasInitMethod = ConstInitMethod(0.2)\nval linear = Linear(3, 2).setName(\nlinear1\n)\nlinear.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(linear.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: 0.2 0.2 0.2\n            0.2 0.2 0.2\n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.2\n          0.2\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0\n                0.0 0.0 0.0\n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = ConstInitMethod(0.2)\nbias_init = ConstInitMethod(0.2)\nlinear = Linear(3, 2)\nlinear.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(linear.get_weights()[0])\nprint(\nbias: \n)\nprint(linear.get_weights()[1])\n\n\n\n\ncreating: createConstInitMethod\ncreating: createConstInitMethod\ncreating: createLinear\nweight:\n[[ 0.2  0.2  0.2]\n [ 0.2  0.2  0.2]]\nbias:\n[ 0.2  0.2]\n\n\n\n\n\nXavier\n\n\nScala:\n\n\nval initMethod = Xavier\n\n\n\n\n\nPython:\n\n\ninit_method = Xavier()\n\n\n\n\nThe Xavier initialization method draws samples from a uniform distribution\nbounded by [-limit, limit) where limit = sqrt(6.0/(fanIn+fanOut)). The rationale\nbehind this formula can be found in the paper\n\nUnderstanding the difficulty of training deep feedforward neural networks\n.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Xavier\nval biasInitMethod = Xavier\nval model = Linear(3, 2).setName(\nlinear1\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: -0.78095555 -0.09939616 0.12034761  \n            -0.3019594  0.11734331  0.80369484  \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 1.0727772\n          -0.6703765\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = Xavier()\nbias_init = Xavier()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createXavier\ncreating: createXavier\ncreating: createLinear\nweight:\n[[ 0.00580597 -0.73662472  0.13767919]\n [ 0.16802482 -0.49394709 -0.74967551]]\nbias: \n[-1.12355328  0.0779365 ]\n\n\n\n\nBilinearFiller\n\n\nScala:\n\n\nval initMethod = BilinearFiller\n\n\n\n\n\nPython:\n\n\ninit_method = BilinearFiller()\n\n\n\n\nInitialize the weight with coefficients for bilinear interpolation. A common use case is with the DeconvolutionLayer acting as upsampling. This initialization method can only be used in the weight initialization of SpatialFullConvolution.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = BilinearFiller\nval biasInitMethod - Zeros\nval model = SpatialFullConvolution(2, 3, 2, 2).setName(\nsfconv\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nsfconv\n).get)\n\n\n\n\n{\n    weight: (1,1,1,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,1,2,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,1,3,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,1,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,2,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,3,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x2x2]\n    bias: 0.0\n          0.0\n          0.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    gradBias: 0.0\n              0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    gradWeight: (1,1,1,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,1,2,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,1,3,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,1,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,2,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,3,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x2x2]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = BilinearFiller()\nbias_init = Zeros()\nmodel =  SpatialFullConvolution(2, 3, 2, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createBilinearFiller\ncreating: createZeros\ncreating: createSpatialFullConvolution\nweight:\n[[[[[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]]\n\n\n  [[[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]]]]\nbias: \n[ 0.  0.  0.]\n\n\n\n\n\n\nRandomNormal\n\n\nScala:\n\n\nval initMethod = RandomNormal(mean, stdv)\n\n\n\n\n\nPython:\n\n\ninit_method = RandomNormal(mean, stdv)\n\n\n\n\nThis initialization method draws samples from a normal distribution.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = RandomNormal(0, 1)\nval biasInitMethod = RandomNormal(0, 1)\nval linear = Linear(3, 2).setName(\nlinear1\n)\nlinear.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(linear.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: -0.5908564  0.32844943  -0.845019   \n            0.21550806  1.2037253   0.6807024   \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.5345903\n          -0.76420456\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n  }\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nfrom bigdl.nn.layer import *\n\nweight_init = RandomNormal(0, 1)\nbias_init = RandomNormal(0, 1)\nlinear= Linear(3, 2)\nlinear.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(linear.get_weights()[0])\nprint(\nbias: \n)\nprint(linear.get_weights()[1])\n\n\n\n\ncreating: createRandomNormal\ncreating: createRandomNormal\ncreating: createLinear\nweight:\n[[-0.00784962  0.77845585 -1.16250944]\n [ 0.03195094 -0.15211993  0.6254822 ]]\nbias: \n[-0.37883148 -0.81106091]\n\n\n\n\n\nRandomUniform\n\n\nScala:\n\n\nval initMethod = RandomUniform(lower, upper)\n\n\n\n\n\nPython:\n\n\ninit_method = RandomUniform(upper=None, lower=None)\n\n\n\n\nThis initialization method draws samples from a uniform distribution. If the lower bound and upper bound of this uniform distribution is not specified, it will be set to [-limit, limit) where limit = 1/sqrt(fanIn).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = RandomUniform\nval biasInitMethod = RandomUniform(0, 1)\nval model = Linear(3, 2).setName(\nlinear1\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: -0.572536   0.13046022  -0.040449623    \n            -0.547542   0.19093458  0.5632484   \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.785292\n          0.63280666\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = RandomUniform()\nbias_init = RandomUniform()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createRandomUniform\ncreating: createRandomUniform\ncreating: createLinear\nweight:\n[[ 0.53153235  0.53016287  0.32831791]\n [-0.45736417 -0.16206641  0.21758588]]\nbias: \n[ 0.32058391  0.26307678]\n\n\n\n\n\nDefine your own Initializer\n\n\nAll customizedInitializer should implement the \nInitializationMethod\n trait\n\n\n/**\n * Initialization method to initialize bias and weight.\n * The init method will be called in Module.reset()\n */\n\ntrait InitializationMethod {\n\n  type Shape = Array[Int]\n\n  /**\n   * Initialize the given variable\n   *\n   * @param variable    the variable to initialize\n   * @param dataFormat  describe the meaning of each dimension of the variable\n   */\n  def init[T](variable: Tensor[T], dataFormat: VariableFormat)\n             (implicit ev: TensorNumeric[T]): Unit\n}\n\n\n\n\nThe \nRandomUniform\n\ncode should give you a good sense of how to implement this trait.\n\n\n_\nPython\n\nCustom initialization method in python is not supported right now.", 
            "title": "Initalizers"
        }, 
        {
            "location": "/APIdocs/Initializers/#zeros", 
            "text": "Scala:  val initMethod = Zeros  Python:  init_method = Zeros()  Initialization method that set tensor to zeros.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Zeros\nval biasInitMethod = Zeros\nval model = Linear(3, 2).setName( linear1 )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( linear1 ).get)  \n {\n    weight: 0.0 0.0 0.0 \n            0.0 0.0 0.0 \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.0\n          0.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = Zeros()\nbias_init = Zeros()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createZeros\ncreating: createZeros\ncreating: createLinear\nweight:\n[[ 0.  0.  0.]\n [ 0.  0.  0.]]\nbias: \n[ 0.  0.]", 
            "title": "Zeros"
        }, 
        {
            "location": "/APIdocs/Initializers/#ones", 
            "text": "Scala:  val initMethod = Ones  Python:  init_method = Ones()  Initialization method that set tensor to be ones.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Ones\nval biasInitMethod = Ones\nval model = Linear(3, 2).setName( linear1 )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( linear1 ).get)   {\n    weight: 1.0 1.0 1.0 \n            1.0 1.0 1.0 \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 1.0\n          1.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = Ones()\nbias_init = Ones()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createOnes\ncreating: createOnes\ncreating: createLinear\nweight:\n[[ 1.  1.  1.]\n [ 1.  1.  1.]]\nbias: \n[ 1.  1.]", 
            "title": "Ones"
        }, 
        {
            "location": "/APIdocs/Initializers/#constinitmethod", 
            "text": "Scala:  val initMethod = ConstInitMethod(value: Double)  Python:  init_method = ConstInitMethod(value)  Initialization method that set tensor to the specified constant value.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\n\nval weightInitMethod = ConstInitMethod(0.2)\nval biasInitMethod = ConstInitMethod(0.2)\nval linear = Linear(3, 2).setName( linear1 )\nlinear.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(linear.getParametersTable().get( linear1 ).get)   {\n    weight: 0.2 0.2 0.2\n            0.2 0.2 0.2\n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.2\n          0.2\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0\n                0.0 0.0 0.0\n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = ConstInitMethod(0.2)\nbias_init = ConstInitMethod(0.2)\nlinear = Linear(3, 2)\nlinear.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(linear.get_weights()[0])\nprint( bias:  )\nprint(linear.get_weights()[1])  creating: createConstInitMethod\ncreating: createConstInitMethod\ncreating: createLinear\nweight:\n[[ 0.2  0.2  0.2]\n [ 0.2  0.2  0.2]]\nbias:\n[ 0.2  0.2]", 
            "title": "ConstInitMethod"
        }, 
        {
            "location": "/APIdocs/Initializers/#xavier", 
            "text": "Scala:  val initMethod = Xavier  Python:  init_method = Xavier()  The Xavier initialization method draws samples from a uniform distribution\nbounded by [-limit, limit) where limit = sqrt(6.0/(fanIn+fanOut)). The rationale\nbehind this formula can be found in the paper Understanding the difficulty of training deep feedforward neural networks .  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Xavier\nval biasInitMethod = Xavier\nval model = Linear(3, 2).setName( linear1 )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( linear1 ).get)   {\n    weight: -0.78095555 -0.09939616 0.12034761  \n            -0.3019594  0.11734331  0.80369484  \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 1.0727772\n          -0.6703765\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = Xavier()\nbias_init = Xavier()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createXavier\ncreating: createXavier\ncreating: createLinear\nweight:\n[[ 0.00580597 -0.73662472  0.13767919]\n [ 0.16802482 -0.49394709 -0.74967551]]\nbias: \n[-1.12355328  0.0779365 ]", 
            "title": "Xavier"
        }, 
        {
            "location": "/APIdocs/Initializers/#bilinearfiller", 
            "text": "Scala:  val initMethod = BilinearFiller  Python:  init_method = BilinearFiller()  Initialize the weight with coefficients for bilinear interpolation. A common use case is with the DeconvolutionLayer acting as upsampling. This initialization method can only be used in the weight initialization of SpatialFullConvolution.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = BilinearFiller\nval biasInitMethod - Zeros\nval model = SpatialFullConvolution(2, 3, 2, 2).setName( sfconv )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( sfconv ).get)  {\n    weight: (1,1,1,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,1,2,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,1,3,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,1,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,2,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,3,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x2x2]\n    bias: 0.0\n          0.0\n          0.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    gradBias: 0.0\n              0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    gradWeight: (1,1,1,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,1,2,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,1,3,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,1,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,2,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,3,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x2x2]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = BilinearFiller()\nbias_init = Zeros()\nmodel =  SpatialFullConvolution(2, 3, 2, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createBilinearFiller\ncreating: createZeros\ncreating: createSpatialFullConvolution\nweight:\n[[[[[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]]\n\n\n  [[[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]]]]\nbias: \n[ 0.  0.  0.]", 
            "title": "BilinearFiller"
        }, 
        {
            "location": "/APIdocs/Initializers/#randomnormal", 
            "text": "Scala:  val initMethod = RandomNormal(mean, stdv)  Python:  init_method = RandomNormal(mean, stdv)  This initialization method draws samples from a normal distribution.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = RandomNormal(0, 1)\nval biasInitMethod = RandomNormal(0, 1)\nval linear = Linear(3, 2).setName( linear1 )\nlinear.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(linear.getParametersTable().get( linear1 ).get)   {\n    weight: -0.5908564  0.32844943  -0.845019   \n            0.21550806  1.2037253   0.6807024   \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.5345903\n          -0.76420456\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n  }  Python example:  from bigdl.nn.initialization_method import *\nfrom bigdl.nn.layer import *\n\nweight_init = RandomNormal(0, 1)\nbias_init = RandomNormal(0, 1)\nlinear= Linear(3, 2)\nlinear.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(linear.get_weights()[0])\nprint( bias:  )\nprint(linear.get_weights()[1])  creating: createRandomNormal\ncreating: createRandomNormal\ncreating: createLinear\nweight:\n[[-0.00784962  0.77845585 -1.16250944]\n [ 0.03195094 -0.15211993  0.6254822 ]]\nbias: \n[-0.37883148 -0.81106091]", 
            "title": "RandomNormal"
        }, 
        {
            "location": "/APIdocs/Initializers/#randomuniform", 
            "text": "Scala:  val initMethod = RandomUniform(lower, upper)  Python:  init_method = RandomUniform(upper=None, lower=None)  This initialization method draws samples from a uniform distribution. If the lower bound and upper bound of this uniform distribution is not specified, it will be set to [-limit, limit) where limit = 1/sqrt(fanIn).  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = RandomUniform\nval biasInitMethod = RandomUniform(0, 1)\nval model = Linear(3, 2).setName( linear1 )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( linear1 ).get)   {\n    weight: -0.572536   0.13046022  -0.040449623    \n            -0.547542   0.19093458  0.5632484   \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.785292\n          0.63280666\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = RandomUniform()\nbias_init = RandomUniform()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createRandomUniform\ncreating: createRandomUniform\ncreating: createLinear\nweight:\n[[ 0.53153235  0.53016287  0.32831791]\n [-0.45736417 -0.16206641  0.21758588]]\nbias: \n[ 0.32058391  0.26307678]", 
            "title": "RandomUniform"
        }, 
        {
            "location": "/APIdocs/Initializers/#define-your-own-initializer", 
            "text": "All customizedInitializer should implement the  InitializationMethod  trait  /**\n * Initialization method to initialize bias and weight.\n * The init method will be called in Module.reset()\n */\n\ntrait InitializationMethod {\n\n  type Shape = Array[Int]\n\n  /**\n   * Initialize the given variable\n   *\n   * @param variable    the variable to initialize\n   * @param dataFormat  describe the meaning of each dimension of the variable\n   */\n  def init[T](variable: Tensor[T], dataFormat: VariableFormat)\n             (implicit ev: TensorNumeric[T]): Unit\n}  The  RandomUniform \ncode should give you a good sense of how to implement this trait.  _ Python \nCustom initialization method in python is not supported right now.", 
            "title": "Define your own Initializer"
        }, 
        {
            "location": "/APIdocs/Regularizers/", 
            "text": "Regularizers are used to avoid overfitting. \n\n\n\n\nL1 Regularizer\n\n\nL1 Regularizer.\n\n\nScala:\n\n\nval l1Regularizer = L1Regularizer(rate)\n\n\n\n\nPython:\n\n\nregularizerl1 = L1Regularizer(rate)\n\n\n\n\n\n\nL2 Regularizer\n\n\nL2 Regularizer.\n\n\nScala:\n\n\nval l2Regularizer = L2Regularizer(rate)\n\n\n\n\nPython:\n\n\nregularizerl2 = L2Regularizer(rate)\n\n\n\n\n\n\nL1L2 Regularizer\n\n\nL1L2 Regularizer.\n\n\nScala:\n\n\nval l1l2Regularizer = L1L2Regularizer(l1rate, l2rate)\n\n\n\n\nPython:\n\n\nregularizerl1l2 = L1L2Regularizer(l1rate, l2rate)\n\n\n\n\n\n\nScala Example\n\n\n\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nRNG.setSeed(100)\n\nval input = Tensor(3, 5).rand\nval linear = Linear(5, 5, wRegularizer = L2Regularizer(0.1), bRegularizer = L2Regularizer(0.1))\n\nval output = linear.forward(input)\n\n\n println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.54340494      0.67115563      0.2783694       0.4120464       0.4245176\n0.52638245      0.84477615      0.14860484      0.004718862     0.15671109\n0.12156912      0.18646719      0.67074907      0.21010774      0.82585275\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x5]\n\n\n\n println(output)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.34797725     0.25985366      -0.1107063      0.44529563      0.18934922\n-0.36947984     0.3738199       0.033136755     0.68634266      0.31736165\n-0.21293467     -0.16091438     -0.15637109     0.12860553      0.2332296\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x5]\n\n\n\n\n\n\nPython Example\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ninput = np.random.uniform(0, 1, (3, 5)).astype(\nfloat32\n)\nlinear = Linear(5, 5, wRegularizer = L2Regularizer(0.1), bRegularizer = L2Regularizer(0.1))\noutput = linear.forward(input)\n\n\n input\narray([[ 0.14070892,  0.35661909,  0.00720507,  0.96832764,  0.34936094],\n       [ 0.14347534,  0.74504513,  0.16517557,  0.27037948,  0.28448409],\n       [ 0.28334993,  0.37042555,  0.32039529,  0.66894925,  0.19935906]], dtype=float32)\n\n\n output\narray([[-0.482759  , -0.12087041, -0.76120645,  0.16693172, -0.21038117],\n       [-0.17725618, -0.20931029, -0.53776515,  0.03298397, -0.40130591],\n       [-0.36628127, -0.32192633, -0.64229649,  0.16954683, -0.15714465]], dtype=float32)", 
            "title": "Regularizers"
        }, 
        {
            "location": "/APIdocs/Regularizers/#l1-regularizer", 
            "text": "L1 Regularizer.  Scala:  val l1Regularizer = L1Regularizer(rate)  Python:  regularizerl1 = L1Regularizer(rate)", 
            "title": "L1 Regularizer"
        }, 
        {
            "location": "/APIdocs/Regularizers/#l2-regularizer", 
            "text": "L2 Regularizer.  Scala:  val l2Regularizer = L2Regularizer(rate)  Python:  regularizerl2 = L2Regularizer(rate)", 
            "title": "L2 Regularizer"
        }, 
        {
            "location": "/APIdocs/Regularizers/#l1l2-regularizer", 
            "text": "L1L2 Regularizer.  Scala:  val l1l2Regularizer = L1L2Regularizer(l1rate, l2rate)  Python:  regularizerl1l2 = L1L2Regularizer(l1rate, l2rate)", 
            "title": "L1L2 Regularizer"
        }, 
        {
            "location": "/APIdocs/Regularizers/#scala-example", 
            "text": "import com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nRNG.setSeed(100)\n\nval input = Tensor(3, 5).rand\nval linear = Linear(5, 5, wRegularizer = L2Regularizer(0.1), bRegularizer = L2Regularizer(0.1))\n\nval output = linear.forward(input)  println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.54340494      0.67115563      0.2783694       0.4120464       0.4245176\n0.52638245      0.84477615      0.14860484      0.004718862     0.15671109\n0.12156912      0.18646719      0.67074907      0.21010774      0.82585275\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x5]  println(output)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.34797725     0.25985366      -0.1107063      0.44529563      0.18934922\n-0.36947984     0.3738199       0.033136755     0.68634266      0.31736165\n-0.21293467     -0.16091438     -0.15637109     0.12860553      0.2332296\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x5]", 
            "title": "Scala Example"
        }, 
        {
            "location": "/APIdocs/Regularizers/#python-example", 
            "text": "from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ninput = np.random.uniform(0, 1, (3, 5)).astype( float32 )\nlinear = Linear(5, 5, wRegularizer = L2Regularizer(0.1), bRegularizer = L2Regularizer(0.1))\noutput = linear.forward(input)  input\narray([[ 0.14070892,  0.35661909,  0.00720507,  0.96832764,  0.34936094],\n       [ 0.14347534,  0.74504513,  0.16517557,  0.27037948,  0.28448409],\n       [ 0.28334993,  0.37042555,  0.32039529,  0.66894925,  0.19935906]], dtype=float32)  output\narray([[-0.482759  , -0.12087041, -0.76120645,  0.16693172, -0.21038117],\n       [-0.17725618, -0.20931029, -0.53776515,  0.03298397, -0.40130591],\n       [-0.36628127, -0.32192633, -0.64229649,  0.16954683, -0.15714465]], dtype=float32)", 
            "title": "Python Example"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optimizer/", 
            "text": "Optimizer\n\n\nAn optimizer is in general to minimize any function with respect to a set of parameters. In case of training a neural network, an optimizer tries to minimize the loss of the neural net with respect to its weights/biases, over the training set.\n\n\nScala API\n\n\nFactory method\n\n\nval optimizer = Opimizer[T: ClassTag](\n  model: Module[T],\n  sampleRDD: RDD[Sample[T]],\n  criterion: Criterion[T],\n  batchSize: Int)\n\n\n\n\nT\n: the numeric type(Float/Double).\n\n\nmodel\n: the model will be optimized.\n\n\nsampleRDD\n: an RDD of training Sample.\n\n\ncriterion\n: the Loss function.\n\n\nbatchSize\n: size of minibatch. \n\n\nval optimizer = Opimizer[T: ClassTag, D](\n  model: Module[T],\n  dataset: DataSet[D],\n  criterion: Criterion[T])\n\n\n\n\nT\n: the numeric type(Float/Double).\n\n\nD\n: should be a kind of MiniBatch.\n\n\nmodel\n: the model will be optimized.\n\n\ndataset\n: the training DataSet.\n\n\ncriterion\n: the Loss function.\n\n\ndef apply[T: ClassTag](\n      model: Module[T],\n      sampleRDD: RDD[Sample[T]],\n      criterion: Criterion[T],\n      batchSize: Int,\n      featurePaddingParam: PaddingParam[T],\n      labelPaddingParam: PaddingParam[T])\n\n\n\n\nApply an Optimizer who could apply padding to the Samples with a padding strategy.\n\n\nmodel\n: model will be optimizied.\n\n\nsampleRDD\n: training Samples.\n\n\ncriterion\n: loss function.\n\n\nbatchSize\n: mini batch size.\n\n\nfeaturePaddingParam\n: feature padding strategy.\n\n\nlabelPaddingParam\n: label padding strategy.\n\n\ndef apply[T: ClassTag](\n      model: Module[T],\n      sampleRDD: RDD[Sample[T]],\n      criterion: Criterion[T],\n      batchSize: Int,\n      miniBatch: MiniBatch[T])\n\n\n\n\nApply an optimizer with User-Defined \nMiniBatch\n.\n\n\nmodel\n: model will be optimizied.\n\n\nsampleRDD\n: training Samples.\n\n\ncriterion\n: loss function.\n\n\nbatchSize\n: mini batch size.\n\n\nminiBatch\n: An User-Defined MiniBatch to construct a mini batch.\n\n\nValidation\n\n\nFunction setValidation is to set a validate evaluation in the \noptimizer\n.\n\n\noptimizer.setValidation(\n  trigger: Trigger,\n  dataset: DataSet[MiniBatch[T]],\n  vMethods : Array[ValidationMethod[T])\n\n\n\n\ntrigger\n: how often to evaluation validation set.\n\n\ndataset\n: validate data set in type of DataSet[MiniBatch].\n\n\nvMethods\n: a set of ValidationMethod.\n\n \n\n\noptimizer.setValidation(\n  trigger: Trigger,\n  sampleRDD: RDD[Sample[T]],\n  vMethods: Array[ValidationMethod[T]],\n  batchSize: Int)\n\n\n\n\ntrigger\n: how often to evaluation validation set.\n\n\nsampleRDD\n: validate data set in type of RDD[Sample].\n\n\nvMethods\n: a set of ValidationMethod.\n\n\nbatchSize\n: size of mini batch.\n\n\nCheckpoint\n\n\noptimizer.setCheckpoint(path: String, trigger: Trigger)\n\n\n\n\nFunction setCheckPoint is used to set a check point saved at \npath\n triggered by \ntrigger\n.\n\n\npath\n: a local/HDFS directory to save checkpoint.\n\n\ntrigger\n: how often to save the check point.\n\n \n\n\nval path = optimizer.getCheckpointPath()\n\n\n\n\nFunction getCheckpointPath is used to get the directory of saving checkpoint.\n\n \n\n\noptimizer.overWriteCheckpoint()\n\n\n\n\nFunction overWriteCheckpoint is enable overwrite saving checkpoint.  \n\n\nSummary\n\n\noptimizer.setTrainSummary(trainSummary: TrainSummary)\n\n\n\n\nFunction setTrainSummary is used to enable train summary in this optimizer.\n\n\ntrainSummary\n: an instance of TrainSummary.\n\n \n\n\noptimizer.setValidationSummary(validationSummary: ValidationSummary)\n\n\n\n\nFunction setValidationSummary is used to enable validation summary in this optimizer.\n\n\nvalidationSummary\n: an instance of ValidationSummary.  \n\n\nOther important API\n\n\nval trainedModel = optimizer.optimize()\n\n\n\n\nFunction optimize will start the training.\n\n \n\n\noptimizer.setModel(newModel: Module[T])\n\n\n\n\nFunction setModel will set a new model to the optimizer.\n\n\nnewModel\n: a model will replace the old model in optimizer.\n\n \n\n\noptimizer.setState(state: Table)\n\n\n\n\nFunction setState is used to set a state(learning rate, epochs...) to the \noptimizer\n.\n\n\nstate\n: the state to be saved.\n\n \n\n\noptimizer.setOptimMethod(method : OptimMethod[T])\n\n\n\n\nFunction setOptimMethod is used to set an optimization method in this \noptimizer\n.\n\n\nmethod\n: the method the optimize the model in this \noptimizer\n.\n\n \n\n\noptimizer.setEndWhen(endWhen: Trigger)\n\n\n\n\nFunction setEndWhen is used to declare when to stop the training invoked by \noptimize()\n.\n\n\nendWhen\n: a trigger to stop the training.\n\n\nScala example\n\n\nHere is an example to new an Optimizer with SGD for optimizing LeNet5 model.\n\n\nval trainingRDD = ...\nval valRDD = ...\nval batchSize = 12\n// Create an optimizer\nval optimizer = Optimizer(\n  model = LeNet5(classNum = 10),\n  sampleRDD = trainingRDD,\n  criterion = ClassNLLCriterion(),\n  batchSize = batchSize\n).setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), batchSize) // set validation method\n  .setEndWhen(Trigger.maxEpoch(15)) // set end trigger\n  .setOptimMethod(new SGD(learningRate = 0.05)) // set optimize method, Since 0.2.0. Older version should use optimizer.setOptimMethod(new SGD()).setState(T(\nlearningRate\n -\n 0.05))\n\nval trainedModel = optimizer.optimize()\n\n\n\n\nPython API\n\n\nFactory method\n\n\noptimizer =  Optimizer(model,\n                 training_rdd,\n                 criterion,\n                 end_trigger,\n                 batch_size,\n                 optim_method=None,\n                 bigdl_type=\nfloat\n)\n\n\n\n\nmodel\n: the model will be optimized.\n\n\ntraining_rdd\n: the training dataset.\n\n\ncriterion\n: the Loss function.\n\n\nend_trigger\n: when to end the optimization.\n\n\nbatch_size\n: size of minibatch.\n\n\noptim_method\n:  the algorithm to use for optimization, e.g. SGD, Adagrad, etc. If optim_method is None, the default algorithm is SGD.\n\n\nbigdl_type\n: the numeric type(Float/Double).  \n\n\nValidation\n\n\nFunction setValidation is to set a validate evaluation in the \noptimizer\n.\n\n\noptimizer.set_validation(batch_size, val_rdd, trigger, val_method=[\nTop1Accuracy\n])\n\n\n\n\ntrigger\n: how often to evaluation validation set.\n\n\nval_rdd\n: validate data set in type of RDD[Sample].\n\n\nval_method\n: a list of ValidationMethod, e.g. \"Top1Accuracy\", \"Top5Accuracy\", \"Loss\".\n\n\nbatch_size\n: size of mini batch.\n\n\nCheckpoint\n\n\noptimizer.set_checkpoint(checkpoint_trigger,\n                      checkpoint_path, isOverWrite=True)\n\n\n\n\nFunction setCheckPoint is used to set a check point saved at \npath\n triggered by \ntrigger\n.\n\n\ncheckpoint_trigger\n: how often to save the check point.\n\ncheckpoint_path\n: a local/HDFS directory to save checkpoint.\n\n\nisOverWrite\n: whether to overwrite existing snapshots in path.default is True\n\n\nSummary\n\n\noptimizer.set_train_summary(summary)\n\n\n\n\nSet train summary. A TrainSummary object contains information necessary for the optimizer to know how often the logs are recorded, where to store the logs and how to retrieve them, etc. For details, refer to the docs of TrainSummary.\n\nsummary\n: an instance of TrainSummary.\n\n\noptimizer.set_validation_summary(summary)\n\n\n\n\nFunction setValidationSummary is used to set validation summary. A ValidationSummary object contains information necessary for the optimizer to know how often the logs are recorded, where to store the logs and how to retrieve them, etc. For details, refer to the docs of ValidationSummary.\n\nsummary\n: an instance of ValidationSummary.\n\n\nStart Training\n\n\ntrained_model = optimizer.optimize()\n\n\n\n\nFunction optimize will start the training.\n\n\nSet Model\n\n\noptimizer.set_model(model)\n\n\n\n\nFunction setModel will set a new model to the optimizer.\n\n\nmodel\n: a model will replace the old model in optimizer.\n\n\nPython example\n\n\nHere is an example to new an Optimizer with SGD for optimizing LeNet5 model.\n\n\ntrain_data = ...\ntest_data = ...\nbatch_size = 12\n# Create an Optimizer, Since 0.2.0\noptimizer = Optimizer(\n  model=lenet_model,\n  training_rdd=train_data,\n  criterion=ClassNLLCriterion(),\n  optim_method=SGD(learningrate=0.01, learningrate_decay=0.0002), # set optim method\n  end_trigger=MaxEpoch(15),\n  batch_size=batch_size)\n\n# Older version, before 0.2.0, use following code: \n# optimizer = Optimizer(\n#   model=model,\n#   training_rdd=train_data,\n#   criterion=ClassNLLCriterion(),\n#   optim_method=\nSGD\n,\n#   state={\nlearningRate\n: 0.05},\n#   end_trigger=MaxEpoch(training_epochs),\n#   batch_size=batch_size)\n\noptimizer.set_validation(\n    batch_size=2048,\n    val_rdd=test_data,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()]\n)\n\n# Older version, before 0.2.0, use following code: \n#optimizer.set_validation(\n#    batch_size=2048,\n#    val_rdd=test_data,\n#    trigger=EveryEpoch(),\n#    val_method=[\nTop1Accuracy\n]\n#)\n\ntrained_model = optimizer.optimize()", 
            "title": "Optimizer"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optimizer/#optimizer", 
            "text": "An optimizer is in general to minimize any function with respect to a set of parameters. In case of training a neural network, an optimizer tries to minimize the loss of the neural net with respect to its weights/biases, over the training set.", 
            "title": "Optimizer"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optimizer/#scala-api", 
            "text": "Factory method  val optimizer = Opimizer[T: ClassTag](\n  model: Module[T],\n  sampleRDD: RDD[Sample[T]],\n  criterion: Criterion[T],\n  batchSize: Int)  T : the numeric type(Float/Double).  model : the model will be optimized.  sampleRDD : an RDD of training Sample.  criterion : the Loss function.  batchSize : size of minibatch.   val optimizer = Opimizer[T: ClassTag, D](\n  model: Module[T],\n  dataset: DataSet[D],\n  criterion: Criterion[T])  T : the numeric type(Float/Double).  D : should be a kind of MiniBatch.  model : the model will be optimized.  dataset : the training DataSet.  criterion : the Loss function.  def apply[T: ClassTag](\n      model: Module[T],\n      sampleRDD: RDD[Sample[T]],\n      criterion: Criterion[T],\n      batchSize: Int,\n      featurePaddingParam: PaddingParam[T],\n      labelPaddingParam: PaddingParam[T])  Apply an Optimizer who could apply padding to the Samples with a padding strategy.  model : model will be optimizied.  sampleRDD : training Samples.  criterion : loss function.  batchSize : mini batch size.  featurePaddingParam : feature padding strategy.  labelPaddingParam : label padding strategy.  def apply[T: ClassTag](\n      model: Module[T],\n      sampleRDD: RDD[Sample[T]],\n      criterion: Criterion[T],\n      batchSize: Int,\n      miniBatch: MiniBatch[T])  Apply an optimizer with User-Defined  MiniBatch .  model : model will be optimizied.  sampleRDD : training Samples.  criterion : loss function.  batchSize : mini batch size.  miniBatch : An User-Defined MiniBatch to construct a mini batch.  Validation  Function setValidation is to set a validate evaluation in the  optimizer .  optimizer.setValidation(\n  trigger: Trigger,\n  dataset: DataSet[MiniBatch[T]],\n  vMethods : Array[ValidationMethod[T])  trigger : how often to evaluation validation set.  dataset : validate data set in type of DataSet[MiniBatch].  vMethods : a set of ValidationMethod. \n   optimizer.setValidation(\n  trigger: Trigger,\n  sampleRDD: RDD[Sample[T]],\n  vMethods: Array[ValidationMethod[T]],\n  batchSize: Int)  trigger : how often to evaluation validation set.  sampleRDD : validate data set in type of RDD[Sample].  vMethods : a set of ValidationMethod.  batchSize : size of mini batch.  Checkpoint  optimizer.setCheckpoint(path: String, trigger: Trigger)  Function setCheckPoint is used to set a check point saved at  path  triggered by  trigger .  path : a local/HDFS directory to save checkpoint.  trigger : how often to save the check point. \n   val path = optimizer.getCheckpointPath()  Function getCheckpointPath is used to get the directory of saving checkpoint. \n   optimizer.overWriteCheckpoint()  Function overWriteCheckpoint is enable overwrite saving checkpoint.    Summary  optimizer.setTrainSummary(trainSummary: TrainSummary)  Function setTrainSummary is used to enable train summary in this optimizer.  trainSummary : an instance of TrainSummary. \n   optimizer.setValidationSummary(validationSummary: ValidationSummary)  Function setValidationSummary is used to enable validation summary in this optimizer.  validationSummary : an instance of ValidationSummary.    Other important API  val trainedModel = optimizer.optimize()  Function optimize will start the training. \n   optimizer.setModel(newModel: Module[T])  Function setModel will set a new model to the optimizer.  newModel : a model will replace the old model in optimizer. \n   optimizer.setState(state: Table)  Function setState is used to set a state(learning rate, epochs...) to the  optimizer .  state : the state to be saved. \n   optimizer.setOptimMethod(method : OptimMethod[T])  Function setOptimMethod is used to set an optimization method in this  optimizer .  method : the method the optimize the model in this  optimizer . \n   optimizer.setEndWhen(endWhen: Trigger)  Function setEndWhen is used to declare when to stop the training invoked by  optimize() .  endWhen : a trigger to stop the training.", 
            "title": "Scala API"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optimizer/#scala-example", 
            "text": "Here is an example to new an Optimizer with SGD for optimizing LeNet5 model.  val trainingRDD = ...\nval valRDD = ...\nval batchSize = 12\n// Create an optimizer\nval optimizer = Optimizer(\n  model = LeNet5(classNum = 10),\n  sampleRDD = trainingRDD,\n  criterion = ClassNLLCriterion(),\n  batchSize = batchSize\n).setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), batchSize) // set validation method\n  .setEndWhen(Trigger.maxEpoch(15)) // set end trigger\n  .setOptimMethod(new SGD(learningRate = 0.05)) // set optimize method, Since 0.2.0. Older version should use optimizer.setOptimMethod(new SGD()).setState(T( learningRate  -  0.05))\n\nval trainedModel = optimizer.optimize()", 
            "title": "Scala example"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optimizer/#python-api", 
            "text": "Factory method  optimizer =  Optimizer(model,\n                 training_rdd,\n                 criterion,\n                 end_trigger,\n                 batch_size,\n                 optim_method=None,\n                 bigdl_type= float )  model : the model will be optimized.  training_rdd : the training dataset.  criterion : the Loss function.  end_trigger : when to end the optimization.  batch_size : size of minibatch.  optim_method :  the algorithm to use for optimization, e.g. SGD, Adagrad, etc. If optim_method is None, the default algorithm is SGD.  bigdl_type : the numeric type(Float/Double).    Validation  Function setValidation is to set a validate evaluation in the  optimizer .  optimizer.set_validation(batch_size, val_rdd, trigger, val_method=[ Top1Accuracy ])  trigger : how often to evaluation validation set.  val_rdd : validate data set in type of RDD[Sample].  val_method : a list of ValidationMethod, e.g. \"Top1Accuracy\", \"Top5Accuracy\", \"Loss\".  batch_size : size of mini batch.  Checkpoint  optimizer.set_checkpoint(checkpoint_trigger,\n                      checkpoint_path, isOverWrite=True)  Function setCheckPoint is used to set a check point saved at  path  triggered by  trigger .  checkpoint_trigger : how often to save the check point. checkpoint_path : a local/HDFS directory to save checkpoint.  isOverWrite : whether to overwrite existing snapshots in path.default is True  Summary  optimizer.set_train_summary(summary)  Set train summary. A TrainSummary object contains information necessary for the optimizer to know how often the logs are recorded, where to store the logs and how to retrieve them, etc. For details, refer to the docs of TrainSummary. summary : an instance of TrainSummary.  optimizer.set_validation_summary(summary)  Function setValidationSummary is used to set validation summary. A ValidationSummary object contains information necessary for the optimizer to know how often the logs are recorded, where to store the logs and how to retrieve them, etc. For details, refer to the docs of ValidationSummary. summary : an instance of ValidationSummary.  Start Training  trained_model = optimizer.optimize()  Function optimize will start the training.  Set Model  optimizer.set_model(model)  Function setModel will set a new model to the optimizer.  model : a model will replace the old model in optimizer.", 
            "title": "Python API"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optimizer/#python-example", 
            "text": "Here is an example to new an Optimizer with SGD for optimizing LeNet5 model.  train_data = ...\ntest_data = ...\nbatch_size = 12\n# Create an Optimizer, Since 0.2.0\noptimizer = Optimizer(\n  model=lenet_model,\n  training_rdd=train_data,\n  criterion=ClassNLLCriterion(),\n  optim_method=SGD(learningrate=0.01, learningrate_decay=0.0002), # set optim method\n  end_trigger=MaxEpoch(15),\n  batch_size=batch_size)\n\n# Older version, before 0.2.0, use following code: \n# optimizer = Optimizer(\n#   model=model,\n#   training_rdd=train_data,\n#   criterion=ClassNLLCriterion(),\n#   optim_method= SGD ,\n#   state={ learningRate : 0.05},\n#   end_trigger=MaxEpoch(training_epochs),\n#   batch_size=batch_size)\n\noptimizer.set_validation(\n    batch_size=2048,\n    val_rdd=test_data,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()]\n)\n\n# Older version, before 0.2.0, use following code: \n#optimizer.set_validation(\n#    batch_size=2048,\n#    val_rdd=test_data,\n#    trigger=EveryEpoch(),\n#    val_method=[ Top1Accuracy ]\n#)\n\ntrained_model = optimizer.optimize()", 
            "title": "Python example"
        }, 
        {
            "location": "/APIdocs/Optimizers/OptimMethod/", 
            "text": "OptimMethod\n\n\nOptimMethod is used to update model gradient parameters.We have defined SGD method, Adagrad method, etc.\nDetails about those optim methods, you can refer to \nOptim-Methods\n.\nNow, method construct parameters(e.g.\"learningRate\") and internal training parameters(e.g.\"epoch\") store in optim method instead of state(since version 0.2.0)\nHere is mainly to describe how to use those methods when training\n\n\nSet method\n\n\nscala\n\n\noptimizer.setOptimMethod(method : OptimMethod[T])\n\n\n\n\npython\n\n\noptimizer = Optimizer(\n    model,\n    training_rdd,\n    criterion,\n    optim_method,\n    end_trigger,\n    batch_size)\n\n\n\n\nin python, you can set optim method when creating an optimizer\n\n\nSave method\n\n\nmethod.save(path: String, overWrite: Boolean = false)\n\n\n\n\nT\n: path to save method\n\n\noverWrite\n: whether to overwrite or not\n\n\nWhen training, you can use optimizer.setCheckPoint(for scala) or optimizer.set_checkpoint(for python) to save methods at regular intervals.\n\n\nLoad method\n\n\nval method = OptimMethod.load(path : String)\n\n\n\n\npath\n: file of optim method path\n\n\nPython can't support loading optim method from a snapshot now, but we are working on fixing it.\n\n\nScala example\n\n\nHere is an example to train LeNet5 model with a loading method.\n\n\nval trainingRDD = ...\nval valRDD = ...\nval batchSize = 12\nval methodPath = ...\n// Load optim method\nval method = OptimMethod.load(methodPath)\n// Create an optimizer\nval optimizer = Optimizer(\n  model = LeNet5(classNum = 10),\n  sampleRDD = trainingRDD,\n  criterion = ClassNLLCriterion(),\n  batchSize = batchSize\n).setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), batchSize)\n  .setEndWhen(Trigger.maxEpoch(15))\n\noptimizer.setOptimMethod(method) // set optim method\n\noptimizer.setCheckpoint(param.checkpoint.get, checkpointTrigger) // set checkpoint to save model and optim method\n\nval trainedModel = optimizer.optimize()\n\n\n\n\nPython example\n\n\nHere is an example to train LeNet5 model with SGD method.\n\n\ntrain_data = ...\ntest_data = ...\nbatch_size = 12\noptimizer = Optimizer(\n  model=lenet_model,\n  training_rdd=train_data,\n  criterion=ClassNLLCriterion(),\n  optim_method=SGD(learningrate=0.01, learningrate_decay=0.0002), # set optim method\n  end_trigger=MaxEpoch(15),\n  batch_size=batch_size)\n\noptimizer.set_validation(\n    batch_size=32,\n    val_rdd=test_data,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()]\n)\n\noptimizer.set_checkpoint(EveryEpoch(), checkpointPath) # set checkpoint to save model and optim method\n\ntrained_model = optimizer.optimize()", 
            "title": "OptimMethod"
        }, 
        {
            "location": "/APIdocs/Optimizers/OptimMethod/#optimmethod", 
            "text": "OptimMethod is used to update model gradient parameters.We have defined SGD method, Adagrad method, etc.\nDetails about those optim methods, you can refer to  Optim-Methods .\nNow, method construct parameters(e.g.\"learningRate\") and internal training parameters(e.g.\"epoch\") store in optim method instead of state(since version 0.2.0)\nHere is mainly to describe how to use those methods when training", 
            "title": "OptimMethod"
        }, 
        {
            "location": "/APIdocs/Optimizers/OptimMethod/#set-method", 
            "text": "scala  optimizer.setOptimMethod(method : OptimMethod[T])  python  optimizer = Optimizer(\n    model,\n    training_rdd,\n    criterion,\n    optim_method,\n    end_trigger,\n    batch_size)  in python, you can set optim method when creating an optimizer", 
            "title": "Set method"
        }, 
        {
            "location": "/APIdocs/Optimizers/OptimMethod/#save-method", 
            "text": "method.save(path: String, overWrite: Boolean = false)  T : path to save method  overWrite : whether to overwrite or not  When training, you can use optimizer.setCheckPoint(for scala) or optimizer.set_checkpoint(for python) to save methods at regular intervals.", 
            "title": "Save method"
        }, 
        {
            "location": "/APIdocs/Optimizers/OptimMethod/#load-method", 
            "text": "val method = OptimMethod.load(path : String)  path : file of optim method path  Python can't support loading optim method from a snapshot now, but we are working on fixing it.", 
            "title": "Load method"
        }, 
        {
            "location": "/APIdocs/Optimizers/OptimMethod/#scala-example", 
            "text": "Here is an example to train LeNet5 model with a loading method.  val trainingRDD = ...\nval valRDD = ...\nval batchSize = 12\nval methodPath = ...\n// Load optim method\nval method = OptimMethod.load(methodPath)\n// Create an optimizer\nval optimizer = Optimizer(\n  model = LeNet5(classNum = 10),\n  sampleRDD = trainingRDD,\n  criterion = ClassNLLCriterion(),\n  batchSize = batchSize\n).setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), batchSize)\n  .setEndWhen(Trigger.maxEpoch(15))\n\noptimizer.setOptimMethod(method) // set optim method\n\noptimizer.setCheckpoint(param.checkpoint.get, checkpointTrigger) // set checkpoint to save model and optim method\n\nval trainedModel = optimizer.optimize()", 
            "title": "Scala example"
        }, 
        {
            "location": "/APIdocs/Optimizers/OptimMethod/#python-example", 
            "text": "Here is an example to train LeNet5 model with SGD method.  train_data = ...\ntest_data = ...\nbatch_size = 12\noptimizer = Optimizer(\n  model=lenet_model,\n  training_rdd=train_data,\n  criterion=ClassNLLCriterion(),\n  optim_method=SGD(learningrate=0.01, learningrate_decay=0.0002), # set optim method\n  end_trigger=MaxEpoch(15),\n  batch_size=batch_size)\n\noptimizer.set_validation(\n    batch_size=32,\n    val_rdd=test_data,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()]\n)\n\noptimizer.set_checkpoint(EveryEpoch(), checkpointPath) # set checkpoint to save model and optim method\n\ntrained_model = optimizer.optimize()", 
            "title": "Python example"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optim-Methods/", 
            "text": "Adam\n\n\nScala:\n\n\nval optim = new Adam(learningRate=1e-3, learningRateDecay=0.0, beta1=0.9, beta2=0.999, Epsilon=1e-8)\n\n\n\n\nPython:\n\n\noptim = Adam(learningRate=1e-3, learningRateDecay-0.0, beta1=0.9, beta2=0.999, Epsilon=1e-8, bigdl_type=\nfloat\n)\n\n\n\n\nAn implementation of Adam optimization, first-order gradient-based optimization of stochastic  objective  functions. http://arxiv.org/pdf/1412.6980.pdf\n\n\nlearningRate\n learning rate. Default value is 1e-3. \n\n\nlearningRateDecay\n learning rate decay. Default value is 0.0.\n\n\nbeta1\n first moment coefficient. Default value is 0.9.\n\n\nbeta2\n second moment coefficient. Default value is 0.999.\n\n\nEpsilon\n for numerical stability. Default value is 1e-8.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval optm = new Adam(learningRate=0.002)\ndef rosenBrock(x: Tensor[Float]): (Float, Tensor[Float]) = {\n    // (1) compute f(x)\n    val d = x.size(1)\n\n    // x1 = x(i)\n    val x1 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n    // x(i + 1) - x(i)^2\n    x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1))\n    // 100 * (x(i + 1) - x(i)^2)^2\n    x1.cmul(x1).mul(100)\n\n    // x0 = x(i)\n    val x0 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n    // 1-x(i)\n    x0.mul(-1).add(1)\n    x0.cmul(x0)\n    // 100*(x(i+1) - x(i)^2)^2 + (1-x(i))^2\n    x1.add(x0)\n\n    val fout = x1.sum()\n\n    // (2) compute f(x)/dx\n    val dxout = Tensor[Float]().resizeAs(x).zero()\n    // df(1:D-1) = - 400*x(1:D-1).*(x(2:D)-x(1:D-1).^2) - 2*(1-x(1:D-1));\n    x1.copy(x.narrow(1, 1, d - 1))\n    x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1)).cmul(x.narrow(1, 1, d - 1)).mul(-400)\n    x0.copy(x.narrow(1, 1, d - 1)).mul(-1).add(1).mul(-2)\n    x1.add(x0)\n    dxout.narrow(1, 1, d - 1).copy(x1)\n\n    // df(2:D) = df(2:D) + 200*(x(2:D)-x(1:D-1).^2);\n    x0.copy(x.narrow(1, 1, d - 1))\n    x0.cmul(x0).mul(-1).add(x.narrow(1, 2, d - 1)).mul(200)\n    dxout.narrow(1, 2, d - 1).add(x0)\n\n    (fout, dxout)\n  }  \nval x = Tensor(2).fill(0)\n\n print(optm.optimize(rosenBrock, x))\n(0.0019999996\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 2],[D@302d88d8)\n\n\n\n\nPython example:\n\n\noptim_method = Adam(learningrate=0.002)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)\n\n\n\n\n\nSGD\n\n\nScala:\n\n\nval optimMethod = SGD(learningRate= 1e-3,learningRateDecay=0.0,\n                      weightDecay=0.0,momentum=0.0,dampening=Double.MaxValue,\n                      nesterov=false,learningRateSchedule=Default(),\n                      learningRates=null,weightDecays=null)\n\n\n\n\nPython:\n\n\noptim_method = SGD(learningrate=1e-3,learningrate_decay=0.0,weightdecay=0.0,\n                   momentum=0.0,dampening=DOUBLEMAX,nesterov=False,\n                   leaningrate_schedule=None,learningrates=None,\n                   weightdecays=None,bigdl_type=\nfloat\n)\n\n\n\n\nA plain implementation of SGD which provides optimize method. After setting \noptimization method when create Optimize, Optimize will call optimization method at the end of \neach iteration.\n\n\nScala example:\n\n\nval optimMethod = new SGD[Float](learningRate= 1e-3,learningRateDecay=0.0,\n                               weightDecay=0.0,momentum=0.0,dampening=Double.MaxValue,\n                               nesterov=false,learningRateSchedule=Default(),\n                               learningRates=null,weightDecays=null)\noptimizer.setOptimMethod(optimMethod)\n\n\n\n\nPython example:\n\n\noptim_method = SGD(learningrate=1e-3,learningrate_decay=0.0,weightdecay=0.0,\n                  momentum=0.0,dampening=DOUBLEMAX,nesterov=False,\n                  leaningrate_schedule=None,learningrates=None,\n                  weightdecays=None,bigdl_type=\nfloat\n)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)\n\n\n\n\nAdadelta\n\n\nAdaDelta\n implementation for \nSGD\n \nIt has been proposed in \nADADELTA: An Adaptive Learning Rate Method\n.\nhttp://arxiv.org/abs/1212.5701.\n\n\nScala:\n\n\nval optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10)\n\n\n\n\nPython:\n\n\noptim_method = AdaDelta(decayrate = 0.9, epsilon = 1e-10)\n\n\n\n\nScala example:\n\n\noptimizer.setOptimMethod(new Adadelta(0.9, 1e-10))\n\n\n\n\n\nPython example:\n\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adadelta(0.9, 0.00001),\n    end_trigger=MaxEpoch(20),\n    batch_size=32)\n\n\n\n\nRMSprop\n\n\nAn implementation of RMSprop (Reference: http://arxiv.org/pdf/1308.0850v5.pdf, Sec 4.2)\n\n learningRate : learning rate\n\n learningRateDecaye : learning rate decay\n\n decayRatee : decayRate, also called rho\n\n Epsilone : for numerical stability\n\n\nAdamax\n\n\nAn implementation of Adamax http://arxiv.org/pdf/1412.6980.pdf\n\n\nArguments:\n\n\n\n\nlearningRate : learning rate\n\n\nbeta1 : first moment coefficient\n\n\nbeta2 : second moment coefficient\n\n\nEpsilon : for numerical stability\n\n\n\n\nReturns:\n\n\nthe new x vector and the function list {fx}, evaluated before the update\n\n\nAdagrad\n\n\nScala:\n\n\nval adagrad = new Adagrad(learningRate = 1e-3,\n                          learningRateDecay = 0.0,\n                          weightDecay = 0.0)\n\n\n\n\n\nAn implementation of Adagrad. See the original paper:\n \nhttp://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor._\nval adagrad = Adagrad(0.01, 0.0, 0.0)\n    def feval(x: Tensor[Float]): (Float, Tensor[Float]) = {\n      // (1) compute f(x)\n      val d = x.size(1)\n      // x1 = x(i)\n      val x1 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n      // x(i + 1) - x(i)^2\n      x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1))\n      // 100 * (x(i + 1) - x(i)^2)^2\n      x1.cmul(x1).mul(100)\n      // x0 = x(i)\n      val x0 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n      // 1-x(i)\n      x0.mul(-1).add(1)\n      x0.cmul(x0)\n      // 100*(x(i+1) - x(i)^2)^2 + (1-x(i))^2\n      x1.add(x0)\n      val fout = x1.sum()\n      // (2) compute f(x)/dx\n      val dxout = Tensor[Float]().resizeAs(x).zero()\n      // df(1:D-1) = - 400*x(1:D-1).*(x(2:D)-x(1:D-1).^2) - 2*(1-x(1:D-1));\n      x1.copy(x.narrow(1, 1, d - 1))\n      x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1)).cmul(x.narrow(1, 1, d - 1)).mul(-400)\n      x0.copy(x.narrow(1, 1, d - 1)).mul(-1).add(1).mul(-2)\n      x1.add(x0)\n      dxout.narrow(1, 1, d - 1).copy(x1)\n      // df(2:D) = df(2:D) + 200*(x(2:D)-x(1:D-1).^2);\n      x0.copy(x.narrow(1, 1, d - 1))\n      x0.cmul(x0).mul(-1).add(x.narrow(1, 2, d - 1)).mul(200)\n      dxout.narrow(1, 2, d - 1).add(x0)\n      (fout, dxout)\n    }\nval x = Tensor(2).fill(0)\nval config = T(\nlearningRate\n -\n 1e-1)\nfor (i \n- 1 to 10) {\n  adagrad.optimize(feval, x, config, config)\n}\nx after optimize: 0.27779138\n0.07226955\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\n\n\n\nScala:\n\n\nval optimMethod = new LBFGS(maxIter=20, maxEval=Double.MaxValue,\n                            tolFun=1e-5, tolX=1e-9, nCorrection=100,\n                            learningRate=1.0, lineSearch=None, lineSearchOptions=None)\n\n\n\n\nPython:\n\n\noptim_method = LBFGS(max_iter=20, max_eval=Double.MaxValue, \\\n                 tol_fun=1e-5, tol_x=1e-9, n_correction=100, \\\n                 learning_rate=1.0, line_search=None, line_search_options=None)\n\n\n\n\nThis implementation of L-BFGS relies on a user-provided line search function\n(state.lineSearch). If this function is not provided, then a simple learningRate\nis used to produce fixed size steps. Fixed size steps are much less costly than line\nsearches, and can be useful for stochastic problems.\n\n\nThe learning rate is used even when a line search is provided.This is also useful for\nlarge-scale stochastic problems, where opfunc is a noisy approximation of f(x). In that\ncase, the learning rate allows a reduction of confidence in the step size.\n\n\nParameters:\n\n\n \nmaxIter\n - Maximum number of iterations allowed. Default: 20\n\n \nmaxEval\n - Maximum number of function evaluations. Default: Double.MaxValue\n\n \ntolFun\n - Termination tolerance on the first-order optimality. Default: 1e-5\n\n \ntolX\n - Termination tol on progress in terms of func/param changes. Default: 1e-9\n\n \nlearningRate\n - the learning rate. Default: 1.0\n\n \nlineSearch\n - A line search function. Default: None\n* \nlineSearchOptions\n - If no line search provided, then a fixed step size is used. Default: None\n\n\nScala example:\n\n\nval optimMethod = new LBFGS(maxIter=20, maxEval=Double.MaxValue,\n                            tolFun=1e-5, tolX=1e-9, nCorrection=100,\n                            learningRate=1.0, lineSearch=None, lineSearchOptions=None)\noptimizer.setOptimMethod(optimMethod)\n\n\n\n\nPython example:\n\n\noptim_method = LBFGS(max_iter=20, max_eval=DOUBLEMAX, \\\n                 tol_fun=1e-5, tol_x=1e-9, n_correction=100, \\\n                 learning_rate=1.0, line_search=None, line_search_options=None)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "Optimization Algorithms"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optim-Methods/#adam", 
            "text": "Scala:  val optim = new Adam(learningRate=1e-3, learningRateDecay=0.0, beta1=0.9, beta2=0.999, Epsilon=1e-8)  Python:  optim = Adam(learningRate=1e-3, learningRateDecay-0.0, beta1=0.9, beta2=0.999, Epsilon=1e-8, bigdl_type= float )  An implementation of Adam optimization, first-order gradient-based optimization of stochastic  objective  functions. http://arxiv.org/pdf/1412.6980.pdf  learningRate  learning rate. Default value is 1e-3.   learningRateDecay  learning rate decay. Default value is 0.0.  beta1  first moment coefficient. Default value is 0.9.  beta2  second moment coefficient. Default value is 0.999.  Epsilon  for numerical stability. Default value is 1e-8.  Scala example:  import com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval optm = new Adam(learningRate=0.002)\ndef rosenBrock(x: Tensor[Float]): (Float, Tensor[Float]) = {\n    // (1) compute f(x)\n    val d = x.size(1)\n\n    // x1 = x(i)\n    val x1 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n    // x(i + 1) - x(i)^2\n    x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1))\n    // 100 * (x(i + 1) - x(i)^2)^2\n    x1.cmul(x1).mul(100)\n\n    // x0 = x(i)\n    val x0 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n    // 1-x(i)\n    x0.mul(-1).add(1)\n    x0.cmul(x0)\n    // 100*(x(i+1) - x(i)^2)^2 + (1-x(i))^2\n    x1.add(x0)\n\n    val fout = x1.sum()\n\n    // (2) compute f(x)/dx\n    val dxout = Tensor[Float]().resizeAs(x).zero()\n    // df(1:D-1) = - 400*x(1:D-1).*(x(2:D)-x(1:D-1).^2) - 2*(1-x(1:D-1));\n    x1.copy(x.narrow(1, 1, d - 1))\n    x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1)).cmul(x.narrow(1, 1, d - 1)).mul(-400)\n    x0.copy(x.narrow(1, 1, d - 1)).mul(-1).add(1).mul(-2)\n    x1.add(x0)\n    dxout.narrow(1, 1, d - 1).copy(x1)\n\n    // df(2:D) = df(2:D) + 200*(x(2:D)-x(1:D-1).^2);\n    x0.copy(x.narrow(1, 1, d - 1))\n    x0.cmul(x0).mul(-1).add(x.narrow(1, 2, d - 1)).mul(200)\n    dxout.narrow(1, 2, d - 1).add(x0)\n\n    (fout, dxout)\n  }  \nval x = Tensor(2).fill(0)  print(optm.optimize(rosenBrock, x))\n(0.0019999996\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 2],[D@302d88d8)  Python example:  optim_method = Adam(learningrate=0.002)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "Adam"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optim-Methods/#sgd", 
            "text": "Scala:  val optimMethod = SGD(learningRate= 1e-3,learningRateDecay=0.0,\n                      weightDecay=0.0,momentum=0.0,dampening=Double.MaxValue,\n                      nesterov=false,learningRateSchedule=Default(),\n                      learningRates=null,weightDecays=null)  Python:  optim_method = SGD(learningrate=1e-3,learningrate_decay=0.0,weightdecay=0.0,\n                   momentum=0.0,dampening=DOUBLEMAX,nesterov=False,\n                   leaningrate_schedule=None,learningrates=None,\n                   weightdecays=None,bigdl_type= float )  A plain implementation of SGD which provides optimize method. After setting \noptimization method when create Optimize, Optimize will call optimization method at the end of \neach iteration.  Scala example:  val optimMethod = new SGD[Float](learningRate= 1e-3,learningRateDecay=0.0,\n                               weightDecay=0.0,momentum=0.0,dampening=Double.MaxValue,\n                               nesterov=false,learningRateSchedule=Default(),\n                               learningRates=null,weightDecays=null)\noptimizer.setOptimMethod(optimMethod)  Python example:  optim_method = SGD(learningrate=1e-3,learningrate_decay=0.0,weightdecay=0.0,\n                  momentum=0.0,dampening=DOUBLEMAX,nesterov=False,\n                  leaningrate_schedule=None,learningrates=None,\n                  weightdecays=None,bigdl_type= float )\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "SGD"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optim-Methods/#adadelta", 
            "text": "AdaDelta  implementation for  SGD  \nIt has been proposed in  ADADELTA: An Adaptive Learning Rate Method .\nhttp://arxiv.org/abs/1212.5701.  Scala:  val optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10)  Python:  optim_method = AdaDelta(decayrate = 0.9, epsilon = 1e-10)  Scala example:  optimizer.setOptimMethod(new Adadelta(0.9, 1e-10))  Python example:  optimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adadelta(0.9, 0.00001),\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "Adadelta"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optim-Methods/#rmsprop", 
            "text": "An implementation of RMSprop (Reference: http://arxiv.org/pdf/1308.0850v5.pdf, Sec 4.2)  learningRate : learning rate  learningRateDecaye : learning rate decay  decayRatee : decayRate, also called rho  Epsilone : for numerical stability", 
            "title": "RMSprop"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optim-Methods/#adamax", 
            "text": "An implementation of Adamax http://arxiv.org/pdf/1412.6980.pdf  Arguments:   learningRate : learning rate  beta1 : first moment coefficient  beta2 : second moment coefficient  Epsilon : for numerical stability   Returns:  the new x vector and the function list {fx}, evaluated before the update", 
            "title": "Adamax"
        }, 
        {
            "location": "/APIdocs/Optimizers/Optim-Methods/#adagrad", 
            "text": "Scala:  val adagrad = new Adagrad(learningRate = 1e-3,\n                          learningRateDecay = 0.0,\n                          weightDecay = 0.0)  An implementation of Adagrad. See the original paper:\n  http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor._\nval adagrad = Adagrad(0.01, 0.0, 0.0)\n    def feval(x: Tensor[Float]): (Float, Tensor[Float]) = {\n      // (1) compute f(x)\n      val d = x.size(1)\n      // x1 = x(i)\n      val x1 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n      // x(i + 1) - x(i)^2\n      x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1))\n      // 100 * (x(i + 1) - x(i)^2)^2\n      x1.cmul(x1).mul(100)\n      // x0 = x(i)\n      val x0 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n      // 1-x(i)\n      x0.mul(-1).add(1)\n      x0.cmul(x0)\n      // 100*(x(i+1) - x(i)^2)^2 + (1-x(i))^2\n      x1.add(x0)\n      val fout = x1.sum()\n      // (2) compute f(x)/dx\n      val dxout = Tensor[Float]().resizeAs(x).zero()\n      // df(1:D-1) = - 400*x(1:D-1).*(x(2:D)-x(1:D-1).^2) - 2*(1-x(1:D-1));\n      x1.copy(x.narrow(1, 1, d - 1))\n      x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1)).cmul(x.narrow(1, 1, d - 1)).mul(-400)\n      x0.copy(x.narrow(1, 1, d - 1)).mul(-1).add(1).mul(-2)\n      x1.add(x0)\n      dxout.narrow(1, 1, d - 1).copy(x1)\n      // df(2:D) = df(2:D) + 200*(x(2:D)-x(1:D-1).^2);\n      x0.copy(x.narrow(1, 1, d - 1))\n      x0.cmul(x0).mul(-1).add(x.narrow(1, 2, d - 1)).mul(200)\n      dxout.narrow(1, 2, d - 1).add(x0)\n      (fout, dxout)\n    }\nval x = Tensor(2).fill(0)\nval config = T( learningRate  -  1e-1)\nfor (i  - 1 to 10) {\n  adagrad.optimize(feval, x, config, config)\n}\nx after optimize: 0.27779138\n0.07226955\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]  Scala:  val optimMethod = new LBFGS(maxIter=20, maxEval=Double.MaxValue,\n                            tolFun=1e-5, tolX=1e-9, nCorrection=100,\n                            learningRate=1.0, lineSearch=None, lineSearchOptions=None)  Python:  optim_method = LBFGS(max_iter=20, max_eval=Double.MaxValue, \\\n                 tol_fun=1e-5, tol_x=1e-9, n_correction=100, \\\n                 learning_rate=1.0, line_search=None, line_search_options=None)  This implementation of L-BFGS relies on a user-provided line search function\n(state.lineSearch). If this function is not provided, then a simple learningRate\nis used to produce fixed size steps. Fixed size steps are much less costly than line\nsearches, and can be useful for stochastic problems.  The learning rate is used even when a line search is provided.This is also useful for\nlarge-scale stochastic problems, where opfunc is a noisy approximation of f(x). In that\ncase, the learning rate allows a reduction of confidence in the step size.  Parameters:    maxIter  - Maximum number of iterations allowed. Default: 20   maxEval  - Maximum number of function evaluations. Default: Double.MaxValue   tolFun  - Termination tolerance on the first-order optimality. Default: 1e-5   tolX  - Termination tol on progress in terms of func/param changes. Default: 1e-9   learningRate  - the learning rate. Default: 1.0   lineSearch  - A line search function. Default: None\n*  lineSearchOptions  - If no line search provided, then a fixed step size is used. Default: None  Scala example:  val optimMethod = new LBFGS(maxIter=20, maxEval=Double.MaxValue,\n                            tolFun=1e-5, tolX=1e-9, nCorrection=100,\n                            learningRate=1.0, lineSearch=None, lineSearchOptions=None)\noptimizer.setOptimMethod(optimMethod)  Python example:  optim_method = LBFGS(max_iter=20, max_eval=DOUBLEMAX, \\\n                 tol_fun=1e-5, tol_x=1e-9, n_correction=100, \\\n                 learning_rate=1.0, line_search=None, line_search_options=None)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "Adagrad"
        }, 
        {
            "location": "/APIdocs/Triggers/", 
            "text": "A trigger specifies a timespot or several timespots during training,\nand a corresponding action will be taken when the timespot(s)\ns reached.\n\n\n\n\nEvery Epoch\n\n\nScala:\n\n\n val trigger = Trigger.everyEpoch\n\n\n\n\nPython:\n\n\n trigger = EveryEpoch()\n\n\n\n\nA trigger that triggers an action when each epoch finishs.\n   Could be used as trigger in \nsetValidation\n and \nsetCheckpoint\n\n   in Optimizer, and also in \nTrainSummary.setSummaryTrigger\n.\n\n\n\n\nSeveral Iteration\n\n\nScala:\n\n\n val trigger = Trigger.severalIteration(n)\n\n\n\n\nPython:\n\n\n trigger = SeveralIteration(n)\n\n\n\n\nA trigger that triggers an action every \nn\n iterations.\n Could be used as trigger in \nsetValidation\n and \nsetCheckpoint\n \n in Optimizer, and also in \nTrainSummary.setSummaryTrigger\n.\n\n\n\n\nMax Epoch\n\n\nScala:\n\n\n val trigger = Trigger.maxEpoch(max)\n\n\n\n\nPython:\n\n\n trigger = MaxEpoch(max)\n\n\n\n\nA trigger that triggers an action when training reaches\n  the number of epochs specified by \"max\".\n  Usually used in \nOptimizer.setEndWhen\n.\n\n\n\n\nMax Iteration\n\n\nScala:\n\n\n val trigger = Trigger.maxIteration(max)\n\n\n\n\nPython:\n\n\n trigger = MaxIteration(max)\n\n\n\n\nA trigger that triggers an action when training reaches\n  the number of iterations specified by \"max\".\n  Usually used in \nOptimizer.setEndWhen\n.\n\n\n\n\nMax Score\n\n\nScala:\n\n\n val trigger = Trigger.maxScore(max)\n\n\n\n\nPython:\n\n\n trigger = MaxScore(max)\n\n\n\n\nA trigger that triggers an action when validation score\n larger than \"max\" score\n\n\n\n\nMin Loss\n\n\nScala:\n\n\n val trigger = Trigger.minLoss(min)\n\n\n\n\nPython:\n\n\n trigger = MinLoss(min)\n\n\n\n\nA trigger that triggers an action when training loss\n less than \"min\" loss", 
            "title": "Triggers"
        }, 
        {
            "location": "/APIdocs/Triggers/#every-epoch", 
            "text": "Scala:   val trigger = Trigger.everyEpoch  Python:   trigger = EveryEpoch()  A trigger that triggers an action when each epoch finishs.\n   Could be used as trigger in  setValidation  and  setCheckpoint \n   in Optimizer, and also in  TrainSummary.setSummaryTrigger .", 
            "title": "Every Epoch"
        }, 
        {
            "location": "/APIdocs/Triggers/#several-iteration", 
            "text": "Scala:   val trigger = Trigger.severalIteration(n)  Python:   trigger = SeveralIteration(n)  A trigger that triggers an action every  n  iterations.\n Could be used as trigger in  setValidation  and  setCheckpoint  \n in Optimizer, and also in  TrainSummary.setSummaryTrigger .", 
            "title": "Several Iteration"
        }, 
        {
            "location": "/APIdocs/Triggers/#max-epoch", 
            "text": "Scala:   val trigger = Trigger.maxEpoch(max)  Python:   trigger = MaxEpoch(max)  A trigger that triggers an action when training reaches\n  the number of epochs specified by \"max\".\n  Usually used in  Optimizer.setEndWhen .", 
            "title": "Max Epoch"
        }, 
        {
            "location": "/APIdocs/Triggers/#max-iteration", 
            "text": "Scala:   val trigger = Trigger.maxIteration(max)  Python:   trigger = MaxIteration(max)  A trigger that triggers an action when training reaches\n  the number of iterations specified by \"max\".\n  Usually used in  Optimizer.setEndWhen .", 
            "title": "Max Iteration"
        }, 
        {
            "location": "/APIdocs/Triggers/#max-score", 
            "text": "Scala:   val trigger = Trigger.maxScore(max)  Python:   trigger = MaxScore(max)  A trigger that triggers an action when validation score\n larger than \"max\" score", 
            "title": "Max Score"
        }, 
        {
            "location": "/APIdocs/Triggers/#min-loss", 
            "text": "Scala:   val trigger = Trigger.minLoss(min)  Python:   trigger = MinLoss(min)  A trigger that triggers an action when training loss\n less than \"min\" loss", 
            "title": "Min Loss"
        }, 
        {
            "location": "/APIdocs/Metrics/", 
            "text": "ValidationMethod is a method to validate the model during model trainning or evaluation.\nThe trait can be extended by user-defined method. Now we have defined Top1Accuracy, Top5Accuracy, Loss.\n\n\n\n\nLoss\n\n\nScala:\n\n\nval loss = new Loss(criterion)\n\n\n\n\nPython:\n\n\nloss = Loss(cri)\n\n\n\n\nCalculate loss of output and target with criterion. The default criterion is ClassNLLCriterion.\n\n\n\n\nTop1Accuracy\n\n\nCaculate the percentage that output's max probability index equals target.\n\n\nScala:\n\n\nval top1accuracy = new Top1Accuracy()\n\n\n\n\nPython:\n\n\ntop1accuracy = Top1Accuracy()\n\n\n\n\n\n\nTop5Accuracy\n\n\nCaculate the percentage that target in output's top5 probability indexes.\n\n\nScala:\n\n\nval top5accuracy = new Top5Accuracy()\n\n\n\n\nPython:\n\n\ntop5accuracy = Top5Accuracy()\n\n\n\n\n\n\nScala Example\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.utils.Engine\nimport org.apache.spark.SparkContext\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.models.lenet.LeNet5\n\nval conf = Engine.createSparkConf()\nval sc = new SparkContext(conf)\nEngine.init\n\nval data = new Array[Sample[Float]](10)\nvar i = 0\nwhile (i \n data.length) {\n  val input = Tensor[Float](28, 28).fill(0.8f)\n  val label = Tensor[Float](1).fill(1.0f)\n  data(i) = Sample(input, label)\n  i += 1\n}\nval model = LeNet5(classNum = 10)\nval dataSet = sc.parallelize(data, 4)\n\nval result = model.evaluate(dataSet, Array(new Top1Accuracy[Float](), new Top5Accuracy[Float](), new Loss[Float]()))\n\n\n\n\nresult is\n\n\nresult: Array[(com.intel.analytics.bigdl.optim.ValidationResult, com.intel.analytics.bigdl.optim.ValidationMethod[Float])] = Array((Accuracy(correct: 0, count: 10, accuracy: 0.0),Top1Accuracy), (Accuracy(correct: 10, count: 10, accuracy: 1.0),Top5Accuracy), ((Loss: 9.21948, count: 4, Average Loss: 2.30487),Loss))\n\n\n\n\nPython Example:\n\n\nfrom pyspark.context import SparkContext\nfrom bigdl.util.common import *\nfrom bigdl.nn.layer import *\nfrom bigdl.optim.optimizer import *\n\nsc = get_spark_context(conf=create_spark_conf())\ninit_engine()\n\ndata_len = 10\nbatch_size = 8\nFEATURES_DIM = 4\n\ndef gen_rand_sample():\n    features = np.random.uniform(0, 1, (FEATURES_DIM))\n    label = features.sum() + 0.4\n    return Sample.from_ndarray(features, label)\n\ntrainingData = sc.parallelize(range(0, data_len)).map(\n    lambda i: gen_rand_sample())\n\nmodel = Sequential()\nmodel.add(Linear(4, 5))\ntest_results = model.test(trainingData, batch_size, [Top1Accuracy(), Top5Accuracy(), Loss()])\n\n\n\n\nresult is\n\n\n print test_results[0]\nTest result: 0.0, total_num: 10, method: Top1Accuracy\n\n print test_results[1]\nTest result: 0.0, total_num: 10, method: Top5Accuracy\n\n print test_results[2]\nTest result: 0.116546951234, total_num: 10, method: Loss", 
            "title": "Metrics"
        }, 
        {
            "location": "/APIdocs/Metrics/#loss", 
            "text": "Scala:  val loss = new Loss(criterion)  Python:  loss = Loss(cri)  Calculate loss of output and target with criterion. The default criterion is ClassNLLCriterion.", 
            "title": "Loss"
        }, 
        {
            "location": "/APIdocs/Metrics/#top1accuracy", 
            "text": "Caculate the percentage that output's max probability index equals target.  Scala:  val top1accuracy = new Top1Accuracy()  Python:  top1accuracy = Top1Accuracy()", 
            "title": "Top1Accuracy"
        }, 
        {
            "location": "/APIdocs/Metrics/#top5accuracy", 
            "text": "Caculate the percentage that target in output's top5 probability indexes.  Scala:  val top5accuracy = new Top5Accuracy()  Python:  top5accuracy = Top5Accuracy()", 
            "title": "Top5Accuracy"
        }, 
        {
            "location": "/APIdocs/Metrics/#scala-example", 
            "text": "import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.utils.Engine\nimport org.apache.spark.SparkContext\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.models.lenet.LeNet5\n\nval conf = Engine.createSparkConf()\nval sc = new SparkContext(conf)\nEngine.init\n\nval data = new Array[Sample[Float]](10)\nvar i = 0\nwhile (i   data.length) {\n  val input = Tensor[Float](28, 28).fill(0.8f)\n  val label = Tensor[Float](1).fill(1.0f)\n  data(i) = Sample(input, label)\n  i += 1\n}\nval model = LeNet5(classNum = 10)\nval dataSet = sc.parallelize(data, 4)\n\nval result = model.evaluate(dataSet, Array(new Top1Accuracy[Float](), new Top5Accuracy[Float](), new Loss[Float]()))  result is  result: Array[(com.intel.analytics.bigdl.optim.ValidationResult, com.intel.analytics.bigdl.optim.ValidationMethod[Float])] = Array((Accuracy(correct: 0, count: 10, accuracy: 0.0),Top1Accuracy), (Accuracy(correct: 10, count: 10, accuracy: 1.0),Top5Accuracy), ((Loss: 9.21948, count: 4, Average Loss: 2.30487),Loss))", 
            "title": "Scala Example"
        }, 
        {
            "location": "/APIdocs/Metrics/#python-example", 
            "text": "from pyspark.context import SparkContext\nfrom bigdl.util.common import *\nfrom bigdl.nn.layer import *\nfrom bigdl.optim.optimizer import *\n\nsc = get_spark_context(conf=create_spark_conf())\ninit_engine()\n\ndata_len = 10\nbatch_size = 8\nFEATURES_DIM = 4\n\ndef gen_rand_sample():\n    features = np.random.uniform(0, 1, (FEATURES_DIM))\n    label = features.sum() + 0.4\n    return Sample.from_ndarray(features, label)\n\ntrainingData = sc.parallelize(range(0, data_len)).map(\n    lambda i: gen_rand_sample())\n\nmodel = Sequential()\nmodel.add(Linear(4, 5))\ntest_results = model.test(trainingData, batch_size, [Top1Accuracy(), Top5Accuracy(), Loss()])  result is   print test_results[0]\nTest result: 0.0, total_num: 10, method: Top1Accuracy  print test_results[1]\nTest result: 0.0, total_num: 10, method: Top5Accuracy  print test_results[2]\nTest result: 0.116546951234, total_num: 10, method: Loss", 
            "title": "Python Example:"
        }, 
        {
            "location": "/APIdocs/scaladoc/", 
            "text": "javadoc", 
            "title": "Scala Docs"
        }, 
        {
            "location": "/APIdocs/scaladoc/#javadoc", 
            "text": "", 
            "title": "javadoc"
        }, 
        {
            "location": "/APIdocs/python-api-doc/", 
            "text": "pythonapidoc", 
            "title": "Python API Docs"
        }, 
        {
            "location": "/APIdocs/python-api-doc/#pythonapidoc", 
            "text": "", 
            "title": "pythonapidoc"
        }, 
        {
            "location": "/powered-by/", 
            "text": "Intel\u2019s BigDL on Databricks\n\n\nUse BigDL on AZure HDInsight\n\n\nA more detailed post for \nHow to use BigDL on Apache Spark for Azure HDInsight\n\n\n\n\n\n\nBigDL on AliCloud E-MapReduce (in Chinese)\n\n\nRunning BigDL, Deep Learning for Apache Spark, on AWS\n\n\nBigDL on CDH and Cloudera Data Science Workbench\n\n\nRunning BigDL on Microsoft Data Science Virtual Machine\n\n\nUsing Apache Spark with Intel BigDL on Mesosphere DC/OS\n by Lightbend", 
            "title": "Powered by"
        }, 
        {
            "location": "/known-issues/", 
            "text": "Currently, BigDL uses synchronous mini-batch SGD in model training. The mini-batch size is expected to be a multiple of \ntotal cores\n used in the job.\n\n\n\n\n\n\nYou may observe very poor performance when running BigDL for Spark 2.0 with Java 7; it is highly recommended to use Java 8 when building and running BigDL for Spark 2.0.\n\n\n\n\n\n\nOn Spark 2.0, please use default Java serializer instead of Kryo because of \nKryo Issue 341\n. The issue has been fixed in Kryo 4.0. However, Spark 2.0 uses Kryo 3.0.3. Spark 1.5 and 1.6 do not have this problem.\n\n\n\n\n\n\nOn CentOS 6 and 7, please increase the max user processes to a larger value (e.g., 514585); otherwise, you may see errors like \"unable to create new native thread\".\n\n\n\n\n\n\nCurrently, BigDL will load all the training and validation data into memory during training. You may encounter errors if it runs out of memory.\n\n\n\n\n\n\nIf you meet the program stuck after \nSave model...\n on Mesos, check the \nspark.driver.memory\n and increase the value. Eg, VGG on Cifar10 may need 20G+.\n\n\n\n\n\n\nIf you meet \ncan't find executor core number\n on Mesos, you should pass the executor cores through \n--conf spark.executor.cores=xxx", 
            "title": "Known Issues"
        }
    ]
}